<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="CS224W-Machine Learning with Graphs, JackHCC">
    <meta name="description" content="Machine Learning with Graphs Notes">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <title>CS224W-Machine Learning with Graphs | JackHCC</title>
    <link rel="icon" type="image/png" href="https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/medias/favicon.png">

    <link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/libs/awesome/css/all.css">
    <link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/libs/materialize/materialize.min.css">
    <link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/libs/aos/aos.css">
    <link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/libs/animate/animate.min.css">
    <link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/libs/lightGallery/css/lightgallery.min.css">
    <link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/css/matery.css">
    <link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/css/my.css">
    
    <script src="https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/libs/jquery/jquery.min.js"></script>
    
<meta name="generator" content="Hexo 4.2.0"><link rel="alternate" href="/atom.xml" title="JackHCC" type="application/atom+xml">
<link rel="stylesheet" href="/css/prism-hopscotch.css" type="text/css">
<link rel="stylesheet" href="/css/prism-line-numbers.css" type="text/css"></head>


<body>
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper head-container">
            <div class="brand-logo">
                <a href="/" class="waves-effect waves-light">
                    
                    <img src="/images/loading.gif" data-original="https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/medias/me.jpg" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">JackHCC</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>首页</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>标签</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>分类</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>归档</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="" class="waves-effect waves-light">

      
      <i class="fas fa-list" style="zoom: 0.6;"></i>
      
      <span>Tools</span>
      <i class="fas fa-chevron-down" aria-hidden="true" style="zoom: 0.6;"></i>
    </a>
    <ul class="sub-nav menus_item_child ">
      
      <li>
        <a href="https://creativecc.cn/" target="_blank" rel="noopener">
          
          <i class="fas fa-book" style="margin-top: -20px; zoom: 0.6;"></i>
          
          <span>Creative工具导航</span>
        </a>
      </li>
      
      <li>
        <a href="https://blog.creativecc.cn/Arxiv-NLP-Reporter/" target="_blank" rel="noopener">
          
          <i class="fas fa-film" style="margin-top: -20px; zoom: 0.6;"></i>
          
          <span>NLP每日论文</span>
        </a>
      </li>
      
      <li>
        <a href="http://chat.creativecc.cn/" target="_blank" rel="noopener">
          
          <i class="fas fa-music" style="margin-top: -20px; zoom: 0.6;"></i>
          
          <span>RocketChat聊天室</span>
        </a>
      </li>
      
      <li>
        <a href="/contact">
          
          <i class="fas fa-comments" style="margin-top: -20px; zoom: 0.6;"></i>
          
          <span>Contact留言板</span>
        </a>
      </li>
      
    </ul>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/friends" class="waves-effect waves-light">
      
      <i class="fas fa-address-book" style="zoom: 0.6;"></i>
      
      <span>友情链接</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/about" class="waves-effect waves-light">
      
      <i class="fas fa-user-circle" style="zoom: 0.6;"></i>
      
      <span>关于</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="搜索" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>

<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/images/loading.gif" data-original="https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/medias/me.jpg" class="logo-img circle responsive-img">
        
        <div class="logo-name">JackHCC</div>
        <div class="logo-desc">
            
            Make the world betterrrr!!!
            
        </div>
    </div>

    

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			首页
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			标签
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			分类
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			归档
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="javascript:;">
			
				<i class="fa-fw fas fa-list"></i>
			
			Tools
			<span class="m-icon"><i class="fas fa-chevron-right"></i></span>
		</a>
            <ul  style="background:  ;" >
              
                <li>   
				
                  <a href="https://creativecc.cn/ " target="_blank" rel="noopener" style="margin-left:75px";>
				  
				   <i class="fa fas fa-book" style="position: absolute;left:50px" ></i>
			      
		          <span>Creative工具导航</span>
                  </a>
                </li>
              
                <li>   
				
                  <a href="https://blog.creativecc.cn/Arxiv-NLP-Reporter/ " target="_blank" rel="noopener" style="margin-left:75px";>
				  
				   <i class="fa fas fa-film" style="position: absolute;left:50px" ></i>
			      
		          <span>NLP每日论文</span>
                  </a>
                </li>
              
                <li>   
				
                  <a href="http://chat.creativecc.cn/ " target="_blank" rel="noopener" style="margin-left:75px";>
				  
				   <i class="fa fas fa-music" style="position: absolute;left:50px" ></i>
			      
		          <span>RocketChat聊天室</span>
                  </a>
                </li>
              
                <li>   
				
                  <a href="/contact " style="margin-left:75px";>
				  
				   <i class="fa fas fa-comments" style="position: absolute;left:50px" ></i>
			      
		          <span>Contact留言板</span>
                  </a>
                </li>
               
            </ul>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/friends" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-address-book"></i>
			
			友情链接
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/about" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-user-circle"></i>
			
			关于
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/JackHCC/JackHCC.github.io" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>

        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/JackHCC/JackHCC.github.io" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    
<script src="https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/libs/cryptojs/crypto-js.min.js"></script>
<script>
    (function() {
        let pwd = '';
        if (pwd && pwd.length > 0) {
            if (pwd !== CryptoJS.SHA256(prompt('请输入访问本文章的密码')).toString(CryptoJS.enc.Hex)) {
                alert('密码错误，将返回主页！');
                location.href = '/';
            }
        }
    })();
</script>




<div class="bg-cover pd-header post-cover" style="background-image: url('https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/medias/featureimages/0.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">CS224W-Machine Learning with Graphs</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/libs/tocbot/tocbot.css">
<style>
    #articleContent h1::before,
    #articleContent h2::before,
    #articleContent h3::before,
    #articleContent h4::before,
    #articleContent h5::before,
    #articleContent h6::before {
        display: block;
        content: " ";
        height: 100px;
        margin-top: -100px;
        visibility: hidden;
    }

    #articleContent :focus {
        outline: none;
    }

    .toc-fixed {
        position: fixed;
        top: 64px;
    }

    .toc-widget {
        width: 345px;
        padding-left: 20px;
    }

    .toc-widget .toc-title {
        margin: 35px 0 15px 0;
        padding-left: 17px;
        font-size: 1.5rem;
        font-weight: bold;
        line-height: 1.5rem;
    }

    .toc-widget ol {
        padding: 0;
        list-style: none;
    }

    #toc-content {
        height: calc(100vh - 250px);
        overflow: auto;
    }

    #toc-content ol {
        padding-left: 10px;
    }

    #toc-content ol li {
        padding-left: 10px;
    }

    #toc-content .toc-link:hover {
        color: #42b983;
        font-weight: 700;
        text-decoration: underline;
    }

    #toc-content .toc-link::before {
        background-color: transparent;
        max-height: 25px;
    }

    #toc-content .is-active-link {
        color: #42b983;
    }

    #toc-content .is-active-link::before {
        background-color: #42b983;
    }

    #floating-toc-btn {
        position: fixed;
        right: 30px;
        bottom: 146px;
        padding-top: 15px;
        margin-bottom: 0;
        z-index: 998;
    }

    #floating-toc-btn .btn-floating {
        width: 48px;
        height: 48px;
    }

    #floating-toc-btn .btn-floating i {
        line-height: 48px;
        font-size: 1.4rem;
    }
</style>
<div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- 文章内容详情 -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/tags/Lesson/">
                                <span class="chip bg-color">Lesson</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/categories/Deep-Learning/" class="post-category">
                                Deep Learning
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>发布日期:&nbsp;&nbsp;
                    2021-11-12
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>更新日期:&nbsp;&nbsp;
                    2021-11-25
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>文章字数:&nbsp;&nbsp;
                    15.8k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>阅读时长:&nbsp;&nbsp;
                    98 分
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>阅读次数:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>

        </div>
        <hr class="clearfix">
        <div class="card-content article-card-content">
            <div id="articleContent">
                <p><a href="http://web.stanford.edu/class/cs224w/" target="_blank" rel="noopener">CS224W | Home (stanford.edu)</a></p>
<h1 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h1><h2 id="Machine-Learning-with-Graphs"><a href="#Machine-Learning-with-Graphs" class="headerlink" title="Machine Learning with Graphs"></a>Machine Learning with Graphs</h2><p><img src="/images/loading.gif" data-original="../images/ML/image-20211114150408195.png" alt=""></p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114150422199.png" alt=""></p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114150432882.png" alt=""></p>
<h3 id="Why-is-Graph-Deep-Learning-Hard"><a href="#Why-is-Graph-Deep-Learning-Hard" class="headerlink" title="Why is Graph Deep Learning Hard?"></a>Why is Graph Deep Learning Hard?</h3><ul>
<li>Networks are complex<ul>
<li>Arbitrary size and complex topological structure (i.e., no spatial locality like grids)</li>
<li>No fixed node ordering or reference point </li>
<li>Often dynamic and have multimodal features</li>
</ul>
</li>
</ul>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114150633660.png" alt=""></p>
<h3 id="Deep-Learning-in-Graphs"><a href="#Deep-Learning-in-Graphs" class="headerlink" title="Deep Learning in Graphs"></a>Deep Learning in Graphs</h3><p><img src="/images/loading.gif" data-original="../images/ML/image-20211114150708217.png" alt=""></p>
<h3 id="Representation-Learning"><a href="#Representation-Learning" class="headerlink" title="Representation Learning"></a>Representation Learning</h3><p>(Supervised) Machine Learning Lifecycle:  This feature, that feature. Every single time!</p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114151141340.png" alt=""></p>
<p>Map nodes to d-dimensional  embeddings such that similar nodes in  the network are embedded close  together</p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114151205981.png" alt=""></p>
<h3 id="Course-Outline"><a href="#Course-Outline" class="headerlink" title="Course Outline"></a>Course Outline</h3><p>We are going to cover various topics in Machine  Learning and Representation Learning for graph  structured data: </p>
<ul>
<li>Traditional methods: Graphlets, Graph Kernels </li>
<li>Methods for node embeddings: DeepWalk, Node2Vec</li>
<li>Graph Neural Networks: GCN, GraphSAGE, GAT,  Theory of GNNs </li>
<li>Knowledge graphs and reasoning: TransE, BetaE </li>
<li>Deep generative models for graphs: GraphRNN </li>
<li>Applications to Biomedicine, Science, Industry</li>
</ul>
<h2 id="Applications-of-Graph-ML"><a href="#Applications-of-Graph-ML" class="headerlink" title="Applications of Graph ML"></a>Applications of Graph ML</h2><h3 id="Different-Types-of-Tasks"><a href="#Different-Types-of-Tasks" class="headerlink" title="Different Types of Tasks"></a>Different Types of Tasks</h3><p><img src="/images/loading.gif" data-original="../images/ML/image-20211114151422981.png" alt=""></p>
<h3 id="Classic-Graph-ML-Tasks"><a href="#Classic-Graph-ML-Tasks" class="headerlink" title="Classic Graph ML Tasks"></a>Classic Graph ML Tasks</h3><ul>
<li>Node classification: Predict a property of a node <ul>
<li>Example: Categorize online users / items </li>
</ul>
</li>
<li>Link prediction: Predict whether there are missing  links between two nodes <ul>
<li>Example: Knowledge graph completion </li>
</ul>
</li>
<li>Graph classification: Categorize different graphs <ul>
<li>Example: Molecule property prediction </li>
</ul>
</li>
<li>Clustering: Detect if nodes form a community <ul>
<li>Example: Social circle detection </li>
</ul>
</li>
<li>Other tasks: <ul>
<li>Graph generation: Drug discovery </li>
<li>Graph evolution: Physical simulation</li>
</ul>
</li>
</ul>
<h2 id="Node-level-ML-Tasks"><a href="#Node-level-ML-Tasks" class="headerlink" title="Node-level ML Tasks"></a>Node-level ML Tasks</h2><h3 id="Protein-Folding"><a href="#Protein-Folding" class="headerlink" title="Protein Folding"></a>Protein Folding</h3><p><strong>A protein chain acquires its native 3D structure</strong></p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114151653238.png" alt=""></p>
<p><strong>The Protein Folding Problem</strong></p>
<p>Computationally predict a protein’s 3D structure  based solely on its amino acid sequence</p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114151741995.png" alt=""></p>
<h3 id="Alphafold-Impact"><a href="#Alphafold-Impact" class="headerlink" title="Alphafold: Impact"></a>Alphafold: Impact</h3><ul>
<li>Key idea: “Spatial graph” <ul>
<li>Nodes: Amino acids in a protein sequence </li>
<li>Edges: Proximity between amino acids (residues)</li>
</ul>
</li>
</ul>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114151833311.png" alt=""></p>
<h2 id="Edge-level-ML-Tasks"><a href="#Edge-level-ML-Tasks" class="headerlink" title="Edge-level ML Tasks"></a>Edge-level ML Tasks</h2><h3 id="Recommender-Systems"><a href="#Recommender-Systems" class="headerlink" title="Recommender Systems"></a>Recommender Systems</h3><ul>
<li>Users interacts with items <ul>
<li>Watch movies, buy merchandise, listen to music </li>
<li>Nodes: Users and items </li>
<li>Edges: User-item interactions </li>
</ul>
</li>
<li>Goal: Recommend items users might like</li>
</ul>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114151940591.png" alt=""></p>
<h3 id="Pinsage-Graph-based-Recommender"><a href="#Pinsage-Graph-based-Recommender" class="headerlink" title="Pinsage: Graph-based Recommender"></a>Pinsage: Graph-based Recommender</h3><p><a href="https://arxiv.org/pdf/1806.01973.pdf" target="_blank" rel="noopener">Ying et al., Graph Convolutional Neural Networks for Web-Scale Recommender Systems, KDD 2018</a></p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114152019114.png" alt=""></p>
<h3 id="Drug-Side-Effects"><a href="#Drug-Side-Effects" class="headerlink" title="Drug Side Effects"></a>Drug Side Effects</h3><ul>
<li>Many patients take multiple drugs to treat  complex or co-existing diseases:<ul>
<li>46% of people ages 70-79 take more than 5 drugs </li>
<li>Many patients take more than 20 drugs to treat  heart disease, depression, insomnia, etc.</li>
</ul>
</li>
<li>Task: Given a pair of drugs predict  adverse side effects</li>
</ul>
<h3 id="Biomedical-Graph-Link-Prediction"><a href="#Biomedical-Graph-Link-Prediction" class="headerlink" title="Biomedical Graph Link Prediction"></a>Biomedical Graph Link Prediction</h3><p><a href="https://arxiv.org/pdf/1802.00543.pdf" target="_blank" rel="noopener">Zitnik et al., Modeling Polypharmacy Side Effects with Graph Convolutional Networks, Bioinformatics 2018</a></p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114152134532.png" alt=""></p>
<h2 id="Subgraph-level-ML-Tasks"><a href="#Subgraph-level-ML-Tasks" class="headerlink" title="Subgraph-level ML Tasks"></a>Subgraph-level ML Tasks</h2><h3 id="Traffic-Prediction"><a href="#Traffic-Prediction" class="headerlink" title="Traffic Prediction"></a>Traffic Prediction</h3><p><strong>Road Network as a Graph</strong></p>
<ul>
<li>Nodes: Road segments </li>
<li>Edges: Connectivity between road segments </li>
<li>Prediction: Time of Arrival (ETA)</li>
</ul>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114152251501.png" alt=""></p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114152307879.png" alt=""></p>
<h2 id="Graph-level-ML-Tasks"><a href="#Graph-level-ML-Tasks" class="headerlink" title="Graph-level ML Tasks"></a>Graph-level ML Tasks</h2><h3 id="Drug-Discovery"><a href="#Drug-Discovery" class="headerlink" title="Drug Discovery"></a>Drug Discovery</h3><ul>
<li>Antibiotics are small molecular graphs <ul>
<li>Nodes: Atoms </li>
<li>Edges: Chemical bonds</li>
</ul>
</li>
</ul>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114152411240.png" alt=""></p>
<p><a href="https://www.mdpi.com/2079-6382/3/2/128" target="_blank" rel="noopener">Konaklieva, Monika I. “Molecular targets of β-lactam-based antimicrobials:  beyond the usual suspects.” Antibiotics 3.2 (2014): 128-142.</a></p>
<h3 id="Deep-Learning-for-Antibiotic-Discovery"><a href="#Deep-Learning-for-Antibiotic-Discovery" class="headerlink" title="Deep Learning for Antibiotic Discovery"></a>Deep Learning for Antibiotic Discovery</h3><p><a href="https://www.sciencedirect.com/science/article/pii/S0092867420301021" target="_blank" rel="noopener">Stokeset al., A Deep Learning Approach to Antibiotic Discovery, Cell 2020</a></p>
<ul>
<li>A Graph Neural Network graph classification model </li>
<li>Predict promising molecules from a pool of candidates</li>
</ul>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114152915938.png" alt=""></p>
<h3 id="Molecule-Generation-Optimization"><a href="#Molecule-Generation-Optimization" class="headerlink" title="Molecule Generation/Optimization"></a>Molecule Generation/Optimization</h3><p><a href="https://arxiv.org/pdf/1806.02473.pdf" target="_blank" rel="noopener">Youet al., Graph Convolutional Policy Network for Goal-Directed Molecular Graph Generation, NeurIPS 2018</a></p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114152955374.png" alt=""></p>
<h3 id="Physics-Simulation"><a href="#Physics-Simulation" class="headerlink" title="Physics Simulation"></a>Physics Simulation</h3><p><a href="https://arxiv.org/pdf/2002.09405.pdf" target="_blank" rel="noopener">Sanchez-Gonzalez et al., Learning to simulate complex physics with graph networks, ICML 2020</a></p>
<ul>
<li>Physical simulation as a graph: <ul>
<li>Nodes: Particles</li>
<li>Edges: Interaction between particles</li>
</ul>
</li>
</ul>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114153108274.png" alt=""></p>
<h4 id="Simulation-Learning-Framework"><a href="#Simulation-Learning-Framework" class="headerlink" title="Simulation Learning Framework"></a>Simulation Learning Framework</h4><p>A graph evolution task: </p>
<ul>
<li>Goal: Predict how a graph will evolve over</li>
</ul>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114153212413.png" alt=""></p>
<h2 id="Choice-of-Graph-Representation"><a href="#Choice-of-Graph-Representation" class="headerlink" title="Choice of Graph Representation"></a>Choice of Graph Representation</h2><h3 id="Components-of-a-Network"><a href="#Components-of-a-Network" class="headerlink" title="Components of a Network"></a>Components of a Network</h3><p><img src="/images/loading.gif" data-original="../images/ML/image-20211114153253676.png" alt=""></p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114153319772.png" alt=""></p>
<h3 id="Choosing-a-Proper-Representation"><a href="#Choosing-a-Proper-Representation" class="headerlink" title="Choosing a Proper Representation"></a>Choosing a Proper Representation</h3><ul>
<li>If you connect individuals that work  with each other, you will explore a  professional network </li>
<li>If you connect those that have a  sexual relationship, you will be  exploring sexual networks </li>
<li>If you connect scientific papers that cite each other, you will be studying the citation network</li>
<li>If you connect all papers with the same word in the title,  what will you be exploring? It is a network, nevertheless</li>
</ul>
<h3 id="How-do-you-define-a-graph"><a href="#How-do-you-define-a-graph" class="headerlink" title="How do you define a graph"></a>How do you define a graph</h3><ul>
<li>How to build a graph: <ul>
<li>What are nodes? </li>
<li>What are edges? </li>
</ul>
</li>
<li>Choice of the proper network representation  of a given domain/problem determines our  ability to use networks successfully: <ul>
<li>In some cases, there is a unique, unambiguous  representation</li>
<li>In other cases, the representation is by no means unique </li>
<li>The way you assign links will determine the nature  of the question you can study</li>
</ul>
</li>
</ul>
<h3 id="Directed-vs-Undirected-Graphs"><a href="#Directed-vs-Undirected-Graphs" class="headerlink" title="Directed vs Undirected Graphs"></a>Directed vs Undirected Graphs</h3><p><img src="/images/loading.gif" data-original="../images/ML/image-20211114153516654.png" alt=""></p>
<h3 id="Heterogeneous-Graphs"><a href="#Heterogeneous-Graphs" class="headerlink" title="Heterogeneous Graphs"></a>Heterogeneous Graphs</h3><p><img src="/images/loading.gif" data-original="../images/ML/image-20211114153544194.png" alt=""></p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114153559429.png" alt=""></p>
<h3 id="Node-Degrees"><a href="#Node-Degrees" class="headerlink" title="Node Degrees"></a>Node Degrees</h3><p><img src="/images/loading.gif" data-original="../images/ML/image-20211114153620904.png" alt=""></p>
<h3 id="Bipartite-Graph"><a href="#Bipartite-Graph" class="headerlink" title="Bipartite Graph"></a>Bipartite Graph</h3><ul>
<li>Bipartite graph is a graph whose nodes can  be divided into two disjoint sets U and V such that  every link connects a node in U to one in V; that is,  U and V are independent sets </li>
<li>Examples: <ul>
<li>Authors-to-Papers (they authored) </li>
<li>Actors-to-Movies (they appeared in) </li>
<li>Users-to-Movies (they rated) </li>
<li>Recipes-to-Ingredients (they contain) </li>
</ul>
</li>
<li>“Folded” networks: <ul>
<li>Author collaboration networks </li>
<li>Movie co-rating networks</li>
</ul>
</li>
</ul>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114153743707.png" alt=""></p>
<h3 id="FoldedProjected-Bipartite-Graphs"><a href="#FoldedProjected-Bipartite-Graphs" class="headerlink" title="FoldedProjected Bipartite Graphs"></a>FoldedProjected Bipartite Graphs</h3><p><img src="/images/loading.gif" data-original="../images/ML/image-20211114153806330.png" alt=""></p>
<h3 id="Representing-Graphs-Adjacency-Matrix"><a href="#Representing-Graphs-Adjacency-Matrix" class="headerlink" title="Representing Graphs: Adjacency Matrix"></a>Representing Graphs: Adjacency Matrix</h3><p><img src="/images/loading.gif" data-original="../images/ML/image-20211114153828291.png" alt=""></p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114153842858.png" alt=""></p>
<h3 id="Networks-are-Sparse-Graphs"><a href="#Networks-are-Sparse-Graphs" class="headerlink" title="Networks are Sparse Graphs"></a>Networks are Sparse Graphs</h3><p><img src="/images/loading.gif" data-original="../images/ML/image-20211114153938780.png" alt=""></p>
<h3 id="Representing-Graphs-Edge-list"><a href="#Representing-Graphs-Edge-list" class="headerlink" title="Representing Graphs: Edge list"></a>Representing Graphs: Edge list</h3><p><img src="/images/loading.gif" data-original="../images/ML/image-20211114154021381.png" alt=""></p>
<h3 id="Representing-Graphs-Adjacency-list"><a href="#Representing-Graphs-Adjacency-list" class="headerlink" title="Representing Graphs: Adjacency list"></a>Representing Graphs: Adjacency list</h3><ul>
<li><p>Adjacency list: </p>
<ul>
<li><p>Easier to work with if network is </p>
<ul>
<li><p>Large </p>
</li>
<li><p>Sparse </p>
</li>
</ul>
</li>
<li><p>Allows us to quickly retrieve all  neighbors of a given node </p>
<ul>
<li><p>1: </p>
</li>
<li><p>2: 3, 4 </p>
</li>
<li><p>3: 2, 4 </p>
</li>
<li><p>4: 5 </p>
</li>
<li><p>5: 1, 2</p>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="Node-and-Edge-Attributes"><a href="#Node-and-Edge-Attributes" class="headerlink" title="Node and Edge Attributes"></a>Node and Edge Attributes</h3><ul>
<li>Possible options: <ul>
<li>Weight (e.g., frequency of communication) </li>
<li>Ranking (best friend, second best friend…) </li>
<li>Type (friend, relative, co-worker) </li>
<li>Sign: Friend vs. Foe, Trust vs. Distrust </li>
<li>Properties depending on the structure of the rest  of the graph: Number of common friends</li>
</ul>
</li>
</ul>
<h3 id="More-Types-of-Graphs"><a href="#More-Types-of-Graphs" class="headerlink" title="More Types of Graphs"></a>More Types of Graphs</h3><p><img src="/images/loading.gif" data-original="../images/ML/image-20211114154354051.png" alt=""></p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114154418078.png" alt=""></p>
<h3 id="Connectivity-of-Undirected-Graphs"><a href="#Connectivity-of-Undirected-Graphs" class="headerlink" title="Connectivity of Undirected Graphs"></a>Connectivity of Undirected Graphs</h3><ul>
<li>Connected (undirected) graph: <ul>
<li>Any two vertices can be joined by a path </li>
</ul>
</li>
<li>A disconnected graph is made up by two or  more connected components</li>
</ul>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114154501411.png" alt=""></p>
<h3 id="Connectivity-Example"><a href="#Connectivity-Example" class="headerlink" title="Connectivity: Example"></a>Connectivity: Example</h3><p>The adjacency matrix of a network with several  components can be written in a block- diagonal  form, so that nonzero elements are confined to  squares, with all other elements being zero:</p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114154537953.png" alt=""></p>
<h3 id="Connectivity-of-Directed-Graphs"><a href="#Connectivity-of-Directed-Graphs" class="headerlink" title="Connectivity of Directed Graphs"></a>Connectivity of Directed Graphs</h3><ul>
<li>Strongly connected directed graph <ul>
<li>has a path from each node to every other node  and vice versa (e.g., A-B path and B-A path)</li>
</ul>
</li>
<li>Weakly connected directed graph <ul>
<li>is connected if we disregard the edge directions</li>
</ul>
</li>
</ul>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114154640547.png" alt=""></p>
<p>Strongly connected components (SCCs) can  be identified, but not every node is part of a  nontrivial strongly connected component.</p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114154659259.png" alt=""></p>
<h1 id="Traditional-Methods-for-Machine-Learning-in-Graphs"><a href="#Traditional-Methods-for-Machine-Learning-in-Graphs" class="headerlink" title="Traditional Methods for Machine Learning in Graphs"></a>Traditional Methods for Machine Learning in Graphs</h1><h2 id="Traditional-Methods-for-Machine-Learning-in-Graphs-1"><a href="#Traditional-Methods-for-Machine-Learning-in-Graphs-1" class="headerlink" title="Traditional Methods for Machine Learning in Graphs"></a>Traditional Methods for Machine Learning in Graphs</h2><h3 id="Traditional-ML-Pipeline"><a href="#Traditional-ML-Pipeline" class="headerlink" title="Traditional ML Pipeline"></a>Traditional ML Pipeline</h3><p>Design features for nodes/links/graphs </p>
<p>Obtain features for all training data</p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114155029705.png" alt=""></p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114155040109.png" alt=""></p>
<h3 id="Feature-Desian"><a href="#Feature-Desian" class="headerlink" title="Feature Desian"></a>Feature Desian</h3><ul>
<li><p>Using effective features over graphs is the key  to achieving good model performance. </p>
</li>
<li><p>Traditional ML pipeline uses hand-designed  features. </p>
</li>
<li><p>In this lecture, we overview the traditional  features for: </p>
<ul>
<li>Node-level prediction </li>
<li>Link-level prediction </li>
<li>Graph-level prediction </li>
</ul>
</li>
<li><p>For simplicity, we focus on undirected graphs.</p>
</li>
<li><p>Goal: Make predictions for a set of objects </p>
</li>
<li><p>Design choices: </p>
<ul>
<li>Features: d-dimensional vectors </li>
<li>Objects: Nodes, edges, sets of nodes,  entire graphs </li>
<li>Objective function: <ul>
<li>What task are we aiming to solve?</li>
</ul>
</li>
</ul>
</li>
</ul>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114155314744.png" alt=""></p>
<h2 id="Node-level-Tasks-and-Features"><a href="#Node-level-Tasks-and-Features" class="headerlink" title="Node-level Tasks and Features"></a>Node-level Tasks and Features</h2><h3 id="Node-level-Features-Overview"><a href="#Node-level-Features-Overview" class="headerlink" title="Node-level Features: Overview"></a>Node-level Features: Overview</h3><ul>
<li>Goal: Characterize the structure and position of  a node in the network: <ul>
<li>Node degree </li>
<li>Node centrality </li>
<li>Clustering coefficient </li>
<li>Graphlets</li>
</ul>
</li>
</ul>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114155446882.png" alt=""></p>
<h3 id="Node-Degree"><a href="#Node-Degree" class="headerlink" title="Node Degree"></a>Node Degree</h3><p><img src="/images/loading.gif" data-original="../images/ML/image-20211114155516487.png" alt=""></p>
<h3 id="Node-Centrality"><a href="#Node-Centrality" class="headerlink" title="Node Centrality"></a>Node Centrality</h3><ul>
<li>Node degree counts the neighboring nodes  without capturing their importance. </li>
<li>Node centrality 𝑐_𝑣 takes the node importance  in a graph into account </li>
<li>Different ways to model importance: <ul>
<li>Engienvector centrality </li>
<li>Betweenness centrality </li>
<li>Closeness centrality </li>
<li>and many others…</li>
</ul>
</li>
</ul>
<h4 id="Eigenvector-centrality"><a href="#Eigenvector-centrality" class="headerlink" title="Eigenvector centrality"></a>Eigenvector centrality</h4><p><img src="/images/loading.gif" data-original="../images/ML/image-20211114155636291.png" alt=""></p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114155651475.png" alt=""></p>
<h4 id="Betweenness-centrality"><a href="#Betweenness-centrality" class="headerlink" title="Betweenness centrality"></a>Betweenness centrality</h4><p><img src="/images/loading.gif" data-original="../images/ML/image-20211114155709827.png" alt=""></p>
<h4 id="Closeness-centrality"><a href="#Closeness-centrality" class="headerlink" title="Closeness centrality"></a>Closeness centrality</h4><p><img src="/images/loading.gif" data-original="../images/ML/image-20211114155731340.png" alt=""></p>
<h3 id="Clustering-Coefficient"><a href="#Clustering-Coefficient" class="headerlink" title="Clustering Coefficient"></a>Clustering Coefficient</h3><p><img src="/images/loading.gif" data-original="../images/ML/image-20211114155816102.png" alt=""></p>
<h3 id="Graphlets"><a href="#Graphlets" class="headerlink" title="Graphlets"></a>Graphlets</h3><p><img src="/images/loading.gif" data-original="../images/ML/image-20211114155840431.png" alt=""></p>
<ul>
<li><p>Goal: Describe network structure around node 𝑢 </p>
<ul>
<li>Graphlets are small subgraphs that describe the  structure of node 𝑢’s network neighborhood Analogy: </li>
</ul>
</li>
<li><p>Degree counts #(edges) that a node touches </p>
</li>
<li><p>Clustering coefficient counts #(triangles) that a  node touches. </p>
</li>
<li><p>Graphlet Degree Vector (GDV): Graphlet-base  features for nodes </p>
<ul>
<li>GDV counts #(graphlets) that a node touches</li>
</ul>
</li>
<li><p>Considering graphlets of size 2-5 nodes we get: </p>
<ul>
<li>Vector of 73 coordinates is a signature of a node  that describes the topology of node’s neighborhood  </li>
</ul>
</li>
<li><p>Graphlet degree vector provides a measure of  a node’s local network topology: </p>
<ul>
<li>Comparing vectors of two nodes provides a more  detailed measure of local topological similarity than  node degrees or clustering coefficient.</li>
</ul>
</li>
</ul>
<h4 id="Induced-Subgraph-Isomorphism"><a href="#Induced-Subgraph-Isomorphism" class="headerlink" title="Induced Subgraph Isomorphism"></a>Induced Subgraph Isomorphism</h4><p>Def: Induced subgraph is another graph, formed  from a subset of vertices and all of the edges  connecting the vertices in that subset.</p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114160056026.png" alt=""></p>
<p>Def: Graph Isomorphism(同构) </p>
<ul>
<li>Two graphs which contain the same number of nodes  connected in the same way are said to be isomorphic.</li>
</ul>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114160128187.png" alt=""></p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114160159336.png" alt=""></p>
<p><strong>Graphlet Degree Vector</strong> (GDV): A count  vector of graphlets rooted at a given node</p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114160238072.png" alt=""></p>
<h3 id="Node-level-Feature-Summary"><a href="#Node-level-Feature-Summary" class="headerlink" title="Node-level Feature: Summary"></a>Node-level Feature: Summary</h3><ul>
<li><p>We have introduced different ways to obtain  node features. </p>
</li>
<li><p>They can be categorized as: </p>
<ul>
<li>Importance-based features: <ul>
<li>Node degree </li>
<li>Different node centrality measures </li>
</ul>
</li>
<li>Structure-based features: <ul>
<li>Node degree </li>
<li>Clustering coefficient </li>
<li>Graphlet count vector</li>
</ul>
</li>
</ul>
</li>
<li><p>Importance-based features: capture the  importance of a node in a graph </p>
<ul>
<li>Node degree: <ul>
<li>Simply counts the number of neighboring nodes </li>
</ul>
</li>
<li>Node centrality: <ul>
<li>Models importance of neighboring nodes in a graph </li>
<li>Different modeling choices: eigenvector centrality,  betweenness centrality, closeness centrality</li>
</ul>
</li>
</ul>
</li>
<li><p>Useful for predicting influential nodes in a graph </p>
<ul>
<li>Example: predicting celebrity users in a social  network</li>
</ul>
</li>
<li><p>Structure-based features: Capture topological  properties of local neighborhood around a node. </p>
<ul>
<li>Node degree: <ul>
<li>Counts the number of neighboring nodes </li>
</ul>
</li>
<li>Clustering coefficient: <ul>
<li>Measures how connected neighboring nodes are </li>
</ul>
</li>
<li>Graphlet degree vector: <ul>
<li>Counts the occurrences of different graphlets </li>
</ul>
</li>
</ul>
</li>
<li><p>Useful for predicting a particular role a node  plays in a graph: </p>
<ul>
<li>Example: Predicting protein functionality in a  protein-protein interaction network</li>
</ul>
</li>
</ul>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114164204808.png" alt=""></p>
<h2 id="Link-Prediction-Task-and-Features"><a href="#Link-Prediction-Task-and-Features" class="headerlink" title="Link Prediction Task and Features"></a>Link Prediction Task and Features</h2><h3 id="Recap"><a href="#Recap" class="headerlink" title="Recap"></a>Recap</h3><ul>
<li>The task is to predict new links based on the  existing links. </li>
<li>At test time, node pairs (with no existing links)  are ranked, and top 𝐾 node pairs are predicted. </li>
<li>The key is to design features for a pair of nodes.</li>
</ul>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114164300332.png" alt=""></p>
<p><strong>Two formulations of the link prediction task:</strong></p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114164327858.png" alt=""></p>
<h3 id="Link-Prediction-via-Proximity"><a href="#Link-Prediction-via-Proximity" class="headerlink" title="Link Prediction via Proximity"></a>Link Prediction via Proximity</h3><ul>
<li>Methodology: <ul>
<li>For each pair of nodes (x,y) compute score c(x,y) <ul>
<li>For example, c(x,y) could be the # of common neighbors  of x and y </li>
</ul>
</li>
<li>Sort pairs (x,y) by the decreasing score c(x,y) </li>
<li>Predict top n pairs as new links </li>
<li>See which of these links actually appear in 𝐺[𝑡1 ,𝑡1 ′ ]</li>
</ul>
</li>
</ul>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114164503916.png" alt=""></p>
<h3 id="Link-level-Features-Overview"><a href="#Link-level-Features-Overview" class="headerlink" title="Link-level Features: Overview"></a>Link-level Features: Overview</h3><ul>
<li>Distance-based feature </li>
<li>Local neighborhood overlap </li>
<li>Global neighborhood overlap</li>
</ul>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114164529982.png" alt=""></p>
<h3 id="Distance-based-Features"><a href="#Distance-based-Features" class="headerlink" title="Distance-based Features"></a>Distance-based Features</h3><p>Shortest-path distance between two nodes</p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114164603800.png" alt=""></p>
<p>However, this does not capture the degree of  neighborhood overlap: </p>
<ul>
<li>Node pair (B, H) has 2 shared neighboring nodes,  while pairs (B, E) and (A, B) only have 1 such node</li>
</ul>
<h3 id="Local-Neighborhood-Overlap"><a href="#Local-Neighborhood-Overlap" class="headerlink" title="Local Neighborhood Overlap"></a>Local Neighborhood Overlap</h3><p><img src="/images/loading.gif" data-original="../images/ML/image-20211114164647894.png" alt=""></p>
<h3 id="Global-Neighborhood-Overlap"><a href="#Global-Neighborhood-Overlap" class="headerlink" title="Global Neighborhood Overlap"></a>Global Neighborhood Overlap</h3><ul>
<li><p>Limitation of local neighborhood features: </p>
<ul>
<li><p>Metric is always zero if the two nodes do not have  any neighbors in common.</p>
</li>
<li><p>However, the two nodes may still potentially be  connected in the future. </p>
</li>
</ul>
</li>
<li><p>Global neighborhood overlap metrics resolve  the limitation by considering the entire graph.</p>
</li>
</ul>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114164745624.png" alt=""></p>
<ul>
<li>Katz index: count the number of walks of all  lengths between a given pair of nodes. </li>
<li>Q: How to compute #walks between two  nodes? <ul>
<li>Use powers of the graph adjacency matrix!</li>
</ul>
</li>
</ul>
<h4 id="Intuition-Powers-of-Adj-Matrices"><a href="#Intuition-Powers-of-Adj-Matrices" class="headerlink" title="Intuition: Powers of Adj Matrices"></a>Intuition: Powers of Adj Matrices</h4><p><strong>Computing #walks between two nodes</strong></p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114164853647.png" alt=""></p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114164908991.png" alt=""></p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114165005720.png" alt=""></p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114165018384.png" alt=""></p>
<h3 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a>Summary</h3><ul>
<li>Distance-based features: <ul>
<li>Uses the shortest path length between two nodes  but does not capture how neighborhood overlaps. </li>
</ul>
</li>
<li>Local neighborhood overlap: <ul>
<li>Captures how many neighboring nodes are shared  by two nodes. </li>
<li>Becomes zero when no neighbor nodes are shared. </li>
</ul>
</li>
<li>Global neighborhood overlap: <ul>
<li>Uses global graph structure to score two nodes. </li>
<li>Katz index counts #walks of all lengths between two  nodes.</li>
</ul>
</li>
</ul>
<h2 id="Graph-level-Features-and-Graph-Kernels"><a href="#Graph-level-Features-and-Graph-Kernels" class="headerlink" title="Graph-level Features and Graph Kernels"></a>Graph-level Features and Graph Kernels</h2><h3 id="Graph-level-Features"><a href="#Graph-level-Features" class="headerlink" title="Graph-level Features"></a>Graph-level Features</h3><p>Goal: We want features that characterize the  structure of an entire graph</p>
<h3 id="Backaround-Kernel-Methods"><a href="#Backaround-Kernel-Methods" class="headerlink" title="Backaround Kernel Methods"></a>Backaround Kernel Methods</h3><ul>
<li>Kernel methods are widely-used for traditional  ML for graph-level prediction. </li>
<li>Idea: Design kernels instead of feature vectors. </li>
<li>A quick introduction to Kernels:</li>
</ul>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114165703860.png" alt=""></p>
<h3 id="Overview"><a href="#Overview" class="headerlink" title="Overview"></a>Overview</h3><ul>
<li>Graph Kernels: Measure similarity between  two graphs: <ul>
<li>Graphlet Kernel [1] </li>
<li>Weisfeiler-Lehman Kernel [2] </li>
<li>Other kernels are also proposed in the literature  (beyond the scope of this lecture) <ul>
<li>Random-walk kernel </li>
<li>Shortest-path graph kernel </li>
<li>And many more…</li>
</ul>
</li>
</ul>
</li>
</ul>
<p>[1] Shervashidze, Nino, et al. “Efficient graphlet kernels for large graph comparison.” Artificial Intelligence and Statistics. 2009. </p>
<p>[2] Shervashidze, Nino, et al. “Weisfeiler-lehman graph kernels.” Journal of Machine Learning Research 12.9 (2011).</p>
<h3 id="Graph-Kernel-Key-Idea"><a href="#Graph-Kernel-Key-Idea" class="headerlink" title="Graph Kernel: Key Idea"></a>Graph Kernel: Key Idea</h3><ul>
<li>Goal: Design graph feature vector 𝜙(𝐺) </li>
<li>Key idea: Bag-of-Words (BoW) for a graph <ul>
<li>Recall: BoW simply uses the word counts as  features for documents (no ordering considered). </li>
<li>Naïve extension to a graph: Regard nodes as words. </li>
<li>Since both graphs have 4 red nodes, we get the  same feature vector for two different graphs…</li>
</ul>
</li>
</ul>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114170336494.png" alt=""></p>
<p>What if we use Bag of node degrees?</p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114170358374.png" alt=""></p>
<p>Both Graphlet Kernel and Weisfeiler-Lehman  (WL) Kernel use Bag-of-* representation of  graph, where * is more sophisticated than  node degrees!</p>
<h3 id="Graphlet-Features"><a href="#Graphlet-Features" class="headerlink" title="Graphlet Features"></a>Graphlet Features</h3><ul>
<li>Key idea: Count the number of different  graphlets in a graph. <ul>
<li>Note: Definition of graphlets here is slightly  different from node-level features.  </li>
<li>The two differences are: <ul>
<li>Nodes in graphlets here do not need to be connected (allows for  isolated nodes) </li>
<li>The graphlets here are not rooted. </li>
<li>Examples in the next slide illustrate this.</li>
</ul>
</li>
</ul>
</li>
</ul>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114170616974.png" alt=""></p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114170627979.png" alt=""></p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114170640069.png" alt=""></p>
<h3 id="Graphlet-Kernel"><a href="#Graphlet-Kernel" class="headerlink" title="Graphlet Kernel"></a>Graphlet Kernel</h3><p><img src="/images/loading.gif" data-original="../images/ML/image-20211114170712399.png" alt=""></p>
<ul>
<li><p>Limitations: Counting graphlets is expensive! </p>
</li>
<li><p>Counting size-𝑘 graphlets for a graph with size 𝑛 by enumeration takes 𝑛^𝑘 . </p>
</li>
<li><p>This is unavoidable in the worst-case since  subgraph isomorphism test (judging whether a  graph is a subgraph of another graph) is NP-hard. </p>
</li>
<li><p>If a graph’s node degree is bounded by 𝑑, an  𝑂(𝑛𝑑^(𝑘−1)) algorithm exists to count all the  graphlets of size 𝑘.  </p>
<p><strong>Can we design a more efficient graph kernel?</strong></p>
</li>
</ul>
<h3 id="Weisfeiler-lehman-Kernel"><a href="#Weisfeiler-lehman-Kernel" class="headerlink" title="Weisfeiler-lehman Kernel"></a>Weisfeiler-lehman Kernel</h3><ul>
<li>Goal: Design an efficient graph feature  descriptor 𝜙 (𝐺) </li>
<li>Idea: Use neighborhood structure to  iteratively enrich node vocabulary.  </li>
<li>Generalized version of Bag of node degrees since  node degrees are one-hop neighborhood  information. </li>
<li>Algorithm to achieve this: Color refinement</li>
</ul>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114170929956.png" alt=""></p>
<p>Example of color refinement given two graphs</p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114170948187.png" alt=""></p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114170958604.png" alt=""></p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114171007420.png" alt=""></p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114171017926.png" alt=""></p>
<p>After color refinement, WL kernel counts number  of nodes with a given color.</p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114171038806.png" alt=""></p>
<p>The WL kernel value is computed by the inner  product of the color count vectors: </p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114171053600.png" alt=""></p>
<ul>
<li>WL kernel is computationally efficient <ul>
<li>The time complexity for color refinement at each step is  linear in #(edges), since it involves aggregating neighboring  colors. </li>
</ul>
</li>
<li>When computing a kernel value, only colors  appeared in the two graphs need to be tracked. <ul>
<li>Thus, #(colors) is at most the total number of nodes. </li>
</ul>
</li>
<li>Counting colors takes linear-time w.r.t. #(nodes). </li>
<li>In total, time complexity is linear in #(edges)</li>
</ul>
<h3 id="Summary-1"><a href="#Summary-1" class="headerlink" title="Summary"></a>Summary</h3><ul>
<li><p>Graphlet Kernel </p>
<ul>
<li>Graph is represented as Bag-of-graphlets </li>
<li>Computationally expensive </li>
</ul>
</li>
<li><p>Weisfeiler-Lehman Kernel </p>
<ul>
<li>Apply 𝐾-step color refinement algorithm to enrich  node colors <ul>
<li>Different colors capture different 𝐾-hop neighborhood  structures </li>
</ul>
</li>
<li>Graph is represented as Bag-of-colors </li>
<li>Computationally efficient </li>
<li>Closely related to Graph Neural Networks (as we  will see!)</li>
</ul>
</li>
<li><p>Traditional ML Pipeline </p>
<ul>
<li>Hand-crafted feature + ML model </li>
</ul>
</li>
<li><p>Hand-crafted features for graph data </p>
<ul>
<li>Node-level: <ul>
<li>Node degree, centrality, clustering coefficient, graphlets </li>
</ul>
</li>
<li>Link-level: <ul>
<li>distance-based feature </li>
<li>local/global neighborhood overlap </li>
</ul>
</li>
<li>Graph-level: <ul>
<li>Graphlet kernel, WL kernel</li>
</ul>
</li>
</ul>
</li>
</ul>
<h1 id="Node-Embeddings"><a href="#Node-Embeddings" class="headerlink" title="Node Embeddings"></a>Node Embeddings</h1><p>Goal: Efficient task-independent feature  learning for machine learning with graphs!</p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114184930238.png" alt=""></p>
<h2 id="Why-Embedding"><a href="#Why-Embedding" class="headerlink" title="Why Embedding?"></a>Why Embedding?</h2><ul>
<li>Task: Map nodes into an embedding space <ul>
<li>Similarity of embeddings between nodes indicates  their similarity in the network. For example: <ul>
<li>Both nodes are close to each other (connected by an edge) </li>
</ul>
</li>
<li>Encode network information </li>
<li>Potentially used for many downstream predictions</li>
</ul>
</li>
</ul>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114185054537.png" alt=""></p>
<p>2D embedding of nodes of the Zachary’s  Karate Club network:</p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114185117044.png" alt=""></p>
<p><a href="https://arxiv.org/pdf/1403.6652.pdf" target="_blank" rel="noopener">Perozzi et al. DeepWalk: Online Learning of Social Representations. KDD 2014</a></p>
<h2 id="Node-Embeddings-Encoder-and-Decoder"><a href="#Node-Embeddings-Encoder-and-Decoder" class="headerlink" title="Node Embeddings Encoder and Decoder"></a>Node Embeddings Encoder and Decoder</h2><h3 id="Setup"><a href="#Setup" class="headerlink" title="Setup"></a>Setup</h3><ul>
<li>Assume we have a graph G: <ul>
<li>V is the vertex set. </li>
<li>A is the adjacency matrix (assume binary). </li>
<li>For simplicity: No node features or extra  information is used</li>
</ul>
</li>
</ul>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114185313810.png" alt=""></p>
<h3 id="Embedding-Nodes"><a href="#Embedding-Nodes" class="headerlink" title="Embedding Nodes"></a>Embedding Nodes</h3><p>Goal is to encode nodes so that similarity in  the embedding space (e.g., dot product)  approximates similarity in the graph</p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114185343379.png" alt=""></p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114185359370.png" alt=""></p>
<h4 id="Learning-Node-Embeddings"><a href="#Learning-Node-Embeddings" class="headerlink" title="Learning Node Embeddings"></a>Learning Node Embeddings</h4><ol>
<li>Encoder maps from nodes to embeddings </li>
<li>Define a node similarity function (i.e., a  measure of similarity in the original network) </li>
<li>Decoder 𝐃𝐄𝐂 maps from embeddings to the  similarity score </li>
<li>Optimize the parameters of the encoder so  that:</li>
</ol>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114185507005.png" alt=""></p>
<h4 id="Two-Key-Components"><a href="#Two-Key-Components" class="headerlink" title="Two Key Components"></a>Two Key Components</h4><p><img src="/images/loading.gif" data-original="../images/ML/image-20211114185541120.png" alt=""></p>
<h4 id="“shallow”Encoding"><a href="#“shallow”Encoding" class="headerlink" title="“shallow”Encoding"></a>“shallow”Encoding</h4><p>Simplest encoding approach: Encoder is just an  embedding-lookup</p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114185622676.png" alt=""></p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114185653217.png" alt=""></p>
<ul>
<li>Each node is assigned a unique embedding vector (i.e., we directly optimize the embedding of each node) </li>
<li>Many methods: DeepWalk, node2vec</li>
</ul>
<h3 id="Framework-Summary"><a href="#Framework-Summary" class="headerlink" title="Framework Summary"></a>Framework Summary</h3><p>Encoder + Decoder Framework</p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114185821145.png" alt=""></p>
<h3 id="How-to-Define-Node-Similarit"><a href="#How-to-Define-Node-Similarit" class="headerlink" title="How to Define Node Similarit"></a>How to Define Node Similarit</h3><ul>
<li>Key choice of methods is how they define node similarity. </li>
<li>Should two nodes have a similar embedding if  they… <ul>
<li>are linked? </li>
<li>share neighbors? </li>
<li>have similar “structural roles”? </li>
</ul>
</li>
<li>We will now learn node similarity definition that uses  random walks, and how to optimize embeddings for  such a similarity measure.</li>
</ul>
<h3 id="Note-on-Node-Embeddings"><a href="#Note-on-Node-Embeddings" class="headerlink" title="Note on Node Embeddings"></a>Note on Node Embeddings</h3><ul>
<li>This is unsupervised/self-supervisedway of  learning node embeddings. <ul>
<li>We are not utilizing node labels </li>
<li>We are not utilizing node features </li>
<li>The goal is to directly estimate a set of coordinates  (i.e., the embedding) of a node so that some aspect  of the network structure (captured by DEC) is  preserved. </li>
</ul>
</li>
<li>These embeddings are task independent <ul>
<li>They are not trained for a specific task but can be  used for any task.</li>
</ul>
</li>
</ul>
<h2 id="Random-Walk-Approaches-for-Node-Embeddings"><a href="#Random-Walk-Approaches-for-Node-Embeddings" class="headerlink" title="Random Walk Approaches for Node Embeddings"></a>Random Walk Approaches for Node Embeddings</h2><h3 id="Notation"><a href="#Notation" class="headerlink" title="Notation"></a>Notation</h3><p><img src="/images/loading.gif" data-original="../images/ML/image-20211114190246623.png" alt=""></p>
<h3 id="Random-Walk"><a href="#Random-Walk" class="headerlink" title="Random Walk"></a>Random Walk</h3><p><img src="/images/loading.gif" data-original="../images/ML/image-20211114191224897.png" alt=""></p>
<h3 id="Random-walk-Embeddings"><a href="#Random-walk-Embeddings" class="headerlink" title="Random-walk Embeddings"></a>Random-walk Embeddings</h3><p><img src="/images/loading.gif" data-original="../images/ML/image-20211114191304620.png" alt=""></p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114191410904.png" alt=""></p>
<h3 id="Why-Random-Walks"><a href="#Why-Random-Walks" class="headerlink" title="Why Random Walks?"></a>Why Random Walks?</h3><ol>
<li>Expressivity: Flexible stochastic(随机的) definition of  node similarity that incorporates both local  and higher-order neighborhood information Idea: if random walk starting from node 𝑢 visits 𝑣 with high probability, 𝑢 and 𝑣 are  similar (high-order multi-hop information) </li>
<li>Efficiency: Do not need to consider all node  pairs when training; only need to consider  pairs that co-occur on random walks</li>
</ol>
<h3 id="Unsupervised-Feature-Learning"><a href="#Unsupervised-Feature-Learning" class="headerlink" title="Unsupervised Feature Learning"></a>Unsupervised Feature Learning</h3><ul>
<li>Intuition: Find embedding of nodes in  𝑑-dimensional space that preserves similarity </li>
<li>Idea: Learn node embedding such that nearby nodes are close together in the network </li>
<li>Given a node 𝑢, how do we define nearby  nodes?</li>
</ul>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114191744402.png" alt=""></p>
<h3 id="Feature-Learning-as-Optimization"><a href="#Feature-Learning-as-Optimization" class="headerlink" title="Feature Learning as Optimization"></a>Feature Learning as Optimization</h3><p><img src="/images/loading.gif" data-original="../images/ML/image-20211114191851755.png" alt=""></p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114192332640.png" alt=""></p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114192807843.png" alt=""></p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114193211508.png" alt=""></p>
<p>But doing this naively is too expensive!</p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114193322978.png" alt=""></p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114193414462.png" alt=""></p>
<h4 id="Negative-Sampling"><a href="#Negative-Sampling" class="headerlink" title="Negative Sampling"></a>Negative Sampling</h4><p><img src="/images/loading.gif" data-original="../images/ML/image-20211114193458015.png" alt=""></p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114194423952.png" alt=""></p>
<h4 id="Stochastic-Gradient-Descent"><a href="#Stochastic-Gradient-Descent" class="headerlink" title="Stochastic Gradient Descent"></a>Stochastic Gradient Descent</h4><p><img src="/images/loading.gif" data-original="../images/ML/image-20211114194708482.png" alt=""></p>
<p>Stochastic Gradient Descent: Instead of evaluating  gradients over all examples, evaluate it for each  individual training example.</p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114194843074.png" alt=""></p>
<h3 id="Random-Walks：Summary"><a href="#Random-Walks：Summary" class="headerlink" title="Random Walks：Summary"></a>Random Walks：Summary</h3><p><img src="/images/loading.gif" data-original="../images/ML/image-20211114195157506.png" alt=""></p>
<h3 id="How-should-we-randomly-walk"><a href="#How-should-we-randomly-walk" class="headerlink" title="How should we randomly walk?"></a>How should we randomly walk?</h3><ul>
<li>So far we have described how to optimize  embeddings given a random walk strategy R -</li>
<li>What strategies should we use to run these  random walks? <ul>
<li>Simplest idea: Just run fixed-length, unbiased  random walks starting from each node (i.e.,  DeepWalk from Perozzi et al., 2013) <ul>
<li>The issue is that such notion of similarity is too constrained </li>
</ul>
</li>
</ul>
</li>
<li>How can we generalize this?</li>
</ul>
<p><a href="https://arxiv.org/pdf/1403.6652.pdf" target="_blank" rel="noopener">Reference: Perozzi et al. 2014. DeepWalk: Online Learning of Social Representations. KDD</a></p>
<h3 id="Overview-of-node2vec"><a href="#Overview-of-node2vec" class="headerlink" title="Overview of node2vec"></a>Overview of node2vec</h3><p><a href="https://cs.stanford.edu/~jure/pubs/node2vec-kdd16.pdf" target="_blank" rel="noopener">Reference: Grover et al. 2016. node2vec: Scalable Feature Learning for Networks. KDD</a></p>
<ul>
<li>Goal: Embed nodes with similar network  neighborhoods close in the feature space. </li>
<li>We frame this goal as a maximum likelihood  optimization problem, independent to the  downstream prediction task.</li>
<li>Key observation: Flexible notion of network  neighborhood 𝑁_𝑅(𝑢) of node 𝑢 leads to rich node  embeddings</li>
<li>Develop biased 2^nd order random walk 𝑅 to  generate network neighborhood 𝑁_𝑅(𝑢) of node 𝑢</li>
</ul>
<h4 id="node2vec-Biased-Walks"><a href="#node2vec-Biased-Walks" class="headerlink" title="node2vec: Biased Walks"></a>node2vec: Biased Walks</h4><p>Idea: use flexible, biased random walks that can  trade off between local and global views of the  network (Grover and Leskovec, 2016). </p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114195719803.png" alt=""></p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114195734036.png" alt=""></p>
<h4 id="BFS-VS-DFS"><a href="#BFS-VS-DFS" class="headerlink" title="BFS VS.DFS"></a>BFS VS.DFS</h4><p><img src="/images/loading.gif" data-original="../images/ML/image-20211114200935414.png" alt=""></p>
<ul>
<li>Biased fixed-length random walk 𝑹 that given a  node 𝒖 generates neighborhood 𝑵_𝑹(𝒖) <ul>
<li>Two parameters: <ul>
<li>Return parameter 𝒑: <ul>
<li>Return back to the previous node </li>
</ul>
</li>
</ul>
</li>
<li>In-out parameter 𝒒: <ul>
<li>Moving outwards (DFS) vs. inwards (BFS) </li>
<li>Intuitively, 𝑞 is the “ratio” of BFS vs. DFS</li>
</ul>
</li>
</ul>
</li>
</ul>
<h4 id="Biased-Random-Walks"><a href="#Biased-Random-Walks" class="headerlink" title="Biased Random Walks"></a>Biased Random Walks</h4><ul>
<li>Biased 2nd -order random walks explore network neighborhoods: <ul>
<li>Rnd. walk just traversed edge (𝑠1 , 𝑤) and is now at 𝑤 </li>
<li>Insight: Neighbors of 𝑤 can only be:</li>
</ul>
</li>
</ul>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114201220400.png" alt=""></p>
<p>Idea: Remember where the walk came from</p>
<ul>
<li>Walker came over edge (𝐬𝟏, 𝐰) and is at 𝐰.  Where to go next?</li>
<li>𝑝, 𝑞 model transition probabilities <ul>
<li>𝑝 … return parameter </li>
<li>𝑞 … ”walk away” parameter</li>
</ul>
</li>
</ul>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114201325434.png" alt=""></p>
<ul>
<li>Walker came over edge (𝐬𝟏, 𝐰) and is at 𝐰.  Where to go next?</li>
</ul>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114201455606.png" alt=""></p>
<h3 id="node2vec-algorithm"><a href="#node2vec-algorithm" class="headerlink" title="node2vec algorithm"></a>node2vec algorithm</h3><p>1) Compute random walk probabilities </p>
<p>2) Simulate 𝑟 random walks of length 𝑙 starting  from each node 𝑢 </p>
<p>3) Optimize the node2vec objective using  Stochastic Gradient Descent </p>
<p>   Linear-time complexity </p>
<p>   All 3 steps are individually parallelizable</p>
<h3 id="Other-Random-Walk-Ideas"><a href="#Other-Random-Walk-Ideas" class="headerlink" title="Other Random Walk Ideas"></a>Other Random Walk Ideas</h3><ul>
<li>Different kinds of biased random walks: <ul>
<li><a href="https://ericdongyx.github.io/papers/KDD17-dong-chawla-swami-metapath2vec.pdf" target="_blank" rel="noopener">Based on node attributes (Dong et al., 2017).</a> </li>
<li><a href="https://arxiv.org/abs/1710.09599" target="_blank" rel="noopener">Based on learned weights (Abu-El-Haija et al., 2017)</a> </li>
</ul>
</li>
<li>Alternative optimization schemes: <ul>
<li><a href="https://arxiv.org/abs/1503.03578" target="_blank" rel="noopener">Directly optimize based on 1-hop and 2-hop random walk  probabilities (as in LINE from Tang et al. 2015).</a> </li>
</ul>
</li>
<li>Network preprocessing techniques: <ul>
<li><a href="https://arxiv.org/abs/1706.07845" target="_blank" rel="noopener">Run random walks on modified versions of the original  network (e.g., Ribeiro et al. 2017’s struct2vec, Chen et al.  2016’s HARP).</a></li>
</ul>
</li>
</ul>
<h3 id="Summary-so-far"><a href="#Summary-so-far" class="headerlink" title="Summary so far"></a>Summary so far</h3><ul>
<li><p>Core idea: Embed nodes so that distances in  embedding space reflect node similarities in  the original network. </p>
</li>
<li><p>Different notions of node similarity: </p>
<ul>
<li>Naïve: similar if two nodes are connected </li>
<li>Neighborhood overlap (covered in Lecture 2) </li>
<li>Random walk approaches (covered today)</li>
</ul>
</li>
<li><p>So what method should I use..? </p>
</li>
<li><p>No one method wins in all cases…. </p>
<ul>
<li>E.g., node2vec performs better on node classification  while alternative methods perform better on link  prediction (<a href="https://arxiv.org/abs/1705.02801" target="_blank" rel="noopener">Goyal and Ferrara, 2017 survey)</a>. </li>
</ul>
</li>
<li><p>Random walk approaches are generally more  efficient. </p>
</li>
<li><p>In general: Must choose definition of node  similarity that matches your application.</p>
</li>
</ul>
<h2 id="Embedding-Entire-Graphs"><a href="#Embedding-Entire-Graphs" class="headerlink" title="Embedding Entire Graphs"></a>Embedding Entire Graphs</h2><h3 id="Embedding-Entire-Graphs-1"><a href="#Embedding-Entire-Graphs-1" class="headerlink" title="Embedding Entire Graphs"></a>Embedding Entire Graphs</h3><p><img src="/images/loading.gif" data-original="../images/ML/image-20211114202611575.png" alt=""></p>
<h3 id="Approach-l"><a href="#Approach-l" class="headerlink" title="Approach l"></a>Approach l</h3><ul>
<li><p>Simple (but effective) approach 1:  </p>
<ul>
<li>Run a standard graph embedding  technique on the (sub)graph 𝐺. </li>
<li>Then just sum (or average) the node  embeddings in the (sub)graph 𝐺.</li>
</ul>
<img src="/images/loading.gif" data-original="../images/ML/image-20211114203010880.png" style="zoom:50%;">

</li>
</ul>
<p><a href="https://arxiv.org/abs/1509.09292" target="_blank" rel="noopener">Used by Duvenaud et al., 2016 to classify  molecules based on their graph structure</a></p>
<h3 id="Approach-2"><a href="#Approach-2" class="headerlink" title="Approach 2"></a>Approach 2</h3><p>Approach 2: Introduce a “virtual node” to  represent the (sub)graph and run a standard  graph embedding technique</p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114203037704.png" alt=""></p>
<p><a href="https://arxiv.org/abs/1511.05493" target="_blank" rel="noopener">Proposed by Li et al., 2016 as a general  technique for subgraph embedding</a></p>
<h3 id="Approach-3-Anonymous-Walk-Embeddings"><a href="#Approach-3-Anonymous-Walk-Embeddings" class="headerlink" title="Approach 3: Anonymous Walk Embeddings"></a>Approach 3: Anonymous Walk Embeddings</h3><p>States in anonymous(匿名的) walks correspond to the index of the first time we visited the node in a  random walk</p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114203144450.png" alt=""></p>
<p><a href="https://arxiv.org/pdf/1805.11921.pdf" target="_blank" rel="noopener">Anonymous Walk Embeddings, ICML 2018</a> </p>
<ul>
<li><p>Agnostic to the identity of the nodes visited  (hence anonymous) </p>
</li>
<li><p>Example: Random walk w1 :</p>
</li>
</ul>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114203318023.png" alt=""></p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114203337873.png" alt=""></p>
<h4 id="Number-of-Walks-Grows"><a href="#Number-of-Walks-Grows" class="headerlink" title="Number of Walks Grows"></a>Number of Walks Grows</h4><p><img src="/images/loading.gif" data-original="../images/ML/image-20211114203413849.png" alt=""></p>
<h4 id="Simple-Use-of-Anonymous-Walks"><a href="#Simple-Use-of-Anonymous-Walks" class="headerlink" title="Simple Use of Anonymous Walks"></a>Simple Use of Anonymous Walks</h4><ul>
<li><p>Simulate anonymous walks 𝑤𝑖 of 𝑙 steps and  record their counts. </p>
</li>
<li><p>Represent the graph as a probability  distribution over these walks. </p>
</li>
<li><p>For example:  </p>
<ul>
<li>Set 𝑙 = 3 </li>
<li>Then we can represent the graph as a 5-dim vector <ul>
<li>Since there are 5 anonymous walks 𝑤𝑖 of length 3: 111, 112,  121, 122, 123 </li>
</ul>
</li>
<li>𝒛_𝑮[𝑖] = probability of anonymous walk 𝑤𝑖 in graph 𝐺.</li>
</ul>
</li>
<li><p>Sampling anonymous walks: Generate  independently a set of 𝑚 random walks. </p>
</li>
<li><p>Represent the graph as a probability distribution  over these walks. </p>
</li>
<li><p>How many random walks 𝑚 do we need?</p>
</li>
</ul>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114203740427.png" alt=""></p>
<h3 id="New-idea-Learn-Walk-Embeddings"><a href="#New-idea-Learn-Walk-Embeddings" class="headerlink" title="New idea: Learn Walk Embeddings"></a>New idea: Learn Walk Embeddings</h3><p>Rather than simply representing each walk by the  fraction of times it occurs, we learn embedding 𝒛_𝒊 of anonymous walk 𝒘_𝒊 .</p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114203928449.png" alt=""></p>
<p>How to embed walks? </p>
<p>Idea: Embed walks s.t. the next walk can be  predicted</p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114204007342.png" alt=""></p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114204043648.png" alt=""></p>
<p><a href="https://arxiv.org/pdf/1805.11921.pdf" target="_blank" rel="noopener">Anonymous Walk Embeddings, ICML 2018</a> </p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114204507319.png" alt=""></p>
<h3 id="Summary-2"><a href="#Summary-2" class="headerlink" title="Summary"></a>Summary</h3><ul>
<li>We discussed 3 ideas to graph embeddings: </li>
<li>Approach 1: Embed nodes and sum/avg them </li>
<li>Approach 2: Create super-node that spans the  (sub) graph and then embed that node. </li>
<li>Approach 3: Anonymous Walk Embeddings <ul>
<li>Idea 1: Sample the anon. walks and represent the  graph as fraction of times each anon walk occurs. </li>
<li>Idea 2: Learn graph embedding together with  anonymous walk embeddings.</li>
</ul>
</li>
</ul>
<h3 id="Preview-Hierarchical-Embeddings"><a href="#Preview-Hierarchical-Embeddings" class="headerlink" title="Preview: Hierarchical Embeddings"></a>Preview: Hierarchical Embeddings</h3><ul>
<li>We will discuss more advanced ways to obtain  graph embeddings in Lecture 8. </li>
<li>We can hierarchically cluster nodes in graphs,  and sum/avg the node embeddings according  to these clusters.</li>
</ul>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114204746252.png" alt=""></p>
<h3 id="How-to-Use-Embeddings"><a href="#How-to-Use-Embeddings" class="headerlink" title="How to Use Embeddings"></a>How to Use Embeddings</h3><p><img src="/images/loading.gif" data-original="../images/ML/image-20211114204819921.png" alt=""></p>
<ul>
<li>Encoder-decoder framework: <ul>
<li>Encoder: embedding lookup </li>
<li>Decoder: predict score based on embedding to match  node similarity </li>
</ul>
</li>
<li>Node similarity measure: (biased) random walk <ul>
<li>Examples: DeepWalk, Node2Vec </li>
</ul>
</li>
<li>Extension to Graph embedding: Node embedding  aggregation and Anonymous Walk Embeddings</li>
</ul>
<h1 id="Graph-as-Matrix-Pagerank-Random-Walks-and-Embeddings"><a href="#Graph-as-Matrix-Pagerank-Random-Walks-and-Embeddings" class="headerlink" title="Graph as Matrix: Pagerank, Random Walks and Embeddings"></a>Graph as Matrix: Pagerank, Random Walks and Embeddings</h1><h2 id="Pagerank-aka-the-Google-Algorithm"><a href="#Pagerank-aka-the-Google-Algorithm" class="headerlink" title="Pagerank(aka the Google Algorithm)"></a>Pagerank(aka the Google Algorithm)</h2><h3 id="Example-The-Web-as-a-Graph"><a href="#Example-The-Web-as-a-Graph" class="headerlink" title="Example: The Web as a Graph"></a>Example: The Web as a Graph</h3><ul>
<li>Q: What does the Web “look like” at  a global level? </li>
<li>Web as a graph: <ul>
<li>Nodes = web pages </li>
<li>Edges = hyperlinks </li>
<li>Side issue: What is a node? <ul>
<li>Dynamic pages created on the fly </li>
<li>“dark matter” – inaccessible  database generated pages</li>
</ul>
</li>
</ul>
</li>
</ul>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114214917553.png" alt=""></p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114214932840.png" alt=""></p>
<h3 id="What-Does-the-Web-Look-Like"><a href="#What-Does-the-Web-Look-Like" class="headerlink" title="What Does the Web Look Like?"></a>What Does the Web Look Like?</h3><ul>
<li>How is the Web linked? </li>
<li>What is the “map” of the Web? </li>
<li>Web as a directed graph [Broder et al. 2000]: <ul>
<li>Given node v, what nodes can v reach?  </li>
<li>What other nodes can reach v?</li>
</ul>
</li>
</ul>
<h3 id="Ranking-Nodes-on-the-Graph"><a href="#Ranking-Nodes-on-the-Graph" class="headerlink" title="Ranking Nodes on the Graph"></a>Ranking Nodes on the Graph</h3><ul>
<li>All web pages are not equally “important” <a href="http://www.thispersondoesnotexist.com" target="_blank" rel="noopener">www.thispersondoesnotexist.com</a> vs. <a href="http://www.stanford.edu" target="_blank" rel="noopener">www.stanford.edu</a> </li>
<li>There is large diversity  in the web-graph  node connectivity. </li>
<li>So, let’s rank the pages  using the web graph link structure!</li>
</ul>
<h3 id="Link-Analysis-Algorithms"><a href="#Link-Analysis-Algorithms" class="headerlink" title="Link Analysis Algorithms"></a>Link Analysis Algorithms</h3><ul>
<li>We will cover the following Link Analysis approaches to compute the importance of  nodes in a graph: <ul>
<li>PageRank </li>
<li>Personalized PageRank (PPR) </li>
<li>Random Walk with Restarts</li>
</ul>
</li>
</ul>
<h3 id="Links-as-Votes"><a href="#Links-as-Votes" class="headerlink" title="Links as Votes"></a>Links as Votes</h3><ul>
<li>Idea: Links as votes <ul>
<li>Page is more important if it has more links <ul>
<li>In-coming links? Out-going links? </li>
</ul>
</li>
</ul>
</li>
<li>Think of in-links as votes: <ul>
<li><a href="http://www.stanford.edu" target="_blank" rel="noopener">www.stanford.edu</a> has 23,400 in-links </li>
<li>thispersondoesnotexist.com has 1 in-link </li>
</ul>
</li>
<li>Are all in-links equal? <ul>
<li>Links from important pages count more </li>
<li>Recursive question! </li>
</ul>
</li>
</ul>
<h3 id="Pagerank-The”Flow”Model"><a href="#Pagerank-The”Flow”Model" class="headerlink" title="Pagerank: The”Flow”Model"></a>Pagerank: The”Flow”Model</h3><ul>
<li>A “vote” from an important page is worth more: <ul>
<li>Each link’s vote is proportional  to the importance of its source  page </li>
<li>If page i with importance ri has  di out-links, each link gets ri / di votes </li>
<li>Page j’s own importance rj is  the sum of the votes on its in-links</li>
</ul>
</li>
</ul>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114215430610.png" alt=""></p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114215601977.png" alt=""></p>
<h3 id="Pagerank-Matrix-Formulation"><a href="#Pagerank-Matrix-Formulation" class="headerlink" title="Pagerank: Matrix Formulation"></a>Pagerank: Matrix Formulation</h3><p><img src="/images/loading.gif" data-original="../images/ML/image-20211114215711107.png" alt=""></p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114215755515.png" alt=""></p>
<h3 id="Connection-to-Random-Walk"><a href="#Connection-to-Random-Walk" class="headerlink" title="Connection to Random Walk"></a>Connection to Random Walk</h3><ul>
<li>Imagine a random web surfer: <ul>
<li>At any time 𝒕, surfer is on some page 𝑖 </li>
<li>At time 𝒕 + 𝟏, the surfer follows an  out-link from 𝒊 uniformly at random </li>
<li>Ends up on some page 𝒋 linked from 𝒊 </li>
<li>Process repeats indefinitely </li>
</ul>
</li>
<li>Let: <ul>
<li>𝒑(𝒕) … vector whose 𝑖^th coordinate is the  prob. that the surfer is at page 𝑖 at time 𝑡 </li>
<li>So, 𝒑(𝒕) is a probability distribution over pages</li>
</ul>
</li>
</ul>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114220023823.png" alt=""></p>
<h3 id="The-Stationary-Distribution"><a href="#The-Stationary-Distribution" class="headerlink" title="The Stationary Distribution"></a>The Stationary Distribution</h3><p><img src="/images/loading.gif" data-original="../images/ML/image-20211114222138055.png" alt=""></p>
<h3 id="Recall-Eigenvector-of-A-Matrix"><a href="#Recall-Eigenvector-of-A-Matrix" class="headerlink" title="Recall Eigenvector of A Matrix"></a>Recall Eigenvector of A Matrix</h3><p><img src="/images/loading.gif" data-original="../images/ML/image-20211114222334844.png" alt=""></p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114222411167.png" alt=""></p>
<h3 id="Summary-3"><a href="#Summary-3" class="headerlink" title="Summary"></a>Summary</h3><p>PageRank: </p>
<ul>
<li>Measures importance of nodes in a graph using  the link structure of the web </li>
<li>Models a random web surfer using the stochastic  adjacency matrix 𝑴 </li>
<li>PageRank solves 𝒓 = 𝑴𝒓 where 𝒓 can be viewed  as both the principle eigenvector of 𝑴 and as the  stationary distribution of a random walk over the  graph</li>
</ul>
<h2 id="Pagerank-How-to-solve"><a href="#Pagerank-How-to-solve" class="headerlink" title="Pagerank: How to solve?"></a>Pagerank: How to solve?</h2><p><img src="/images/loading.gif" data-original="../images/ML/image-20211114222947387.png" alt=""></p>
<h3 id="Power-Iteration-Method"><a href="#Power-Iteration-Method" class="headerlink" title="Power Iteration Method"></a>Power Iteration Method</h3><p>Given a web graph with N nodes, where the  nodes are pages and edges are hyperlinks</p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114223059886.png" alt=""></p>
<p>About 50 iterations is sufficient to estimate the limiting solution.</p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114223659426.png" alt=""></p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114223740435.png" alt=""></p>
<h3 id="Three-Ouestions"><a href="#Three-Ouestions" class="headerlink" title="Three Ouestions"></a>Three Ouestions</h3><p><img src="/images/loading.gif" data-original="../images/ML/image-20211114223836586.png" alt=""></p>
<ul>
<li>Does this converge? </li>
<li>Does it converge to what we want? </li>
<li>Are results reasonable?</li>
</ul>
<h3 id="Problems"><a href="#Problems" class="headerlink" title="Problems"></a>Problems</h3><p>Two problems: </p>
<p>(1) Some pages are  dead ends (have no out-links) </p>
<p>​    Such pages cause  importance to “leak out” </p>
<p>(2) Spider traps (all out-links are within the group) </p>
<p>​    Eventually spider traps absorb all importance</p>
<h3 id="Does-this-converge"><a href="#Does-this-converge" class="headerlink" title="Does this converge"></a>Does this converge</h3><p><img src="/images/loading.gif" data-original="../images/ML/image-20211114224138856.png" alt=""></p>
<h3 id="Does-it-converge-to-what-we-want"><a href="#Does-it-converge-to-what-we-want" class="headerlink" title="Does it converge to what we want?"></a>Does it converge to what we want?</h3><p><img src="/images/loading.gif" data-original="../images/ML/image-20211114224207948.png" alt=""></p>
<h3 id="Solution-to-Spider-Traps"><a href="#Solution-to-Spider-Traps" class="headerlink" title="Solution to Spider Traps"></a>Solution to Spider Traps</h3><p><img src="/images/loading.gif" data-original="../images/ML/image-20211114224305329.png" alt=""></p>
<h3 id="Solution-to-Dead-Ends"><a href="#Solution-to-Dead-Ends" class="headerlink" title="Solution to Dead Ends"></a>Solution to Dead Ends</h3><ul>
<li>Teleports: Follow random teleport links with  total probability 1.0 from dead-ends <ul>
<li>Adjust matrix accordingly</li>
</ul>
</li>
</ul>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114224421867.png" alt=""></p>
<h3 id="Why-Teleports-Solve-the-Problem"><a href="#Why-Teleports-Solve-the-Problem" class="headerlink" title="Why Teleports Solve the Problem?"></a>Why Teleports Solve the Problem?</h3><ul>
<li>Why are dead-ends and spider traps a problem  and why do teleports solve the problem? </li>
<li>Spider-traps are not a problem, but with traps  PageRank scores are not what we want <ul>
<li>Solution: Never get stuck in a spider trap by  teleporting out of it in a finite number of steps </li>
</ul>
</li>
<li>Dead-ends are a problem <ul>
<li>The matrix is not column stochastic so our initial  assumptions are not met </li>
<li>Solution: Make matrix column stochastic by always  teleporting when there is nowhere else to go</li>
</ul>
</li>
</ul>
<h3 id="Solution-Random-Teleports"><a href="#Solution-Random-Teleports" class="headerlink" title="Solution: Random Teleports"></a>Solution: Random Teleports</h3><p><img src="/images/loading.gif" data-original="../images/ML/image-20211114224754314.png" alt=""></p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114224833186.png" alt=""></p>
<h4 id="Random-Teleports-beta-0-8"><a href="#Random-Teleports-beta-0-8" class="headerlink" title="Random Teleports(beta=0.8)"></a>Random Teleports(beta=0.8)</h4><p><img src="/images/loading.gif" data-original="../images/ML/image-20211114224910775.png" alt=""></p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114224924774.png" alt=""></p>
<h3 id="Summary-4"><a href="#Summary-4" class="headerlink" title="Summary"></a>Summary</h3><ul>
<li>PageRank solves for 𝒓 = 𝑮𝒓 and can be  efficiently computed by power iteration of the  stochastic adjacency matrix (𝑮)  </li>
<li>Adding random uniform teleportation solves  issues of dead-ends and spider-traps</li>
</ul>
<h2 id="Random-Walk-with-Restarts-and-Personalized-Pagerank"><a href="#Random-Walk-with-Restarts-and-Personalized-Pagerank" class="headerlink" title="Random Walk with Restarts and Personalized Pagerank"></a>Random Walk with Restarts and Personalized Pagerank</h2><h3 id="Example-Recommendation"><a href="#Example-Recommendation" class="headerlink" title="Example: Recommendation"></a>Example: Recommendation</h3><p>Given:  A bipartite graph representing user and item  interactions (e.g. purchase) </p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114225052686.png" alt=""></p>
<p>Goal: Proximity on graphs </p>
<ul>
<li>What items should we recommend to a user who  interacts with item Q? </li>
<li>Intuition: if items Q and P are interacted by similar  users, recommend P when user interacts with Q</li>
</ul>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114225134281.png" alt=""></p>
<p>Which is more related A,A’ or B,B’?</p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114225159496.png" alt=""></p>
<h3 id="Node-proximity-Measurements"><a href="#Node-proximity-Measurements" class="headerlink" title="Node proximity Measurements"></a>Node proximity Measurements</h3><p>Which is more related A,A’, B,B’ or C,C’?</p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114225227419.png" alt=""></p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114225246889.png" alt=""></p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114225258445.png" alt=""></p>
<h3 id="Proximity-on-Graphs"><a href="#Proximity-on-Graphs" class="headerlink" title="Proximity on Graphs"></a>Proximity on Graphs</h3><p>PageRank: </p>
<ul>
<li>Ranks nodes by “importance” </li>
<li>Teleports(传送) with uniform probability to any node in  the network </li>
</ul>
<p>Personalized PageRank: </p>
<ul>
<li>Ranks proximity of nodes to the teleport nodes 𝑺 </li>
</ul>
<p>Proximity(接近) on graphs: </p>
<ul>
<li>Q: What is most related item to Item Q? </li>
<li>Random Walks with Restarts <ul>
<li>Teleport back to the starting node: 𝑺 = {𝑸}</li>
</ul>
</li>
</ul>
<h3 id="Idea-Random-Walks"><a href="#Idea-Random-Walks" class="headerlink" title="Idea: Random Walks"></a>Idea: Random Walks</h3><ul>
<li>Idea <ul>
<li>Every node has some importance </li>
<li>Importance gets evenly split among all edges and  pushed to the neighbors: </li>
</ul>
</li>
<li>Given a set of QUERY_NODES, we simulate a  random walk: <ul>
<li>Make a step to a random neighbor and record the visit  (visit count) </li>
<li>With probability ALPHA, restart the walk at one of the  QUERY_NODES </li>
<li>The nodes with the highest visit count have highest  proximity to the QUERY_NODES</li>
</ul>
</li>
</ul>
<p>Idea: </p>
<ul>
<li>Every node has some importance <ul>
<li>Importance gets evenly split among all edges and  pushed to the neighbors </li>
<li>Given a set of QUERY NODES Q, simulate a  random walk:</li>
</ul>
</li>
</ul>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114230011267.png" alt=""></p>
<h3 id="Random-Walk-Algorithm"><a href="#Random-Walk-Algorithm" class="headerlink" title="Random Walk Algorithm"></a>Random Walk Algorithm</h3><p><img src="/images/loading.gif" data-original="../images/ML/image-20211114230036155.png" alt=""></p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114230058590.png" alt=""></p>
<h3 id="Benefits"><a href="#Benefits" class="headerlink" title="Benefits"></a>Benefits</h3><p>Why is this a good solution? </p>
<p>Because the “similarity” considers: </p>
<ul>
<li>Multiple connections </li>
<li>Multiple paths </li>
<li>Direct and indirect connections </li>
<li>Degree of the node</li>
</ul>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114230143054.png" alt=""></p>
<h3 id="Summary-Page-Rank-Variants"><a href="#Summary-Page-Rank-Variants" class="headerlink" title="Summary: Page Rank Variants"></a>Summary: Page Rank Variants</h3><ul>
<li><p>PageRank: </p>
<ul>
<li>Teleports to any node </li>
<li>Nodes can have the same probability of the surfer landing: 𝑺 = [0.1,0.1,0.1, 0.1,0.1,0.1, 0.1,0.1,0.1, 0.1] </li>
</ul>
</li>
<li><p>Topic-Specific PageRank aka Personalized PageRank: </p>
<ul>
<li>Teleports to a specific set of nodes </li>
<li>Nodes can have different probabilities of the surfer landing  there: 𝑺 = [0.1,0, 0,0.2, 0, 0,0.5,0,0, 0.2] </li>
</ul>
</li>
<li><p>Random Walk with Restarts: </p>
<ul>
<li>Topic-Specific PageRank where teleport is always to the same  node: 𝑺 = [0,0, 0,0, 𝟏, 0, 0, 0, 0, 0,0]</li>
</ul>
</li>
</ul>
<ul>
<li>A graph is naturally represented as a matrix </li>
<li>We defined a random walk process over the  graph <ul>
<li>Random surfer moving across the links and with  random teleportation </li>
<li>Stochastic adjacency matrix M </li>
</ul>
</li>
<li>PageRank = Limiting distribution of the surfer  location represented node importance <ul>
<li>Corresponds to the leading eigenvector of  transformed adjacency matrix M.</li>
</ul>
</li>
</ul>
<h2 id="Matrix-Factorization-and-Node-Embeddings"><a href="#Matrix-Factorization-and-Node-Embeddings" class="headerlink" title="Matrix Factorization and Node Embeddings"></a>Matrix Factorization and Node Embeddings</h2><h3 id="Embeddings-Matrix-Factorization-因式分解"><a href="#Embeddings-Matrix-Factorization-因式分解" class="headerlink" title="Embeddings Matrix Factorization(因式分解)"></a>Embeddings Matrix Factorization(因式分解)</h3><p>Recall: encoder as an embedding lookup</p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114230445458.png" alt=""></p>
<h3 id="Connection-to-Matrix-Factorization"><a href="#Connection-to-Matrix-Factorization" class="headerlink" title="Connection to Matrix Factorization"></a>Connection to Matrix Factorization</h3><p><img src="/images/loading.gif" data-original="../images/ML/image-20211114230551299.png" alt=""></p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114230605362.png" alt=""></p>
<h3 id="Random-Walk-based-Similarity"><a href="#Random-Walk-based-Similarity" class="headerlink" title="Random Walk-based Similarity"></a>Random Walk-based Similarity</h3><ul>
<li>DeepWalk and node2vec have a more  complex node similarity definition based on  random walks </li>
<li>DeepWalk is equivalent to matrix  factorization of the following complex matrix  expression:</li>
</ul>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114230645556.png" alt=""></p>
<p><a href="https://keg.cs.tsinghua.edu.cn/jietang/publications/WSDM18-Qiu-et-al-NetMF-network-embedding.pdf" target="_blank" rel="noopener">Network Embedding as Matrix Factorization: Unifying DeepWalk, LINE, PTE, and node2vec, WSDM 18</a></p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114230726746.png" alt=""></p>
<p>Node2vec can also be formulated as a matrix  factorization (albeit a more complex matrix)</p>
<h3 id="Limitations"><a href="#Limitations" class="headerlink" title="Limitations"></a>Limitations</h3><p>Limitations of node embeddings via matrix  factorization and random walks </p>
<ul>
<li>Cannot obtain embeddings for nodes not in the  training set</li>
</ul>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114230810157.png" alt=""></p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114230825196.png" alt=""></p>
<ul>
<li>Node 1 and 11 are structurally similar – part of  one triangle, degree 2, … </li>
<li>However, they have very different embeddings. <ul>
<li>It’s unlikely that a random walk will reach  node 11 from node 1. </li>
</ul>
</li>
<li>DeepWalk and node2vec do not capture  structural similarity.</li>
<li>Cannot utilize node, edge and graph features</li>
</ul>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211114230907768.png" alt=""></p>
<p>Solution to these limitations: Deep Representation  Learning and Graph Neural Networks </p>
<h3 id="Summary-5"><a href="#Summary-5" class="headerlink" title="Summary"></a>Summary</h3><ul>
<li>PageRank <ul>
<li>Measures importance of nodes in graph </li>
<li>Can be efficiently computed by power iteration of  adjacency matrix </li>
</ul>
</li>
<li>Personalized PageRank (PPR) <ul>
<li>Measures importance of nodes with respect to a  particular node or set of nodes </li>
<li>Can be efficiently computed by random walk </li>
</ul>
</li>
<li>Node embeddings based on random walks can  be expressed as matrix factorization </li>
<li>Viewing graphs as matrices plays a key role in all  above algorithms!</li>
</ul>
<h1 id="Message-Passing-and-Node-Classification"><a href="#Message-Passing-and-Node-Classification" class="headerlink" title="Message Passing and Node Classification"></a>Message Passing and Node Classification</h1><h2 id="Example-Node-Classification"><a href="#Example-Node-Classification" class="headerlink" title="Example Node Classification"></a>Example Node Classification</h2><p><img src="/images/loading.gif" data-original="../images/ML/image-20211116225627573.png" alt=""></p>
<ul>
<li>Given labels of some nodes </li>
<li>Let’s predict labels of unlabeled nodes </li>
<li>This is called <strong>semi-supervised node classification</strong></li>
</ul>
<h3 id="Correlations-相关性-Exist-in-Networks"><a href="#Correlations-相关性-Exist-in-Networks" class="headerlink" title="Correlations(相关性) Exist in Networks"></a>Correlations(相关性) Exist in Networks</h3><ul>
<li><p>Behaviors of nodes are correlated across the  links of the network </p>
</li>
<li><p>Correlation: Nearby nodes have the same  color (belonging to the same class)</p>
</li>
<li><p>Two explanations for why behaviors of nodes  in networks are correlated:</p>
</li>
</ul>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211116225929813.png" alt=""></p>
<h3 id="Social-Homophily-趋同性"><a href="#Social-Homophily-趋同性" class="headerlink" title="Social Homophily(趋同性)"></a>Social Homophily(趋同性)</h3><ul>
<li>Homophily: The tendency of  individuals to associate and bond  with similar others <ul>
<li>“Birds of a feather flock together”</li>
<li>It has been observed in a vast array of  network studies, based on a variety of  attributes (e.g., age, gender,  organizational role, etc.) </li>
<li>Example: Researchers who focus on  the same research area are more likely  to establish a connection (meeting at  conferences, interacting in academic  talks, etc.)</li>
</ul>
</li>
</ul>
<p><strong>Example of homophily</strong> </p>
<ul>
<li>Online social network <ul>
<li>Nodes = people</li>
<li>Edges = friendship</li>
<li>Node color = interests  (sports, arts, etc.)</li>
</ul>
</li>
<li>People with the same  interest are more closely  connected due to  homophily</li>
</ul>
<h3 id="Social-Influence-Example"><a href="#Social-Influence-Example" class="headerlink" title="Social Influence Example"></a>Social Influence Example</h3><ul>
<li>Influence: Social connections can  influence the individual  characteristics of a person. <ul>
<li>Example: I recommend my musical  preferences to my friends, until one of  them grows to like my same favorite  genres!</li>
</ul>
</li>
</ul>
<h2 id="How-do-we-leverage-node-correlations-in-networks"><a href="#How-do-we-leverage-node-correlations-in-networks" class="headerlink" title="How do we leverage node correlations in networks?"></a>How do we leverage node correlations in networks?</h2><h3 id="Classification-with-Network-Data"><a href="#Classification-with-Network-Data" class="headerlink" title="Classification with Network Data"></a>Classification with Network Data</h3><p>How do we leverage(影响力) this correlation observed  in networks to help predict node labels?</p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211116230602159.png" alt=""></p>
<p>How do we predict the labels for the nodes in grey?</p>
<h3 id="Motivation"><a href="#Motivation" class="headerlink" title="Motivation"></a>Motivation</h3><ul>
<li><p>Similar nodes are typically close together or  directly connected in the network: </p>
<ul>
<li>Guilt-by-association: If I am connected to a  node with label X, then I am likely to have  label X as well. </li>
<li>Example: Malicious/benign web page: Malicious web pages link to one another to  increase visibility, look credible, and rank  higher in search engines</li>
</ul>
</li>
<li><p>Classification label of a node v in network  may depend on: </p>
<ul>
<li>Features of v </li>
<li>Labels of the nodes in v’s neighborhood </li>
<li>Features of the nodes in v’s neighborhood</li>
</ul>
</li>
</ul>
<h3 id="Semi-supervised-Learning"><a href="#Semi-supervised-Learning" class="headerlink" title="Semi-supervised Learning"></a>Semi-supervised Learning</h3><ul>
<li><p>Formal setting: </p>
<ul>
<li>Given:  <ul>
<li>Graph </li>
<li>Few labeled nodes </li>
</ul>
</li>
<li>Find: Class (red/green) of  remaining nodes </li>
<li>Main assumption: There is  homophily in the network</li>
</ul>
</li>
<li><p>Example task:</p>
</li>
</ul>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211116230940679.png" alt=""></p>
<h4 id="Problem-Setting"><a href="#Problem-Setting" class="headerlink" title="Problem Setting"></a>Problem Setting</h4><p><img src="/images/loading.gif" data-original="../images/ML/image-20211116231029875.png" alt=""></p>
<h4 id="Example-applications"><a href="#Example-applications" class="headerlink" title="Example applications"></a>Example applications</h4><ul>
<li>Many applications under this setting: <ul>
<li>Document classification  </li>
<li>Part of speech tagging  </li>
<li>Link prediction  </li>
<li>Optical character recognition  </li>
<li>Image/3D data segmentation  </li>
<li>Entity resolution in sensor networks  </li>
<li>Spam and fraud detection</li>
</ul>
</li>
</ul>
<p>We focus on semi-supervised binary node classification </p>
<p>We will introduce three approaches: </p>
<ul>
<li><strong>Relational classification</strong> </li>
<li><strong>Iterative classification</strong> </li>
<li><strong>Correct &amp; Smooth</strong></li>
</ul>
<h2 id="Relational-Classification"><a href="#Relational-Classification" class="headerlink" title="Relational Classification"></a>Relational Classification</h2><h3 id="Probabilistic-Relational-Classifier"><a href="#Probabilistic-Relational-Classifier" class="headerlink" title="Probabilistic Relational Classifier"></a>Probabilistic Relational Classifier</h3><p><img src="/images/loading.gif" data-original="../images/ML/image-20211116231427817.png" alt=""></p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211116231506341.png" alt=""></p>
<p>Challenges: </p>
<ul>
<li>Convergence is not guaranteed </li>
<li>Model cannot use node feature information</li>
</ul>
<h3 id="Example-Initialization"><a href="#Example-Initialization" class="headerlink" title="Example: Initialization"></a>Example: Initialization</h3><p>Initialization: </p>
<ul>
<li>All labeled nodes with their labels </li>
<li>All unlabeled nodes 0.5 (belonging to class 1 with  probability 0.5)</li>
</ul>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211116231641765.png" alt=""></p>
<h3 id="Example-lst-Iteration-Update-Node"><a href="#Example-lst-Iteration-Update-Node" class="headerlink" title="Example: lst Iteration, Update Node"></a>Example: lst Iteration, Update Node</h3><p><img src="/images/loading.gif" data-original="../images/ML/image-20211116231741748.png" alt=""></p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211116231846430.png" alt=""></p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211116231924192.png" alt=""></p>
<h3 id="Example-After-1st-Iteration"><a href="#Example-After-1st-Iteration" class="headerlink" title="Example: After 1st Iteration"></a>Example: After 1st Iteration</h3><p>After Iteration 1 (a round of updates for all  unlabeled nodes)</p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211116232015529.png" alt=""></p>
<h3 id="Example-After-2nd-Iteration"><a href="#Example-After-2nd-Iteration" class="headerlink" title="Example: After 2nd Iteration"></a>Example: After 2nd Iteration</h3><p><img src="/images/loading.gif" data-original="../images/ML/image-20211116232051667.png" alt=""></p>
<h3 id="Example-After-3-Iteration"><a href="#Example-After-3-Iteration" class="headerlink" title="Example: After 3] Iteration"></a>Example: After 3] Iteration</h3><p><img src="/images/loading.gif" data-original="../images/ML/image-20211116232207605.png" alt=""></p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211116232229830.png" alt=""></p>
<h3 id="Convergence"><a href="#Convergence" class="headerlink" title="Convergence"></a>Convergence</h3><p><img src="/images/loading.gif" data-original="../images/ML/image-20211116232257216.png" alt=""></p>
<h2 id="Iterative-迭代的-Classification"><a href="#Iterative-迭代的-Classification" class="headerlink" title="Iterative(迭代的) Classification"></a>Iterative(迭代的) Classification</h2><p>Relational classifier does not use node  attributes.  </p>
<p>How can one leverage them?</p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211116232406683.png" alt=""></p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211116232421194.png" alt=""></p>
<h3 id="Computing-the-Summary-Z-v"><a href="#Computing-the-Summary-Z-v" class="headerlink" title="Computing the Summary Z_v"></a>Computing the Summary Z_v</h3><p><img src="/images/loading.gif" data-original="../images/ML/image-20211116232625455.png" alt=""></p>
<h3 id="Architecture-of-Iterative-Classifiers"><a href="#Architecture-of-Iterative-Classifiers" class="headerlink" title="Architecture of Iterative Classifiers"></a>Architecture of Iterative Classifiers</h3><p><img src="/images/loading.gif" data-original="../images/ML/image-20211116232728306.png" alt=""></p>
<h3 id="Example-Web-Page-Classification"><a href="#Example-Web-Page-Classification" class="headerlink" title="Example: Web Page Classification"></a>Example: Web Page Classification</h3><ul>
<li>Input: Graph of web pages </li>
<li>Node: Web page </li>
<li>Edge: Hyper-link between web pages </li>
<li>Directed edge: a page points to another page <ul>
<li>Node features: Webpage description </li>
</ul>
</li>
<li>For simplicity, we only consider two binary features <ul>
<li>Task: Predict the topic of the webpage</li>
</ul>
</li>
</ul>
<p>Baseline: Train a classifier (e.g., linear classifier) to  classify pages based on node attributes</p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211116232938924.png" alt=""></p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211116232956241.png" alt=""></p>
<h3 id="Iterative-Classifier"><a href="#Iterative-Classifier" class="headerlink" title="Iterative Classifier"></a>Iterative Classifier</h3><h4 id="step-1"><a href="#step-1" class="headerlink" title="step 1"></a>step 1</h4><p><img src="/images/loading.gif" data-original="../images/ML/image-20211116233242445.png" alt=""></p>
<h4 id="step-2"><a href="#step-2" class="headerlink" title="step 2"></a>step 2</h4><p><img src="/images/loading.gif" data-original="../images/ML/image-20211116233317039.png" alt=""></p>
<h4 id="step-3-1"><a href="#step-3-1" class="headerlink" title="step 3. 1"></a>step 3. 1<img src="/images/loading.gif" data-original="../images/ML/image-20211116233349992.png" alt=""></h4><h4 id="step-3-2"><a href="#step-3-2" class="headerlink" title="step 3. 2"></a>step 3. 2<img src="/images/loading.gif" data-original="../images/ML/image-20211116233427721.png" alt=""></h4><p><img src="/images/loading.gif" data-original="../images/ML/image-20211116233537476.png" alt=""></p>
<h4 id="Final-Prediction"><a href="#Final-Prediction" class="headerlink" title="Final Prediction"></a>Final Prediction</h4><p><img src="/images/loading.gif" data-original="../images/ML/image-20211116233603237.png" alt=""></p>
<h3 id="Summary-6"><a href="#Summary-6" class="headerlink" title="Summary"></a>Summary</h3><ul>
<li>We talked about 2 approaches to collective  classification </li>
<li>Relational classification <ul>
<li>Iteratively update probabilities of node belonging  to a label class based on its neighbors </li>
</ul>
</li>
<li>Iterative classification <ul>
<li>Improve over collective classification to handle  attribute/feature information </li>
<li>Classify node v based on its features as well as  labels of neighbors</li>
</ul>
</li>
</ul>
<h2 id="Collective-Classification-Correct-amp-Smooth"><a href="#Collective-Classification-Correct-amp-Smooth" class="headerlink" title="Collective Classification Correct &amp; Smooth"></a>Collective Classification Correct &amp; Smooth</h2><h3 id="Correct-amp-Smooth"><a href="#Correct-amp-Smooth" class="headerlink" title="Correct &amp; Smooth"></a>Correct &amp; Smooth</h3><p><a href="https://arxiv.org/abs/2010.13993" target="_blank" rel="noopener">Combining Label Propagation and Simple Models Out-performs Graph Neural Networks</a></p>
<p><a href="https://ogb.stanford.edu/docs/leader_nodeprop/" target="_blank" rel="noopener">OGB leaderboard</a> snapshot at Oct 1st, 2021</p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211116233952486.png" alt=""></p>
<p>Setting: A partially labeled graph and features  over nodes.</p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211116234021971.png" alt=""></p>
<p>C&amp;S follows the three-step procedure: </p>
<ol>
<li>Train base predictor </li>
<li>Use the base predictor to predict soft labels of all nodes. </li>
<li>Post-process the predictions using graph structure to  obtain the final predictions of all nodes.</li>
</ol>
<h3 id="Train-Base-Predictor"><a href="#Train-Base-Predictor" class="headerlink" title="Train Base Predictor"></a>Train Base Predictor</h3><p>Train a base predictor that predict soft  labels (class probabilities) over all nodes. </p>
<ul>
<li>Labeled nodes are used for train/validation data. </li>
<li>Base predictor can be simple: <ul>
<li>Linear model/Multi-Layer-Perceptron(MLP) over node  features</li>
</ul>
</li>
</ul>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211116234148551.png" alt=""></p>
<h3 id="Predict-Over-All-Nodes"><a href="#Predict-Over-All-Nodes" class="headerlink" title="Predict Over All Nodes"></a>Predict Over All Nodes</h3><p>Given a trained base predictor, we apply it  to obtain soft labels for all the nodes. </p>
<ul>
<li>We expect these soft labels to be decently accurate. </li>
<li>Can we use graph structure to post-process the  predictions to make them more accurate?</li>
</ul>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211116234246360.png" alt=""></p>
<h3 id="Post-process-Predictions"><a href="#Post-process-Predictions" class="headerlink" title="Post-process Predictions"></a>Post-process Predictions</h3><p>C&amp;S uses the 2-step procedure to post-process the soft predictions. </p>
<ol>
<li>Correct step</li>
<li>Smooth step</li>
</ol>
<h3 id="C-amp-S-Post-processing-Correct-Step"><a href="#C-amp-S-Post-processing-Correct-Step" class="headerlink" title="C&amp;S Post-processing: Correct Step"></a>C&amp;S Post-processing: Correct Step</h3><ul>
<li>The key idea is that we expect errors in the base  prediction to be positively correlated along  edges in the graph.  </li>
<li>In other words, an error at node u increases the  chance of a similar error at neighbors of u.  </li>
<li>Thus, we should “spread” such uncertainty over the  graph</li>
</ul>
<h3 id="Intuition-of-Correct-amp-Smooth"><a href="#Intuition-of-Correct-amp-Smooth" class="headerlink" title="Intuition of Correct &amp; Smooth"></a>Intuition of Correct &amp; Smooth</h3><p><img src="/images/loading.gif" data-original="../images/ML/image-20211116234441693.png" alt=""></p>
<h3 id="Correct-Step"><a href="#Correct-Step" class="headerlink" title="Correct Step"></a>Correct Step</h3><ul>
<li>Compute training errors of nodes. <ul>
<li>Training error: Ground-truth label minus soft label.  Defined as 0 for unlabeled nodes.</li>
</ul>
</li>
</ul>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211116234544537.png" alt=""></p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211116234836282.png" alt=""></p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211116234914939.png" alt=""></p>
<p><a href="https://mlg.eng.cam.ac.uk/zoubin/papers/zgl.pdf" target="_blank" rel="noopener">Zhu et al. ICML 2013</a></p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211116234952059.png" alt=""></p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211116235007332.png" alt=""></p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211116235025205.png" alt=""></p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211116235042742.png" alt=""></p>
<h3 id="Smooth-Step"><a href="#Smooth-Step" class="headerlink" title="Smooth Step"></a>Smooth Step</h3><ul>
<li>Smoothen the corrected soft labels along the  edges. <ul>
<li>Assumption: Neighboring nodes tend to share the  same labels.  </li>
<li>Note: For training nodes, we use the ground-truth  hard labels instead of the soft labels.</li>
</ul>
</li>
</ul>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211116235129283.png" alt=""></p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211116235142063.png" alt=""></p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211116235155937.png" alt=""></p>
<h3 id="Toy-Example-Summary"><a href="#Toy-Example-Summary" class="headerlink" title="Toy Example Summary"></a>Toy Example Summary</h3><p>Our toy example shows that C&amp;S successfully  improves base model performance using  graph structure.</p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211116235223544.png" alt=""></p>
<h3 id="C-amp-S-on-a-Real-world-Dataset"><a href="#C-amp-S-on-a-Real-world-Dataset" class="headerlink" title="C&amp;S on a Real-world Dataset"></a>C&amp;S on a Real-world Dataset</h3><p>C&amp;S significantly improves the performance  of the base model (MLP). </p>
<p>C&amp;S outperforms Smooth-only (no correct  step) baseline.</p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20211116235256008.png" alt=""></p>
<h3 id="Summary-7"><a href="#Summary-7" class="headerlink" title="Summary"></a>Summary</h3><ul>
<li>Correct &amp; Smooth (C&amp;S) uses graph structure  to post-process the soft node labels predicted  by any base model. </li>
<li><strong>Correction step</strong>: Diffuse and correct for the  training errors of the base predictor. </li>
<li><strong>Smooth step</strong>: Smoothen the prediction of the  base predictor. </li>
<li>C&amp;S achieves strong performance on semisupervised node classification</li>
</ul>
<p>We learned how to leverage correlation in  graphs to make prediction on nodes. </p>
<p>Key techniques: </p>
<ul>
<li><strong>Relational classification</strong> </li>
<li><strong>Iterative classification</strong> </li>
<li><strong>Correct &amp; Smooth</strong></li>
</ul>
<h1 id="Graph-Neural-Networks"><a href="#Graph-Neural-Networks" class="headerlink" title="Graph Neural Networks"></a>Graph Neural Networks</h1><h2 id="Basics-of-Deep-Learning"><a href="#Basics-of-Deep-Learning" class="headerlink" title="Basics of Deep Learning"></a>Basics of Deep Learning</h2><h2 id="Deep-Learning-for-Graphs"><a href="#Deep-Learning-for-Graphs" class="headerlink" title="Deep Learning for Graphs"></a>Deep Learning for Graphs</h2><h3 id="Content"><a href="#Content" class="headerlink" title="Content"></a>Content</h3><ul>
<li>Local network neighborhoods: <ul>
<li>Describe aggregation strategies </li>
<li>Define computation graphs </li>
</ul>
</li>
<li>Stacking multiple layers: <ul>
<li>Describe the model, parameters, training </li>
<li>How to fit the model? </li>
<li>Simple example for unsupervised and  supervised training</li>
</ul>
</li>
</ul>
<h3 id="Setup-1"><a href="#Setup-1" class="headerlink" title="Setup"></a>Setup</h3><p><img src="/images/loading.gif" data-original="../images/basic/image-20211118160355282.png" alt=""></p>
<h3 id="A-Naive-Approach"><a href="#A-Naive-Approach" class="headerlink" title="A Naive Approach"></a>A Naive Approach</h3><ul>
<li>Join adjacency matrix and features </li>
<li>Feed them into a deep neural net:</li>
</ul>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211118160533035.png" alt=""></p>
<p>Issues with this idea: </p>
<ul>
<li>O(|V|) parameters </li>
<li>Not applicable to graphs of different sizes </li>
<li>Sensitive to node ordering</li>
</ul>
<h3 id="Idea-Convolutional-Networks"><a href="#Idea-Convolutional-Networks" class="headerlink" title="Idea: Convolutional Networks"></a>Idea: Convolutional Networks</h3><p>Goal is to generalize convolutions beyond simple lattices（格子） </p>
<p>Leverage node features/attributes (e.g., text, images)</p>
<h3 id="Real-world-Graphs"><a href="#Real-world-Graphs" class="headerlink" title="Real-world Graphs"></a><img src="/images/loading.gif" data-original="../images/basic/image-20211118160820640.png" alt="">Real-world Graphs</h3><p>But our graphs look like this:</p>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211118160936978.png" alt=""></p>
<p>There is no fixed notion of locality or sliding  window on the graph </p>
<p>Graph is permutation invariant</p>
<h3 id="Permutation-Invariance（置换不变性）"><a href="#Permutation-Invariance（置换不变性）" class="headerlink" title="Permutation Invariance（置换不变性）"></a><strong>Permutation Invariance（置换不变性）</strong></h3><ul>
<li>Graph does not have a canonical order of the nodes! </li>
<li>We can have many different order plans.</li>
</ul>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211118161107818.png" alt=""></p>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211118161127139.png" alt=""></p>
<p>Graph and node representations  should be the same for Order plan 1 and Order plan 2</p>
<p>What does it mean by “graph representation is  same for two order plans”?</p>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211118161207951.png" alt=""></p>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211118171943856.png" alt=""></p>
<h3 id="Permutation-Equivariance（置换等变）"><a href="#Permutation-Equivariance（置换等变）" class="headerlink" title="Permutation Equivariance（置换等变）"></a>Permutation Equivariance（置换等变）</h3><p><img src="/images/loading.gif" data-original="../images/basic/image-20211118172015343.png" alt="">For node representation</p>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211118172455838.png" alt=""></p>
<h3 id="Graph-Neural-Network-Overview"><a href="#Graph-Neural-Network-Overview" class="headerlink" title="Graph Neural Network Overview"></a>Graph Neural Network Overview</h3><p>Graph neural networks consist of multiple  permutation equivariant / invariant functions</p>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211118172659819.png" alt=""></p>
<p>Next: Design graph neural  networks that are permutation  invariant / equivariant by  passing and aggregating  information from neighbors</p>
<h2 id="Graph-Convolutional-Networks"><a href="#Graph-Convolutional-Networks" class="headerlink" title="Graph Convolutional Networks"></a>Graph Convolutional Networks</h2><p>Idea: Node’s neighborhood defines a  computation graph</p>
<p>Learn how to propagate information across the  graph to compute node features</p>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211118173222021.png" alt=""></p>
<h3 id="Idea-Aggregate-Neiahbors"><a href="#Idea-Aggregate-Neiahbors" class="headerlink" title="Idea: Aggregate Neiahbors"></a>Idea: Aggregate Neiahbors</h3><p>Key idea: Generate node embeddings based  on local network neighborhoods</p>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211118173341846.png" alt=""></p>
<p>Intuition: Nodes aggregate information from  their neighbors using neural networks</p>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211118173504017.png" alt=""></p>
<h3 id="Deep-Model-Many-Layers"><a href="#Deep-Model-Many-Layers" class="headerlink" title="Deep Model: Many Layers"></a>Deep Model: Many Layers</h3><p>Model can be of arbitrary depth: </p>
<p>Nodes have embeddings at each layer </p>
<p>Layer-0 embedding of node v is its input feature, x_v </p>
<p>Layer-k embedding gets information from nodes that are k hops away</p>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211118173642097.png" alt=""></p>
<h3 id="Neighborhood-Aggregation-聚集"><a href="#Neighborhood-Aggregation-聚集" class="headerlink" title="Neighborhood Aggregation(聚集)"></a>Neighborhood Aggregation(聚集)</h3><p>Neighborhood aggregation: Key distinctions  are in how different approaches aggregate  information across the layers</p>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211118173805151.png" alt=""></p>
<p>Basic approach: Average information from  neighbors and apply a neural network</p>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211118173840669.png" alt=""></p>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211118173904027.png" alt=""></p>
<h3 id="Equivariant-Property"><a href="#Equivariant-Property" class="headerlink" title="Equivariant Property"></a>Equivariant Property</h3><p><img src="/images/loading.gif" data-original="../images/basic/image-20211118174540447.png" alt=""></p>
<p>The target node (blue) has  the same computation graph  for different order plans</p>
<h3 id="Training-the-Model"><a href="#Training-the-Model" class="headerlink" title="Training the Model"></a>Training the Model</h3><p><img src="/images/loading.gif" data-original="../images/basic/image-20211118174741645.png" alt=""></p>
<p>Need to define a loss function on the embeddings.</p>
<h3 id="Model-Parameters"><a href="#Model-Parameters" class="headerlink" title="Model Parameters"></a>Model Parameters</h3><p><img src="/images/loading.gif" data-original="../images/basic/image-20211118174912365.png" alt=""></p>
<h3 id="Matrix-Formulation"><a href="#Matrix-Formulation" class="headerlink" title="Matrix Formulation"></a>Matrix Formulation</h3><p>Many aggregations can be performed  efficiently by (sparse) matrix operations</p>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211118175202660.png" alt=""></p>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211118175300420.png" alt=""></p>
<p>Note: not all GNNs can be expressed in matrix form, when  aggregation function is complex</p>
<h3 id="How-to-Train-A-GNN"><a href="#How-to-Train-A-GNN" class="headerlink" title="How to Train A GNN"></a>How to Train A GNN</h3><p><img src="/images/loading.gif" data-original="../images/basic/image-20211118175458003.png" alt=""></p>
<h4 id="Unsupervised-Training"><a href="#Unsupervised-Training" class="headerlink" title="Unsupervised Training"></a>Unsupervised Training</h4><p><img src="/images/loading.gif" data-original="../images/basic/image-20211118175554816.png" alt=""></p>
<p>Node similarity can be anything from  Lecture 3, e.g., a loss based on: </p>
<ul>
<li>Random walks (node2vec, DeepWalk, struc2vec) </li>
<li>Matrix factorization </li>
<li>Node proximity in the grap</li>
</ul>
<h4 id="Supervised-Training"><a href="#Supervised-Training" class="headerlink" title="Supervised Training"></a>Supervised Training</h4><p>Directly train the model for a supervised task  (e.g., node classification)</p>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211118175707510.png" alt=""></p>
<p>Directly train the model for a supervised task  (e.g., node classification) </p>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211118175750731.png" alt=""></p>
<h3 id="Model-Design-Overview"><a href="#Model-Design-Overview" class="headerlink" title="Model Design: Overview"></a>Model Design: Overview</h3><p><img src="/images/loading.gif" data-original="../images/basic/image-20211118175855277.png" alt=""></p>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211118175932975.png" alt=""></p>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211118175959015.png" alt=""></p>
<h3 id="Inductive-Capability"><a href="#Inductive-Capability" class="headerlink" title="Inductive Capability"></a>Inductive Capability</h3><p>The same aggregation parameters are shared  for all nodes: </p>
<ul>
<li><p>The number of model parameters is sublinear in  |V| and we can <strong>generalize to unseen nodes</strong>!</p>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211118180108993.png" alt=""></p>
</li>
</ul>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211118180222936.png" alt=""></p>
<p>Inductive node embedding  =&gt; Generalize to entirely unseen graphs </p>
<p>E.g., train on protein interaction graph from model organism A and generate  embeddings on newly collected data about organism B</p>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211118180326559.png" alt=""></p>
<p>Many application settings constantly encounter  previously unseen nodes: </p>
<ul>
<li>E.g., Reddit, YouTube, Google Scholar </li>
</ul>
<p>Need to generate new embeddings “on the fly”</p>
<h2 id="GNNs-subsume-CNNs-and-Transformers"><a href="#GNNs-subsume-CNNs-and-Transformers" class="headerlink" title="GNNs subsume CNNs and  Transformers"></a>GNNs subsume CNNs and  Transformers</h2><h3 id="Architecture-Comparison"><a href="#Architecture-Comparison" class="headerlink" title="Architecture Comparison"></a>Architecture Comparison</h3><p>How does GNNs compare to prominent  architectures such as Convolutional Neural  Nets, and Transformers?</p>
<h3 id="GNN-VS-CNN"><a href="#GNN-VS-CNN" class="headerlink" title="GNN VS. CNN"></a>GNN VS. CNN</h3><p><img src="/images/loading.gif" data-original="../images/basic/image-20211118180612722.png" alt=""></p>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211118180749671.png" alt=""></p>
<p>CNN can be seen as a special GNN with fixed neighbor  size and ordering: </p>
<ul>
<li>The size of the filter is pre-defined for a CNN. </li>
<li>The advantage of GNN is it processes arbitrary  graphs with different degrees for each node</li>
</ul>
<p>CNN is not permutation equivariant. </p>
<ul>
<li>Switching the order of pixels will leads to different  outputs</li>
</ul>
<h3 id="Transformer"><a href="#Transformer" class="headerlink" title="Transformer"></a>Transformer</h3><p>[Attention is all you need. Vaswani et al., NeurIPS 2017]</p>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211118181019045.png" alt=""></p>
<h3 id="GNN-vs-Transformer"><a href="#GNN-vs-Transformer" class="headerlink" title="GNN vs, Transformer"></a>GNN vs, Transformer</h3><p>A nice blog plot for this: <a href="https://towardsdatascience.com/transformers-are-graph-neural-networks-bca9f75412aa" target="_blank" rel="noopener">https://towardsdatascience.com/transformers-are-graph-neural-networks-bca9f75412aa</a></p>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211118181135494.png" alt=""></p>
<h3 id="Summary-8"><a href="#Summary-8" class="headerlink" title="Summary"></a>Summary</h3><ul>
<li>Basics of neural networks <ul>
<li>Loss, Optimization, Gradient, SGD, non-linearity, MLP</li>
</ul>
</li>
<li>Idea for Deep Learning for Graphs <ul>
<li>Multiple layers of embedding transformation </li>
<li>At every layer, use the embedding at previous layer as  the input </li>
<li>Aggregation of neighbors and self-embeddings </li>
</ul>
</li>
<li>Graph Convolutional Network <ul>
<li>Mean aggregation; can be expressed in matrix form </li>
</ul>
</li>
<li>GNN is a general architecture <ul>
<li>CNN and Transformer can be viewed as a special GNN</li>
</ul>
</li>
</ul>
<h1 id="Graph-Neural-Networks-2"><a href="#Graph-Neural-Networks-2" class="headerlink" title="Graph Neural Networks[2]"></a>Graph Neural Networks[2]</h1><h2 id="A-General-Perspective-on-Graph-Neural-Networks"><a href="#A-General-Perspective-on-Graph-Neural-Networks" class="headerlink" title="A General Perspective on Graph Neural Networks"></a>A General Perspective on Graph Neural Networks</h2><h3 id="A-Genera-GNN-Framework"><a href="#A-Genera-GNN-Framework" class="headerlink" title="A Genera GNN Framework"></a>A Genera GNN Framework</h3><p><a href="https://arxiv.org/pdf/2011.08843.pdf" target="_blank" rel="noopener">J. You, R. Ying, J. Leskovec. Design Space of Graph Neural Networks, NeurIPS 2020</a></p>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211118181625296.png" alt=""></p>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211118181708448.png" alt=""></p>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211118181736747.png" alt=""></p>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211118181750672.png" alt=""></p>
<h3 id="Summary-9"><a href="#Summary-9" class="headerlink" title="Summary"></a>Summary</h3><p><img src="/images/loading.gif" data-original="../images/basic/image-20211118181828938.png" alt=""></p>
<h2 id="A-Single-Layer-of-a-GNN"><a href="#A-Single-Layer-of-a-GNN" class="headerlink" title="A Single Layer of a GNN"></a>A Single Layer of a GNN</h2><h3 id="A-Single-GNN-Layer"><a href="#A-Single-GNN-Layer" class="headerlink" title="A Single GNN Layer"></a>A Single GNN Layer</h3><p><img src="/images/loading.gif" data-original="../images/basic/image-20211118181939133.png" alt=""></p>
<h4 id="Message-Computation"><a href="#Message-Computation" class="headerlink" title="Message Computation"></a>Message Computation</h4><h4 id="Aggregation"><a href="#Aggregation" class="headerlink" title="Aggregation"></a><img src="/images/loading.gif" data-original="../images/basic/image-20211118182057368.png" alt="">Aggregation</h4><p><img src="/images/loading.gif" data-original="../images/basic/image-20211118182129781.png" alt=""></p>
<h4 id="Issue"><a href="#Issue" class="headerlink" title="Issue"></a>Issue</h4><p><img src="/images/loading.gif" data-original="../images/basic/image-20211118182215334.png" alt=""></p>
<h4 id="Putting-things-together"><a href="#Putting-things-together" class="headerlink" title="Putting things together"></a>Putting things together</h4><p><img src="/images/loading.gif" data-original="../images/basic/image-20211118182315450.png" alt=""></p>
<h3 id="Classical-GNN-Layers-GCN"><a href="#Classical-GNN-Layers-GCN" class="headerlink" title="Classical GNN Layers: GCN"></a>Classical GNN Layers: GCN</h3><p><a href="https://arxiv.org/pdf/1609.02907.pdf" target="_blank" rel="noopener">T. Kipf, M. Welling. Semi-Supervised Classification with Graph Convolutional Networks, ICLR 2017</a></p>
<p>Graph Convolutional Networks (GCN)</p>
<img src="/images/loading.gif" data-original="../images/basic/image-20211118182440842.png" style="zoom:50%;">

<p>How to write this as Message + Aggregation?</p>
<img src="/images/loading.gif" data-original="../images/basic/image-20211118182508447.png" style="zoom:67%;">

<p><img src="/images/loading.gif" data-original="../images/basic/image-20211118182531818.png" alt=""></p>
<h3 id="GraphSAGE"><a href="#GraphSAGE" class="headerlink" title="GraphSAGE"></a>GraphSAGE</h3><p><a href="https://arxiv.org/pdf/1706.02216.pdf" target="_blank" rel="noopener">Hamilton et al. Inductive Representation Learning on Large Graphs, NeurIPS 2017</a></p>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211118182605344.png" alt=""></p>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211118182721525.png" alt=""></p>
<h4 id="L2-Normalization"><a href="#L2-Normalization" class="headerlink" title="L2 Normalization"></a>L2 Normalization</h4><p><img src="/images/loading.gif" data-original="../images/basic/image-20211118182808881.png" alt=""></p>
<h3 id="GAT"><a href="#GAT" class="headerlink" title="GAT"></a>GAT</h3><p>Graph Attention Networks</p>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211118182917446.png" alt=""></p>
<p>Not all node’s neighbors are equally important </p>
<ul>
<li><p>Attention is inspired by cognitive attention.  </p>
</li>
<li><p>The attention a_uv focuses on the important parts of  the input data and fades out the rest.  </p>
<ul>
<li><p>Idea: the NN should devote more computing power on that  small but important part of the data.  </p>
</li>
<li><p>Which part of the data is more important depends on the  context and is learned through training.</p>
</li>
</ul>
</li>
</ul>
<p>Can we do better than simple  neighborhood aggregation?</p>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211118183053526.png" alt=""></p>
<h4 id="Attention-Mechanism"><a href="#Attention-Mechanism" class="headerlink" title="Attention Mechanism"></a>Attention Mechanism</h4><p><img src="/images/loading.gif" data-original="../images/basic/image-20211118183127306.png" alt=""></p>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211118183206950.png" alt=""></p>
<p>What is the form of attention mechanism a? </p>
<ul>
<li>The approach is agnostic to the choice of a </li>
<li>E.g., use a simple single-layer neural network </li>
<li>a have trainable parameters (weights in the Linear layer)</li>
</ul>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211118183316007.png" alt=""></p>
<p><strong>Multi-head attention</strong>: Stabilizes the learning  process of attention mechanism</p>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211118183340078.png" alt=""></p>
<h4 id="Benefits-of-Attention-Mechanism"><a href="#Benefits-of-Attention-Mechanism" class="headerlink" title="Benefits of Attention Mechanism"></a>Benefits of Attention Mechanism</h4><p><img src="/images/loading.gif" data-original="../images/basic/image-20211118183547862.png" alt=""></p>
<h2 id="GNN-Layers-in-Practice"><a href="#GNN-Layers-in-Practice" class="headerlink" title="GNN Layers in Practice"></a>GNN Layers in Practice</h2><p><img src="/images/loading.gif" data-original="../images/basic/image-20211118183651153.png" alt=""></p>
<p>Many modern deep learning modules can be  incorporated into a GNN layer </p>
<ul>
<li>Batch Normalization: <ul>
<li>Stabilize neural network training </li>
</ul>
</li>
<li>Dropout: <ul>
<li>Prevent overfitting </li>
</ul>
</li>
<li>Attention/Gating: <ul>
<li>Control the importance of a message </li>
</ul>
</li>
<li>More: <ul>
<li>Any other useful deep learning modules</li>
</ul>
</li>
</ul>
<h3 id="Batch-Normalization"><a href="#Batch-Normalization" class="headerlink" title="Batch Normalization"></a>Batch Normalization</h3><p><a href="https://arxiv.org/pdf/1502.03167.pdf" target="_blank" rel="noopener">S. Loffe, C.Szegedy. Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift, ICML 2015</a></p>
<ul>
<li>Goal: Stabilize neural networks training </li>
<li>Idea: Given a batch of inputs (node embeddings) <ul>
<li>Re-center the node embeddings into zero mean  </li>
<li>Re-scale the variance into unit variance</li>
</ul>
</li>
</ul>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211118183903183.png" alt=""></p>
<h3 id="Dropout"><a href="#Dropout" class="headerlink" title="Dropout"></a>Dropout</h3><ul>
<li>Goal: Regularize a neural net to prevent overfitting. </li>
<li>Idea:  <ul>
<li>During training: with some probability p, randomly set  neurons to zero (turn off) </li>
<li>During testing: Use all the neurons for computation</li>
</ul>
</li>
</ul>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211118184007286.png" alt=""></p>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211118184033018.png" alt=""></p>
<h3 id="Activation-Non-linearity"><a href="#Activation-Non-linearity" class="headerlink" title="Activation(Non-linearity)"></a>Activation(Non-linearity)</h3><p><img src="/images/loading.gif" data-original="../images/basic/image-20211118184103165.png" alt=""></p>
<p>Summary: </p>
<ul>
<li>Modern deep learning  modules can be included into a GNN  layer for better performance </li>
<li>Designing novel GNN layers is still  an active research frontier! </li>
<li>Suggested resources: You can  explore diverse GNN designs or try  out your own ideas in GraphGym</li>
</ul>
<h3 id="Stacking-Layers-of-a-GNN"><a href="#Stacking-Layers-of-a-GNN" class="headerlink" title="Stacking Layers of a GNN"></a>Stacking Layers of a GNN</h3><ul>
<li>How to construct a Graph Neural Network? </li>
<li>The standard way: Stack GNN layers sequentially</li>
</ul>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211118184246785.png" alt=""></p>
<h3 id="The-Over-smoothing-Problem"><a href="#The-Over-smoothing-Problem" class="headerlink" title="The Over-smoothing Problem"></a>The Over-smoothing Problem</h3><ul>
<li>The Issue of stacking many GNN layers <ul>
<li>GNN suffers from the over-smoothing problem </li>
</ul>
</li>
<li>The over-smoothing problem: all the node  embeddings converge to the same value <ul>
<li>This is bad because we want to use node  embeddings to differentiate nodes </li>
</ul>
</li>
<li>Why does the over-smoothing problem  happen?</li>
</ul>
<h3 id="Receptive-Field-of-a-GNN"><a href="#Receptive-Field-of-a-GNN" class="headerlink" title="Receptive Field of a GNN"></a>Receptive Field of a GNN</h3><ul>
<li>Receptive field: the set of nodes that determine  the embedding of a node of interest <ul>
<li>In a k-layer GNN, each node has a receptive field of  k-hop neighborhood</li>
</ul>
</li>
</ul>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211118184451889.png" alt=""></p>
<ul>
<li>Receptive field overlap for two nodes <ul>
<li>The shared neighbors quickly grows when we  increase the number of hops (num of GNN layers)</li>
</ul>
</li>
</ul>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211118184537134.png" alt=""></p>
<ul>
<li>We can explain over-smoothing via the notion  of receptive field <ul>
<li>We knew the embedding of a node is determined  by its receptive field <ul>
<li>If two nodes have highly-overlapped receptive fields, then  their embeddings are highly similar </li>
</ul>
</li>
</ul>
</li>
<li>Stack many GNN layers -&gt; nodes will have highlyoverlapped receptive fields -&gt; node embeddings  will be highly similar -&gt; suffer from the over-smoothing problem </li>
<li>Next: how do we overcome over-smoothing problem?</li>
</ul>
<h3 id="Design-GNN-Layer-Connectivity"><a href="#Design-GNN-Layer-Connectivity" class="headerlink" title="Design GNN Layer Connectivity"></a>Design GNN Layer Connectivity</h3><ul>
<li>What do we learn from the over-smoothing problem?  </li>
<li>Lesson 1: Be cautious when adding GNN layers <ul>
<li>Unlike neural networks in other domains (CNN for image  classification), adding more GNN layers do not always help </li>
<li>Step 1: Analyze the necessary receptive field to solve your  problem. E.g., by computing the diameter of the graph </li>
<li>Step 2: Set number of GNN layers L to be a bit more than the  receptive field we like. Do not set L to be unnecessarily  large! </li>
</ul>
</li>
<li>Question: How to enhance the expressive power of a  GNN, if the number of GNN layers is small?</li>
</ul>
<h3 id="Expressive-Power-for-Shallow-GNNS"><a href="#Expressive-Power-for-Shallow-GNNS" class="headerlink" title="Expressive Power for Shallow GNNS"></a>Expressive Power for Shallow GNNS</h3><ul>
<li>How to make a shallow GNN more expressive? </li>
<li>Solution 1: Increase the expressive power within  each GNN layer <ul>
<li>In our previous examples, each transformation or  aggregation function only include one linear layer </li>
<li>We can make aggregation / transformation become a  deep neural network!</li>
</ul>
</li>
</ul>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211118184904401.png" alt=""></p>
<ul>
<li>Solution 2: Add layers that do not pass messages <ul>
<li>A GNN does not necessarily only contain GNN layers <ul>
<li>E.g., we can add MLP layers (applied to each node) before and after  GNN layers, as pre-process layers and post-process layers </li>
</ul>
</li>
<li>Pre-processing layers: Important when  encoding node features is necessary. </li>
<li>E.g., when nodes represent images/text </li>
<li>Post-processing layers: Important when  reasoning / transformation over node  embeddings are needed </li>
<li>E.g., graph classification, knowledge graphs </li>
<li>In practice, adding these layers works great</li>
</ul>
</li>
</ul>
<p>What if my problem still requires many GNN layers? </p>
<ul>
<li><p>Lesson 2: Add skip connections in GNNs </p>
<ul>
<li><p>Observation from over-smoothing: Node embeddings in  earlier GNN layers can sometimes better differentiate nodes </p>
</li>
<li><p>Solution: We can increase the impact of earlier layers on the  final node embeddings, by adding shortcuts in GNN</p>
</li>
</ul>
</li>
</ul>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211118185158513.png" alt=""></p>
<p><a href="https://openaccess.thecvf.com/content_cvpr_2016/papers/He_Deep_Residual_Learning_CVPR_2016_paper.pdf" target="_blank" rel="noopener">He et al. Deep Residual Learning for Image Recognition, CVPR 2015</a></p>
<h3 id="Idea-of-Skip-Connections"><a href="#Idea-of-Skip-Connections" class="headerlink" title="Idea of Skip Connections"></a>Idea of Skip Connections</h3><p>Why do skip connections work?</p>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211118185307362.png" alt=""></p>
<p><a href="https://arxiv.org/abs/1605.06431" target="_blank" rel="noopener">Veit et al. Residual Networks Behave Like Ensembles of Relatively Shallow Networks, ArXiv 2016</a></p>
<h3 id="Example-GCN-with-Skip-Connections"><a href="#Example-GCN-with-Skip-Connections" class="headerlink" title="Example: GCN with Skip Connections"></a>Example: GCN with Skip Connections</h3><p><img src="/images/loading.gif" data-original="../images/basic/image-20211118185405314.png" alt=""></p>
<h3 id="Other-Options-of-Skip-Connections"><a href="#Other-Options-of-Skip-Connections" class="headerlink" title="Other Options of Skip Connections"></a>Other Options of Skip Connections</h3><p><a href="https://arxiv.org/abs/1806.03536" target="_blank" rel="noopener">Xu et al. Representation learning on graphs with jumping knowledge networks, ICML 2018</a></p>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211118185509213.png" alt=""></p>
<h1 id="GNN-Augmentation-增强-and-Training"><a href="#GNN-Augmentation-增强-and-Training" class="headerlink" title="GNN Augmentation(增强) and Training"></a>GNN Augmentation(增强) and Training</h1><h2 id="Graph-Augmentation-for-GNNS"><a href="#Graph-Augmentation-for-GNNS" class="headerlink" title="Graph Augmentation for GNNS"></a>Graph Augmentation for GNNS</h2><p>Our assumption so far has been  </p>
<ul>
<li>Raw input graph = computational graph </li>
</ul>
<p>Reasons for breaking this assumption </p>
<ul>
<li><p>Features:  </p>
<ul>
<li>The input graph lacks features </li>
</ul>
</li>
<li><p>Graph structure: </p>
<ul>
<li>The graph is too sparse(稀疏的) -&gt; inefficient message passing </li>
<li>The graph is too dense -&gt; message passing is too costly </li>
<li>The graph is too large -&gt; cannot fit the computational  graph into a GPU </li>
</ul>
</li>
<li><p>It’s unlikely that the input graph happens to be  the optimal computation graph for embeddings</p>
</li>
</ul>
<h3 id="Graph-Augmentation-Approaches"><a href="#Graph-Augmentation-Approaches" class="headerlink" title="Graph Augmentation Approaches"></a>Graph Augmentation Approaches</h3><ul>
<li>Graph Feature augmentation <ul>
<li>The input graph lacks features -&gt; feature  augmentation </li>
</ul>
</li>
<li>Graph Structure augmentation <ul>
<li>The graph is too sparse -&gt; Add virtual nodes / edges </li>
<li>The graph is too dense -&gt; Sample neighbors when  doing message passing </li>
<li>The graph is too large -&gt; Sample subgraphs to  compute embeddings  </li>
</ul>
</li>
<li>Will cover later in lecture: Scaling up GNNs</li>
</ul>
<p>Why do we need feature augmentation? </p>
<p><strong>(1) Input graph does not have node features</strong> </p>
<p>This is common when we only have the adj. matrix ¡ Standard approaches: </p>
<p>​    a) Assign constant values to node</p>
<p>​    b) Assign unique IDs to nodes </p>
<p>​        These IDs are converted into one-hot vectors</p>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211121121440814.png" alt=""></p>
<h3 id="Feature-augmentation-constant-vs-one-hot"><a href="#Feature-augmentation-constant-vs-one-hot" class="headerlink" title="Feature augmentation: constant vs. one-hot"></a>Feature augmentation: constant vs. one-hot</h3><p><img src="/images/loading.gif" data-original="../images/basic/image-20211121121513731.png" alt=""></p>
<p>J. You, J. Gomes-Selman, R. Ying, J. Leskovec. Identity-aware Graph Neural Networks, AAAI 2021</p>
<p><strong>(2) Certain structures are hard to learn by GNN</strong> </p>
<p>​    Example: Cycle count feature: </p>
<p>​        Can GNN learn the length of a cycle that v1 resides in? </p>
<p>​        Unfortunately, no</p>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211121122002057.png" alt=""></p>
<p>​    v1 cannot differentiate which graph it resides in  </p>
<ul>
<li>Because all the nodes in the graph have degree of 2 </li>
<li>The computational graphs will be the same binary tree</li>
</ul>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211121122106176.png" alt=""></p>
<p>Solution:  </p>
<ul>
<li>We can use cycle count as augmented node features</li>
</ul>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211121122157777.png" alt=""></p>
<p>Other commonly used augmented features: </p>
<ul>
<li>Node degree </li>
<li>Clustering coefficient </li>
<li>PageRank </li>
<li>Centrality </li>
<li>…</li>
</ul>
<h3 id="Add-Virtual-Nodes-Edges"><a href="#Add-Virtual-Nodes-Edges" class="headerlink" title="Add Virtual Nodes/ Edges"></a>Add Virtual Nodes/ Edges</h3><p>Motivation: Augment sparse graphs </p>
<p>(1) Add virtual edges </p>
<ul>
<li>Common approach: Connect 2-hop neighbors via  virtual edges </li>
<li>Intuition: Instead of using adj. matrix A for GNN  computation, use A + A^2,</li>
</ul>
<p>Use cases: Bipartite graphs </p>
<ul>
<li>Author-to-papers (they authored) </li>
<li>2-hop virtual edges make an author-author collaboration graph</li>
</ul>
<p>(2) Add virtual nodes </p>
<ul>
<li><p>The virtual node will connect to all the  nodes in the graph </p>
<ul>
<li><p>Suppose in a sparse graph, two nodes have  shortest path distance of 10 </p>
</li>
<li><p>After adding the virtual node, all the nodes  will have a distance of two </p>
<ul>
<li>Node A – Virtual node – Node B </li>
</ul>
</li>
</ul>
</li>
<li><p>Benefits: Greatly improves message  passing in sparse graphs</p>
</li>
</ul>
<img src="/images/loading.gif" data-original="../images/basic/image-20211121123047322.png" style="zoom:67%;">

<h3 id="Node-Neighborhood-Sampling"><a href="#Node-Neighborhood-Sampling" class="headerlink" title="Node Neighborhood Sampling"></a>Node Neighborhood Sampling</h3><p><a href="https://arxiv.org/pdf/1706.02216.pdf" target="_blank" rel="noopener">Hamilton et al. Inductive Representation Learning on Large Graphs, NeurIPS 2017</a></p>
<p>Previously: </p>
<ul>
<li>All the nodes are used for message passing</li>
</ul>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211121123211164.png" alt=""></p>
<p>New idea: (Randomly) sample a node’s  neighborhood for message passing</p>
<p>For example, we can randomly choose 2 neighbors to pass messages in a given layer </p>
<ul>
<li>Only nodes B and D will pass messages to A</li>
</ul>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211121123313579.png" alt=""></p>
<p>In the next layer when we compute the embeddings, we can sample different  neighbors </p>
<ul>
<li>Only nodes C and D will pass messages to A</li>
</ul>
<p>In expectation, we get embeddings similar to  the case where all the neighbors are used </p>
<ul>
<li>Benefits: Greatly reduces computational cost <ul>
<li>Allows for scaling to large graphs (more about this later) </li>
</ul>
</li>
<li>And in practice it works great!</li>
</ul>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211121123433789.png" alt=""></p>
<h2 id="Prediction-with-GNNS"><a href="#Prediction-with-GNNS" class="headerlink" title="Prediction with GNNS"></a>Prediction with GNNS</h2><h3 id="GNN-Training-Pipeline"><a href="#GNN-Training-Pipeline" class="headerlink" title="GNN Training Pipeline"></a>GNN Training Pipeline</h3><p><img src="/images/loading.gif" data-original="../images/basic/image-20211121123545999.png" alt=""></p>
<h3 id="Pipeline"><a href="#Pipeline" class="headerlink" title="Pipeline"></a>Pipeline</h3><p>(1) Different prediction heads: </p>
<ul>
<li>Node-level tasks </li>
<li>Edge-level tasks </li>
<li>Graph-level tasks</li>
</ul>
<h3 id="GNN-Prediction-Heads"><a href="#GNN-Prediction-Heads" class="headerlink" title="GNN Prediction Heads"></a>GNN Prediction Heads</h3><p>Idea: Different task levels require different  prediction heads</p>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211121123718495.png" alt=""></p>
<h4 id="Node-level"><a href="#Node-level" class="headerlink" title="Node-level"></a>Node-level</h4><p><strong>Node-level prediction</strong>: We can directly make  prediction using node embeddings!</p>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211121123800804.png" alt=""></p>
<h4 id="Edae-level"><a href="#Edae-level" class="headerlink" title="Edae-level"></a>Edae-level</h4><p><strong>Edge-level prediction</strong>: Make prediction using  pairs of node embeddings</p>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211121124152229.png" alt=""></p>
<p><strong>(1) Concatenation + Linear</strong></p>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211121124251201.png" alt=""></p>
<p><strong>(2) Dot product</strong></p>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211121124319360.png" alt=""></p>
<h4 id="Graph-level"><a href="#Graph-level" class="headerlink" title="Graph-level"></a>Graph-level</h4><p><strong>Graph-level prediction</strong>: Make prediction using  all the node embeddings in our graph</p>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211121124422963.png" alt=""></p>
<p><a href="https://arxiv.org/pdf/1810.00826.pdf" target="_blank" rel="noopener">K. Xu<em>, W. Hu</em>, J. Leskovec, S. Jegelka. How Powerful Are Graph Neural Networks, ICLR 2019</a></p>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211121124519131.png" alt=""></p>
<h5 id="Issue-of-Global-Pooling"><a href="#Issue-of-Global-Pooling" class="headerlink" title="Issue of Global Pooling"></a>Issue of Global Pooling</h5><p>Issue: Global pooling over a (large) graph will lose  information</p>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211121124630985.png" alt=""></p>
<h5 id="Hierarchical-Global-Pooling"><a href="#Hierarchical-Global-Pooling" class="headerlink" title="Hierarchical Global Pooling"></a>Hierarchical Global Pooling</h5><p>A solution: Let’s aggregate all the node  embeddings hierarchically(等级的)</p>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211121124801967.png" alt=""></p>
<p><a href="https://arxiv.org/pdf/1806.08804.pdf" target="_blank" rel="noopener">Ying et al. Hierarchical Graph Representation Learning with Differentiable Pooling, NeurIPS 2018</a></p>
<p>DiffPool idea: </p>
<ul>
<li>Hierarchically pool node embedding</li>
</ul>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211121124919721.png" alt=""></p>
<p>Leverage 2 independent GNNs at each level </p>
<ul>
<li>GNN A: Compute node embeddings </li>
<li>GNN B: Compute the cluster that a node belongs to </li>
</ul>
<p>GNNs A and B at each level can be executed in parallel</p>
<p>For each Pooling layer </p>
<ul>
<li>Use clustering assignments from GNN B to aggregate node  embeddings generated by GNN A </li>
<li>Create a single new node for each cluster, maintaining  edges between clusters to generated a new pooled network </li>
</ul>
<p>Jointly train GNN A and GNN B</p>
<h2 id="Training-Graph-Neural-Networks"><a href="#Training-Graph-Neural-Networks" class="headerlink" title="Training Graph Neural Networks"></a>Training Graph Neural Networks</h2><h3 id="Pipeline-1"><a href="#Pipeline-1" class="headerlink" title="Pipeline"></a>Pipeline</h3><p>(2) Where does ground-truth come from?  </p>
<ul>
<li>Supervised labels </li>
<li>Unsupervised signals</li>
</ul>
<h3 id="Supervised-Vs-Unsupervised"><a href="#Supervised-Vs-Unsupervised" class="headerlink" title="Supervised Vs Unsupervised"></a>Supervised Vs Unsupervised</h3><ul>
<li>Supervised learning on graphs <ul>
<li>Labels come from external sources <ul>
<li>E.g., predict drug likeness of a molecular graph </li>
</ul>
</li>
</ul>
</li>
<li>Unsupervised learning on graphs <ul>
<li>Signals come from graphs themselves  <ul>
<li>E.g., link prediction: predict if two nodes are connected </li>
</ul>
</li>
</ul>
</li>
<li>Sometimes the differences are blurry <ul>
<li>We still have “supervision” in unsupervised learning <ul>
<li>E.g., train a GNN to predict node clustering coefficient </li>
</ul>
</li>
<li>An alternative name for “unsupervised” is “self-supervised”</li>
</ul>
</li>
</ul>
<h3 id="Supervised-Labels-on-Graphs"><a href="#Supervised-Labels-on-Graphs" class="headerlink" title="Supervised Labels on Graphs"></a>Supervised Labels on Graphs</h3><p>Supervised labels come from the specific use  cases. For example:</p>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211121125549048.png" alt=""></p>
<p>Advice: Reduce your task to node / edge / graph  labels, since they are easy to work with </p>
<ul>
<li>E.g., we knew some nodes form a cluster. We can treat  the cluster that a node belongs to as a node label</li>
</ul>
<h3 id="Unsupervised-Signals-on-Graphs"><a href="#Unsupervised-Signals-on-Graphs" class="headerlink" title="Unsupervised Signals on Graphs"></a>Unsupervised Signals on Graphs</h3><ul>
<li>The problem: sometimes we only have a graph,  without any external labels </li>
<li>The solution: “self-supervised learning”, we can  find supervision signals within the graph. <ul>
<li>For example, we can let GNN predict the following:</li>
</ul>
</li>
</ul>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211121125728956.png" alt=""></p>
<p>These tasks do not require any external labels!</p>
<h3 id="Pipeline-2"><a href="#Pipeline-2" class="headerlink" title="Pipeline"></a>Pipeline</h3><p>(3) How do we compute the final loss? </p>
<ul>
<li>Classification loss </li>
<li>Regression loss</li>
</ul>
<h3 id="Settings-for-GNN-Training"><a href="#Settings-for-GNN-Training" class="headerlink" title="Settings for GNN Training"></a>Settings for GNN Training</h3><p><img src="/images/loading.gif" data-original="../images/basic/image-20211121125933719.png" alt=""></p>
<h3 id="Classification-or-Rearession"><a href="#Classification-or-Rearession" class="headerlink" title="Classification or Rearession"></a>Classification or Rearession</h3><p><img src="/images/loading.gif" data-original="../images/basic/image-20211121130003206.png" alt=""></p>
<h4 id="Classification-LOSS"><a href="#Classification-LOSS" class="headerlink" title="Classification LOSS"></a>Classification LOSS</h4><p>As discussed in lecture 6, cross entropy (CE) is a very common loss function in classification</p>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211121130041014.png" alt=""></p>
<h4 id="Regression-Loss"><a href="#Regression-Loss" class="headerlink" title="Regression Loss"></a>Regression Loss</h4><p>For regression tasks we often use Mean Squared  Error (MSE) a.k.a. L2 loss</p>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211121130126580.png" alt=""></p>
<h3 id="Pipeline-3"><a href="#Pipeline-3" class="headerlink" title="Pipeline"></a>Pipeline</h3><p>(4) How do we measure the success of a GNN? </p>
<ul>
<li>Accuracy </li>
<li>ROC AUC</li>
</ul>
<h3 id="Evaluation-Metrics-Rearession"><a href="#Evaluation-Metrics-Rearession" class="headerlink" title="Evaluation Metrics: Rearession"></a>Evaluation Metrics: Rearession</h3><ul>
<li>We use standard evaluation metrics for GNN <ul>
<li>(Content below can be found in any ML course)</li>
<li>In practice we will use sklearn for implementation </li>
<li>Suppose we make predictions for N data points </li>
</ul>
</li>
<li>Evaluate regression tasks on graphs:</li>
</ul>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211121130302297.png" alt=""></p>
<h3 id="Evaluation-Metrics-Classification"><a href="#Evaluation-Metrics-Classification" class="headerlink" title="Evaluation Metrics: Classification"></a>Evaluation Metrics: Classification</h3><p>Evaluate classification tasks on graphs:</p>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211121130344635.png" alt=""></p>
<h3 id="Metrics-for-Binary-Classification"><a href="#Metrics-for-Binary-Classification" class="headerlink" title="Metrics for Binary Classification"></a>Metrics for Binary Classification</h3><p><img src="/images/loading.gif" data-original="../images/basic/image-20211121130405807.png" alt=""></p>
<p>ROC Curve: Captures the tradeoff in TPR and  FPR as the classification threshold is varied  for a binary classifier.</p>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211121130436056.png" alt=""></p>
<p>ROC AUC: Area under the ROC Curve.  </p>
<p>Intuition: The probability that a classifier will rank a  randomly chosen positive instance higher than a  randomly chosen negative one</p>
<h2 id="Setting-up-GNN-Prediction-Tasks"><a href="#Setting-up-GNN-Prediction-Tasks" class="headerlink" title="Setting-up GNN Prediction Tasks"></a>Setting-up GNN Prediction Tasks</h2><h3 id="Pipeline-4"><a href="#Pipeline-4" class="headerlink" title="Pipeline"></a>Pipeline</h3><p>(5) How do we split our dataset  into train / validation / test set?</p>
<h3 id="Dataset-Split-Fixed-Random-Split"><a href="#Dataset-Split-Fixed-Random-Split" class="headerlink" title="Dataset Split: Fixed/ Random Split"></a>Dataset Split: Fixed/ Random Split</h3><ul>
<li>Fixed split: We will split our dataset once <ul>
<li>Training set: used for optimizing GNN parameters </li>
<li>Validation set: develop model/hyperparameters </li>
<li>Test set: held out until we report final performance </li>
</ul>
</li>
<li>A concern: sometimes we cannot guarantee  that the test set will really be held out </li>
<li>Random split: we will randomly split our  dataset into training / validation / test <ul>
<li>We report average performance over different  random seeds</li>
</ul>
</li>
</ul>
<h3 id="Why-Splitting-Graphs-is-Special"><a href="#Why-Splitting-Graphs-is-Special" class="headerlink" title="Why Splitting Graphs is Special"></a>Why Splitting Graphs is Special</h3><p>Suppose we want to split an image dataset </p>
<ul>
<li>Image classification: Each data point is an image </li>
<li>Here data points are independent <ul>
<li>Image 5 will not affect our prediction on image 1</li>
</ul>
</li>
</ul>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211121130839404.png" alt=""></p>
<p>Splitting a graph dataset is different! </p>
<ul>
<li>Node classification: Each data point is a node </li>
<li>Here data points are NOT independent<ul>
<li>Node 5 will affect our prediction on node 1, because it will  participate in message passing -&gt; affect node 1’s embedding</li>
</ul>
</li>
</ul>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211121130957508.png" alt=""></p>
<p>What are our options?</p>
<p>Solution 1 (<strong>Transductive(传导的) setting</strong>): The input  graph can be observed in all the dataset splits  (training, validation and test set).  </p>
<p>We will only split the (node) labels </p>
<ul>
<li>At training time, we compute embeddings using the  entire graph, and train using node 1&amp;2’s labels </li>
<li>At validation time, we compute embeddings using  the entire graph, and evaluate on node 3&amp;4’s labels</li>
</ul>
<p>Solution 2 (<strong>Inductive(归纳法的) setting</strong>): We break the edges  between splits to get multiple graphs </p>
<ul>
<li>Now we have 3 graphs that are independent. Node 5 will  not affect our prediction on node 1 any more </li>
<li>At training time, we compute embeddings using the  graph over node 1&amp;2, and train using node 1&amp;2’s labels </li>
<li>At validation time, we compute embeddings using the  graph over node 3&amp;4, and evaluate on node 3&amp;4’s labels</li>
</ul>
<p>Transductive setting: training / validation / test  sets are on the same graph </p>
<ul>
<li>The dataset consists of one graph </li>
<li>The entire graph can be observed in all dataset splits,  we only split the labels </li>
<li>Only applicable to node / edge prediction tasks </li>
</ul>
<p>Inductive setting: training / validation / test sets  are on different graphs </p>
<ul>
<li>The dataset consists of multiple graphs </li>
<li>Each split can only observe the graph(s) within the split.  A successful model should generalize to unseen graphs </li>
<li>Applicable to node / edge / graph tasks</li>
</ul>
<h3 id="Graph-Classification"><a href="#Graph-Classification" class="headerlink" title="Graph Classification"></a>Graph Classification</h3><p><img src="/images/loading.gif" data-original="../images/basic/image-20211121131929640.png" alt=""></p>
<p>Only the <strong>inductive setting is well defined for  graph classification</strong> </p>
<ul>
<li>Because we have to test on unseen graphs</li>
<li>Suppose we have a dataset of 5 graphs. Each split  will contain independent graph(s)</li>
</ul>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211121132032550.png" alt=""></p>
<h3 id="Link-Prediction"><a href="#Link-Prediction" class="headerlink" title="Link Prediction"></a>Link Prediction</h3><p>Goal of link prediction: predict missing edges </p>
<p>Setting up link prediction is tricky: </p>
<ul>
<li>Link prediction is an unsupervised / self-supervised  task. We need to create the labels and dataset  splits on our own </li>
<li>Concretely, we need to hide some edges from the  GNN and the let the GNN predict if the edges exist</li>
</ul>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211121132251694.png" alt=""></p>
<p>For link prediction, we will split edges twice </p>
<p>Step 1: Assign 2 types of edges in the original graph </p>
<ul>
<li><p>Message edges: Used for GNN message passing </p>
</li>
<li><p>Supervision edges: Use for computing objectives </p>
</li>
<li><p>After step 1: </p>
<ul>
<li><p>Only message edges will remain in the graph </p>
</li>
<li><p>Supervision edges are used as supervision for edge  predictions made by the model, will not be fed into GNN!</p>
</li>
</ul>
</li>
</ul>
<p>Step 2: Split edges into train / validation / test </p>
<ul>
<li>Option 1: Inductive link prediction split <ul>
<li>Suppose we have a dataset of 3 graphs. Each  inductive split will contain an independent grap</li>
<li>Suppose we have a dataset of 3 graphs. Each  inductive split will contain an independent graph </li>
<li>In train or val or test set, each graph will have 2 types of edges: message edges + supervision edges § Supervision edges are not the input to GNN</li>
</ul>
</li>
</ul>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211121132836775.png" alt=""></p>
<ul>
<li><p>Option 2: Transductive link prediction split: </p>
<ul>
<li><p>This is the default setting when people talk about  link prediction </p>
</li>
<li><p>Suppose we have a dataset of 1 graph</p>
</li>
<li><p>By definition of “transductive”, the entire graph can  be observed in all dataset splits </p>
<ul>
<li>But since edges are both part of graph structure and the  supervision, we need to hold out validation / test edges </li>
<li>To train the training set, we further need to hold out  supervision edges for the training set</li>
</ul>
</li>
<li><p>Next: we will show the exact settings</p>
</li>
</ul>
</li>
</ul>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211121133040720.png" alt=""></p>
<p>Summary: Transductive link prediction split</p>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211121133105561.png" alt=""></p>
<ul>
<li>Note: Link prediction settings are tricky and complex. You may find papers do link prediction differently.  </li>
<li>Luckily, we have full support in PyG and <a href="https://github.com/snap-stanford/GraphGym" target="_blank" rel="noopener">GraphGym</a></li>
</ul>
<h3 id="GNN-Training-Pipeline-1"><a href="#GNN-Training-Pipeline-1" class="headerlink" title="GNN Training Pipeline"></a>GNN Training Pipeline</h3><p><img src="/images/loading.gif" data-original="../images/basic/image-20211121133226107.png" alt=""></p>
<p>Implementation resources: </p>
<ul>
<li><a href="https://github.com/snap-stanford/deepsnap" target="_blank" rel="noopener">DeepSNAP</a> provides core modules for this pipeline  </li>
<li><a href="https://github.com/snap-stanford/GraphGym" target="_blank" rel="noopener">GraphGym</a> further implements the full pipeline to facilitate GNN design</li>
</ul>
<h3 id="Summary-10"><a href="#Summary-10" class="headerlink" title="Summary"></a>Summary</h3><ul>
<li>GNN Layer:  <ul>
<li>Transformation + Aggregation </li>
<li>Classic GNN layers: GCN, GraphSAGE, GAT </li>
</ul>
</li>
<li>Layer connectivity:  <ul>
<li>The over-smoothing problem </li>
<li>Solution: skip connections </li>
</ul>
</li>
<li>Graph Augmentation: <ul>
<li>Feature augmentation </li>
<li>Structure augmentation </li>
</ul>
</li>
<li>Learning Objectives <ul>
<li>The full training pipeline of a GNN</li>
</ul>
</li>
</ul>
<h2 id="When-Things-Dont-Go-As-Planned"><a href="#When-Things-Dont-Go-As-Planned" class="headerlink" title="When Things Dont Go As Planned"></a>When Things Dont Go As Planned</h2><h3 id="General-Tips"><a href="#General-Tips" class="headerlink" title="General Tips"></a>General Tips</h3><ul>
<li>Data preprocessing is important:  <ul>
<li>Node attributes can vary a lot! <ul>
<li>E.g. probability ranges (0,1), but some inputs could have much  larger range, say (−1000, 1000) </li>
</ul>
</li>
<li>Use normalization </li>
</ul>
</li>
<li>Optimizer:  <ul>
<li>ADAM is relatively robust to learning rate </li>
</ul>
</li>
<li>Activation function <ul>
<li>ReLU activation function often works well </li>
<li>Other alternatives: LeakyReLU, SWISH, rational activation </li>
<li>No activation function at your output layer:  </li>
</ul>
</li>
<li>Include bias term in every layer  </li>
<li>Embedding dimensions: <ul>
<li>32, 64 and 128 are often good starting points</li>
</ul>
</li>
</ul>
<h3 id="Debugging-Deep-Networks"><a href="#Debugging-Deep-Networks" class="headerlink" title="Debugging Deep Networks"></a>Debugging Deep Networks</h3><ul>
<li>Debug issues: Loss/accuracy not converging  during training <ul>
<li>Check pipeline (e.g. in PyTorch we need zero_grad) </li>
<li>Adjust hyperparameters such as learning rate </li>
<li>Pay attention to weight parameter initialization </li>
</ul>
</li>
<li>Important for model development: <ul>
<li>Overfit on (part of) training data:  <ul>
<li>With a small training dataset, loss should be essentially close  to 0, with an expressive neural network </li>
<li>If neural network cannot overfit a single data point, something  is wrong </li>
</ul>
</li>
<li>Scrutinize loss function! </li>
<li>Scrutinize visualizations!</li>
</ul>
</li>
</ul>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211121133751138.png" alt=""></p>
<h1 id="Setting-up-GNN-Prediction-Tasks-1"><a href="#Setting-up-GNN-Prediction-Tasks-1" class="headerlink" title="Setting-up GNN Prediction Tasks"></a>Setting-up GNN Prediction Tasks</h1><h2 id="How-Expressive-are-Graph-Neural-Networks"><a href="#How-Expressive-are-Graph-Neural-Networks" class="headerlink" title="How Expressive are Graph Neural Networks?"></a>How Expressive are Graph Neural Networks?</h2><h3 id="Theory-of-GNNS"><a href="#Theory-of-GNNS" class="headerlink" title="Theory of GNNS"></a>Theory of GNNS</h3><p>How powerful are GNNs? </p>
<ul>
<li>Many GNN models have been proposed (e.g.,  GCN, GAT, GraphSAGE, design space). </li>
<li>What is the expressive power (ability to  distinguish different graph structures) of these  GNN models? </li>
<li>How to design a maximally expressive GNN  model?</li>
</ul>
<h3 id="Background-Many-GNN-Models"><a href="#Background-Many-GNN-Models" class="headerlink" title="Background: Many GNN Models"></a>Background: Many GNN Models</h3><p>Many GNN models have been proposed: </p>
<ul>
<li>GCN, GraphSAGE, GAT, Design Space etc.</li>
</ul>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211124232206183.png" alt=""></p>
<h3 id="GNN-Model-Example"><a href="#GNN-Model-Example" class="headerlink" title="GNN Model Example"></a>GNN Model Example</h3><ul>
<li>GCN (mean-pool) [Kipf and Welling ICLR 2017]</li>
</ul>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211124232333035.png" alt=""></p>
<ul>
<li>GraphSAGE (max-pool) [Hamilton et al. NeurIPS 2017]</li>
</ul>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211124232404770.png" alt=""></p>
<h3 id="Note-Node-Colors"><a href="#Note-Node-Colors" class="headerlink" title="Note: Node Colors"></a>Note: Node Colors</h3><ul>
<li>We use node same/different colors to represent  nodes with same/different features. <ul>
<li>For example, the graph below assumes all the nodes share the same feature.</li>
</ul>
</li>
</ul>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211124232516186.png" alt=""></p>
<ul>
<li>Key question: How well can a GNN distinguish  different graph structures?</li>
</ul>
<h3 id="Local-Neighborhood-Structures"><a href="#Local-Neighborhood-Structures" class="headerlink" title="Local Neighborhood Structures"></a>Local Neighborhood Structures</h3><p>We specifically consider local neighborhood  structures around each node in a graph.</p>
<ul>
<li>Example: Nodes 1 and 5  have different  neighborhood structures  because they have  different node degrees.</li>
</ul>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211124232626141.png" alt=""></p>
<p>We specifically consider local neighborhood  structures around each node in a graph. 1 2 3 5 4 </p>
<ul>
<li>Example: Nodes 1 and 4 both have the same node  degree of 2. However, they  still have different neighborhood structures  because their neighbors  have different node degrees</li>
</ul>
<p>Node 1 has neighbors of degrees 2 and 3. Node 4 has neighbors of degrees 1 and 3.</p>
<p>We specifically consider local neighborhood  structures around each node in a graph. 1 2 3 5 4 </p>
<ul>
<li>Example: Nodes 1 and 2  have the same neighborhood structure  because they are  symmetric within the  graph.</li>
</ul>
<p>Node 1 has neighbors of degrees 2 and 3. Node 2 has neighbors of degrees 2 and 3. And even if we go a step deeper to 2nd hop neighbors, both nodes have the same degrees (Node 4 of degree 2)</p>
<ul>
<li>Key question: Can GNN node embeddings  distinguish different node’s local  neighborhood structures? <ul>
<li>If so, when? If not, when will a GNN fail? </li>
</ul>
</li>
<li>Next: We need to understand how a GNN  captures local neighborhood structures. <ul>
<li>Key concept: Computational graph</li>
</ul>
</li>
</ul>
<h3 id="Computational-Graph"><a href="#Computational-Graph" class="headerlink" title="Computational Graph"></a>Computational Graph</h3><p>In each layer, a GNN aggregates neighboring node  embeddings. </p>
<p>A GNN generates node embeddings through a  computational graph defined by the neighborhood. </p>
<ul>
<li>Ex: Node 1’s computational graph (2-layer GNN)</li>
</ul>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211124233256304.png" alt=""></p>
<ul>
<li>Ex: Nodes 1 and 2’s computational graphs.</li>
</ul>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211124233315665.png" alt=""></p>
<ul>
<li>Ex: Nodes 1 and 2’s computational graphs. </li>
<li>But GNN only sees node features (not IDs):</li>
</ul>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211124233337139.png" alt=""></p>
<p>A GNN will generate the same embedding for  nodes 1 and 2 because: </p>
<ul>
<li>Computational graphs are the same. </li>
<li>Node features (colors) are identical.</li>
</ul>
<p>Note: GNN does not care about node ids, it just aggregates features vectors of different nodes.</p>
<p>In general, different local neighborhoods  define different computational graphs</p>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211124233437411.png" alt=""></p>
<p>Computational graphs are identical to rooted  subtree structures around each node.</p>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211124233458316.png" alt=""></p>
<p>GNN‘s node embeddings capture rooted  subtree structures.</p>
<p>Most expressive GNN maps different rooted  subtrees into different node embeddings  (represented by different colors).</p>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211124233528263.png" alt=""></p>
<h3 id="Recall-Iniective-Function"><a href="#Recall-Iniective-Function" class="headerlink" title="Recall: Iniective Function"></a>Recall: Iniective Function</h3><p><img src="/images/loading.gif" data-original="../images/basic/image-20211124233555015.png" alt=""></p>
<h3 id="How-Expressive-is-a-GNN"><a href="#How-Expressive-is-a-GNN" class="headerlink" title="How Expressive is a GNN?"></a>How Expressive is a GNN?</h3><p>Most expressive GNN should map subtrees to  the node embeddings injectively.</p>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211124233631327.png" alt=""></p>
<p>Key observation: Subtrees of the same depth  can be recursively characterized from the leaf  nodes to the root nodes.</p>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211124233656532.png" alt=""></p>
<p>If each step of GNN’s aggregation can fully  retain the neighboring information, the  generated node embeddings can distinguish  different rooted subtrees.</p>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211124233724688.png" alt=""></p>
<p>In other words, most expressive GNN would  use an injective neighbor aggregation function at each step. </p>
<p>Maps different neighbors to different embeddings.</p>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211124233745404.png" alt=""></p>
<p>Summary so far </p>
<ul>
<li>To generate a node embedding, GNNs use a computational graph corresponding to a subtree  rooted around each node.</li>
</ul>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211124233818826.png" alt=""></p>
<ul>
<li>GNN can fully distinguish different subtree  structures if every step of its neighbor  aggregation is injective.</li>
</ul>
<h2 id="Designing-the-Most-Powerful-Graph-Neural-Network"><a href="#Designing-the-Most-Powerful-Graph-Neural-Network" class="headerlink" title="Designing the Most Powerful Graph Neural Network"></a>Designing the Most Powerful Graph Neural Network</h2><h3 id="Expressive-Power-of-GNNS"><a href="#Expressive-Power-of-GNNS" class="headerlink" title="Expressive Power of GNNS"></a>Expressive Power of GNNS</h3><ul>
<li>Key observation: Expressive power of GNNs  can be characterized by that of neighbor  aggregation functions they use. <ul>
<li>A more expressive aggregation function leads to a  more expressive a GNN. </li>
<li>Injective aggregation function leads to the most  expressive GNN. </li>
</ul>
</li>
<li>Next: <ul>
<li>Theoretically analyze expressive power of  aggregation functions.</li>
</ul>
</li>
</ul>
<h3 id="Neighbor-Aggregation"><a href="#Neighbor-Aggregation" class="headerlink" title="Neighbor Aggregation"></a>Neighbor Aggregation</h3><p>Observation: Neighbor aggregation can be abstracted as a function over a multi-set (a  set with repeating elements).</p>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211124234114863.png" alt=""></p>
<p>Next: We analyze aggregation functions of  two popular GNN models</p>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211124234133971.png" alt=""></p>
<ul>
<li>GCN (mean-pool) [Kipf &amp; Welling ICLR 2017] <ul>
<li>Take element-wise mean, followed by linear  function and ReLU activation, i.e., max(0, x). </li>
<li>Theorem [Xu et al. ICLR 2019]  <ul>
<li>GCN’s aggregation function cannot distinguish different  multi-sets with the same color proportion.</li>
</ul>
</li>
</ul>
</li>
</ul>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211124234305197.png" alt=""></p>
<p>For simplicity, we assume node colors are  represented by one-hot encoding. </p>
<p>Example) If there are two distinct colors:</p>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211124234323852.png" alt=""></p>
<p>This assumption is sufficient to illustrate how GCN  fails.</p>
<p> <strong>Failure case illustration</strong></p>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211124234427536.png" alt=""></p>
<ul>
<li>GraphSAGE (max-pool) [Hamilton et al. NeurIPS 2017] <ul>
<li>Apply an MLP, then take element-wise max. </li>
<li>Theorem [Xu et al. ICLR 2019]  <ul>
<li>GraphSAGE’s aggregation function cannot distinguish  different multi-sets with the same set of distinct colors. </li>
</ul>
</li>
</ul>
</li>
</ul>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211124234506874.png" alt=""></p>
<p><strong>Failure case illustration</strong></p>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211124234534845.png" alt=""></p>
<h3 id="Summary-So-Far"><a href="#Summary-So-Far" class="headerlink" title="Summary So Far"></a>Summary So Far</h3><p>We analyzed the expressive power of GNNs. </p>
<p>Main takeaways:  </p>
<ul>
<li>Expressive power of GNNs can be characterized by  that of the neighbor aggregation function. </li>
<li>Neighbor aggregation is a function over multi-sets  (sets with repeating elements)  </li>
<li>GCN and GraphSAGE’s aggregation functions fail to  distinguish some basic multi-sets; hence not injective. </li>
<li>Therefore, GCN and GraphSAGE are not maximally  powerful GNNs.</li>
</ul>
<h3 id="Designing-Most-Expressive-GNNS"><a href="#Designing-Most-Expressive-GNNS" class="headerlink" title="Designing Most Expressive GNNS"></a>Designing Most Expressive GNNS</h3><ul>
<li>Our goal: Design maximally powerful GNNs  in the class of message-passing GNNs. </li>
<li>This can be achieved by designing injective neighbor aggregation function over multi-sets. </li>
<li>Here, we design a neural network that can  model injective multiset function.</li>
</ul>
<h3 id="Injective-Multi-set-Function"><a href="#Injective-Multi-set-Function" class="headerlink" title="Injective Multi-set Function"></a>Injective Multi-set Function</h3><p><img src="/images/loading.gif" data-original="../images/basic/image-20211124234725881.png" alt=""></p>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211124234816499.png" alt=""></p>
<h3 id="Universal-Approximation-Theorem"><a href="#Universal-Approximation-Theorem" class="headerlink" title="Universal Approximation Theorem"></a>Universal Approximation Theorem</h3><p><img src="/images/loading.gif" data-original="../images/basic/image-20211124234842803.png" alt=""></p>
<h3 id="Injective-Multi-set-Function-1"><a href="#Injective-Multi-set-Function-1" class="headerlink" title="Injective Multi-set Function"></a>Injective Multi-set Function</h3><p>We have arrived at a neural network that can  model any injective multi-set function.</p>
<img src="/images/loading.gif" data-original="../images/basic/image-20211124234919909.png" style="zoom:50%;">

<p>In practice, MLP hidden dimensionality of 100 to  500 is sufficient.</p>
<h3 id="Most-Expressive-GNN"><a href="#Most-Expressive-GNN" class="headerlink" title="Most Expressive GNN"></a>Most Expressive GNN</h3><p>Graph Isomorphism Network (GIN) [Xu et al. ICLR 2019] </p>
<p>Apply an MLP, element-wise sum, followed by  another MLP</p>
<img src="/images/loading.gif" data-original="../images/basic/image-20211124235014695.png" style="zoom:50%;">

<ul>
<li>Theorem [Xu et al. ICLR 2019]  <ul>
<li>GIN‘s neighbor aggregation function is injective. </li>
</ul>
</li>
<li>No failure cases! </li>
<li>GIN is THE most expressive GNN in the class of  message-passing GNNs!</li>
</ul>
<h3 id="Full-Model-of-GIN"><a href="#Full-Model-of-GIN" class="headerlink" title="Full Model of GIN"></a>Full Model of GIN</h3><p>So far: We have described the neighbor  aggregation part of GIN. </p>
<p>We now describe the full model of GIN by  relating it to WL graph kernel (traditional way  of obtaining graph-level features). </p>
<ul>
<li>We will see how GIN is a “neural network” version  of the WL graph kernel.</li>
</ul>
<h3 id="Relation-to-WL-Graph-Kernel"><a href="#Relation-to-WL-Graph-Kernel" class="headerlink" title="Relation to WL Graph Kernel"></a>Relation to WL Graph Kernel</h3><p>Recall: Color refinement algorithm in WL kernel.</p>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211124235238709.png" alt=""></p>
<h3 id="Color-Refinement"><a href="#Color-Refinement" class="headerlink" title="Color Refinement"></a>Color Refinement</h3><p>Example of color refinement given two graphs</p>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211124235311686.png" alt=""></p>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211124235328474.png" alt=""></p>
<p>Example of color refinement given two graphs </p>
<ul>
<li>Process continues until a stable coloring is  reached </li>
<li>Two graphs are considered isomorphic if they  have the same set of colors.</li>
</ul>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211124235354421.png" alt=""></p>
<h3 id="The-Complete-GIN-Mode"><a href="#The-Complete-GIN-Mode" class="headerlink" title="The Complete GIN Mode"></a>The Complete GIN Mode</h3><p>GIN uses a neural network to model the  injective HASH function.</p>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211124235423462.png" alt=""></p>
<p>Specifically, we will model the injective  function over the tuple:</p>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211124235437403.png" alt=""></p>
<p>Theorem (Xu et al. ICLR 2019) </p>
<p>Any injective function over the tuple</p>
<img src="/images/loading.gif" data-original="../images/basic/image-20211124235529779.png" style="zoom:50%;">

<p><img src="/images/loading.gif" data-original="../images/basic/image-20211124235552059.png" alt=""></p>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211124235634820.png" alt=""></p>
<h3 id="GIN-and-WL-Graph-Kernel"><a href="#GIN-and-WL-Graph-Kernel" class="headerlink" title="GIN and WL Graph Kernel"></a>GIN and WL Graph Kernel</h3><p>GIN can be understood as differentiable neural  version of the WL graph Kernel:</p>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211124235709357.png" alt=""></p>
<p>Advantages of GIN over the WL graph kernel are: </p>
<ul>
<li>Node embeddings are low-dimensional; hence, they can  capture the fine-grained similarity of different nodes. </li>
<li>Parameters of the update function can be learned for the  downstream tasks.</li>
</ul>
<h3 id="Expressive-Power-of-GIN"><a href="#Expressive-Power-of-GIN" class="headerlink" title="Expressive Power of GIN"></a>Expressive Power of GIN</h3><ul>
<li>Because of the relation between GIN and the  WL graph kernel, their expressive is exactly the  same. <ul>
<li>If two graphs can be distinguished by GIN, they can be  also distinguished by the WL kernel, and vice versa. </li>
</ul>
</li>
<li>How powerful is this? <ul>
<li>WL kernel has been both theoretically and  empirically shown to distinguish most of the real-world graphs [Cai et al. 1992]. </li>
<li>Hence, GIN is also powerful enough to distinguish  most of the real graphs!</li>
</ul>
</li>
</ul>
<h3 id="Summary-of-the-Lecture"><a href="#Summary-of-the-Lecture" class="headerlink" title="Summary of the Lecture"></a>Summary of the Lecture</h3><ul>
<li>We design a neural network that can model  injective multi-set function. </li>
<li>We use the neural network for neighbor  aggregation function and arrive at GIN—the  most expressive GNN model. </li>
<li>The key is to use element-wise sum pooling,  instead of mean-/max-pooling. </li>
<li>GIN is closely related to the WL graph kernel. </li>
<li>Both GIN and WL graph kernel can distinguish  most of the real graphs!</li>
</ul>
<h3 id="The-Power-of-Pooling"><a href="#The-Power-of-Pooling" class="headerlink" title="The Power of Pooling"></a>The Power of Pooling</h3><p><img src="/images/loading.gif" data-original="../images/basic/image-20211124235927640.png" alt=""></p>
<p>Can expressive power of GNNs be improved? </p>
<p>There are basic graph structures that existing GNN  framework cannot distinguish, such as difference in cycles.</p>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211124235955061.png" alt=""></p>
<p>GNNs’ expressive power can be improved to resolve  the above problem. [You et al. AAAI 2021, Li et al. NeurIPS 2020]</p>
<h3 id="Summary-11"><a href="#Summary-11" class="headerlink" title="Summary"></a>Summary</h3><p>GNNs and connection to bijective functions  on sets. </p>
<p>Most powerful GNN is equivalent to WL graph  isomorphism test. </p>
<p>GIN is the most powerful GNN. </p>
<ul>
<li>Sum aggregator is more powerful than mean is  more powerful than max.</li>
</ul>
<h1 id="Heterogeneous-Graphs-and-Knowledge-Graph-Embeddings"><a href="#Heterogeneous-Graphs-and-Knowledge-Graph-Embeddings" class="headerlink" title="Heterogeneous Graphs and Knowledge Graph Embeddings"></a>Heterogeneous Graphs and Knowledge Graph Embeddings</h1><h2 id="Heterogeneous-异构-Graphs-and-Relational-GCN-RGCN"><a href="#Heterogeneous-异构-Graphs-and-Relational-GCN-RGCN" class="headerlink" title="Heterogeneous(异构) Graphs and Relational GCN (RGCN)"></a>Heterogeneous(异构) Graphs and Relational GCN (RGCN)</h2><h3 id="Heterogeneous-异构-Graphs"><a href="#Heterogeneous-异构-Graphs" class="headerlink" title="Heterogeneous(异构) Graphs"></a>Heterogeneous(异构) Graphs</h3><p>A heterogeneous graph is defined as</p>
<img src="/images/loading.gif" data-original="../images/basic/image-20211125113232278.png" style="zoom:67%;">

<p><img src="/images/loading.gif" data-original="../images/basic/image-20211125113635518.png" alt=""></p>
<h3 id="Relational-GCN"><a href="#Relational-GCN" class="headerlink" title="Relational GCN"></a>Relational GCN</h3><p><a href="https://arxiv.org/pdf/1703.06103.pdf" target="_blank" rel="noopener">Schlichtkrull et al., Modeling Relational Data with Graph Convolutional Networks, ESWC 2018</a></p>
<p>We will extend GCN to handle heterogeneous  graphs with multiple edge/relation types </p>
<p>We start with a directed graph with one relation </p>
<ul>
<li>How do we run GCN and update the representation  of the target node A on this graph?</li>
</ul>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211125114001101.png" alt=""></p>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211125114034454.png" alt=""></p>
<p><strong>What if the graph has multiple relation types?</strong></p>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211125114430879.png" alt=""></p>
<p>What if the graph has multiple relation types? </p>
<p>Use different neural network weights for  different relation types</p>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211125114452613.png" alt=""></p>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211125114519967.png" alt=""></p>
<h4 id="Definition"><a href="#Definition" class="headerlink" title="Definition"></a>Definition</h4><p><img src="/images/loading.gif" data-original="../images/basic/image-20211125114555629.png" alt=""></p>
<h4 id="RGCN-Scalability"><a href="#RGCN-Scalability" class="headerlink" title="RGCN: Scalability"></a>RGCN: Scalability</h4><p><img src="/images/loading.gif" data-original="../images/basic/image-20211125114654160.png" alt=""></p>
<h3 id="Block-Diagonal-Matrices"><a href="#Block-Diagonal-Matrices" class="headerlink" title="Block Diagonal Matrices"></a>Block Diagonal Matrices</h3><p>Key insight: make the weights sparse</p>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211125114730067.png" alt=""></p>
<p>Key insight: Share weights across different  relations!</p>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211125122421352.png" alt=""></p>
<h3 id="Example-Entity-Node-Classification"><a href="#Example-Entity-Node-Classification" class="headerlink" title="Example: Entity/Node Classification"></a>Example: Entity/Node Classification</h3><p>Goal: Predict the label of a given node</p>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211125122510604.png" alt=""></p>
<h3 id="Example-Link-Prediction"><a href="#Example-Link-Prediction" class="headerlink" title="Example Link Prediction"></a>Example Link Prediction</h3><p><img src="/images/loading.gif" data-original="../images/basic/image-20211125122540731.png" alt=""></p>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211125122601001.png" alt=""></p>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211125122618427.png" alt=""></p>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211125123058036.png" alt=""></p>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211125123121341.png" alt=""></p>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211125123802792.png" alt=""></p>
<h3 id="Summary-of-RGCN"><a href="#Summary-of-RGCN" class="headerlink" title="Summary of RGCN"></a>Summary of RGCN</h3><ul>
<li>Relational GCN, a graph neural network for  heterogeneous graphs </li>
<li>Can perform entity classification as well as  link prediction tasks. </li>
<li>Ideas can easily be extended into RGNN  (RGraphSAGE, RGAT, etc.)</li>
</ul>
<h2 id="Knowledge-Graphs-KG-Completion-with-Embeddings"><a href="#Knowledge-Graphs-KG-Completion-with-Embeddings" class="headerlink" title="Knowledge Graphs KG Completion with Embeddings"></a>Knowledge Graphs KG Completion with Embeddings</h2><h3 id="Knowledge-Graphs-KG"><a href="#Knowledge-Graphs-KG" class="headerlink" title="Knowledge Graphs( KG)"></a>Knowledge Graphs( KG)</h3><p>Knowledge in graph form: </p>
<p>Capture entities, types, and relationships </p>
<ul>
<li>Nodes are entities </li>
<li>Nodes are labeled with  their types </li>
<li>Edges between two nodes capture relationships  between entities </li>
<li>KG is an example of a  heterogeneous graph</li>
</ul>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211125124156465.png" alt=""></p>
<h3 id="Example-Bibliographic-Networks"><a href="#Example-Bibliographic-Networks" class="headerlink" title="Example: Bibliographic Networks"></a>Example: Bibliographic Networks</h3><ul>
<li>Node types: paper, title, author, conference,  year </li>
<li>Relation types: pubWhere, pubYear, hasTitle,  hasAuthor, cite</li>
</ul>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211125124253212.png" alt=""></p>
<h3 id="Example-Bio-Knowledge-Graphs"><a href="#Example-Bio-Knowledge-Graphs" class="headerlink" title="Example: Bio Knowledge Graphs"></a>Example: Bio Knowledge Graphs</h3><ul>
<li>Node types: drug, disease, adverse event,  protein, pathways </li>
<li>Relation types: has_func, causes, assoc, treats,  is_a</li>
</ul>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211125124658360.png" alt=""></p>
<h3 id="Knowledge-Graphs-in-Practice"><a href="#Knowledge-Graphs-in-Practice" class="headerlink" title="Knowledge Graphs in Practice"></a>Knowledge Graphs in Practice</h3><ul>
<li>Examples of knowledge graphs </li>
<li>Google Knowledge Graph  </li>
<li>Amazon Product Graph </li>
<li>Facebook Graph API  </li>
<li>IBM Watson  </li>
<li>Microsoft Satori  </li>
<li>Project Hanover/Literome </li>
<li>LinkedIn Knowledge Graph  </li>
<li>Yandex Object Answer</li>
</ul>
<h3 id="Applications-of-Knowledge-Graphs"><a href="#Applications-of-Knowledge-Graphs" class="headerlink" title="Applications of Knowledge Graphs"></a>Applications of Knowledge Graphs</h3><ul>
<li>Serving information</li>
<li>Question answering and conversation agents</li>
</ul>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211125124833006.png" alt=""></p>
<h3 id="Knowledge-Graph-Datasets"><a href="#Knowledge-Graph-Datasets" class="headerlink" title="Knowledge Graph Datasets"></a>Knowledge Graph Datasets</h3><ul>
<li>Publicly available KGs: <ul>
<li>FreeBase, Wikidata, Dbpedia, YAGO, NELL, etc. </li>
</ul>
</li>
<li>Common characteristics: <ul>
<li>Massive: millions of nodes and edges </li>
<li>Incomplete: many true edges are missing</li>
</ul>
</li>
</ul>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211125124916364.png" alt=""></p>
<h3 id="Example-Freebase"><a href="#Example-Freebase" class="headerlink" title="Example: Freebase"></a>Example: Freebase</h3><p><img src="/images/loading.gif" data-original="../images/basic/image-20211125124942905.png" alt=""></p>
<h2 id="Knowledge-Graph-Completion-TransE-TransR-DistMul-ComplEx"><a href="#Knowledge-Graph-Completion-TransE-TransR-DistMul-ComplEx" class="headerlink" title="Knowledge Graph Completion TransE, TransR, DistMul, ComplEx"></a>Knowledge Graph Completion TransE, TransR, DistMul, ComplEx</h2><h3 id="KG-Completion-Task"><a href="#KG-Completion-Task" class="headerlink" title="KG Completion Task"></a>KG Completion Task</h3><ul>
<li>Given an enormous KG, can we complete the KG? </li>
<li>For a given (head, relation), we predict missing tails. <ul>
<li>(Note this is slightly different from link prediction task)</li>
</ul>
</li>
</ul>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211125125118472.png" alt=""></p>
<h3 id="KG-Representation"><a href="#KG-Representation" class="headerlink" title="KG Representation"></a>KG Representation</h3><p><img src="/images/loading.gif" data-original="../images/basic/image-20211125125200568.png" alt=""></p>
<h3 id="TransE"><a href="#TransE" class="headerlink" title="TransE"></a>TransE</h3><p><a href="https://hal.archives-ouvertes.fr/file/index/docid/920777/filename/bordes13nips.pdf" target="_blank" rel="noopener">Bordes, et al., Translating embeddings for modeling multi-relational data, NeurIPS 2013</a></p>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211125125309091.png" alt=""></p>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211125125342479.png" alt=""></p>
<h4 id="Connectivity-Patterns-in-KG"><a href="#Connectivity-Patterns-in-KG" class="headerlink" title="Connectivity Patterns in KG"></a>Connectivity Patterns in KG</h4><p>Relations in a heterogeneous KG have  different properties</p>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211125125414582.png" alt=""></p>
<p>Can we categorize these relation patterns? </p>
<p>Are KG embedding methods (e.g., TransE)  expressive enough to model these patterns?</p>
<h4 id="Relation-Patterns"><a href="#Relation-Patterns" class="headerlink" title="Relation Patterns"></a>Relation Patterns</h4><p><img src="/images/loading.gif" data-original="../images/basic/image-20211125125520866.png" alt=""></p>
<h4 id="Antisymmetric-Relations-in-Transe"><a href="#Antisymmetric-Relations-in-Transe" class="headerlink" title="Antisymmetric Relations in Transe"></a>Antisymmetric Relations in Transe</h4><p><img src="/images/loading.gif" data-original="../images/basic/image-20211125125638800.png" alt=""></p>
<h4 id="Inverse-Relations-in-TransE"><a href="#Inverse-Relations-in-TransE" class="headerlink" title="Inverse Relations in TransE"></a>Inverse Relations in TransE</h4><p><img src="/images/loading.gif" data-original="../images/basic/image-20211125125730171.png" alt=""></p>
<h4 id="Composition-in-Transe"><a href="#Composition-in-Transe" class="headerlink" title="Composition in Transe"></a>Composition in Transe</h4><p><img src="/images/loading.gif" data-original="../images/basic/image-20211125125753671.png" alt=""></p>
<h4 id="Limitation-Symmetric-Relations"><a href="#Limitation-Symmetric-Relations" class="headerlink" title="Limitation Symmetric Relations"></a>Limitation Symmetric Relations</h4><p><img src="/images/loading.gif" data-original="../images/basic/image-20211125125845889.png" alt=""></p>
<h4 id="Limitation-1-to-n-Relations"><a href="#Limitation-1-to-n-Relations" class="headerlink" title="Limitation: 1-to-n Relations"></a>Limitation: 1-to-n Relations</h4><p><img src="/images/loading.gif" data-original="../images/basic/image-20211125125911425.png" alt=""></p>
<h2 id="Knowledge-Graph-Completion-TransR"><a href="#Knowledge-Graph-Completion-TransR" class="headerlink" title="Knowledge Graph Completion : TransR"></a>Knowledge Graph Completion : TransR</h2><h3 id="TransR"><a href="#TransR" class="headerlink" title="TransR"></a>TransR</h3><p><a href="https://www.aaai.org/ocs/index.php/AAAI/AAAI15/paper/viewFile/9571/9523/" target="_blank" rel="noopener">Lin, et al., Learning entity and relation embeddings for knowledge graph completion,AAAI 2015</a></p>
<p>TransE models translation of any relation in  the same embedding space.</p>
<p>Can we design a new space for each relation  and do translation in relation-specific space?</p>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211125130224413.png" alt=""></p>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211125130249365.png" alt=""></p>
<h3 id="Symmetric-Relations-in-TransR"><a href="#Symmetric-Relations-in-TransR" class="headerlink" title="Symmetric Relations in TransR"></a>Symmetric Relations in TransR</h3><p><img src="/images/loading.gif" data-original="../images/basic/image-20211125130412532.png" alt=""></p>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211125130427466.png" alt=""></p>
<h3 id="1-to-n-Relations-in-TransR"><a href="#1-to-n-Relations-in-TransR" class="headerlink" title="1-to-n Relations in TransR"></a>1-to-n Relations in TransR</h3><p><img src="/images/loading.gif" data-original="../images/basic/image-20211125130641871.png" alt=""></p>
<h3 id="Inverse-Relations-in-TransR"><a href="#Inverse-Relations-in-TransR" class="headerlink" title="Inverse Relations in TransR"></a>Inverse Relations in TransR</h3><p><img src="/images/loading.gif" data-original="../images/basic/image-20211125131052646.png" alt=""></p>
<h3 id="Composition-Relations-in-TransR"><a href="#Composition-Relations-in-TransR" class="headerlink" title="Composition Relations in TransR"></a>Composition Relations in TransR</h3><p><img src="/images/loading.gif" data-original="../images/basic/image-20211125132011443.png" alt=""></p>
<p>High-level intuition: TransR models a triple with  linear functions, they are chainable</p>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211125132035316.png" alt=""></p>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211125132052181.png" alt=""></p>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211125132127097.png" alt=""></p>
<h2 id="Knowledge-Graph-Completion-DistMult"><a href="#Knowledge-Graph-Completion-DistMult" class="headerlink" title="Knowledge Graph Completion DistMult"></a>Knowledge Graph Completion DistMult</h2><h3 id="New-Idea-Bilinear-Modeling"><a href="#New-Idea-Bilinear-Modeling" class="headerlink" title="New Idea: Bilinear Modeling"></a>New Idea: Bilinear Modeling</h3><p><a href="https://arxiv.org/pdf/1412.6575.pdf" target="_blank" rel="noopener">Yang et al, Embedding Entities and Relations for Learning and Inference in Knowledge Bases, ICLR 2015</a></p>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211125132249137.png" alt=""></p>
<h3 id="DistMult"><a href="#DistMult" class="headerlink" title="DistMult"></a>DistMult</h3><p><img src="/images/loading.gif" data-original="../images/basic/image-20211125132316903.png" alt=""></p>
<h3 id="1-to-n-Relations-in-DistMult"><a href="#1-to-n-Relations-in-DistMult" class="headerlink" title="1-to-n Relations in DistMult"></a>1-to-n Relations in DistMult</h3><p><img src="/images/loading.gif" data-original="../images/basic/image-20211125132452417.png" alt=""></p>
<h3 id="Symmetric-Relations-in-DistMult"><a href="#Symmetric-Relations-in-DistMult" class="headerlink" title="Symmetric Relations in DistMult"></a>Symmetric Relations in DistMult</h3><p><img src="/images/loading.gif" data-original="../images/basic/image-20211125132517641.png" alt=""></p>
<h3 id="Limitation-Antisymmetric-Relations"><a href="#Limitation-Antisymmetric-Relations" class="headerlink" title="Limitation: Antisymmetric Relations"></a>Limitation: Antisymmetric Relations</h3><p><img src="/images/loading.gif" data-original="../images/basic/image-20211125132547836.png" alt=""></p>
<h3 id="Limitation-Inverse-Relations"><a href="#Limitation-Inverse-Relations" class="headerlink" title="Limitation: Inverse Relations"></a>Limitation: Inverse Relations</h3><p><img src="/images/loading.gif" data-original="../images/basic/image-20211125132910534.png" alt=""></p>
<h3 id="Limitation-Composition-Relations"><a href="#Limitation-Composition-Relations" class="headerlink" title="Limitation: Composition Relations"></a>Limitation: Composition Relations</h3><p><img src="/images/loading.gif" data-original="../images/basic/image-20211125133048467.png" alt=""></p>
<h2 id="Knowledge-Graph-Completion-ComplEx"><a href="#Knowledge-Graph-Completion-ComplEx" class="headerlink" title="Knowledge Graph Completion ComplEx"></a>Knowledge Graph Completion ComplEx</h2><h3 id="ComplEx"><a href="#ComplEx" class="headerlink" title="ComplEx"></a>ComplEx</h3><p><a href="http://proceedings.mlr.press/v48/trouillon16.pdf" target="_blank" rel="noopener">Trouillon et al, Complex Embeddings for Simple Link Prediction, ICML 2016</a></p>
<p>Based on Distmult, ComplEx embeds entities  and relations in Complex vector space</p>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211125133511498.png" alt=""></p>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211125133526515.png" alt=""></p>
<h3 id="Antisymmetric-Relations-in-Complex"><a href="#Antisymmetric-Relations-in-Complex" class="headerlink" title="Antisymmetric Relations in Complex"></a>Antisymmetric Relations in Complex</h3><p><img src="/images/loading.gif" data-original="../images/basic/image-20211125133642715.png" alt=""></p>
<h3 id="Symmetric-Relations-in-Complex"><a href="#Symmetric-Relations-in-Complex" class="headerlink" title="Symmetric Relations in Complex"></a>Symmetric Relations in Complex</h3><p><img src="/images/loading.gif" data-original="../images/basic/image-20211125133723426.png" alt=""></p>
<h3 id="Inverse-Relations-in-ComplEx"><a href="#Inverse-Relations-in-ComplEx" class="headerlink" title="Inverse Relations in ComplEx"></a>Inverse Relations in ComplEx</h3><p><img src="/images/loading.gif" data-original="../images/basic/image-20211125133751079.png" alt=""></p>
<h3 id="Composition-and-1-to-n"><a href="#Composition-and-1-to-n" class="headerlink" title="Composition and 1-to-n"></a>Composition and 1-to-n</h3><p><img src="/images/loading.gif" data-original="../images/basic/image-20211125133823651.png" alt=""></p>
<h3 id="Expressiveness-of-All-Models"><a href="#Expressiveness-of-All-Models" class="headerlink" title="Expressiveness of All Models"></a>Expressiveness of All Models</h3><p>Properties and expressive power of different  KG completion methods:</p>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211125133858385.png" alt=""></p>
<h3 id="KG-Embeddings-in-Practice"><a href="#KG-Embeddings-in-Practice" class="headerlink" title="KG Embeddings in Practice"></a>KG Embeddings in Practice</h3><p><a href="https://openreview.net/forum?id=HkgEQnRqYQ&amp;noteId=HJlFFR7167" target="_blank" rel="noopener">Sun et al, RotatE: Knowledge Graph Embedding by Relational Rotation in Complex Space, ICLR 2019</a></p>
<ul>
<li>Different KGs may have drastically different  relation patterns! </li>
<li>There is not a general embedding that works  for all KGs, use the table to select models </li>
<li>Try TransE for a quick run if the target KG does  not have much symmetric relations </li>
<li>Then use more expressive models, e.g.,  ComplEx, RotatE (TransE in Complex space)</li>
</ul>
<h3 id="Summary-12"><a href="#Summary-12" class="headerlink" title="Summary"></a>Summary</h3><ul>
<li>Link prediction / Graph completion is one of  the prominent tasks on knowledge graphs </li>
<li>Introduce <strong>TransE / TransR / DistMult /  ComplEx</strong> models with different embedding space and expressiveness</li>
</ul>
<h1 id="Reasoning-in-Knowledge-Graphs-using-Embeddings"><a href="#Reasoning-in-Knowledge-Graphs-using-Embeddings" class="headerlink" title="Reasoning in Knowledge Graphs using Embeddings"></a>Reasoning in Knowledge Graphs using Embeddings</h1><h3 id="Example-KG-Biomedicine"><a href="#Example-KG-Biomedicine" class="headerlink" title="Example KG: Biomedicine"></a>Example KG: Biomedicine</h3><p><img src="/images/loading.gif" data-original="../images/basic/image-20211125134236838.png" alt=""></p>
<h3 id="Predictive-Queries-on-KG"><a href="#Predictive-Queries-on-KG" class="headerlink" title="Predictive Queries on KG"></a>Predictive Queries on KG</h3><p>Can we do multi-hop reasoning, i.e., answer  complex queries on an incomplete, massive KG?</p>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211125134322354.png" alt=""></p>
<h3 id="Predictive-One-hop-Queries"><a href="#Predictive-One-hop-Queries" class="headerlink" title="Predictive One-hop Queries"></a>Predictive One-hop Queries</h3><p>We can formulate knowledge graph completion  problems as answering one-hop queries.</p>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211125134350031.png" alt=""></p>
<h3 id="Path-Queries"><a href="#Path-Queries" class="headerlink" title="Path Queries"></a>Path Queries</h3><p>Generalize one-hop queries to path queries by  adding more relations on the path.</p>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211125134559315.png" alt=""></p>
<p>Query plan of path queries is a chain.</p>
<p>Question: “What proteins are associated with  adverse events caused by Fulvestrant?”</p>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211125134636080.png" alt=""></p>
<p>Query: (e:Fulvestrant, (r:Causes, r:Assoc)) Given a KG, how to answer a path query?</p>
<h3 id="Traversing-Knowledge-Graphs"><a href="#Traversing-Knowledge-Graphs" class="headerlink" title="Traversing Knowledge Graphs"></a>Traversing Knowledge Graphs</h3><ul>
<li>We answer path queries by traversing the KG:  “What proteins are associated with adverse  events caused by Fulvestrant?” </li>
<li>Query: (e:Fulvestrant, (r:Causes, r:Assoc))</li>
</ul>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211125134858926.png" alt=""></p>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211125134912765.png" alt=""></p>
<h3 id="However-KGS-are-incomplete"><a href="#However-KGS-are-incomplete" class="headerlink" title="However, KGS are incomplete"></a>However, KGS are incomplete</h3><ul>
<li>Answering queries seems easy: Just traverse  the graph. </li>
<li>But KGs are incomplete and unknown: <ul>
<li>Many relations between entities are missing or are  incomplete <ul>
<li>For example, we lack all the biomedical knowledge </li>
<li>Enumerating all the facts takes non-trivial time and cost,  we cannot hope that KGs will ever be fully complete </li>
</ul>
</li>
</ul>
</li>
<li>Due to KG incompleteness, one is not able to  identify all the answer entities</li>
</ul>
<p>Can we first do KG completion and then  traverse the completed (probabilistic) KG?</p>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211125140136209.png" alt=""></p>
<h3 id="Task-Predictive-Oueries"><a href="#Task-Predictive-Oueries" class="headerlink" title="Task: Predictive Oueries"></a>Task: Predictive Oueries</h3><p>We need a way to answer path-based queries  over an incomplete knowledge graph.</p>
<p> We want our approach to implicitly impute and  account for the incomplete KG. </p>
<p>Task: Predictive queries </p>
<ul>
<li>Want to be able to answer arbitrary queries while implicitly imputing for the missing information </li>
<li>Generalization of the link prediction task</li>
</ul>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211125140245867.png" alt=""></p>
<h2 id="Answering-Predictive-Queries-on-Knowledge-Graphs"><a href="#Answering-Predictive-Queries-on-Knowledge-Graphs" class="headerlink" title="Answering Predictive Queries on Knowledge Graphs"></a>Answering Predictive Queries on Knowledge Graphs</h2><h3 id="General-Idea"><a href="#General-Idea" class="headerlink" title="General Idea"></a>General Idea</h3><p><img src="/images/loading.gif" data-original="../images/basic/image-20211125140416321.png" alt=""></p>
<p>Map queries into embedding space. Learn to reason in  that space </p>
<ul>
<li>Embed query into a single point in the Euclidean space:  answer nodes are close to the query. </li>
<li>Query2Box: Embed query into a hyper-rectangle (box) in the  Euclidean space: answer nodes are enclosed in the box.</li>
</ul>
<p>[<a href="https://arxiv.org/abs/1806.01445" target="_blank" rel="noopener">Embedding Logical Queries on Knowledge Graphs.</a> Hamilton, et al., NeurIPS 2018] </p>
<p>[<a href="http://snap.stanford.edu/query2box/" target="_blank" rel="noopener">Query2box: Reasoning over Knowledge Graphs in Vector Space Using Box Embeddings</a>. Ren, et al., ICLR 2020]</p>
<h3 id="Idea-Traversing-KG-in-Vector-Space"><a href="#Idea-Traversing-KG-in-Vector-Space" class="headerlink" title="Idea: Traversing KG in Vector Space"></a>Idea: Traversing KG in Vector Space</h3><p><a href="https://aclanthology.org/D15-1038.pdf" target="_blank" rel="noopener">Guu, et al., Traversing knowledge graphs in vector space, EMNLP 2015</a></p>
<p>Key idea: Embed queries!</p>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211125140710859.png" alt=""></p>
<h3 id="Traversing-KG-in-Vector-Space"><a href="#Traversing-KG-in-Vector-Space" class="headerlink" title="Traversing KG in Vector Space"></a>Traversing KG in Vector Space</h3><p><img src="/images/loading.gif" data-original="../images/basic/image-20211125140749787.png" alt=""></p>
<p>The embedding process only involves vector  addition, independent of # entities in the KG!</p>
<p>Embed path queries in vector space. </p>
<ul>
<li>Question: “What proteins are associated with  adverse events caused by Fulvestrant?” </li>
<li>Query: (e:Fulvestrant, (r:Causes , r:Assoc))</li>
</ul>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211125140839122.png" alt=""></p>
<p>Insights: </p>
<ul>
<li>We can train TransE to optimize knowledge  graph completion objective (Lecture 10) </li>
<li>Since TransE can naturally handle compositional  relations, it can handle path queries by  translating in the latent space for multiple hops  using addition of relation embeddings. </li>
<li>For TransR / DistMult / ComplEx, since they  cannot handle compositional relations, they  cannot be easily extended to handle path  queries.</li>
</ul>
<h3 id="Conjunctive-Queries"><a href="#Conjunctive-Queries" class="headerlink" title="Conjunctive Queries"></a>Conjunctive Queries</h3><p>Can we answer more complex queries with logic  conjunction operation? </p>
<ul>
<li>Conjunctive Queries: “What are drugs that cause Short  of Breath and treat diseases associated with protein ESR2?” ((e:ESR2, (r:Assoc, r:TreatedBy)), (e:Short of Breath, (r:CausedBy))</li>
</ul>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211125141006116.png" alt=""></p>
<p>How do we answer the question by KG traversal?</p>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211125141028674.png" alt=""></p>
<p>Traverse KG from anchor nodes: ESR2 and Short of  Breath:</p>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211125141105096.png" alt=""></p>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211125141419215.png" alt=""></p>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211125141438965.png" alt=""></p>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211125141454464.png" alt=""></p>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211125141520705.png" alt=""></p>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211125141535370.png" alt=""></p>
<ul>
<li>How can we use embeddings to implicitly impute  the missing (ESR2, Assoc, Breast Cancer)?  </li>
<li>Intuition: ESR2 interacts with both BRCA1 and ESR1.  Both proteins are associated with breast cancer</li>
</ul>
<h3 id="Traversing-KG-in-Vector-Space-1"><a href="#Traversing-KG-in-Vector-Space-1" class="headerlink" title="Traversing KG in Vector Space"></a>Traversing KG in Vector Space</h3><p>“What are drugs that cause Short of Breath and  treat diseases associated with protein ESR2?”</p>
<p> ((e:ESR2, (r:Assoc, r:TreatedBy)), (e:Short of Breath, (r:CausedBy))</p>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211125141716535.png" alt=""></p>
<p>Each intermediate node represents a set of entities, how do we  represent it? How do we define the intersection operation in  the latent space?</p>
<h2 id="Qvery2box-Reasoning-over-KGS-Using-Box-Embeddings"><a href="#Qvery2box-Reasoning-over-KGS-Using-Box-Embeddings" class="headerlink" title="Qvery2box: Reasoning over KGS Using Box Embeddings"></a>Qvery2box: Reasoning over KGS Using Box Embeddings</h2><h3 id="Conjunctive-Queries-1"><a href="#Conjunctive-Queries-1" class="headerlink" title="Conjunctive Queries"></a>Conjunctive Queries</h3><p>How can we answer more complex queries with  logical conjunction operation?</p>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211125141834101.png" alt=""></p>
<p>(1) Each intermediate node represents a set of  entities; how do we represent it?</p>
<p>(2) How do we define the intersection operation  in the latent space?</p>
<h3 id="Box-Embeddings"><a href="#Box-Embeddings" class="headerlink" title="Box Embeddings"></a>Box Embeddings</h3><p><a href="https://openreview.net/forum?id=BJgr4kSFDS" target="_blank" rel="noopener">Ren et al., Query2box: Reasoning over Knowledge Graphs in Vector Space Using Box Embeddings, ICLR 2020.</a></p>
<p>Embed queries with hyper-rectangles (boxes)</p>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211125142002604.png" alt=""></p>
<h3 id="Key-Insight-Intersection-交点"><a href="#Key-Insight-Intersection-交点" class="headerlink" title="Key Insight: Intersection(交点)"></a>Key Insight: Intersection(交点)</h3><ul>
<li>Intersection of boxes is well-defined! </li>
<li>When we traverse the KG to find the answers,  each step produces a set of reachable entities. </li>
<li>How can we better model these sets?  <ul>
<li>Boxes are a powerful abstraction, as we can  project the center and control the offset to model  the set of entities enclosed in the box</li>
</ul>
</li>
</ul>
<h3 id="Embed-with-Box-Embedding"><a href="#Embed-with-Box-Embedding" class="headerlink" title="Embed with Box Embedding"></a>Embed with Box Embedding</h3><p><img src="/images/loading.gif" data-original="../images/basic/image-20211125142209680.png" alt=""></p>
<h3 id="Projection-预测-Operator"><a href="#Projection-预测-Operator" class="headerlink" title="Projection(预测) Operator"></a>Projection(预测) Operator</h3><p><img src="/images/loading.gif" data-original="../images/basic/image-20211125142322344.png" alt=""></p>
<h3 id="Embed-with-Box-Embedding-1"><a href="#Embed-with-Box-Embedding-1" class="headerlink" title="Embed with Box Embedding"></a>Embed with Box Embedding</h3><p>How do we take intersection of boxes?</p>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211125142406480.png" alt=""></p>
<h3 id="Intersection-Operator"><a href="#Intersection-Operator" class="headerlink" title="Intersection Operator"></a>Intersection Operator</h3><p><img src="/images/loading.gif" data-original="../images/basic/image-20211125142437146.png" alt=""></p>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211125142506973.png" alt=""></p>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211125142541674.png" alt=""></p>
<p><strong>Use box intersection operator</strong></p>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211125142629495.png" alt=""></p>
<h3 id="Entity-to-box-Distance"><a href="#Entity-to-box-Distance" class="headerlink" title="Entity-to-box Distance"></a>Entity-to-box Distance</h3><p><img src="/images/loading.gif" data-original="../images/basic/image-20211125142708751.png" alt=""></p>
<h3 id="Extending-to-Union-Operation"><a href="#Extending-to-Union-Operation" class="headerlink" title="Extending to Union Operation"></a>Extending to Union Operation</h3><ul>
<li>Can we embed complex queries with union? E.g.: “What drug can treat breast cancer or lung cancer?” </li>
<li>Conjunctive queries + disjunction is called  Existential Positive First-order (EPFO) queries. We’ll refer to them as AND-OR queries. </li>
<li>Can we also design a disjunction operator and  embed AND-OR queries in low-dimensional  vector space?</li>
</ul>
<h3 id="Embedding-AND-OR-Queries"><a href="#Embedding-AND-OR-Queries" class="headerlink" title="Embedding AND-OR Queries"></a>Embedding AND-OR Queries</h3><ul>
<li>Can we embed AND-OR queries in a low-dimensional vector space? </li>
<li>No! Intuition: Allowing union over arbitrary  queries requires high-dimensional embeddings! </li>
<li>Example:</li>
</ul>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211125142818003.png" alt=""></p>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211125142832336.png" alt=""></p>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211125142913967.png" alt=""></p>
<ul>
<li>Example 2:</li>
</ul>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211125142945483.png" alt=""></p>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211125142957994.png" alt=""></p>
<p>Can we embed AND-OR queries in low-dimensional vector space?</p>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211125143030021.png" alt=""></p>
<p>Since we cannot embed AND-OR queries in lowdimensional space, can we still handle them? </p>
<ul>
<li>Key idea: take all unions out and only do union  at the last step!</li>
</ul>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211125143057507.png" alt=""></p>
<h3 id="Disjunctive-Normal-Form"><a href="#Disjunctive-Normal-Form" class="headerlink" title="Disjunctive Normal Form"></a>Disjunctive Normal Form</h3><p>Any AND-OR query can be transformed into  equivalent DNF, i.e., disjunction of  conjunctive queries.</p>
<img src="/images/loading.gif" data-original="../images/basic/image-20211125143152733.png" style="zoom:67%;">

<h3 id="Distance-Between-q-and-an-Entity"><a href="#Distance-Between-q-and-an-Entity" class="headerlink" title="Distance Between q and an Entity"></a>Distance Between q and an Entity</h3><p><img src="/images/loading.gif" data-original="../images/basic/image-20211125143335482.png" alt=""></p>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211125143351801.png" alt=""></p>
<h2 id="How-to-Train-Query2box"><a href="#How-to-Train-Query2box" class="headerlink" title="How to Train Query2box"></a>How to Train Query2box</h2><h3 id="Training-Overview"><a href="#Training-Overview" class="headerlink" title="Training Overview"></a>Training Overview</h3><p><img src="/images/loading.gif" data-original="../images/basic/image-20211125143431185.png" alt=""></p>
<p>How to achieve a query, its answers, its negative  answers from the KG to train the parameters? </p>
<p>How to split the KG for query answering?</p>
<h3 id="Training"><a href="#Training" class="headerlink" title="Training"></a>Training</h3><p><img src="/images/loading.gif" data-original="../images/basic/image-20211125143503403.png" alt=""></p>
<h3 id="Query-Generation-from-Templates"><a href="#Query-Generation-from-Templates" class="headerlink" title="Query Generation from Templates"></a>Query Generation from Templates</h3><p>Generate queries from multiple query  templates:</p>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211125143605107.png" alt=""></p>
<ul>
<li>How can we generate a complex query? </li>
<li>We start with a query template </li>
<li>Query template can be viewed as an abstraction of the  query</li>
<li>We generate a query by instantiating every variable with  a concrete entity and relation from the KG <ul>
<li>E.g., instantiate Anchor1 with ESR2 (a node on KG) </li>
<li>E.g., instantiate Rel1 with Assoc (an edge on KG) </li>
</ul>
</li>
<li>How to instantiate query template given a KG?</li>
</ul>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211125143700064.png" alt=""></p>
<p>How to instantiate a query template given a KG?</p>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211125143725279.png" alt=""></p>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211125143746088.png" alt=""></p>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211125143824359.png" alt=""></p>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211125143836765.png" alt=""></p>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211125143851219.png" alt=""></p>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211125143914046.png" alt=""></p>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211125143927158.png" alt=""></p>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211125144011278.png" alt=""></p>
<h2 id="Example-of-Query2box"><a href="#Example-of-Query2box" class="headerlink" title="Example of Query2box"></a>Example of Query2box</h2><h3 id="Visualization"><a href="#Visualization" class="headerlink" title="Visualization"></a>Visualization</h3><ul>
<li>What do box embeddings actually learn? Example: “List male instrumentalists who play  string instruments” </li>
<li>We use t-SNE to reduce the embedding space  to a 2-dimensional space, in order to visualize  the query results</li>
</ul>
<h3 id="Embedding-Space"><a href="#Embedding-Space" class="headerlink" title="Embedding Space"></a>Embedding Space</h3><p><img src="/images/loading.gif" data-original="../images/basic/image-20211125144257396.png" alt=""></p>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211125144311368.png" alt=""></p>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211125144322567.png" alt=""></p>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211125144337800.png" alt=""></p>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211125144348928.png" alt=""></p>
<h3 id="Summary-13"><a href="#Summary-13" class="headerlink" title="Summary"></a>Summary</h3><p>We introduce answering predictive queries  on large knowledge graphs. </p>
<p>The key idea is to embed queries by  navigating the embedding space! </p>
<p>We embed the query by composing learned  operators </p>
<p>Embedding of the query is close to its answers in  the embedding space</p>
<h1 id="Fast-Neural-Subgraph-Matching-and-Counting"><a href="#Fast-Neural-Subgraph-Matching-and-Counting" class="headerlink" title="Fast Neural Subgraph Matching and Counting"></a>Fast Neural Subgraph Matching and Counting</h1><h3 id="Subgraphs"><a href="#Subgraphs" class="headerlink" title="Subgraphs"></a>Subgraphs</h3><p>Subgraphs are the building blocks of  networks:</p>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211125144546910.png" alt=""></p>
<p>They have the power to characterize and  discriminate networks</p>
<h3 id="Building-Blocks-of-Networks"><a href="#Building-Blocks-of-Networks" class="headerlink" title="Building Blocks of Networks"></a>Building Blocks of Networks</h3><p><img src="/images/loading.gif" data-original="../images/basic/image-20211125144618204.png" alt=""></p>
<h2 id="Subgraphs-and-Motifs"><a href="#Subgraphs-and-Motifs" class="headerlink" title="Subgraphs and Motifs"></a>Subgraphs and Motifs</h2><h3 id="Definition-1"><a href="#Definition-1" class="headerlink" title="Definition"></a>Definition</h3><p>Two ways to formalize “network building blocks”</p>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211125144717760.png" alt=""></p>
<p>Alternate terminology: “induced subgraph”</p>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211125144742483.png" alt=""></p>
<p>Alternate terminology: “non-induced subgraph” or  just “subgraph”</p>
<p>The best definition depends on the domain!  Examples: </p>
<ul>
<li>Chemistry: Node-induced (functional groups) </li>
<li>Knowledge graphs: Often edge-induced (focus is on  edges representing logical relations)</li>
</ul>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211125144929169.png" alt=""></p>
<h3 id="Graph-Isomorphism-同构关系"><a href="#Graph-Isomorphism-同构关系" class="headerlink" title="Graph Isomorphism(同构关系)"></a>Graph Isomorphism(同构关系)</h3><p><strong>Graph isomorphism problem</strong>: Check whether two  graphs are identical:</p>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211125145041160.png" alt=""></p>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211125145101036.png" alt=""></p>
<h3 id="Case-Example-of-Subgraphs"><a href="#Case-Example-of-Subgraphs" class="headerlink" title="Case Example of Subgraphs"></a>Case Example of Subgraphs</h3><p>All non-isomorphic, connected, undirected  graphs of size 4</p>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211125145144457.png" alt=""></p>
<p>All non-isomorphic, connected, directed  graphs of size 3</p>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211125145200590.png" alt=""></p>
<h3 id="Network-Motifs"><a href="#Network-Motifs" class="headerlink" title="Network Motifs"></a>Network Motifs</h3><p>Network motifs: “recurring, significant  patterns of interconnections”  </p>
<p>How to define a network motif:  </p>
<ul>
<li>Pattern: Small (node-induced) subgraph </li>
<li>Recurring: Found many times, i.e., with high  frequency </li>
<li>Significant: More frequent than expected, i.e., in  randomly generated graphs? </li>
<li>How to define frequency? How to define random graphs?</li>
</ul>
<h3 id="Motifs-Induced-Subaraphs"><a href="#Motifs-Induced-Subaraphs" class="headerlink" title="Motifs: Induced Subaraphs"></a>Motifs: Induced Subaraphs</h3><p><img src="/images/loading.gif" data-original="../images/basic/image-20211125145359536.png" alt=""></p>
<h3 id="Why-Do-We-Need-Motifs"><a href="#Why-Do-We-Need-Motifs" class="headerlink" title="Why Do We Need Motifs?"></a>Why Do We Need Motifs?</h3><p><img src="/images/loading.gif" data-original="../images/basic/image-20211125145427190.png" alt=""></p>
<h3 id="Subgraph-Frequency"><a href="#Subgraph-Frequency" class="headerlink" title="Subgraph Frequency"></a>Subgraph Frequency</h3><p><img src="/images/loading.gif" data-original="../images/basic/image-20211125145455485.png" alt=""></p>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211125145508992.png" alt=""></p>
<p>What if the dataset contains multiple graphs,  and we want to compute frequency of  subgraphs in the dataset? </p>
<p>Solution: Treat the dataset as a giant graph G_T with disconnected components corresponding  to individual graphs</p>
<h3 id="Defining-Motif-Significance"><a href="#Defining-Motif-Significance" class="headerlink" title="Defining Motif Significance"></a>Defining Motif Significance</h3><p>To define significance, we need to have a  null-model (i.e., point of comparison). </p>
<p>Key idea: Subgraphs that occur in a real  network much more often than in a random network have functional significance.</p>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211125145619042.png" alt=""></p>
<h3 id="Defining-Random-Graphs"><a href="#Defining-Random-Graphs" class="headerlink" title="Defining Random Graphs"></a>Defining Random Graphs</h3><p><img src="/images/loading.gif" data-original="../images/basic/image-20211125145657559.png" alt=""></p>
<h3 id="New-Model-Configuration-Mode"><a href="#New-Model-Configuration-Mode" class="headerlink" title="New Model: Configuration Mode"></a>New Model: Configuration Mode</h3><p><img src="/images/loading.gif" data-original="../images/basic/image-20211125145743250.png" alt=""></p>
<h3 id="Alternative-for-Spokes-Switching"><a href="#Alternative-for-Spokes-Switching" class="headerlink" title="Alternative for Spokes: Switching"></a>Alternative for Spokes: Switching</h3><p><img src="/images/loading.gif" data-original="../images/basic/image-20211125145836452.png" alt=""></p>
<p>Intuition: Motifs are overrepresented in a  network when compared to random graphs: </p>
<ul>
<li>Step 1: Count motifs in the given graph (G_real) </li>
<li>Step 2: Generate random graphs with similar  statistics (e.g. number of nodes, edges, degree  sequence), and count motifs in the random  graphs </li>
<li>Step 3: Use statistical measures to evaluate  how significant is each motif <ul>
<li>Use Z-score</li>
</ul>
</li>
</ul>
<h3 id="Z-score-for-Statistical-Sianificance"><a href="#Z-score-for-Statistical-Sianificance" class="headerlink" title="Z-score for Statistical Sianificance"></a>Z-score for Statistical Sianificance</h3><p><img src="/images/loading.gif" data-original="../images/basic/image-20211125145951798.png" alt=""></p>
<ul>
<li><p>For each subgraph:  </p>
<ul>
<li><p>z-score metric is capable of classifying the subgraph  “significance”: </p>
<ul>
<li><p>Negative values indicate under-representation  </p>
</li>
<li><p>Positive values indicate over-representation  </p>
</li>
</ul>
</li>
</ul>
</li>
<li><p>We create a network significance profile:  </p>
<ul>
<li>A feature vector with values for all subgraph types </li>
</ul>
</li>
<li><p>Next: Compare profiles of different graphs with random  graphs: </p>
<ul>
<li>Regulatory network (gene regulation)  </li>
<li>Neuronal network (synaptic connections)  </li>
<li>World Wide Web (hyperlinks between pages)  </li>
<li>Social network (friendships)</li>
<li>Language networks (word adjacency)</li>
</ul>
</li>
</ul>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211125150115901.png" alt=""></p>
<h3 id="Summary-Detecting-Motifs-主题"><a href="#Summary-Detecting-Motifs-主题" class="headerlink" title="Summary: Detecting Motifs(主题)"></a>Summary: Detecting Motifs(主题)</h3><p><img src="/images/loading.gif" data-original="../images/basic/image-20211125150139494.png" alt=""></p>
<h3 id="Variations-on-the-Motif-Concept"><a href="#Variations-on-the-Motif-Concept" class="headerlink" title="Variations on the Motif Concept"></a>Variations on the Motif Concept</h3><ul>
<li><p>Extensions: </p>
<ul>
<li>Directed and undirected  </li>
<li>Colored and uncolored  </li>
<li>Temporal and static motifs </li>
</ul>
</li>
<li><p>Variations on the concept:  </p>
<ul>
<li>Different frequency concepts  </li>
<li>Different significance metrics  </li>
<li>Under-Representation (anti-motifs)  </li>
<li>Different null models</li>
</ul>
</li>
<li><p>Subgraphs and motifs are the building blocks  of graphs </p>
<ul>
<li>Subgraph isomorphism and counting are NP-hard </li>
</ul>
</li>
<li><p>Understanding which motifs are frequent or  significant in a dataset gives insight into the  unique characteristics of that domain </p>
</li>
<li><p>Use random graphs as null model to evaluate  the significance of motif via Z-score</p>
</li>
</ul>
<h2 id="Neural-Subgraph-Matching"><a href="#Neural-Subgraph-Matching" class="headerlink" title="Neural Subgraph Matching"></a>Neural Subgraph Matching</h2><p>Given:  </p>
<ul>
<li>Large target graph (can be disconnected) </li>
<li>Query graph (connected)</li>
</ul>
<p>Decide: </p>
<ul>
<li>Is a query graph a subgraph in the target graph?</li>
</ul>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211125150553375.png" alt=""></p>
<h3 id="Isomorphism-as-an-ML-Task"><a href="#Isomorphism-as-an-ML-Task" class="headerlink" title="Isomorphism as an ML Task"></a>Isomorphism as an ML Task</h3><ul>
<li>Large target graph (can be disconnected) </li>
<li>Query graph (has to be connected) </li>
<li>Use GNN to predict subgraph isomorphism:</li>
<li>Intuition: Exploit the geometric shape of  embedding space to capture the properties of  subgraph isomorphism</li>
</ul>
<h3 id="Task-Setup"><a href="#Task-Setup" class="headerlink" title="Task Setup"></a>Task Setup</h3><p>Consider a binary prediction: Return True if  query is isomorphic to a subgraph of the  target graph, else return False</p>
<p>Finding node correspondences between Q and T is another challenging  problem, which will not be covered in this lecture.</p>
<h3 id="Overview-of-the-Approach"><a href="#Overview-of-the-Approach" class="headerlink" title="Overview of the Approach"></a>Overview of the Approach</h3><p><img src="/images/loading.gif" data-original="../images/basic/image-20211125151601190.png" alt=""></p>
<h3 id="Neural-Architecture-for-Subgraphs"><a href="#Neural-Architecture-for-Subgraphs" class="headerlink" title="Neural Architecture for Subgraphs"></a>Neural Architecture for Subgraphs</h3><p>(1) We are going to work with node-anchored  definitions:</p>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211125151651322.png" alt=""></p>
<p>(2) We are going to work with node-anchored neighborhoods:</p>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211125151712449.png" alt=""></p>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211125151727903.png" alt=""></p>
<h3 id="Why-Anchor"><a href="#Why-Anchor" class="headerlink" title="Why Anchor?"></a>Why Anchor?</h3><p><img src="/images/loading.gif" data-original="../images/basic/image-20211125151751318.png" alt=""></p>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211125151808372.png" alt=""></p>
<h3 id="Order-Embedding-Space"><a href="#Order-Embedding-Space" class="headerlink" title="Order Embedding Space"></a>Order Embedding Space</h3><p><img src="/images/loading.gif" data-original="../images/basic/image-20211125151828591.png" alt=""></p>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211125151842772.png" alt=""></p>
<h3 id="Why-Order-Embedding-Space"><a href="#Why-Order-Embedding-Space" class="headerlink" title="Why Order Embedding Space?"></a>Why Order Embedding Space?</h3><p>Subgraph isomorphism relationship can be  nicely encoded in order embedding space</p>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211125151910651.png" alt=""></p>
<p>All properties have their counter-parts in the  order embedding space</p>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211125151935557.png" alt=""></p>
<h3 id="Order-Constraint"><a href="#Order-Constraint" class="headerlink" title="Order Constraint"></a>Order Constraint</h3><ul>
<li>We use a GNN to learn to embed neighborhoods  and preserve the order embedding structure </li>
<li>What loss function should we use, so that the  learned order embedding reflects the subgraph  relationship? </li>
<li>We design loss functions based on the order  constraint: <ul>
<li>Order constraint specifies the ideal order embedding  property that reflects subgraph relationships</li>
</ul>
</li>
</ul>
<p>We specify the order constraint to ensure that  the subgraph properties are preserved in the  order embedding space</p>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211125152050328.png" alt=""></p>
<h3 id="Loss-Function"><a href="#Loss-Function" class="headerlink" title="Loss Function"></a>Loss Function</h3><p>GNN Embeddings are learned by minimizing a max-margin loss</p>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211125152129798.png" alt=""></p>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211125152148335.png" alt=""></p>
<h3 id="Training-Neural-Subgraph-Matching"><a href="#Training-Neural-Subgraph-Matching" class="headerlink" title="Training Neural Subgraph Matching"></a>Training Neural Subgraph Matching</h3><p><img src="/images/loading.gif" data-original="../images/basic/image-20211125152212144.png" alt=""></p>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211125152226314.png" alt=""></p>
<h3 id="Training-Details"><a href="#Training-Details" class="headerlink" title="Training Details"></a>Training Details</h3><ul>
<li>How many training examples to sample? <ul>
<li>At every iteration, we sample new training pairs </li>
<li>Benefit: Every iteration, the model sees different  subgraph examples </li>
<li>Improves performance and avoids overfitting – since  there are exponential number of possible subgraphs  to sample from </li>
</ul>
</li>
<li>How deep is the BFS sampling? <ul>
<li>A hyper-parameter that trades off runtime and  performance </li>
<li>Usually use 3-5, depending on size of the dataset</li>
</ul>
</li>
</ul>
<h3 id="Subgraph-Predictions-on-New-Graphs"><a href="#Subgraph-Predictions-on-New-Graphs" class="headerlink" title="Subgraph Predictions on New Graphs"></a>Subgraph Predictions on New Graphs</h3><p><img src="/images/loading.gif" data-original="../images/basic/image-20211125152332240.png" alt=""></p>
<h3 id="Summary-Neural-Subgraph-Matching"><a href="#Summary-Neural-Subgraph-Matching" class="headerlink" title="Summary: Neural Subgraph Matching"></a>Summary: Neural Subgraph Matching</h3><ul>
<li>Neural subgraph matching uses a machine learning-based approach to learn the NP-hard problem of  subgraph isomorphism <ul>
<li>Given query and target graph, it embeds both graphs into an  order embedding space </li>
<li>Using these embeddings, it then computes E(G_q, G_t) to  determine whether query is a subgraph of the target </li>
</ul>
</li>
<li>Embedding graphs within an order embedding  space allows subgraph isomorphism to be  efficiently represented and tested by the relative  positions of graph embeddings</li>
</ul>
<h2 id="Finding-Frequent-Subgraphs"><a href="#Finding-Frequent-Subgraphs" class="headerlink" title="Finding Frequent Subgraphs"></a>Finding Frequent Subgraphs</h2><h3 id="Intro"><a href="#Intro" class="headerlink" title="Intro"></a>Intro</h3><p>Generally, finding the most frequent size-k motifs requires solving two challenges:  </p>
<p>1) Enumerating all size-k connected subgraphs<br>2) Counting #(occurrences of each subgraph type)</p>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211125154601404.png" alt=""></p>
<h3 id="Why-is-it-Hard"><a href="#Why-is-it-Hard" class="headerlink" title="Why is it Hard?"></a>Why is it Hard?</h3><ul>
<li>Just knowing if a certain subgraph exists in  a graph, is a hard computational problem! <ul>
<li>Subgraph isomorphism is NP-complete  </li>
</ul>
</li>
<li>Computation time grows exponentially as  the size of the subgraphs increases  <ul>
<li>Feasible motif size for traditional methods is  relatively small (3 to 7)</li>
</ul>
</li>
</ul>
<h3 id="Solution-with-Representation-Learning"><a href="#Solution-with-Representation-Learning" class="headerlink" title="Solution with Representation Learning"></a>Solution with Representation Learning</h3><ul>
<li>Finding frequent subgraph patterns is  computationally hard <ul>
<li>Combinatorial explosion of number of possible patterns </li>
<li>Counting subgraph frequency is NP-hard </li>
</ul>
</li>
<li>Representation learning can tackle these  challenges: <ul>
<li>Combinatorial explosion -&gt; organize the search space </li>
<li>Subgraph isomorphism -&gt; prediction using GNN</li>
</ul>
</li>
</ul>
<p>Representation learning can tackle these  challenges: </p>
<ul>
<li>Counting #(occurrences of each subgraph type) <ul>
<li>Solution: Use GNN to “predict” the frequency of the subgraph. </li>
</ul>
</li>
<li>Enumerating all size-k connected subgraphs <ul>
<li>Solution: Don’t enumerate subgraphs but construct a  size-k subgraph incrementally <ul>
<li>Note: We are only interested  in high frequency subgraphs</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="Problem-Setup-Frequent-Motif-Mining"><a href="#Problem-Setup-Frequent-Motif-Mining" class="headerlink" title="Problem Setup: Frequent Motif Mining"></a>Problem Setup: Frequent Motif Mining</h3><p><img src="/images/loading.gif" data-original="../images/basic/image-20211125155541458.png" alt=""></p>
<h3 id="SpMiner-Overview"><a href="#SpMiner-Overview" class="headerlink" title="SpMiner: Overview"></a>SpMiner: Overview</h3><p>SPMiner: A neural model to identify frequent motifs</p>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211125155630964.png" alt=""></p>
<h3 id="Key-Idea"><a href="#Key-Idea" class="headerlink" title="Key Idea"></a>Key Idea</h3><p><img src="/images/loading.gif" data-original="../images/basic/image-20211125155658883.png" alt=""></p>
<h3 id="Motif-Frequency-Estimation"><a href="#Motif-Frequency-Estimation" class="headerlink" title="Motif Frequency Estimation"></a>Motif Frequency Estimation</h3><p><img src="/images/loading.gif" data-original="../images/basic/image-20211125155725778.png" alt=""></p>
<h3 id="Spminer-Search-Procedure"><a href="#Spminer-Search-Procedure" class="headerlink" title="Spminer Search Procedure"></a>Spminer Search Procedure</h3><p><img src="/images/loading.gif" data-original="../images/basic/image-20211125155754537.png" alt=""></p>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211125155810214.png" alt=""></p>
<p>Termination: Upon reaching a desired motif size, take  the subgraph of the target graph induced by S.</p>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211125155835995.png" alt=""></p>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211125155938661.png" alt=""></p>
<h3 id="Results-Small-Motifs"><a href="#Results-Small-Motifs" class="headerlink" title="Results: Small Motifs"></a>Results: Small Motifs</h3><ul>
<li>Ground-truth: Find most frequent 10 motifs in  dataset by brute-force exact enumeration (expensive) </li>
<li>Question: Can the model identify frequent motifs? </li>
<li>Result: The model identifies 9 and 8 of the top 10  motifs, respectively.</li>
</ul>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211125160016447.png" alt=""></p>
<h3 id="Experiments-Large-motifs"><a href="#Experiments-Large-motifs" class="headerlink" title="Experiments: Large motifs"></a>Experiments: Large motifs</h3><ul>
<li>Question: How do the frequencies of the  identified motif compare? </li>
<li>Result: SPMiner identifies motifs that appear  10-100x more frequently than the baselines</li>
</ul>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211125160058760.png" alt=""></p>
<h3 id="Summary-14"><a href="#Summary-14" class="headerlink" title="Summary"></a>Summary</h3><ul>
<li>Subgraphs and motifs are important concepts that  provide insights into the structure of graphs. Their  frequency can be used as features for nodes/graphs. </li>
<li>We covered neural approaches to prediction subgraph  isomorphism relationship. </li>
<li>Order embeddings have desirable properties and can  be used to encode subgraph relations </li>
<li>Neural embedding-guided search in order embedding  space can enable ML model to identify motifs much  more frequent than existing methods</li>
</ul>
<h1 id="GNNS-for-Recommender-Systems"><a href="#GNNS-for-Recommender-Systems" class="headerlink" title="GNNS for Recommender Systems"></a>GNNS for Recommender Systems</h1><h2 id="Recommender-Systems-Task-and-Evaluation"><a href="#Recommender-Systems-Task-and-Evaluation" class="headerlink" title="Recommender Systems Task and Evaluation"></a>Recommender Systems Task and Evaluation</h2><h3 id="Preliminary-of-Recommendation"><a href="#Preliminary-of-Recommendation" class="headerlink" title="Preliminary of Recommendation"></a>Preliminary of Recommendation</h3><p>Information Explosion in the era of Internet </p>
<ul>
<li>10K+ movies in Netflix </li>
<li>12M products in Amazon </li>
<li>70M+ music tracks in Spotify </li>
<li>10B+ videos on YouTube </li>
<li>200B+ pins (images) in Pinterest </li>
</ul>
<p>Personalized recommendation (i.e., suggesting  a small number of interesting items for each  user) is critical for users to effectively explore  the content of their interest.</p>
<h3 id="Recommender-System-as-a-Graph"><a href="#Recommender-System-as-a-Graph" class="headerlink" title="Recommender System as a Graph"></a>Recommender System as a Graph</h3><p>Recommender system can  be naturally modeled as a  bipartite graph </p>
<ul>
<li>A graph with two node types:  users and items. </li>
<li>Edges connect users and items <ul>
<li>Indicates user-item interaction  (e.g., click, purchase, review etc.) </li>
<li>Often associated with timestamp  (timing of the interaction).</li>
</ul>
</li>
</ul>
<h3 id="Recommendation-Task"><a href="#Recommendation-Task" class="headerlink" title="Recommendation Task"></a>Recommendation Task</h3><ul>
<li>Given <ul>
<li>Past user-item interactions </li>
</ul>
</li>
<li>Task <ul>
<li>Predict new items each user will  interact in the future. </li>
<li>Can be cast as link prediction problem. <ul>
<li>Predict new user-item interaction  edges given the past edges.</li>
</ul>
</li>
</ul>
</li>
</ul>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211125161301314.png" alt=""></p>
<h3 id="Top-k-Recommendation"><a href="#Top-k-Recommendation" class="headerlink" title="Top-k Recommendation"></a>Top-k Recommendation</h3><p><img src="/images/loading.gif" data-original="../images/basic/image-20211125161327256.png" alt=""></p>
<h3 id="Evaluation-Metric-Recall-k-1"><a href="#Evaluation-Metric-Recall-k-1" class="headerlink" title="Evaluation Metric: Recall@k(1)"></a>Evaluation Metric: Recall@k(1)</h3><p><img src="/images/loading.gif" data-original="../images/basic/image-20211125161418271.png" alt=""></p>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211125161433448.png" alt=""></p>
<h2 id="Recommender-Systems-Embedding-based-Models"><a href="#Recommender-Systems-Embedding-based-Models" class="headerlink" title="Recommender Systems Embedding-based Models"></a>Recommender Systems Embedding-based Models</h2><h3 id="Notation-1"><a href="#Notation-1" class="headerlink" title="Notation"></a>Notation</h3><p><img src="/images/loading.gif" data-original="../images/basic/image-20211125161544042.png" alt=""></p>
<h3 id="Score-Function"><a href="#Score-Function" class="headerlink" title="Score Function"></a>Score Function</h3><p><img src="/images/loading.gif" data-original="../images/basic/image-20211125161724097.png" alt=""></p>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211125161753654.png" alt=""></p>
<h3 id="Training-Objective"><a href="#Training-Objective" class="headerlink" title="Training Objective"></a>Training Objective</h3><p>Embedding-based models have three kinds of  parameters:</p>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211125161848761.png" alt=""></p>
<p>Training objective: Optimize the model  parameters to achieve high recall@K on seen  (i.e., training) user-item interactions </p>
<ul>
<li>We hope this objective would lead to high  recall@K on unseen (i.e., test) interactions.</li>
</ul>
<h3 id="Surrogate-代理-Loss-Functions"><a href="#Surrogate-代理-Loss-Functions" class="headerlink" title="Surrogate(代理) Loss Functions"></a>Surrogate(代理) Loss Functions</h3><ul>
<li>The vanilla training objective (training  recall@K) is not differentiable. <ul>
<li>Cannot apply efficient gradient-based optimization. </li>
</ul>
</li>
<li>Two surrogate loss functions are widely-used  to enable efficient gradient-based  optimization. <ul>
<li>Binary loss </li>
<li>Bayesian Personalized Ranking (BPR) loss </li>
</ul>
</li>
<li>Surrogate losses are differentiable and should  align well with the original training objective.</li>
</ul>
<h3 id="Binary-Loss"><a href="#Binary-Loss" class="headerlink" title="Binary Loss"></a>Binary Loss</h3><p><img src="/images/loading.gif" data-original="../images/basic/image-20211125162203724.png" alt=""></p>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211125162305170.png" alt=""></p>
<p>Binary loss pushes the scores of positive edges  higher than those of negative edges. </p>
<ul>
<li>This aligns with the training recall metric since  positive edges need to be recalled.</li>
</ul>
<p>Issue: </p>
<ul>
<li>In the binary loss, the scores of ALL positive edges are pushed higher than those  of ALL negative edges. </li>
<li>This would unnecessarily penalize model  predictions even if the training recall metric is  perfect. </li>
<li>Why? (example in the next slide)</li>
</ul>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211125162600294.png" alt=""></p>
<ul>
<li>Key insight: The binary loss is non-personalized in the sense that the positive/negative edges  are considered across ALL users at once. </li>
<li>However, the recall metric is inherently  personalized (defined for each user).  <ul>
<li>The non-personalized binary loss is overly-stringent  for the personalized recall metric.</li>
</ul>
</li>
</ul>
<h3 id="Desirable-Surrogate-Loss"><a href="#Desirable-Surrogate-Loss" class="headerlink" title="Desirable Surrogate Loss"></a>Desirable Surrogate Loss</h3><p>Lesson learned: Surrogate loss  function should be defined in  a personalized manner. </p>
<ul>
<li><p>For each user, we want the  scores of positive items to be  higher than those of the  negative items </p>
</li>
<li><p>We do not care about the score  ordering across users. </p>
</li>
</ul>
<p>Bayesian Personalized Ranking  (BPR) loss achieves this!</p>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211125162736104.png" alt=""></p>
<p>Bayesian Personalized Ranking (BPR) loss is a  personalized surrogate loss that aligns better  with the recall@K metric.</p>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211125162806352.png" alt=""></p>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211125162824987.png" alt=""></p>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211125162840657.png" alt=""></p>
<h3 id="Summary-15"><a href="#Summary-15" class="headerlink" title="Summary"></a>Summary</h3><ul>
<li>We have introduced  <ul>
<li>Recall@K as a metric for personalized  recommendation </li>
<li>Embedding-based models <ul>
<li>Three kinds of parameters to learn <ul>
<li>user encoder to generate user embeddings </li>
<li>item encoder to generate item embeddings </li>
<li>score function to predict the user-item interaction likelihood. </li>
</ul>
</li>
</ul>
</li>
<li>Surrogate loss functions to achieve the high recall  metric. </li>
</ul>
</li>
<li>Embedding-based models have achieved SoTA in recommender systems.  <ul>
<li>Why do they work so well?</li>
</ul>
</li>
</ul>
<h3 id="Why-Embedding-Models-Work"><a href="#Why-Embedding-Models-Work" class="headerlink" title="Why Embedding Models Work?"></a>Why Embedding Models Work?</h3><ul>
<li>Underlying idea: </li>
<li>Collaborative filtering <ul>
<li>Recommend items for a  user by collecting  preferences of many  other similar users. </li>
<li>Similar users tend to  prefer similar items. </li>
</ul>
</li>
<li>Key question: How to  capture similarity  between users/items?</li>
</ul>
<img src="/images/loading.gif" data-original="../images/basic/image-20211125163152461.png" style="zoom:50%;">

<p>Embedding-based models can capture  similarity of users/items! </p>
<ul>
<li>Low-dimensional embeddings cannot simply  memorize all user-item interaction data. </li>
<li>Embeddings are forced to capture similarity  between users/items to fit the data. </li>
<li>This allows the models to make effective prediction  on unseen user-item interactions.</li>
</ul>
<h3 id="This-Lecture-GNNS-for-Recsys"><a href="#This-Lecture-GNNS-for-Recsys" class="headerlink" title="This Lecture: GNNS for Recsys"></a>This Lecture: GNNS for Recsys</h3><p>Neural Graph Collaborative Filtering (NGCF)  [Wang et al. 2019], LightGCN [He et al. 2020] </p>
<ul>
<li>Improve the conventional collaborative filtering  models (i.e., matrix factorization) by explicitly  modeling graph structure using GNNs. </li>
</ul>
<p>PinSAGE [Ying et al. 2018] </p>
<ul>
<li>Use GNNs to generate high-quality embeddings by  simultaneously capturing rich node attributes (e.g.,  images) and the graph structure.</li>
</ul>
<h2 id="Neural-Graph-Collaborative-Filtering"><a href="#Neural-Graph-Collaborative-Filtering" class="headerlink" title="Neural Graph Collaborative Filtering"></a>Neural Graph Collaborative Filtering</h2><h3 id="Conventional-Collaborative-Filtering"><a href="#Conventional-Collaborative-Filtering" class="headerlink" title="Conventional Collaborative Filtering"></a>Conventional Collaborative Filtering</h3><p><img src="/images/loading.gif" data-original="../images/basic/image-20211125163443389.png" alt=""></p>
<h3 id="Limitations-of-MF"><a href="#Limitations-of-MF" class="headerlink" title="Limitations of MF"></a>Limitations of MF</h3><p>The model itself does not explicitly capture  graph structure </p>
<ul>
<li>The graph structure is only implicitly captured in  the training objective. </li>
</ul>
<p>Only the first-order graph structure (i.e.,  edges) is captured in the training objective. </p>
<ul>
<li>High-order graph structure (e.g., k-hop paths  between two nodes) is not explicitly captured.</li>
</ul>
<h3 id="Motivation-1"><a href="#Motivation-1" class="headerlink" title="Motivation"></a>Motivation</h3><ul>
<li>We want a model that… <ul>
<li>explicitly captures graph structure (beyond  implicitly through the training objective)</li>
<li>captures high-order graph structure (beyond the  first-order edge connectivity structure) </li>
</ul>
</li>
<li>GNNs are a natural approach to achieve both! <ul>
<li>Neural Graph Collaborative Filtering (NGCF) [Wang et  al. 2019] </li>
<li>LightGCN [He et al. 2020] <ul>
<li>A simplified and improved version of NGCF</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="NGCF-Overview"><a href="#NGCF-Overview" class="headerlink" title="NGCF: Overview"></a>NGCF: Overview</h3><p>Neural Graph Collaborative Filtering (NGCF)  explicitly incorporates high-order graph structure  when generating user/item embeddings. </p>
<p>Key idea: Use a GNN to generate graph-aware  user/item embeddings.</p>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211125164048727.png" alt=""></p>
<h3 id="Framework"><a href="#Framework" class="headerlink" title="Framework"></a>Framework</h3><ul>
<li>Given: User-item bipartite graph. </li>
<li>NGCF framework: <ul>
<li>Prepare shallow learnable embedding  for each node. </li>
<li>Use multi-layer GNNs to propagate  embeddings along the bipartite graph. <ul>
<li>High-order graph structure is captured. </li>
</ul>
</li>
<li>Final embeddings are explicitly graph-aware! </li>
</ul>
</li>
<li>Two kinds of learnable params are  jointly learned: <ul>
<li>Shallow user/item embeddings </li>
<li>GNN’s parameters</li>
</ul>
</li>
</ul>
<h3 id="Initial-Node-Embeddings"><a href="#Initial-Node-Embeddings" class="headerlink" title="Initial Node Embeddings"></a>Initial Node Embeddings</h3><p><img src="/images/loading.gif" data-original="../images/basic/image-20211125164223519.png" alt=""></p>
<h3 id="Neighbor-Aggregation-1"><a href="#Neighbor-Aggregation-1" class="headerlink" title="Neighbor Aggregation"></a>Neighbor Aggregation</h3><p><img src="/images/loading.gif" data-original="../images/basic/image-20211125164418608.png" alt=""></p>
<h3 id="Final-Embeddings-and-Score-Function"><a href="#Final-Embeddings-and-Score-Function" class="headerlink" title="Final Embeddings and Score Function"></a>Final Embeddings and Score Function</h3><p><img src="/images/loading.gif" data-original="../images/basic/image-20211125164518298.png" alt=""></p>
<h3 id="NGCF-Summary"><a href="#NGCF-Summary" class="headerlink" title="NGCF: Summary"></a>NGCF: Summary</h3><ul>
<li>Conventional collaborative filtering uses  shallow user/item embeddings. <ul>
<li>The embeddings do not explicitly model graph  structure. </li>
<li>The training objective does not model high-order  graph structure.</li>
</ul>
</li>
<li>NGCF uses a GNN to propagate the shallow  embeddings. <ul>
<li>The embeddings are explicitly aware of high-order graph structure.</li>
</ul>
</li>
</ul>
<h2 id="Lightgcn"><a href="#Lightgcn" class="headerlink" title="Lightgcn"></a>Lightgcn</h2><h3 id="Motivation-2"><a href="#Motivation-2" class="headerlink" title="Motivation"></a>Motivation</h3><ul>
<li>Recall: NGCF jointly learns two kinds of  parameters: <ul>
<li>Shallow user/item embeddings </li>
<li>GNN’s parameters </li>
</ul>
</li>
<li>Observation: Shallow learnable embeddings are  already quite expressive.</li>
</ul>
<img src="/images/loading.gif" data-original="../images/basic/image-20211125164722937.png" style="zoom: 67%;">

<ul>
<li>Can we simplify the GNN used in NGCF (e.g.,  remove its learnable parameters)? <ul>
<li>Answer: Yes!  </li>
<li>Bonus: Simplification improves the  recommendation performance! </li>
</ul>
</li>
<li>Overview of the idea: <ul>
<li>Adjacency matrix for a bipartite graph </li>
<li>Matrix formulation of GCN </li>
<li>Simplification of GCN by removing non-linearity <ul>
<li>Related: SGC for scalable GNN [Wu et al. 2019]</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="Adjacency-and-Embedding-Matrices"><a href="#Adjacency-and-Embedding-Matrices" class="headerlink" title="Adjacency and Embedding Matrices"></a>Adjacency and Embedding Matrices</h3><p>Adjacency matrix of a (undirected) bipartite graph. </p>
<p>Shallow embedding matrix</p>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211125164949611.png" alt=""></p>
<h3 id="Matrix-Formulation-of-GCN"><a href="#Matrix-Formulation-of-GCN" class="headerlink" title="Matrix Formulation of GCN"></a>Matrix Formulation of GCN</h3><p><img src="/images/loading.gif" data-original="../images/basic/image-20211125165017394.png" alt=""></p>
<h3 id="Simplifying-GCN"><a href="#Simplifying-GCN" class="headerlink" title="Simplifying GCN"></a>Simplifying GCN</h3><p><img src="/images/loading.gif" data-original="../images/basic/image-20211125165047626.png" alt=""></p>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211125165133435.png" alt=""></p>
<h3 id="Multi-scale-Diffusion"><a href="#Multi-scale-Diffusion" class="headerlink" title="Multi-scale Diffusion"></a>Multi-scale Diffusion</h3><p><img src="/images/loading.gif" data-original="../images/basic/image-20211125172521953.png" alt=""></p>
<h3 id="LightGCN-Model-Overview"><a href="#LightGCN-Model-Overview" class="headerlink" title="LightGCN: Model Overview"></a>LightGCN: Model Overview</h3><p>Given:  </p>
<ul>
<li>Adjacency matrix A </li>
<li>Initial learnable embedding matrix E</li>
</ul>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211125172642247.png" alt=""></p>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211125172656965.png" alt=""></p>
<p>Average the embedding matrices at  different scales</p>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211125172722635.png" alt=""></p>
<p>Score function:</p>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211125172741407.png" alt=""></p>
<h3 id="LightGCN-Intuition"><a href="#LightGCN-Intuition" class="headerlink" title="LightGCN: Intuition"></a>LightGCN: Intuition</h3><p>Question: Why does the simple diffusion  propagation work well? </p>
<p>Answer: The diffusion directly encourages the  embeddings of similar users/items to be  similar. </p>
<ul>
<li>Similar users share many common neighbors  (items) and are expected to have similar future  preferences (interact with similar items)</li>
</ul>
<h3 id="Lightgcn-and-GCN-C-amp-S"><a href="#Lightgcn-and-GCN-C-amp-S" class="headerlink" title="Lightgcn and GCN/C&amp;S"></a>Lightgcn and GCN/C&amp;S</h3><p><img src="/images/loading.gif" data-original="../images/basic/image-20211125172851331.png" alt=""></p>
<h3 id="LIGHTGCN-and-MF-Comparison"><a href="#LIGHTGCN-and-MF-Comparison" class="headerlink" title="LIGHTGCN and MF: Comparison"></a>LIGHTGCN and MF: Comparison</h3><ul>
<li>Both LightGCN and Matrix Factorization (MF)  learn a unique embedding for each user/item. </li>
<li>The difference is that <ul>
<li>MF directly uses the shallow user/item embeddings  for scoring. </li>
<li>LightGCN uses the diffused user/item embeddings  for scoring. </li>
</ul>
</li>
<li>LightGCN performs better than MF but are also  more computationally expensive due to the  additional diffusion step. <ul>
<li>The final embedding of a user/item is obtained  by aggregating embeddings of its multi-hop  neighboring nodes.</li>
</ul>
</li>
</ul>
<h3 id="Summary-16"><a href="#Summary-16" class="headerlink" title="Summary"></a>Summary</h3><ul>
<li>LightGCN simplifies NGCF by removing the  learnable parameters of GNNs. </li>
<li>Learnable parameters are all in the shallow  input node embeddings. <ul>
<li>Diffusion propagation only involves matrix-vector multiplication. </li>
<li>The simplification leads to better empirical  performance than NGCF</li>
</ul>
</li>
</ul>
<h2 id="PINSAGE"><a href="#PINSAGE" class="headerlink" title="PINSAGE"></a>PINSAGE</h2><h3 id="Motivation-3"><a href="#Motivation-3" class="headerlink" title="Motivation"></a>Motivation</h3><p>P2P recommendation</p>
<h3 id="PINSAGE-Pin-Embedding"><a href="#PINSAGE-Pin-Embedding" class="headerlink" title="PINSAGE: Pin Embedding"></a>PINSAGE: Pin Embedding</h3><ul>
<li>Unifies visual, textual, and graph information. </li>
<li>The largest industry deployment of a Graph  Convolutional Networks </li>
<li>Huge Adoption across Pinterest </li>
<li>Works for fresh content and is available in  a few seconds after pin creation</li>
</ul>
<p><a href="https://arxiv.org/pdf/1806.01973.pdf" target="_blank" rel="noopener">Graph Convolutional Neural Networks for Web-Scale Recommender Systems</a></p>
<p>PinSage graph convolutional network: </p>
<ul>
<li><p>Goal: Generate embeddings for nodes in a large-scale  Pinterest graph containing billions of objects </p>
</li>
<li><p>Key Idea: Borrow information from nearby nodes </p>
<ul>
<li>E.g., bed rail Pin might look like a garden fence, but gates  and beds are rarely adjacent in the graph</li>
</ul>
</li>
<li><p>Pin embeddings are essential to various tasks like  recommendation of Pins, classification, ranking </p>
</li>
<li><p>Services like “Related Pins”, “Search”, “Shopping”, “Ads”</p>
</li>
</ul>
<h3 id="Harnessing-Pins-and-Boards"><a href="#Harnessing-Pins-and-Boards" class="headerlink" title="Harnessing Pins and Boards"></a>Harnessing Pins and Boards</h3><p><img src="/images/loading.gif" data-original="../images/basic/image-20211125173813144.png" alt=""></p>
<h3 id="PINSAGE-Graph-Neural-Network"><a href="#PINSAGE-Graph-Neural-Network" class="headerlink" title="PINSAGE: Graph Neural Network"></a>PINSAGE: Graph Neural Network</h3><ul>
<li>Graph has tens of billions of nodes and edges </li>
<li>Further resolves embeddings across the  Pinterest graph</li>
</ul>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211125173859891.png" alt=""></p>
<h3 id="PINSAGE-Methods-for-Scaling-Up"><a href="#PINSAGE-Methods-for-Scaling-Up" class="headerlink" title="PINSAGE: Methods for Scaling Up"></a>PINSAGE: Methods for Scaling Up</h3><p>In addition to the GNN model, the PinSAGE paper introduces several methods to scale the  GNN to a billion-scale recommender system  (e.g., Pinterest). </p>
<ul>
<li>Shared negative samples across users in a mini-batch </li>
<li>Hard negative samples </li>
<li>Curriculum learning </li>
<li>Mini-batch training of GNNs on a large-graph (to be  covered in the future lecture)</li>
</ul>
<h3 id="PINSAGE-Model"><a href="#PINSAGE-Model" class="headerlink" title="PINSAGE Model"></a>PINSAGE Model</h3><p><img src="/images/loading.gif" data-original="../images/basic/image-20211125174011968.png" alt=""></p>
<h3 id="Training-Data"><a href="#Training-Data" class="headerlink" title="Training Data"></a>Training Data</h3><p>1+B repin pairs: </p>
<ul>
<li><p>From Related Pins surface </p>
</li>
<li><p>Capture semantic relatedness </p>
</li>
<li><p>Goal: Embed such pairs to be “neighbors”</p>
<p>Example positive training pairs (Q,X):</p>
</li>
</ul>
<h3 id="Shared-Negative-Samples"><a href="#Shared-Negative-Samples" class="headerlink" title="Shared Negative Samples"></a>Shared Negative Samples</h3><p><img src="/images/loading.gif" data-original="../images/basic/image-20211125174135035.png" alt=""></p>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211125174150402.png" alt=""></p>
<h3 id="Curriculum-Learning"><a href="#Curriculum-Learning" class="headerlink" title="Curriculum Learning"></a>Curriculum Learning</h3><ul>
<li>Key insight: It is effective to make the  negative samples gradually harder in the  process of training. </li>
<li>At n-th epoch, we add n − 1 hard negative  items. <ul>
<li>#(Hard negatives) gradually increases in the  process of training. </li>
</ul>
</li>
<li>The model will gradually learn to make finer-grained predictions</li>
</ul>
<p>Idea: use harder and harder negative samples </p>
<p>Include more and more hard negative  samples for each epoch</p>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211125174536511.png" alt=""></p>
<h3 id="Hard-Negatives"><a href="#Hard-Negatives" class="headerlink" title="Hard Negatives"></a>Hard Negatives</h3><p>Challenge: Industrial recsys needs to make  extremely fine-grained predictions. </p>
<ul>
<li><p>#Total items: Up to billions. </p>
</li>
<li><p>#Items to recommend for each user: 10 to 100. </p>
</li>
</ul>
<p>Issue: The shared negative items are  randomly sampled from all items </p>
<ul>
<li>Most of them are “easy negatives”, i.e., a model  does not need to be fine-grained to distinguish  them from positive items. </li>
</ul>
<p>We need a way to sample “hard negatives” to  force the model to be fine-grained</p>
<ul>
<li>For each user node, the hard negatives are item  nodes that are close (but not connected) to the  user node in the graph. </li>
<li>Hard negatives for user u ∈ U are obtained as  follows: <ul>
<li>Compute personalized page rank (PPR) for user u. </li>
<li>Sort items in the descending order of their PPR scores. </li>
<li>Randomly sample item nodes that are ranked high  but not too high, e.g., 2000th —5000th . <ul>
<li>Item nodes that are close but not too close (connected) to  the user node. </li>
</ul>
</li>
</ul>
</li>
<li>The hard negatives for each user are used in  addition to the shared negatives.</li>
</ul>
<h3 id="PINSAGE-Negative-Sampling"><a href="#PINSAGE-Negative-Sampling" class="headerlink" title="PINSAGE: Negative Sampling"></a>PINSAGE: Negative Sampling</h3><ul>
<li>(q, p) positive pairs are given but various  methods to sample negatives to form (q, p, n) </li>
<li>Distance Weighted Sampling (<a href="https://arxiv.org/abs/1706.07567" target="_blank" rel="noopener">Wu et al., 2017</a>)  - Sample negatives so that query-negative distance  distribution is approx U[0.5, 1.4]</li>
</ul>
<p><img src="/images/loading.gif" data-original="../images/basic/image-20211125175002076.png" alt=""></p>
<h3 id="Fine-grained-Object-Similarity"><a href="#Fine-grained-Object-Similarity" class="headerlink" title="Fine-grained Object Similarity"></a>Fine-grained Object Similarity</h3><p><img src="/images/loading.gif" data-original="../images/basic/image-20211125175626904.png" alt=""></p>
<h3 id="Compare-against-Prod"><a href="#Compare-against-Prod" class="headerlink" title="Compare against Prod"></a>Compare against Prod</h3><p><img src="/images/loading.gif" data-original="../images/basic/image-20211125175653407.png" alt=""></p>
<h3 id="PINSAGE-Summary"><a href="#PINSAGE-Summary" class="headerlink" title="PINSAGE: Summary"></a>PINSAGE: Summary</h3><ul>
<li>PinSAGE uses GNNs to generate high-quality  user/item embeddings that capture both the  rich node attributes and graph structure. </li>
<li>The PinSAGE model is effectively trained using  sophisticated negative sampling strategies. </li>
<li>PinSAGE is successfully deployed at Pinterest,  a billion-scale image content recommendation  service. <ul>
<li>Uncovered in this lecture: How to scale up GNNs to  large-scale graphs. Will be covered in a later lecture</li>
</ul>
</li>
</ul>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        文章作者:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://jackhcc.github.io" rel="external nofollow noreferrer">杰克成</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        文章链接:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://jackhcc.github.io/posts/Lesson-CS224W-Machine-Learning-with-Graphs.html">https://jackhcc.github.io/posts/Lesson-CS224W-Machine-Learning-with-Graphs.html</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        版权声明:
                    </i>
                </span>
                <span class="reprint-info">
                    本博客所有文章除特別声明外，均采用
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    许可协议。转载请注明来源
                    <a href="https://jackhcc.github.io" target="_blank">杰克成</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>复制成功，请遵循本文的转载规则</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">查看</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/tags/Lesson/">
                                    <span class="chip bg-color">Lesson</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/libs/share/css/share.min.css">

<div id="article-share">
    
    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>微信扫一扫即可分享！</p>"></div>
    <script src="https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
                <style>
    #reward {
        margin: 40px 0;
        text-align: center;
    }

    #reward .reward-link {
        font-size: 1.4rem;
        line-height: 38px;
    }

    #reward .btn-floating:hover {
        box-shadow: 0 6px 12px rgba(0, 0, 0, 0.2), 0 5px 15px rgba(0, 0, 0, 0.2);
    }

    #rewardModal {
        width: 320px;
        height: 350px;
    }

    #rewardModal .reward-title {
        margin: 15px auto;
        padding-bottom: 5px;
    }

    #rewardModal .modal-content {
        padding: 10px;
    }

    #rewardModal .close {
        position: absolute;
        right: 15px;
        top: 15px;
        color: rgba(0, 0, 0, 0.5);
        font-size: 1.3rem;
        line-height: 20px;
        cursor: pointer;
    }

    #rewardModal .close:hover {
        color: #ef5350;
        transform: scale(1.3);
        -moz-transform:scale(1.3);
        -webkit-transform:scale(1.3);
        -o-transform:scale(1.3);
    }

    #rewardModal .reward-tabs {
        margin: 0 auto;
        width: 210px;
    }

    .reward-tabs .tabs {
        height: 38px;
        margin: 10px auto;
        padding-left: 0;
    }

    .reward-content ul {
        padding-left: 0 !important;
    }

    .reward-tabs .tabs .tab {
        height: 38px;
        line-height: 38px;
    }

    .reward-tabs .tab a {
        color: #fff;
        background-color: #ccc;
    }

    .reward-tabs .tab a:hover {
        background-color: #ccc;
        color: #fff;
    }

    .reward-tabs .wechat-tab .active {
        color: #fff !important;
        background-color: #22AB38 !important;
    }

    .reward-tabs .alipay-tab .active {
        color: #fff !important;
        background-color: #019FE8 !important;
    }

    .reward-tabs .reward-img {
        width: 210px;
        height: 210px;
    }
</style>

<div id="reward">
    <a href="#rewardModal" class="reward-link modal-trigger btn-floating btn-medium waves-effect waves-light red">赏</a>

    <!-- Modal Structure -->
    <div id="rewardModal" class="modal">
        <div class="modal-content">
            <a class="close modal-close"><i class="fas fa-times"></i></a>
            <h4 class="reward-title">你的赏识是我前进的动力</h4>
            <div class="reward-content">
                <div class="reward-tabs">
                    <ul class="tabs row">
                        <li class="tab col s6 alipay-tab waves-effect waves-light"><a href="#alipay">支付宝</a></li>
                        <li class="tab col s6 wechat-tab waves-effect waves-light"><a href="#wechat">微 信</a></li>
                    </ul>
                    <div id="alipay">
                        <img src="/images/loading.gif" data-original="https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/medias/reward/aliqr.png" class="reward-img" alt="支付宝打赏二维码">
                    </div>
                    <div id="wechat">
                        <img src="/images/loading.gif" data-original="https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/medias/reward/wxqr.png" class="reward-img" alt="微信打赏二维码">
                    </div>
                </div>
            </div>
        </div>
    </div>
</div>

<script>
    $(function () {
        $('.tabs').tabs();
    });
</script>
            
        </div>
    </div>

    
        <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/libs/gitalk/gitalk.css">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/css/my-gitalk.css">

<div class="card gitalk-card" data-aos="fade-up">
    <div class="comment_headling" style="font-size: 20px; font-weight: 700; position: relative; left: 20px; top: 15px; padding-bottom: 5px;">
        <i class="fas fa-comments fa-fw" aria-hidden="true"></i>
        <span>评论</span>
    </div>
    <div id="gitalk-container" class="card-content"></div>
</div>

<script src="https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/libs/gitalk/gitalk.min.js"></script>
<script>
    let gitalk = new Gitalk({
        clientID: '3821a0bbb773038a51fc',
        clientSecret: '4b30b507d67ec5497ec0e77f43f80cb3e0d7dd3a',
        repo: 'JackHCC.github.io',
        owner: 'JackHCC',
        admin: "JackHCC",
        id: '2021-11-12T12-20-03',
        distractionFreeMode: false  // Facebook-like distraction free mode
    });

    gitalk.render('gitalk-container');
</script>
    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;上一篇</div>
            <div class="card">
                <a href="/posts/blog-python28.html">
                    <div class="card-image">
                        
                        
                        <img src="/images/loading.gif" data-original="https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/medias/featureimages/0.jpg" class="responsive-img" alt="Python-学习资料">
                        
                        <span class="card-title">Python-学习资料</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            Python-学习资料汇总【Archived】
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2021-11-13
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/categories/Python/" class="post-category">
                                    Python
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/tags/Python/">
                        <span class="chip bg-color">Python</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                下一篇&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/posts/dl-series18.html">
                    <div class="card-image">
                        
                        
                        <img src="/images/loading.gif" data-original="https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/medias/featureimages/5.jpg" class="responsive-img" alt="DL专栏18-Normalization">
                        
                        <span class="card-title">DL专栏18-Normalization</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            Normalization方法
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2021-11-11
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/categories/Deep-Learning/" class="post-category">
                                    Deep Learning
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/tags/Normalization/">
                        <span class="chip bg-color">Normalization</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- 代码块功能依赖 -->
<script type="text/javascript" src="https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/libs/codeBlock/codeBlockFuction.js"></script>

<!-- 代码语言 -->

<script type="text/javascript" src="https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/libs/codeBlock/codeLang.js"></script>


<!-- 代码块复制 -->

<script type="text/javascript" src="https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/libs/codeBlock/codeCopy.js"></script>


<!-- 代码块收缩 -->

<script type="text/javascript" src="https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/libs/codeBlock/codeShrink.js"></script>


<!-- 代码块折行 -->

<style type="text/css">
code[class*="language-"], pre[class*="language-"] { white-space: pre !important; }
</style>


    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;目录</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC 悬浮按钮. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('4'),
            headingSelector: 'h1, h2, h3, h4'
        });

        // modify the toc link href to support Chinese.
        let i = 0;
        let tocHeading = 'toc-heading-';
        $('#toc-content a').each(function () {
            $(this).attr('href', '#' + tocHeading + (++i));
        });

        // modify the heading title id to support Chinese.
        i = 0;
        $('#articleContent').children('h1, h2, h3, h4').each(function () {
            $(this).attr('id', tocHeading + (++i));
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* 修复文章卡片 div 的宽度. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // 切换TOC目录展开收缩的相关操作.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>

    

</main>



    <footer class="page-footer bg-color">
    <div class="container row center-align" style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            <span id="year">2020</span>
            <a href="https://jackhcc.github.io" target="_blank">杰克成</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            <br>
            
            &nbsp;<i class="fas fa-chart-area"></i>&nbsp;站点总字数:&nbsp;<span
                class="white-color">3591.2k</span>&nbsp;字
            
            
            
            
            
            
            <span id="busuanzi_container_site_pv">
                |&nbsp;<i class="far fa-eye"></i>&nbsp;总访问量:&nbsp;<span id="busuanzi_value_site_pv"
                    class="white-color"></span>&nbsp;次
            </span>
            
            
            <span id="busuanzi_container_site_uv">
                |&nbsp;<i class="fas fa-users"></i>&nbsp;总访问人数:&nbsp;<span id="busuanzi_value_site_uv"
                    class="white-color"></span>&nbsp;人
            </span>
            
            <br>
            
            <span id="sitetime">载入运行时间...</span>
            <script>
                function siteTime() {
                    var seconds = 1000;
                    var minutes = seconds * 60;
                    var hours = minutes * 60;
                    var days = hours * 24;
                    var years = days * 365;
                    var today = new Date();
                    var startYear = "2020";
                    var startMonth = "2";
                    var startDate = "27";
                    var startHour = "6";
                    var startMinute = "30";
                    var startSecond = "0";
                    var todayYear = today.getFullYear();
                    var todayMonth = today.getMonth() + 1;
                    var todayDate = today.getDate();
                    var todayHour = today.getHours();
                    var todayMinute = today.getMinutes();
                    var todaySecond = today.getSeconds();
                    var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                    var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                    var diff = t2 - t1;
                    var diffYears = Math.floor(diff / years);
                    var diffDays = Math.floor((diff / days) - diffYears * 365);
                    var diffHours = Math.floor((diff - (diffYears * 365 + diffDays) * days) / hours);
                    var diffMinutes = Math.floor((diff - (diffYears * 365 + diffDays) * days - diffHours * hours) /
                        minutes);
                    var diffSeconds = Math.floor((diff - (diffYears * 365 + diffDays) * days - diffHours * hours -
                        diffMinutes * minutes) / seconds);
                    if (startYear == todayYear) {
                        document.getElementById("year").innerHTML = todayYear;
                        document.getElementById("sitetime").innerHTML = "本站已安全运行 " + diffDays + " 天 " + diffHours +
                            " 小时 " + diffMinutes + " 分钟 " + diffSeconds + " 秒";
                    } else {
                        document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                        document.getElementById("sitetime").innerHTML = "本站已安全运行 " + diffYears + " 年 " + diffDays +
                            " 天 " + diffHours + " 小时 " + diffMinutes + " 分钟 " + diffSeconds + " 秒";
                    }
                }
                setInterval(siteTime, 1000);
            </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/JackHCC" class="tooltipped" target="_blank" data-tooltip="访问我的GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:jackcc0701@163.com" class="tooltipped" target="_blank" data-tooltip="邮件联系我" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>



    <a href="https://www.facebook.com/profile.php?id=100046343443643" class="tooltipped" target="_blank" data-tooltip="关注我的Facebook: https://www.facebook.com/profile.php?id=100046343443643" data-position="top" data-delay="50">
        <i class="fab fa-facebook-f"></i>
    </a>



    <a href="https://twitter.com/JackChe66021834" class="tooltipped" target="_blank" data-tooltip="关注我的Twitter: https://twitter.com/JackChe66021834" data-position="top" data-delay="50">
        <i class="fab fa-twitter"></i>
    </a>



    <a href="tencent://AddContact/?fromId=50&fromSubId=1&subcmd=all&uin=2508074836" class="tooltipped" target="_blank" data-tooltip="QQ联系我: 2508074836" data-position="top" data-delay="50">
        <i class="fab fa-qq"></i>
    </a>



    <a href="https://weibo.com/u/6885584679" class="tooltipped" target="_blank" data-tooltip="关注我的微博: https://weibo.com/u/6885584679" data-position="top" data-delay="50">
        <i class="fab fa-weibo"></i>
    </a>



    <a href="https://www.zhihu.com/people/8f8482f01f0d6a04e844efe32e0f0710" class="tooltipped" target="_blank" data-tooltip="关注我的知乎: https://www.zhihu.com/people/8f8482f01f0d6a04e844efe32e0f0710" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">知</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- 搜索遮罩框 -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;搜索</span>
            <input type="search" id="searchInput" name="s" placeholder="请输入搜索的关键字"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script src="https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/js/search.js"></script>
<script type="text/javascript">
$(function () {
    searchFunc("https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/" + "search.xml", 'searchInput', 'searchResult');
});
</script>
    <!-- 回到顶部按钮 -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/libs/materialize/materialize.min.js"></script>
    <script src="https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/libs/aos/aos.js"></script>
    <script src="https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/js/matery.js"></script>

    <canvas class="fireworks" style="position: fixed;left: 0;top: 0;z-index: 1; pointer-events: none;" ></canvas>
    <script type="text/javascript" src="//cdn.bootcss.com/animejs/2.2.0/anime.min.js"></script>
    <script type="text/javascript" src="/js/fireworks.js"></script>

    <script type="text/javascript">
        //只在桌面版网页启用特效
        var windowWidth = $(window).width();
        if (windowWidth > 768) {
            document.write('<script type="text/javascript" src="/js/sakura.js"><\/script>'); }
    </script>

    <!-- weather -->
	<script type="text/javascript">
	WIDGET = {FID: 'TToslpmkVO'}
	</script>
	<script type="text/javascript" src="https://apip.weatherdt.com/float/static/js/r.js?v=1111"></script>


    <!-- Global site tag (gtag.js) - Google Analytics -->


    <!-- Baidu Analytics -->

<script>
    var _hmt = _hmt || [];
    (function () {
        var hm = document.createElement("script");
        hm.src = "https://hm.baidu.com/hm.js?";
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(hm, s);
    })();
</script>

    <!-- Baidu Push -->

    
    
    <script async src="https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/libs/others/busuanzi.pure.mini.js"></script>
    

    
        <script src="//code.tidio.co/kqhlkxviiccyoa0czpfpu4ijuey9hfre.js"></script>
        <script> 
            $(document).ready(function () {
                setInterval(change_Tidio, 50);  
                function change_Tidio() { 
                    var tidio=$("#tidio-chat iframe");
                    if(tidio.css("display")=="block"&& $(window).width()>977 ){
                        document.getElementById("tidio-chat-iframe").style.bottom= ($("div#backTop.top-scroll").css("display")=="none" &&$(window).width()>977)>0? "-40px" : ($("div.toc-title").length&&$(window).width()>977)>0?"85px":"20px";   
                        document.getElementById("tidio-chat-iframe").style.right="-15px";   
                        document.getElementById("tidio-chat-iframe").style.height=parseInt(tidio.css("height"))>=520?"520px":tidio.css("height");
                        document.getElementById("tidio-chat-iframe").style.zIndex="997";
                    } 
                    else if(tidio.css("display")=="block"&&$(window).width()>601 &&$(window).width()<992 ){
                        document.getElementById("tidio-chat-iframe").style.bottom= ($("div#backTop.top-scroll").css("display")=="none" && 601< $(window).width()<992)>0? "-40px":"20px" ;   
                        document.getElementById("tidio-chat-iframe").style.right="-15px"; 
                        document.getElementById("tidio-chat-iframe").style.zIndex="997";
                    }
                    else if(tidio.css("display")=="block"&&$(window).width()<601 && parseInt(tidio.css("height"))<230){
                        document.getElementById("tidio-chat-iframe").style.bottom= ($("div#backTop.top-scroll").css("display")=="none" && $(window).width()<601)>0? "-10px":"45px" ;   
                        document.getElementById("tidio-chat-iframe").style.zIndex="997";
                    }
                    if( tidio.css("display")=="block"&&$(window).width()<601 && parseInt(tidio.css("height"))>=230){
                        document.getElementById("tidio-chat-iframe").style.zIndex="998";
                    }
                } 
            }); 
        </script>
    

    

    
    <script type="text/javascript" color="0,0,255"
        pointColor="0,0,255" opacity='0.7'
        zIndex="-1" count="99"
        src="https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/libs/background/canvas-nest.js"></script>
    

    

    
    <script type="text/javascript" src="https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/libs/background/ribbon-dynamic.js" async="async"></script>
    
    
    
    <script src="https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/libs/instantpage/instantpage.js" type="module"></script>
    

        <script src="//cdn.jsdelivr.net/npm/js-base64/base64.min.js"></script>
        <script>
        $('a').each(function() {
          const $this = $(this);
          const href = $this.attr('href');
          if (href && href.match('^((http|https|thunder|qqdl|ed2k|Flashget|qbrowser|ftp|rtsp|mms)://)')) {
            const strs = href.split('/');
            if (strs.length >= 3) {
                const host = strs[2];
                if (host !== 'your_domain' || window.location.host) {
                    $this.attr('href', '/go.html?u='+Base64.encode(href)+'').attr('rel', 'external nofollow noopener noreferrer');
                    if (true) {
                        $this.attr('target', '_blank');
                    }
                }
            }
          }
        });
        </script><script>!function(e){var c=Array.prototype.slice.call(document.querySelectorAll("img[data-original]"));function i(){for(var r=0;r<c.length;r++)t=c[r],0<=(n=t.getBoundingClientRect()).bottom&&0<=n.left&&n.top<=(e.innerHeight||document.documentElement.clientHeight)&&function(){var t,n,e,i,o=c[r];t=o,n=function(){c=c.filter(function(t){return o!==t})},e=new Image,i=t.getAttribute("data-original"),e.onload=function(){t.src=i,n&&n()},e.src=i}();var t,n}i(),e.addEventListener("scroll",function(){var t,n;t=i,n=e,clearTimeout(t.tId),t.tId=setTimeout(function(){t.call(n)},500)})}(this);</script><script>window.addEventListener("load",function(){var t=/\.(gif|jpg|jpeg|tiff|png)$/i,r=/^data:image\/[a-z]+;base64,/;Array.prototype.slice.call(document.querySelectorAll("img[data-original]")).forEach(function(a){var e=a.parentNode;"A"===e.tagName&&(e.href.match(t)||e.href.match(r))&&(e.href=a.dataset.original)})});</script></body>

</html>

