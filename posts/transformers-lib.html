<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="TransformersåŒ…è¯¦è§£, JackHCC">
    <meta name="description" content="Transformerså®è·µæ‰‹å†Œ">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <title>TransformersåŒ…è¯¦è§£ | JackHCC</title>
    <link rel="icon" type="image/png" href="https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/medias/favicon.png">

    <link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/libs/awesome/css/all.css">
    <link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/libs/materialize/materialize.min.css">
    <link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/libs/aos/aos.css">
    <link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/libs/animate/animate.min.css">
    <link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/libs/lightGallery/css/lightgallery.min.css">
    <link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/css/matery.css">
    <link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/css/my.css">
    
    <script src="https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/libs/jquery/jquery.min.js"></script>
    
<meta name="generator" content="Hexo 4.2.0"><link rel="alternate" href="/atom.xml" title="JackHCC" type="application/atom+xml">
<link rel="stylesheet" href="/css/prism-hopscotch.css" type="text/css">
<link rel="stylesheet" href="/css/prism-line-numbers.css" type="text/css"></head>


<body>
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper head-container">
            <div class="brand-logo">
                <a href="/" class="waves-effect waves-light">
                    
                    <img src="/images/loading.gif" data-original="https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/medias/me.jpg" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">JackHCC</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>é¦–é¡µ</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>æ ‡ç­¾</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>åˆ†ç±»</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>å½’æ¡£</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="" class="waves-effect waves-light">

      
      <i class="fas fa-list" style="zoom: 0.6;"></i>
      
      <span>Tools</span>
      <i class="fas fa-chevron-down" aria-hidden="true" style="zoom: 0.6;"></i>
    </a>
    <ul class="sub-nav menus_item_child ">
      
      <li>
        <a href="https://creativecc.cn/" target="_blank" rel="noopener">
          
          <i class="fas fa-book" style="margin-top: -20px; zoom: 0.6;"></i>
          
          <span>Creativeå·¥å…·å¯¼èˆª</span>
        </a>
      </li>
      
      <li>
        <a href="https://blog.creativecc.cn/Arxiv-NLP-Reporter/" target="_blank" rel="noopener">
          
          <i class="fas fa-film" style="margin-top: -20px; zoom: 0.6;"></i>
          
          <span>NLPæ¯æ—¥è®ºæ–‡</span>
        </a>
      </li>
      
      <li>
        <a href="http://chat.creativecc.cn/" target="_blank" rel="noopener">
          
          <i class="fas fa-music" style="margin-top: -20px; zoom: 0.6;"></i>
          
          <span>RocketChatèŠå¤©å®¤</span>
        </a>
      </li>
      
      <li>
        <a href="/contact">
          
          <i class="fas fa-comments" style="margin-top: -20px; zoom: 0.6;"></i>
          
          <span>Contactç•™è¨€æ¿</span>
        </a>
      </li>
      
    </ul>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/friends" class="waves-effect waves-light">
      
      <i class="fas fa-address-book" style="zoom: 0.6;"></i>
      
      <span>å‹æƒ…é“¾æ¥</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/about" class="waves-effect waves-light">
      
      <i class="fas fa-user-circle" style="zoom: 0.6;"></i>
      
      <span>å…³äº</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="æœç´¢" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>

<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/images/loading.gif" data-original="https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/medias/me.jpg" class="logo-img circle responsive-img">
        
        <div class="logo-name">JackHCC</div>
        <div class="logo-desc">
            
            Make the world betterrrr!!!
            
        </div>
    </div>

    

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			é¦–é¡µ
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			æ ‡ç­¾
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			åˆ†ç±»
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			å½’æ¡£
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="javascript:;">
			
				<i class="fa-fw fas fa-list"></i>
			
			Tools
			<span class="m-icon"><i class="fas fa-chevron-right"></i></span>
		</a>
            <ul  style="background:  ;" >
              
                <li>   
				
                  <a href="https://creativecc.cn/ " target="_blank" rel="noopener" style="margin-left:75px";>
				  
				   <i class="fa fas fa-book" style="position: absolute;left:50px" ></i>
			      
		          <span>Creativeå·¥å…·å¯¼èˆª</span>
                  </a>
                </li>
              
                <li>   
				
                  <a href="https://blog.creativecc.cn/Arxiv-NLP-Reporter/ " target="_blank" rel="noopener" style="margin-left:75px";>
				  
				   <i class="fa fas fa-film" style="position: absolute;left:50px" ></i>
			      
		          <span>NLPæ¯æ—¥è®ºæ–‡</span>
                  </a>
                </li>
              
                <li>   
				
                  <a href="http://chat.creativecc.cn/ " target="_blank" rel="noopener" style="margin-left:75px";>
				  
				   <i class="fa fas fa-music" style="position: absolute;left:50px" ></i>
			      
		          <span>RocketChatèŠå¤©å®¤</span>
                  </a>
                </li>
              
                <li>   
				
                  <a href="/contact " style="margin-left:75px";>
				  
				   <i class="fa fas fa-comments" style="position: absolute;left:50px" ></i>
			      
		          <span>Contactç•™è¨€æ¿</span>
                  </a>
                </li>
               
            </ul>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/friends" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-address-book"></i>
			
			å‹æƒ…é“¾æ¥
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/about" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-user-circle"></i>
			
			å…³äº
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/JackHCC/JackHCC.github.io" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>

        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/JackHCC/JackHCC.github.io" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    
<script src="https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/libs/cryptojs/crypto-js.min.js"></script>
<script>
    (function() {
        let pwd = '';
        if (pwd && pwd.length > 0) {
            if (pwd !== CryptoJS.SHA256(prompt('è¯·è¾“å…¥è®¿é—®æœ¬æ–‡ç« çš„å¯†ç ')).toString(CryptoJS.enc.Hex)) {
                alert('å¯†ç é”™è¯¯ï¼Œå°†è¿”å›ä¸»é¡µï¼');
                location.href = '/';
            }
        }
    })();
</script>




<div class="bg-cover pd-header post-cover" style="background-image: url('https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/medias/featureimages/0.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">TransformersåŒ…è¯¦è§£</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/libs/tocbot/tocbot.css">
<style>
    #articleContent h1::before,
    #articleContent h2::before,
    #articleContent h3::before,
    #articleContent h4::before,
    #articleContent h5::before,
    #articleContent h6::before {
        display: block;
        content: " ";
        height: 100px;
        margin-top: -100px;
        visibility: hidden;
    }

    #articleContent :focus {
        outline: none;
    }

    .toc-fixed {
        position: fixed;
        top: 64px;
    }

    .toc-widget {
        width: 345px;
        padding-left: 20px;
    }

    .toc-widget .toc-title {
        margin: 35px 0 15px 0;
        padding-left: 17px;
        font-size: 1.5rem;
        font-weight: bold;
        line-height: 1.5rem;
    }

    .toc-widget ol {
        padding: 0;
        list-style: none;
    }

    #toc-content {
        height: calc(100vh - 250px);
        overflow: auto;
    }

    #toc-content ol {
        padding-left: 10px;
    }

    #toc-content ol li {
        padding-left: 10px;
    }

    #toc-content .toc-link:hover {
        color: #42b983;
        font-weight: 700;
        text-decoration: underline;
    }

    #toc-content .toc-link::before {
        background-color: transparent;
        max-height: 25px;
    }

    #toc-content .is-active-link {
        color: #42b983;
    }

    #toc-content .is-active-link::before {
        background-color: #42b983;
    }

    #floating-toc-btn {
        position: fixed;
        right: 30px;
        bottom: 146px;
        padding-top: 15px;
        margin-bottom: 0;
        z-index: 998;
    }

    #floating-toc-btn .btn-floating {
        width: 48px;
        height: 48px;
    }

    #floating-toc-btn .btn-floating i {
        line-height: 48px;
        font-size: 1.4rem;
    }
</style>
<div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- æ–‡ç« å†…å®¹è¯¦æƒ… -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/tags/Deep-Learning/">
                                <span class="chip bg-color">Deep Learning</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/categories/Transformers/" class="post-category">
                                Transformers
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>å‘å¸ƒæ—¥æœŸ:&nbsp;&nbsp;
                    2022-05-01
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>æ›´æ–°æ—¥æœŸ:&nbsp;&nbsp;
                    2022-05-01
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>æ–‡ç« å­—æ•°:&nbsp;&nbsp;
                    19.1k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>é˜…è¯»æ—¶é•¿:&nbsp;&nbsp;
                    100 åˆ†
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>é˜…è¯»æ¬¡æ•°:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>

        </div>
        <hr class="clearfix">
        <div class="card-content article-card-content">
            <div id="articleContent">
                <h1 id="Transformers"><a href="#Transformers" class="headerlink" title="Transformers"></a>Transformers</h1><p><strong>å®˜æ–¹æ–‡æ¡£ï¼š</strong><a href="https://huggingface.co/docs/transformers/index" target="_blank" rel="noopener">https://huggingface.co/docs/transformers/index</a></p>
<p>ğŸ¤— Transformers provides APIs to easily download and train state-of-the-art pretrained models. Using pretrained models can reduce your compute costs, carbon footprint, and save you time from training a model from scratch. The models can be used across different modalities such as:</p>
<ul>
<li>ğŸ“ Text: text classification, information extraction, question answering, summarization, translation, and text generation in over 100 languages.</li>
<li>ğŸ–¼ï¸ Images: image classification, object detection, and segmentation.</li>
<li>ğŸ—£ï¸ Audio: speech recognition and audio classification.</li>
<li>ğŸ™ Multimodal: table question answering, optical character recognition, information extraction from scanned documents, video classification, and visual question answering.</li>
</ul>
<h2 id="å®‰è£…"><a href="#å®‰è£…" class="headerlink" title="å®‰è£…"></a>å®‰è£…</h2><h3 id="Pip"><a href="#Pip" class="headerlink" title="Pip"></a>Pip</h3><pre class="line-numbers language-python"><code class="language-python">pip install transformers<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<h3 id="Conda"><a href="#Conda" class="headerlink" title="Conda"></a>Conda</h3><pre class="line-numbers language-python"><code class="language-python">conda install <span class="token operator">-</span>c huggingface transformers<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<h2 id="Pipeline-usage"><a href="#Pipeline-usage" class="headerlink" title="Pipeline usage"></a>Pipeline usage</h2><h3 id="Pipeline"><a href="#Pipeline" class="headerlink" title="Pipeline"></a>Pipeline</h3><ol>
<li>Start by creating a <strong><a href="https://huggingface.co/docs/transformers/v4.18.0/en/main_classes/pipelines#transformers.pipeline" target="_blank" rel="noopener">pipeline()</a></strong> and specify an inference task:</li>
</ol>
<pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">from</span> transformers <span class="token keyword">import</span> pipeline

generator <span class="token operator">=</span> pipeline<span class="token punctuation">(</span>task<span class="token operator">=</span><span class="token string">"text-generation"</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre>
<ol>
<li>Pass your input text to the <strong><a href="https://huggingface.co/docs/transformers/v4.18.0/en/main_classes/pipelines#transformers.pipeline" target="_blank" rel="noopener">pipeline()</a></strong>:</li>
</ol>
<pre class="line-numbers language-python"><code class="language-python">generator<span class="token punctuation">(</span><span class="token string">"Three Rings for the Elven-kings under the sky, Seven for the Dwarf-lords in their halls of stone"</span><span class="token punctuation">)</span>
<span class="token punctuation">[</span><span class="token punctuation">{</span><span class="token string">'generated_text'</span><span class="token punctuation">:</span> <span class="token string">'Three Rings for the Elven-kings under the sky, Seven for the Dwarf-lords in their halls of stone, Seven for the Iron-priests at the door to the east, and thirteen for the Lord Kings at the end of the mountain'</span><span class="token punctuation">}</span><span class="token punctuation">]</span>

generator<span class="token punctuation">(</span>
    <span class="token punctuation">[</span>
        <span class="token string">"Three Rings for the Elven-kings under the sky, Seven for the Dwarf-lords in their halls of stone"</span><span class="token punctuation">,</span>
        <span class="token string">"Nine for Mortal Men, doomed to die, One for the Dark Lord on his dark throne"</span><span class="token punctuation">,</span>
    <span class="token punctuation">]</span>
<span class="token punctuation">)</span>

generator<span class="token punctuation">(</span>
    <span class="token string">"Three Rings for the Elven-kings under the sky, Seven for the Dwarf-lords in their halls of stone"</span><span class="token punctuation">,</span>
    num_return_sequences<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span>
<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<h3 id="Choose-a-model-and-tokenizer"><a href="#Choose-a-model-and-tokenizer" class="headerlink" title="Choose a model and tokenizer"></a>Choose a model and tokenizer</h3><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">from</span> transformers <span class="token keyword">import</span> AutoTokenizer<span class="token punctuation">,</span> AutoModelForCausalLM

tokenizer <span class="token operator">=</span> AutoTokenizer<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span><span class="token string">"distilgpt2"</span><span class="token punctuation">)</span>
model <span class="token operator">=</span> AutoModelForCausalLM<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span><span class="token string">"distilgpt2"</span><span class="token punctuation">)</span>

<span class="token keyword">from</span> transformers <span class="token keyword">import</span> pipeline

generator <span class="token operator">=</span> pipeline<span class="token punctuation">(</span>task<span class="token operator">=</span><span class="token string">"text-generation"</span><span class="token punctuation">,</span> model<span class="token operator">=</span>model<span class="token punctuation">,</span> tokenizer<span class="token operator">=</span>tokenizer<span class="token punctuation">)</span>

generator<span class="token punctuation">(</span><span class="token string">"Three Rings for the Elven-kings under the sky, Seven for the Dwarf-lords in their halls of stone"</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<h3 id="Audio-pipeline"><a href="#Audio-pipeline" class="headerlink" title="Audio pipeline"></a>Audio pipeline</h3><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">from</span> transformers <span class="token keyword">import</span> pipeline

audio_classifier <span class="token operator">=</span> pipeline<span class="token punctuation">(</span>
    task<span class="token operator">=</span><span class="token string">"audio-classification"</span><span class="token punctuation">,</span> model<span class="token operator">=</span><span class="token string">"ehcalabres/wav2vec2-lg-xlsr-en-speech-emotion-recognition"</span>
<span class="token punctuation">)</span>

audio_classifier<span class="token punctuation">(</span><span class="token string">"jfk_moon_speech.wav"</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<h3 id="Vision-pipeline"><a href="#Vision-pipeline" class="headerlink" title="Vision pipeline"></a>Vision pipeline</h3><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">from</span> transformers <span class="token keyword">import</span> pipeline

vision_classifier <span class="token operator">=</span> pipeline<span class="token punctuation">(</span>task<span class="token operator">=</span><span class="token string">"image-classification"</span><span class="token punctuation">)</span>
vision_classifier<span class="token punctuation">(</span>
    images<span class="token operator">=</span><span class="token string">"&lt;https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/pipeline-cat-chonk.jpeg>"</span>
<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<h2 id="Load-pretrained-instances-with-an-AutoClass"><a href="#Load-pretrained-instances-with-an-AutoClass" class="headerlink" title="Load pretrained instances with an AutoClass"></a>Load pretrained instances with an AutoClass</h2><h3 id="AutoTokenizer"><a href="#AutoTokenizer" class="headerlink" title="AutoTokenizer"></a>AutoTokenizer</h3><p>å‡ ä¹æ¯ä¸ª NLP ä»»åŠ¡éƒ½ä»åˆ†è¯å™¨å¼€å§‹ã€‚åˆ†è¯å™¨å°†æ‚¨çš„è¾“å…¥è½¬æ¢ä¸ºæ¨¡å‹å¯ä»¥å¤„ç†çš„æ ¼å¼ã€‚</p>
<p>Load a tokenizer with <strong><a href="https://huggingface.co/docs/transformers/v4.18.0/en/model_doc/auto#transformers.AutoTokenizer.from_pretrained" target="_blank" rel="noopener">AutoTokenizer.from_pretrained()</a></strong></p>
<pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">from</span> transformers <span class="token keyword">import</span> AutoTokenizer

tokenizer <span class="token operator">=</span> AutoTokenizer<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span><span class="token string">"bert-base-uncased"</span><span class="token punctuation">)</span>

sequence <span class="token operator">=</span> <span class="token string">"In a hole in the ground there lived a hobbit."</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>tokenizer<span class="token punctuation">(</span>sequence<span class="token punctuation">)</span><span class="token punctuation">)</span>

<span class="token punctuation">{</span><span class="token string">'input_ids'</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token number">101</span><span class="token punctuation">,</span> <span class="token number">1999</span><span class="token punctuation">,</span> <span class="token number">1037</span><span class="token punctuation">,</span> <span class="token number">4920</span><span class="token punctuation">,</span> <span class="token number">1999</span><span class="token punctuation">,</span> <span class="token number">1996</span><span class="token punctuation">,</span> <span class="token number">2598</span><span class="token punctuation">,</span> <span class="token number">2045</span><span class="token punctuation">,</span> <span class="token number">2973</span><span class="token punctuation">,</span> <span class="token number">1037</span><span class="token punctuation">,</span> <span class="token number">7570</span><span class="token punctuation">,</span> <span class="token number">10322</span><span class="token punctuation">,</span> <span class="token number">4183</span><span class="token punctuation">,</span> <span class="token number">1012</span><span class="token punctuation">,</span> <span class="token number">102</span><span class="token punctuation">]</span><span class="token punctuation">,</span> 
 <span class="token string">'token_type_ids'</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> 
 <span class="token string">'attention_mask'</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<h3 id="AutoFeatureExtractor"><a href="#AutoFeatureExtractor" class="headerlink" title="AutoFeatureExtractor"></a>AutoFeatureExtractor</h3><p>å¯¹äºéŸ³é¢‘å’Œè§†è§‰ä»»åŠ¡ï¼Œç‰¹å¾æå–å™¨å°†éŸ³é¢‘ä¿¡å·æˆ–å›¾åƒå¤„ç†ä¸ºæ­£ç¡®çš„è¾“å…¥æ ¼å¼ã€‚</p>
<p>Load a feature extractor with <strong><a href="https://huggingface.co/docs/transformers/v4.18.0/en/model_doc/auto#transformers.AutoFeatureExtractor.from_pretrained" target="_blank" rel="noopener">AutoFeatureExtractor.from_pretrained()</a></strong></p>
<pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">from</span> transformers <span class="token keyword">import</span> AutoFeatureExtractor

feature_extractor <span class="token operator">=</span> AutoFeatureExtractor<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span>
    <span class="token string">"ehcalabres/wav2vec2-lg-xlsr-en-speech-emotion-recognition"</span>
<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<h3 id="AutoProcessor"><a href="#AutoProcessor" class="headerlink" title="AutoProcessor"></a>AutoProcessor</h3><p>å¤šæ¨¡å¼ä»»åŠ¡éœ€è¦ç»“åˆä¸¤ç§é¢„å¤„ç†å·¥å…·çš„å¤„ç†å™¨ã€‚ä¾‹å¦‚ï¼Œ<strong><a href="https://huggingface.co/docs/transformers/model_doc/layoutlmv2" target="_blank" rel="noopener">LayoutLMV2</a></strong>æ¨¡å‹éœ€è¦ä¸€ä¸ªç‰¹å¾æå–å™¨æ¥å¤„ç†å›¾åƒå’Œä¸€ä¸ªåˆ†è¯å™¨æ¥å¤„ç†æ–‡æœ¬ï¼›å¤„ç†å™¨å°†ä¸¤è€…ç»“åˆåœ¨ä¸€èµ·ã€‚</p>
<p>Load a processor with <strong><a href="https://huggingface.co/docs/transformers/v4.18.0/en/model_doc/auto#transformers.AutoProcessor.from_pretrained" target="_blank" rel="noopener">AutoProcessor.from_pretrained()</a></strong></p>
<pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">from</span> transformers <span class="token keyword">import</span> AutoProcessor

processor <span class="token operator">=</span> AutoProcessor<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span><span class="token string">"microsoft/layoutlmv2-base-uncased"</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre>
<h3 id="AutoModel"><a href="#AutoModel" class="headerlink" title="AutoModel"></a>AutoModel</h3><p>æœ€åï¼Œè¿™äº›<code>AutoModelFor</code>ç±»å…è®¸æ‚¨ä¸ºç»™å®šä»»åŠ¡åŠ è½½é¢„è®­ç»ƒæ¨¡å‹ï¼ˆæœ‰å…³å¯ç”¨ä»»åŠ¡çš„å®Œæ•´åˆ—è¡¨ï¼Œè¯·å‚è§<strong><a href="https://huggingface.co/docs/transformers/model_doc/auto" target="_blank" rel="noopener">æ­¤å¤„</a></strong>ï¼‰ã€‚ä¾‹å¦‚ï¼Œä½¿ç”¨<strong><a href="https://huggingface.co/docs/transformers/v4.18.0/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained" target="_blank" rel="noopener">AutoModelForSequenceClassification.from_pretrained()</a></strong>åŠ è½½åºåˆ—åˆ†ç±»æ¨¡å‹ï¼š</p>
<pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">from</span> transformers <span class="token keyword">import</span> AutoModelForSequenceClassification

model <span class="token operator">=</span> AutoModelForSequenceClassification<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span><span class="token string">"distilbert-base-uncased"</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre>
<p>è½»æ¾é‡ç”¨ç›¸åŒçš„æ£€æŸ¥ç‚¹æ¥ä¸ºä¸åŒçš„ä»»åŠ¡åŠ è½½æ¶æ„ï¼š</p>
<pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">from</span> transformers <span class="token keyword">import</span> AutoModelForTokenClassification

model <span class="token operator">=</span> AutoModelForTokenClassification<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span><span class="token string">"distilbert-base-uncased"</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre>
<p>é€šå¸¸ï¼Œæˆ‘ä»¬å»ºè®®ä½¿ç”¨<code>AutoTokenizer</code>ç±»å’Œ<code>AutoModelFor</code>ç±»æ¥åŠ è½½æ¨¡å‹çš„é¢„è®­ç»ƒå®ä¾‹ã€‚è¿™å°†ç¡®ä¿æ‚¨æ¯æ¬¡éƒ½åŠ è½½æ­£ç¡®çš„æ¶æ„ã€‚</p>
<h2 id="Preprocessã€é¢„å¤„ç†ã€‘"><a href="#Preprocessã€é¢„å¤„ç†ã€‘" class="headerlink" title="Preprocessã€é¢„å¤„ç†ã€‘"></a>Preprocessã€é¢„å¤„ç†ã€‘</h2><p>åœ¨æ‚¨å¯ä»¥åœ¨æ¨¡å‹ä¸­ä½¿ç”¨æ•°æ®ä¹‹å‰ï¼Œéœ€è¦å°†æ•°æ®å¤„ç†ä¸ºæ¨¡å‹å¯æ¥å—çš„æ ¼å¼ã€‚æ¨¡å‹ä¸ç†è§£åŸå§‹æ–‡æœ¬ã€å›¾åƒæˆ–éŸ³é¢‘ã€‚è¿™äº›è¾“å…¥éœ€è¦è½¬æ¢æˆæ•°å­—å¹¶ç»„è£…æˆå¼ é‡ã€‚</p>
<ul>
<li>ä½¿ç”¨åˆ†è¯å™¨é¢„å¤„ç†æ–‡æœ¬æ•°æ®ã€‚</li>
<li>ä½¿ç”¨ç‰¹å¾æå–å™¨é¢„å¤„ç†å›¾åƒæˆ–éŸ³é¢‘æ•°æ®ã€‚</li>
<li>ä½¿ç”¨å¤„ç†å™¨é¢„å¤„ç†å¤šæ¨¡å¼ä»»åŠ¡çš„æ•°æ®ã€‚</li>
</ul>
<h3 id="NLP"><a href="#NLP" class="headerlink" title="NLP"></a>NLP</h3><p>å¤„ç†æ–‡æœ¬æ•°æ®çš„ä¸»è¦å·¥å…·æ˜¯<strong><a href="https://huggingface.co/docs/transformers/main_classes/tokenizer" target="_blank" rel="noopener">åˆ†è¯</a></strong>å™¨ã€‚æ ‡è®°å™¨é¦–å…ˆæ ¹æ®ä¸€ç»„è§„åˆ™å°†æ–‡æœ¬æ‹†åˆ†ä¸º<em>æ ‡è®°ã€‚</em>æ ‡è®°è¢«è½¬æ¢ä¸ºæ•°å­—ï¼Œç”¨äºæ„å»ºå¼ é‡ä½œä¸ºæ¨¡å‹çš„è¾“å…¥ã€‚æ¨¡å‹æ‰€éœ€çš„ä»»ä½•å…¶ä»–è¾“å…¥ä¹Ÿç”±æ ‡è®°å™¨æ·»åŠ ã€‚</p>
<p>å¦‚æœæ‚¨è®¡åˆ’ä½¿ç”¨é¢„è®­ç»ƒæ¨¡å‹ï¼Œè¯·åŠ¡å¿…ä½¿ç”¨ç›¸å…³çš„é¢„è®­ç»ƒæ ‡è®°å™¨ã€‚è¿™ç¡®ä¿æ–‡æœ¬ä»¥ä¸é¢„è®­ç»ƒè¯­æ–™åº“ç›¸åŒçš„æ–¹å¼æ‹†åˆ†ï¼Œå¹¶åœ¨é¢„è®­ç»ƒæœŸé—´ä½¿ç”¨ç›¸åŒçš„ç›¸åº”æ ‡è®°åˆ°ç´¢å¼•ï¼ˆé€šå¸¸ç§°ä¸º<em>vocab</em>ï¼‰ã€‚</p>
<p><strong><a href="https://huggingface.co/docs/transformers/v4.18.0/en/model_doc/auto#transformers.AutoTokenizer" target="_blank" rel="noopener">é€šè¿‡ä½¿ç”¨AutoTokenizer</a></strong>ç±»åŠ è½½é¢„è®­ç»ƒçš„åˆ†è¯å™¨æ¥å¿«é€Ÿå¼€å§‹ã€‚è¿™ä¼šä¸‹è½½æ¨¡å‹é¢„è®­ç»ƒæ—¶ä½¿ç”¨çš„<em>è¯æ±‡</em>ã€‚</p>
<h3 id="Tokenize"><a href="#Tokenize" class="headerlink" title="Tokenize"></a>Tokenize</h3><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">from</span> transformers <span class="token keyword">import</span> AutoTokenizer

tokenizer <span class="token operator">=</span> AutoTokenizer<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span><span class="token string">"bert-base-cased"</span><span class="token punctuation">)</span>

encoded_input <span class="token operator">=</span> tokenizer<span class="token punctuation">(</span><span class="token string">"Do not meddle in the affairs of wizards, for they are subtle and quick to anger."</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>encoded_input<span class="token punctuation">)</span>
<span class="token punctuation">{</span><span class="token string">'input_ids'</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token number">101</span><span class="token punctuation">,</span> <span class="token number">2079</span><span class="token punctuation">,</span> <span class="token number">2025</span><span class="token punctuation">,</span> <span class="token number">19960</span><span class="token punctuation">,</span> <span class="token number">10362</span><span class="token punctuation">,</span> <span class="token number">1999</span><span class="token punctuation">,</span> <span class="token number">1996</span><span class="token punctuation">,</span> <span class="token number">3821</span><span class="token punctuation">,</span> <span class="token number">1997</span><span class="token punctuation">,</span> <span class="token number">16657</span><span class="token punctuation">,</span> <span class="token number">1010</span><span class="token punctuation">,</span> <span class="token number">2005</span><span class="token punctuation">,</span> <span class="token number">2027</span><span class="token punctuation">,</span> <span class="token number">2024</span><span class="token punctuation">,</span> <span class="token number">11259</span><span class="token punctuation">,</span> <span class="token number">1998</span><span class="token punctuation">,</span> <span class="token number">4248</span><span class="token punctuation">,</span> <span class="token number">2000</span><span class="token punctuation">,</span> <span class="token number">4963</span><span class="token punctuation">,</span> <span class="token number">1012</span><span class="token punctuation">,</span> <span class="token number">102</span><span class="token punctuation">]</span><span class="token punctuation">,</span> 
 <span class="token string">'token_type_ids'</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> 
 <span class="token string">'attention_mask'</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>åˆ†è¯å™¨è¿”å›ä¸€ä¸ªåŒ…å«ä¸‰ä¸ªé‡è¦é¡¹ç›®çš„å­—å…¸ï¼š</p>
<ul>
<li><strong><a href="https://huggingface.co/docs/transformers/glossary#input-ids" target="_blank" rel="noopener">input_ids</a></strong>æ˜¯å¥å­ä¸­æ¯ä¸ªæ ‡è®°å¯¹åº”çš„ç´¢å¼•ã€‚</li>
<li><strong><a href="https://huggingface.co/docs/transformers/glossary#attention-mask" target="_blank" rel="noopener">attention_mask</a></strong>æŒ‡ç¤ºæ˜¯å¦åº”æ³¨æ„ä»¤ç‰Œã€‚</li>
<li>å½“æœ‰å¤šä¸ªåºåˆ—æ—¶ï¼Œ<strong><a href="https://huggingface.co/docs/transformers/glossary#token-type-ids" target="_blank" rel="noopener">token_type_idsæ ‡è¯†ä»¤ç‰Œå±äºå“ªä¸ªåºåˆ—ã€‚</a></strong></li>
</ul>
<pre class="line-numbers language-python"><code class="language-python">tokenizer<span class="token punctuation">.</span>decode<span class="token punctuation">(</span>encoded_input<span class="token punctuation">[</span><span class="token string">"input_ids"</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
batch_sentences <span class="token operator">=</span> <span class="token punctuation">[</span>
    <span class="token string">"But what about second breakfast?"</span><span class="token punctuation">,</span>
    <span class="token string">"Don't think he knows about second breakfast, Pip."</span><span class="token punctuation">,</span>
    <span class="token string">"What about elevensies?"</span><span class="token punctuation">,</span>
<span class="token punctuation">]</span>
encoded_inputs <span class="token operator">=</span> tokenizer<span class="token punctuation">(</span>batch_sentences<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>encoded_inputs<span class="token punctuation">)</span>
<span class="token punctuation">{</span><span class="token string">'input_ids'</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">101</span><span class="token punctuation">,</span> <span class="token number">1252</span><span class="token punctuation">,</span> <span class="token number">1184</span><span class="token punctuation">,</span> <span class="token number">1164</span><span class="token punctuation">,</span> <span class="token number">1248</span><span class="token punctuation">,</span> <span class="token number">6462</span><span class="token punctuation">,</span> <span class="token number">136</span><span class="token punctuation">,</span> <span class="token number">102</span><span class="token punctuation">]</span><span class="token punctuation">,</span> 
               <span class="token punctuation">[</span><span class="token number">101</span><span class="token punctuation">,</span> <span class="token number">1790</span><span class="token punctuation">,</span> <span class="token number">112</span><span class="token punctuation">,</span> <span class="token number">189</span><span class="token punctuation">,</span> <span class="token number">1341</span><span class="token punctuation">,</span> <span class="token number">1119</span><span class="token punctuation">,</span> <span class="token number">3520</span><span class="token punctuation">,</span> <span class="token number">1164</span><span class="token punctuation">,</span> <span class="token number">1248</span><span class="token punctuation">,</span> <span class="token number">6462</span><span class="token punctuation">,</span> <span class="token number">117</span><span class="token punctuation">,</span> <span class="token number">21902</span><span class="token punctuation">,</span> <span class="token number">1643</span><span class="token punctuation">,</span> <span class="token number">119</span><span class="token punctuation">,</span> <span class="token number">102</span><span class="token punctuation">]</span><span class="token punctuation">,</span> 
               <span class="token punctuation">[</span><span class="token number">101</span><span class="token punctuation">,</span> <span class="token number">1327</span><span class="token punctuation">,</span> <span class="token number">1164</span><span class="token punctuation">,</span> <span class="token number">5450</span><span class="token punctuation">,</span> <span class="token number">23434</span><span class="token punctuation">,</span> <span class="token number">136</span><span class="token punctuation">,</span> <span class="token number">102</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span> 
 <span class="token string">'token_type_ids'</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> 
                    <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> 
                    <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span> 
 <span class="token string">'attention_mask'</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> 
                    <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> 
                    <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<h3 id="Pad"><a href="#Pad" class="headerlink" title="Pad"></a>Pad</h3><p>è¿™ç»™æˆ‘ä»¬å¸¦æ¥äº†ä¸€ä¸ªé‡è¦çš„è¯é¢˜ã€‚å½“æ‚¨å¤„ç†ä¸€æ‰¹å¥å­æ—¶ï¼Œå®ƒä»¬çš„é•¿åº¦å¹¶ä¸æ€»æ˜¯ç›¸åŒçš„ã€‚è¿™æ˜¯ä¸€ä¸ªé—®é¢˜ï¼Œå› ä¸ºä½œä¸ºæ¨¡å‹è¾“å…¥çš„å¼ é‡éœ€è¦å…·æœ‰ç»Ÿä¸€çš„å½¢çŠ¶ã€‚å¡«å……æ˜¯ä¸€ç§é€šè¿‡å‘å…·æœ‰è¾ƒå°‘æ ‡è®°çš„å¥å­æ·»åŠ ç‰¹æ®Š<em>å¡«å……æ ‡è®°</em>æ¥ç¡®ä¿å¼ é‡æ˜¯çŸ©å½¢çš„ç­–ç•¥ã€‚</p>
<p>å°†<code>padding</code>å‚æ•°è®¾ç½®<code>True</code>ä¸ºå¡«å……æ‰¹æ¬¡ä¸­è¾ƒçŸ­çš„åºåˆ—ä»¥åŒ¹é…æœ€é•¿çš„åºåˆ—ï¼š</p>
<pre class="line-numbers language-python"><code class="language-python">batch_sentences <span class="token operator">=</span> <span class="token punctuation">[</span>
    <span class="token string">"But what about second breakfast?"</span><span class="token punctuation">,</span>
    <span class="token string">"Don't think he knows about second breakfast, Pip."</span><span class="token punctuation">,</span>
    <span class="token string">"What about elevensies?"</span><span class="token punctuation">,</span>
<span class="token punctuation">]</span>
encoded_input <span class="token operator">=</span> tokenizer<span class="token punctuation">(</span>batch_sentences<span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>encoded_input<span class="token punctuation">)</span>
<span class="token punctuation">{</span><span class="token string">'input_ids'</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">101</span><span class="token punctuation">,</span> <span class="token number">1252</span><span class="token punctuation">,</span> <span class="token number">1184</span><span class="token punctuation">,</span> <span class="token number">1164</span><span class="token punctuation">,</span> <span class="token number">1248</span><span class="token punctuation">,</span> <span class="token number">6462</span><span class="token punctuation">,</span> <span class="token number">136</span><span class="token punctuation">,</span> <span class="token number">102</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> 
               <span class="token punctuation">[</span><span class="token number">101</span><span class="token punctuation">,</span> <span class="token number">1790</span><span class="token punctuation">,</span> <span class="token number">112</span><span class="token punctuation">,</span> <span class="token number">189</span><span class="token punctuation">,</span> <span class="token number">1341</span><span class="token punctuation">,</span> <span class="token number">1119</span><span class="token punctuation">,</span> <span class="token number">3520</span><span class="token punctuation">,</span> <span class="token number">1164</span><span class="token punctuation">,</span> <span class="token number">1248</span><span class="token punctuation">,</span> <span class="token number">6462</span><span class="token punctuation">,</span> <span class="token number">117</span><span class="token punctuation">,</span> <span class="token number">21902</span><span class="token punctuation">,</span> <span class="token number">1643</span><span class="token punctuation">,</span> <span class="token number">119</span><span class="token punctuation">,</span> <span class="token number">102</span><span class="token punctuation">]</span><span class="token punctuation">,</span> 
               <span class="token punctuation">[</span><span class="token number">101</span><span class="token punctuation">,</span> <span class="token number">1327</span><span class="token punctuation">,</span> <span class="token number">1164</span><span class="token punctuation">,</span> <span class="token number">5450</span><span class="token punctuation">,</span> <span class="token number">23434</span><span class="token punctuation">,</span> <span class="token number">136</span><span class="token punctuation">,</span> <span class="token number">102</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span> 
 <span class="token string">'token_type_ids'</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> 
                    <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> 
                    <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span> 
 <span class="token string">'attention_mask'</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> 
                    <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> 
                    <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<h3 id="Truncation"><a href="#Truncation" class="headerlink" title="Truncation"></a>Truncation</h3><p>å¦ä¸€æ–¹é¢ï¼Œæœ‰æ—¶åºåˆ—å¯èƒ½å¤ªé•¿ï¼Œæ¨¡å‹æ— æ³•å¤„ç†ã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œæ‚¨éœ€è¦å°†åºåˆ—æˆªæ–­ä¸ºæ›´çŸ­çš„é•¿åº¦ã€‚</p>
<p>å°†<code>truncation</code>å‚æ•°è®¾ç½®<code>True</code>ä¸ºå°†åºåˆ—æˆªæ–­ä¸ºæ¨¡å‹æ¥å—çš„æœ€å¤§é•¿åº¦ï¼š</p>
<pre class="line-numbers language-python"><code class="language-python">batch_sentences <span class="token operator">=</span> <span class="token punctuation">[</span>
    <span class="token string">"But what about second breakfast?"</span><span class="token punctuation">,</span>
    <span class="token string">"Don't think he knows about second breakfast, Pip."</span><span class="token punctuation">,</span>
    <span class="token string">"What about elevensies?"</span><span class="token punctuation">,</span>
<span class="token punctuation">]</span>
encoded_input <span class="token operator">=</span> tokenizer<span class="token punctuation">(</span>batch_sentences<span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> truncation<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>encoded_input<span class="token punctuation">)</span>
<span class="token punctuation">{</span><span class="token string">'input_ids'</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">101</span><span class="token punctuation">,</span> <span class="token number">1252</span><span class="token punctuation">,</span> <span class="token number">1184</span><span class="token punctuation">,</span> <span class="token number">1164</span><span class="token punctuation">,</span> <span class="token number">1248</span><span class="token punctuation">,</span> <span class="token number">6462</span><span class="token punctuation">,</span> <span class="token number">136</span><span class="token punctuation">,</span> <span class="token number">102</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> 
               <span class="token punctuation">[</span><span class="token number">101</span><span class="token punctuation">,</span> <span class="token number">1790</span><span class="token punctuation">,</span> <span class="token number">112</span><span class="token punctuation">,</span> <span class="token number">189</span><span class="token punctuation">,</span> <span class="token number">1341</span><span class="token punctuation">,</span> <span class="token number">1119</span><span class="token punctuation">,</span> <span class="token number">3520</span><span class="token punctuation">,</span> <span class="token number">1164</span><span class="token punctuation">,</span> <span class="token number">1248</span><span class="token punctuation">,</span> <span class="token number">6462</span><span class="token punctuation">,</span> <span class="token number">117</span><span class="token punctuation">,</span> <span class="token number">21902</span><span class="token punctuation">,</span> <span class="token number">1643</span><span class="token punctuation">,</span> <span class="token number">119</span><span class="token punctuation">,</span> <span class="token number">102</span><span class="token punctuation">]</span><span class="token punctuation">,</span> 
               <span class="token punctuation">[</span><span class="token number">101</span><span class="token punctuation">,</span> <span class="token number">1327</span><span class="token punctuation">,</span> <span class="token number">1164</span><span class="token punctuation">,</span> <span class="token number">5450</span><span class="token punctuation">,</span> <span class="token number">23434</span><span class="token punctuation">,</span> <span class="token number">136</span><span class="token punctuation">,</span> <span class="token number">102</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span> 
 <span class="token string">'token_type_ids'</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> 
                    <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> 
                    <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span> 
 <span class="token string">'attention_mask'</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> 
                    <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> 
                    <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<h3 id="Build-tensors"><a href="#Build-tensors" class="headerlink" title="Build tensors"></a>Build tensors</h3><p>æœ€åï¼Œå¸Œæœ›æ ‡è®°å™¨è¿”å›é¦ˆé€åˆ°æ¨¡å‹çš„å®é™…å¼ é‡ã€‚</p>
<p>å°†<code>return_tensors</code>å‚æ•°è®¾ç½®<code>pt</code>ä¸º PyTorch æˆ–<code>tf</code>TensorFlowï¼š</p>
<pre class="line-numbers language-python"><code class="language-python">batch_sentences <span class="token operator">=</span> <span class="token punctuation">[</span>
    <span class="token string">"But what about second breakfast?"</span><span class="token punctuation">,</span>
    <span class="token string">"Don't think he knows about second breakfast, Pip."</span><span class="token punctuation">,</span>
    <span class="token string">"What about elevensies?"</span><span class="token punctuation">,</span>
<span class="token punctuation">]</span>
encoded_input <span class="token operator">=</span> tokenizer<span class="token punctuation">(</span>batch<span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> truncation<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> return_tensors<span class="token operator">=</span><span class="token string">"pt"</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>encoded_input<span class="token punctuation">)</span>
<span class="token punctuation">{</span><span class="token string">'input_ids'</span><span class="token punctuation">:</span> tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span>  <span class="token number">101</span><span class="token punctuation">,</span>   <span class="token number">153</span><span class="token punctuation">,</span>  <span class="token number">7719</span><span class="token punctuation">,</span> <span class="token number">21490</span><span class="token punctuation">,</span>  <span class="token number">1122</span><span class="token punctuation">,</span>  <span class="token number">1114</span><span class="token punctuation">,</span>  <span class="token number">9582</span><span class="token punctuation">,</span>  <span class="token number">1623</span><span class="token punctuation">,</span>   <span class="token number">102</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
                      <span class="token punctuation">[</span>  <span class="token number">101</span><span class="token punctuation">,</span>  <span class="token number">5226</span><span class="token punctuation">,</span>  <span class="token number">1122</span><span class="token punctuation">,</span>  <span class="token number">9649</span><span class="token punctuation">,</span>  <span class="token number">1199</span><span class="token punctuation">,</span>  <span class="token number">2610</span><span class="token punctuation">,</span>  <span class="token number">1236</span><span class="token punctuation">,</span>   <span class="token number">102</span><span class="token punctuation">,</span>     <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span> 
 <span class="token string">'token_type_ids'</span><span class="token punctuation">:</span> tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
                           <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span> 
 <span class="token string">'attention_mask'</span><span class="token punctuation">:</span> tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
                           <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<h3 id="Audio"><a href="#Audio" class="headerlink" title="Audio"></a>Audio</h3><p>éŸ³é¢‘è¾“å…¥çš„é¢„å¤„ç†ä¸æ–‡æœ¬è¾“å…¥ä¸åŒï¼Œä½†æœ€ç»ˆç›®æ ‡ä¿æŒä¸å˜ï¼šåˆ›å»ºæ¨¡å‹å¯ä»¥ç†è§£çš„æ•°å­—åºåˆ—ã€‚<strong><a href="https://huggingface.co/docs/transformers/main_classes/feature_extractor" target="_blank" rel="noopener">ç‰¹å¾æå–å™¨</a></strong>æ—¨åœ¨ä»åŸå§‹å›¾åƒæˆ–éŸ³é¢‘æ•°æ®ä¸­æå–ç‰¹å¾å¹¶å°†å…¶è½¬æ¢ä¸ºå¼ é‡ã€‚</p>
<pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">from</span> datasets <span class="token keyword">import</span> load_dataset<span class="token punctuation">,</span> Audio

dataset <span class="token operator">=</span> load_dataset<span class="token punctuation">(</span><span class="token string">"superb"</span><span class="token punctuation">,</span> <span class="token string">"ks"</span><span class="token punctuation">)</span>

dataset<span class="token punctuation">[</span><span class="token string">"train"</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">"audio"</span><span class="token punctuation">]</span>
<span class="token punctuation">{</span><span class="token string">'array'</span><span class="token punctuation">:</span> array<span class="token punctuation">(</span><span class="token punctuation">[</span> <span class="token number">0</span><span class="token punctuation">.</span>        <span class="token punctuation">,</span>  <span class="token number">0</span><span class="token punctuation">.</span>        <span class="token punctuation">,</span>  <span class="token number">0</span><span class="token punctuation">.</span>        <span class="token punctuation">,</span> <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.00592041</span><span class="token punctuation">,</span>
        <span class="token operator">-</span><span class="token number">0.00405884</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.00253296</span><span class="token punctuation">]</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>float32<span class="token punctuation">)</span><span class="token punctuation">,</span>
 <span class="token string">'path'</span><span class="token punctuation">:</span> <span class="token string">'/root/.cache/huggingface/datasets/downloads/extracted/05734a36d88019a09725c20cc024e1c4e7982e37d7d55c0c1ca1742ea1cdd47f/_background_noise_/doing_the_dishes.wav'</span><span class="token punctuation">,</span>
 <span class="token string">'sampling_rate'</span><span class="token punctuation">:</span> <span class="token number">16000</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>è¿™å°†è¿”å›ä¸‰ä¸ªé¡¹ç›®ï¼š</p>
<ul>
<li><code>array</code>æ˜¯å°†è¯­éŸ³ä¿¡å·åŠ è½½ - å¹¶å¯èƒ½é‡æ–°é‡‡æ · - ä½œä¸ºä¸€ç»´æ•°ç»„ã€‚</li>
<li><code>path</code>æŒ‡å‘éŸ³é¢‘æ–‡ä»¶çš„ä½ç½®ã€‚</li>
<li><code>sampling_rate</code>æŒ‡æ¯ç§’æµ‹é‡è¯­éŸ³ä¿¡å·ä¸­çš„æ•°æ®ç‚¹æ•°ã€‚</li>
</ul>
<h3 id="Resample"><a href="#Resample" class="headerlink" title="Resample"></a>Resample</h3><pre class="line-numbers language-python"><code class="language-python">lj_speech <span class="token operator">=</span> load_dataset<span class="token punctuation">(</span><span class="token string">"lj_speech"</span><span class="token punctuation">,</span> split<span class="token operator">=</span><span class="token string">"train"</span><span class="token punctuation">)</span>
lj_speech<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">"audio"</span><span class="token punctuation">]</span>

lj_speech <span class="token operator">=</span> lj_speech<span class="token punctuation">.</span>cast_column<span class="token punctuation">(</span><span class="token string">"audio"</span><span class="token punctuation">,</span> Audio<span class="token punctuation">(</span>sampling_rate<span class="token operator">=</span>16_000<span class="token punctuation">)</span><span class="token punctuation">)</span>

lj_speech<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">"audio"</span><span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<h3 id="Feature-extractor"><a href="#Feature-extractor" class="headerlink" title="Feature extractor"></a>Feature extractor</h3><p>ä¸‹ä¸€æ­¥æ˜¯åŠ è½½ä¸€ä¸ªç‰¹å¾æå–å™¨æ¥è§„èŒƒåŒ–å’Œå¡«å……è¾“å…¥ã€‚å¡«å……æ–‡æœ¬æ•°æ®æ—¶ï¼Œ<code>0</code>ä¸ºè¾ƒçŸ­çš„åºåˆ—æ·»åŠ  aã€‚åŒæ ·çš„æƒ³æ³•ä¹Ÿé€‚ç”¨äºéŸ³é¢‘æ•°æ®ï¼ŒéŸ³é¢‘ç‰¹å¾æå–å™¨å°†æ·»åŠ ä¸€ä¸ª<code>0</code>- è§£é‡Šä¸ºé™éŸ³ - åˆ°<code>array</code>.</p>
<pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">from</span> transformers <span class="token keyword">import</span> AutoFeatureExtractor

feature_extractor <span class="token operator">=</span> AutoFeatureExtractor<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span><span class="token string">"facebook/wav2vec2-base"</span><span class="token punctuation">)</span>
audio_input <span class="token operator">=</span> <span class="token punctuation">[</span>dataset<span class="token punctuation">[</span><span class="token string">"train"</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">"audio"</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">"array"</span><span class="token punctuation">]</span><span class="token punctuation">]</span>
feature_extractor<span class="token punctuation">(</span>audio_input<span class="token punctuation">,</span> sampling_rate<span class="token operator">=</span><span class="token number">16000</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<h3 id="Pad-and-truncate"><a href="#Pad-and-truncate" class="headerlink" title="Pad and truncate"></a>Pad and truncate</h3><pre class="line-numbers language-python"><code class="language-python">dataset<span class="token punctuation">[</span><span class="token string">"train"</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">"audio"</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">"array"</span><span class="token punctuation">]</span><span class="token punctuation">.</span>shape

dataset<span class="token punctuation">[</span><span class="token string">"train"</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">"audio"</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">"array"</span><span class="token punctuation">]</span><span class="token punctuation">.</span>shape

<span class="token keyword">def</span> <span class="token function">preprocess_function</span><span class="token punctuation">(</span>examples<span class="token punctuation">)</span><span class="token punctuation">:</span>
    audio_arrays <span class="token operator">=</span> <span class="token punctuation">[</span>x<span class="token punctuation">[</span><span class="token string">"array"</span><span class="token punctuation">]</span> <span class="token keyword">for</span> x <span class="token keyword">in</span> examples<span class="token punctuation">[</span><span class="token string">"audio"</span><span class="token punctuation">]</span><span class="token punctuation">]</span>
    inputs <span class="token operator">=</span> feature_extractor<span class="token punctuation">(</span>
        audio_arrays<span class="token punctuation">,</span>
        sampling_rate<span class="token operator">=</span><span class="token number">16000</span><span class="token punctuation">,</span>
        padding<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>
        max_length<span class="token operator">=</span><span class="token number">1000000</span><span class="token punctuation">,</span>
        truncation<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>
    <span class="token punctuation">)</span>
    <span class="token keyword">return</span> inputs

processed_dataset <span class="token operator">=</span> preprocess_function<span class="token punctuation">(</span>dataset<span class="token punctuation">[</span><span class="token string">"train"</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token number">5</span><span class="token punctuation">]</span><span class="token punctuation">)</span>

processed_dataset<span class="token punctuation">[</span><span class="token string">"input_values"</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>shape

processed_dataset<span class="token punctuation">[</span><span class="token string">"input_values"</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">.</span>shape<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<h3 id="Vision"><a href="#Vision" class="headerlink" title="Vision"></a>Vision</h3><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">from</span> datasets <span class="token keyword">import</span> load_dataset

dataset <span class="token operator">=</span> load_dataset<span class="token punctuation">(</span><span class="token string">"food101"</span><span class="token punctuation">,</span> split<span class="token operator">=</span><span class="token string">"train[:100]"</span><span class="token punctuation">)</span>

dataset<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">"image"</span><span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<h3 id="Feature-extractor-1"><a href="#Feature-extractor-1" class="headerlink" title="Feature extractor"></a>Feature extractor</h3><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">from</span> transformers <span class="token keyword">import</span> AutoFeatureExtractor

feature_extractor <span class="token operator">=</span> AutoFeatureExtractor<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span><span class="token string">"google/vit-base-patch16-224"</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre>
<h3 id="Data-augmentation"><a href="#Data-augmentation" class="headerlink" title="Data augmentation"></a>Data augmentation</h3><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">from</span> torchvision<span class="token punctuation">.</span>transforms <span class="token keyword">import</span> Compose<span class="token punctuation">,</span> Normalize<span class="token punctuation">,</span> RandomResizedCrop<span class="token punctuation">,</span> ColorJitter<span class="token punctuation">,</span> ToTensor

normalize <span class="token operator">=</span> Normalize<span class="token punctuation">(</span>mean<span class="token operator">=</span>feature_extractor<span class="token punctuation">.</span>image_mean<span class="token punctuation">,</span> std<span class="token operator">=</span>feature_extractor<span class="token punctuation">.</span>image_std<span class="token punctuation">)</span>
_transforms <span class="token operator">=</span> Compose<span class="token punctuation">(</span>
    <span class="token punctuation">[</span>RandomResizedCrop<span class="token punctuation">(</span>feature_extractor<span class="token punctuation">.</span>size<span class="token punctuation">)</span><span class="token punctuation">,</span> ColorJitter<span class="token punctuation">(</span>brightness<span class="token operator">=</span><span class="token number">0.5</span><span class="token punctuation">,</span> hue<span class="token operator">=</span><span class="token number">0.5</span><span class="token punctuation">)</span><span class="token punctuation">,</span> ToTensor<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> normalize<span class="token punctuation">]</span>
<span class="token punctuation">)</span>

<span class="token keyword">def</span> <span class="token function">transforms</span><span class="token punctuation">(</span>examples<span class="token punctuation">)</span><span class="token punctuation">:</span>
    examples<span class="token punctuation">[</span><span class="token string">"pixel_values"</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token punctuation">[</span>_transforms<span class="token punctuation">(</span>image<span class="token punctuation">.</span>convert<span class="token punctuation">(</span><span class="token string">"RGB"</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token keyword">for</span> image <span class="token keyword">in</span> examples<span class="token punctuation">[</span><span class="token string">"image"</span><span class="token punctuation">]</span><span class="token punctuation">]</span>
    <span class="token keyword">return</span> examples

dataset<span class="token punctuation">.</span>set_transform<span class="token punctuation">(</span>transforms<span class="token punctuation">)</span>

dataset<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">"image"</span><span class="token punctuation">]</span>

<span class="token punctuation">{</span><span class="token string">'image'</span><span class="token punctuation">:</span> <span class="token operator">&lt;</span>PIL<span class="token punctuation">.</span>JpegImagePlugin<span class="token punctuation">.</span>JpegImageFile image mode<span class="token operator">=</span>RGB size<span class="token operator">=</span>384x512 at <span class="token number">0x7F1A7B0630D0</span><span class="token operator">></span><span class="token punctuation">,</span>
 <span class="token string">'label'</span><span class="token punctuation">:</span> <span class="token number">6</span><span class="token punctuation">,</span>
 <span class="token string">'pixel_values'</span><span class="token punctuation">:</span> tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token punctuation">[</span> <span class="token number">0.0353</span><span class="token punctuation">,</span>  <span class="token number">0.0745</span><span class="token punctuation">,</span>  <span class="token number">0.1216</span><span class="token punctuation">,</span>  <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.9922</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.9922</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.9922</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
          <span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">0.0196</span><span class="token punctuation">,</span>  <span class="token number">0.0667</span><span class="token punctuation">,</span>  <span class="token number">0.1294</span><span class="token punctuation">,</span>  <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.9765</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.9843</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.9922</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
          <span class="token punctuation">[</span> <span class="token number">0.0196</span><span class="token punctuation">,</span>  <span class="token number">0.0824</span><span class="token punctuation">,</span>  <span class="token number">0.1137</span><span class="token punctuation">,</span>  <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.9765</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.9686</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.8667</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
          <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">,</span>
          <span class="token punctuation">[</span> <span class="token number">0.0275</span><span class="token punctuation">,</span>  <span class="token number">0.0745</span><span class="token punctuation">,</span>  <span class="token number">0.0510</span><span class="token punctuation">,</span>  <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.1137</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.1216</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.0824</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
          <span class="token punctuation">[</span> <span class="token number">0.0667</span><span class="token punctuation">,</span>  <span class="token number">0.0824</span><span class="token punctuation">,</span>  <span class="token number">0.0667</span><span class="token punctuation">,</span>  <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.0588</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.0745</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.0980</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
          <span class="token punctuation">[</span> <span class="token number">0.0353</span><span class="token punctuation">,</span>  <span class="token number">0.0353</span><span class="token punctuation">,</span>  <span class="token number">0.0431</span><span class="token punctuation">,</span>  <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.0039</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.0039</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.0588</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span>

         <span class="token punctuation">[</span><span class="token punctuation">[</span> <span class="token number">0.2078</span><span class="token punctuation">,</span>  <span class="token number">0.2471</span><span class="token punctuation">,</span>  <span class="token number">0.2863</span><span class="token punctuation">,</span>  <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.9451</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.9373</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.9451</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
          <span class="token punctuation">[</span> <span class="token number">0.1608</span><span class="token punctuation">,</span>  <span class="token number">0.2471</span><span class="token punctuation">,</span>  <span class="token number">0.3098</span><span class="token punctuation">,</span>  <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.9373</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.9451</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.9373</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
          <span class="token punctuation">[</span> <span class="token number">0.2078</span><span class="token punctuation">,</span>  <span class="token number">0.2706</span><span class="token punctuation">,</span>  <span class="token number">0.3020</span><span class="token punctuation">,</span>  <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.9608</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.9373</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.8275</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
          <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">,</span>
          <span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">0.0353</span><span class="token punctuation">,</span>  <span class="token number">0.0118</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.0039</span><span class="token punctuation">,</span>  <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.2392</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.2471</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.2078</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
          <span class="token punctuation">[</span> <span class="token number">0.0196</span><span class="token punctuation">,</span>  <span class="token number">0.0353</span><span class="token punctuation">,</span>  <span class="token number">0.0196</span><span class="token punctuation">,</span>  <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.1843</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.2000</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.2235</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
          <span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">0.0118</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.0039</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.0039</span><span class="token punctuation">,</span>  <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.0980</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.0980</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.1529</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span>

         <span class="token punctuation">[</span><span class="token punctuation">[</span> <span class="token number">0.3961</span><span class="token punctuation">,</span>  <span class="token number">0.4431</span><span class="token punctuation">,</span>  <span class="token number">0.4980</span><span class="token punctuation">,</span>  <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.9216</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.9137</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.9216</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
          <span class="token punctuation">[</span> <span class="token number">0.3569</span><span class="token punctuation">,</span>  <span class="token number">0.4510</span><span class="token punctuation">,</span>  <span class="token number">0.5216</span><span class="token punctuation">,</span>  <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.9059</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.9137</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.9137</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
          <span class="token punctuation">[</span> <span class="token number">0.4118</span><span class="token punctuation">,</span>  <span class="token number">0.4745</span><span class="token punctuation">,</span>  <span class="token number">0.5216</span><span class="token punctuation">,</span>  <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.9137</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.8902</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.7804</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
          <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">,</span>
          <span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">0.2314</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.1922</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.2078</span><span class="token punctuation">,</span>  <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.4196</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.4275</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.3882</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
          <span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">0.1843</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.1686</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.2000</span><span class="token punctuation">,</span>  <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.3647</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.3804</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.4039</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
          <span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">0.1922</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.1922</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.1922</span><span class="token punctuation">,</span>  <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.2941</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.2863</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.3412</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<h3 id="Multimodal"><a href="#Multimodal" class="headerlink" title="Multimodal"></a>Multimodal</h3><p>ç”¨äºå¤šæ¨¡å¼ä»»åŠ¡ã€‚æ‚¨å°†ç»“åˆè¿„ä»Šä¸ºæ­¢æ‰€å­¦çš„æ‰€æœ‰çŸ¥è¯†ï¼Œå¹¶å°†æ‚¨çš„æŠ€èƒ½åº”ç”¨äºè‡ªåŠ¨è¯­éŸ³è¯†åˆ« (ASR) ä»»åŠ¡ã€‚è¿™æ„å‘³ç€æ‚¨å°†éœ€è¦ï¼š</p>
<ul>
<li>ç”¨äºé¢„å¤„ç†éŸ³é¢‘æ•°æ®çš„ç‰¹å¾æå–å™¨ã€‚</li>
<li>ç”¨äºå¤„ç†æ–‡æœ¬çš„æ ‡è®°å™¨ã€‚</li>
</ul>
<pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">from</span> datasets <span class="token keyword">import</span> load_dataset

lj_speech <span class="token operator">=</span> load_dataset<span class="token punctuation">(</span><span class="token string">"lj_speech"</span><span class="token punctuation">,</span> split<span class="token operator">=</span><span class="token string">"train"</span><span class="token punctuation">)</span>

lj_speech <span class="token operator">=</span> lj_speech<span class="token punctuation">.</span>map<span class="token punctuation">(</span>remove_columns<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">"file"</span><span class="token punctuation">,</span> <span class="token string">"id"</span><span class="token punctuation">,</span> <span class="token string">"normalized_text"</span><span class="token punctuation">]</span><span class="token punctuation">)</span>

lj_speech<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">"audio"</span><span class="token punctuation">]</span>

lj_speech<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">"text"</span><span class="token punctuation">]</span>

lj_speech <span class="token operator">=</span> lj_speech<span class="token punctuation">.</span>cast_column<span class="token punctuation">(</span><span class="token string">"audio"</span><span class="token punctuation">,</span> Audio<span class="token punctuation">(</span>sampling_rate<span class="token operator">=</span>16_000<span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<h3 id="Processor"><a href="#Processor" class="headerlink" title="Processor"></a>Processor</h3><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">from</span> transformers <span class="token keyword">import</span> AutoProcessor

processor <span class="token operator">=</span> AutoProcessor<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span><span class="token string">"facebook/wav2vec2-base-960h"</span><span class="token punctuation">)</span>

<span class="token keyword">def</span> <span class="token function">prepare_dataset</span><span class="token punctuation">(</span>example<span class="token punctuation">)</span><span class="token punctuation">:</span>
    audio <span class="token operator">=</span> example<span class="token punctuation">[</span><span class="token string">"audio"</span><span class="token punctuation">]</span>

    example<span class="token punctuation">[</span><span class="token string">"input_values"</span><span class="token punctuation">]</span> <span class="token operator">=</span> processor<span class="token punctuation">(</span>audio<span class="token punctuation">[</span><span class="token string">"array"</span><span class="token punctuation">]</span><span class="token punctuation">,</span> sampling_rate<span class="token operator">=</span><span class="token number">16000</span><span class="token punctuation">)</span>

    <span class="token keyword">with</span> processor<span class="token punctuation">.</span>as_target_processor<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        example<span class="token punctuation">[</span><span class="token string">"labels"</span><span class="token punctuation">]</span> <span class="token operator">=</span> processor<span class="token punctuation">(</span>example<span class="token punctuation">[</span><span class="token string">"text"</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">.</span>input_ids
    <span class="token keyword">return</span> example

prepare_dataset<span class="token punctuation">(</span>lj_speech<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<h2 id="Fine-tune-a-pretrained-modelã€å¾®è°ƒã€‘"><a href="#Fine-tune-a-pretrained-modelã€å¾®è°ƒã€‘" class="headerlink" title="Fine-tune a pretrained modelã€å¾®è°ƒã€‘"></a>Fine-tune a pretrained modelã€å¾®è°ƒã€‘</h2><p>ä½¿ç”¨é¢„è®­ç»ƒæ¨¡å‹æœ‰å¾ˆå¤šå¥½å¤„ã€‚å®ƒé™ä½äº†è®¡ç®—æˆæœ¬å’Œç¢³è¶³è¿¹ï¼Œå¹¶å…è®¸æ‚¨ä½¿ç”¨æœ€å…ˆè¿›çš„æ¨¡å‹ï¼Œè€Œæ— éœ€ä»å¤´å¼€å§‹è®­ç»ƒã€‚ğŸ¤— Transformers ä¸ºå„ç§ä»»åŠ¡æä¾›äº†å¯¹æ•°åƒä¸ªé¢„è®­ç»ƒæ¨¡å‹çš„è®¿é—®ã€‚å½“æ‚¨ä½¿ç”¨é¢„è®­ç»ƒæ¨¡å‹æ—¶ï¼Œæ‚¨å¯ä»¥åœ¨ç‰¹å®šäºæ‚¨çš„ä»»åŠ¡çš„æ•°æ®é›†ä¸Šå¯¹å…¶è¿›è¡Œè®­ç»ƒã€‚è¿™è¢«ç§°ä¸ºå¾®è°ƒï¼Œä¸€ç§éå¸¸å¼ºå¤§çš„è®­ç»ƒæŠ€æœ¯ã€‚</p>
<p>åœ¨å¾®è°ƒé¢„è®­ç»ƒæ¨¡å‹ä¹‹å‰ï¼Œè¯·ä¸‹è½½æ•°æ®é›†å¹¶ä¸ºè®­ç»ƒåšå¥½å‡†å¤‡</p>
<pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">from</span> datasets <span class="token keyword">import</span> load_dataset

dataset <span class="token operator">=</span> load_dataset<span class="token punctuation">(</span><span class="token string">"yelp_review_full"</span><span class="token punctuation">)</span>
dataset<span class="token punctuation">[</span><span class="token string">"train"</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">100</span><span class="token punctuation">]</span>

<span class="token punctuation">{</span><span class="token string">'label'</span><span class="token punctuation">:</span> <span class="token number">0</span><span class="token punctuation">,</span>
 <span class="token string">'text'</span><span class="token punctuation">:</span> <span class="token string">'My expectations for McDonalds are t rarely high. But for one to still fail so spectacularly...that takes something special!\\\\nThe cashier took my friends\\'</span>s order<span class="token punctuation">,</span> then promptly ignored me<span class="token punctuation">.</span> I had to force myself <span class="token keyword">in</span> front of a cashier who opened his register to wait on the person BEHIND me<span class="token punctuation">.</span> I waited over five minutes <span class="token keyword">for</span> a gigantic order that included precisely one kid\\<span class="token string">'s meal. After watching two people who ordered after me be handed their food, I asked where mine was. The manager started yelling at the cashiers for \\\\"serving off their orders\\\\" when they didn\\'</span>t have their food<span class="token punctuation">.</span> But neither cashier was anywhere near those controls<span class="token punctuation">,</span> <span class="token operator">and</span> the manager was the one serving food to customers <span class="token operator">and</span> clearing the boards<span class="token punctuation">.</span>\\\\nThe manager was rude when giving me my order<span class="token punctuation">.</span> She didn\\<span class="token string">'t make sure that I had everything ON MY RECEIPT, and never even had the decency to apologize that I felt I was getting poor service.\\\\nI\\'</span>ve eaten at various McDonalds restaurants <span class="token keyword">for</span> over <span class="token number">30</span> years<span class="token punctuation">.</span> I\\<span class="token string">'ve worked at more than one location. I expect bad days, bad moods, and the occasional mistake. But I have yet to have a decent experience at this store. It will remain a place I avoid unless someone in my party needs to avoid illness from low blood sugar. Perhaps I should go back to the racially biased service of Steak n Shake instead!'</span><span class="token punctuation">}</span>

<span class="token keyword">from</span> transformers <span class="token keyword">import</span> AutoTokenizer

tokenizer <span class="token operator">=</span> AutoTokenizer<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span><span class="token string">"bert-base-cased"</span><span class="token punctuation">)</span>

<span class="token keyword">def</span> <span class="token function">tokenize_function</span><span class="token punctuation">(</span>examples<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">return</span> tokenizer<span class="token punctuation">(</span>examples<span class="token punctuation">[</span><span class="token string">"text"</span><span class="token punctuation">]</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token string">"max_length"</span><span class="token punctuation">,</span> truncation<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>

tokenized_datasets <span class="token operator">=</span> dataset<span class="token punctuation">.</span>map<span class="token punctuation">(</span>tokenize_function<span class="token punctuation">,</span> batched<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>

small_train_dataset <span class="token operator">=</span> tokenized_datasets<span class="token punctuation">[</span><span class="token string">"train"</span><span class="token punctuation">]</span><span class="token punctuation">.</span>shuffle<span class="token punctuation">(</span>seed<span class="token operator">=</span><span class="token number">42</span><span class="token punctuation">)</span><span class="token punctuation">.</span>select<span class="token punctuation">(</span>range<span class="token punctuation">(</span><span class="token number">1000</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
small_eval_dataset <span class="token operator">=</span> tokenized_datasets<span class="token punctuation">[</span><span class="token string">"test"</span><span class="token punctuation">]</span><span class="token punctuation">.</span>shuffle<span class="token punctuation">(</span>seed<span class="token operator">=</span><span class="token number">42</span><span class="token punctuation">)</span><span class="token punctuation">.</span>select<span class="token punctuation">(</span>range<span class="token punctuation">(</span><span class="token number">1000</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<h3 id="Train"><a href="#Train" class="headerlink" title="Train"></a>Train</h3><p>Transformers æä¾›äº†ä¸€ä¸ªé’ˆå¯¹è®­ç»ƒä¼˜åŒ–çš„<strong><a href="https://huggingface.co/docs/transformers/v4.18.0/en/main_classes/trainer#transformers.Trainer" target="_blank" rel="noopener">Trainer</a></strong>ç±» ğŸ¤— Transformers æ¨¡å‹ï¼Œæ— éœ€æ‰‹åŠ¨ç¼–å†™è‡ªå·±çš„è®­ç»ƒå¾ªç¯å³å¯æ›´è½»æ¾åœ°å¼€å§‹è®­ç»ƒã€‚<strong><a href="https://huggingface.co/docs/transformers/v4.18.0/en/main_classes/trainer#transformers.Trainer" target="_blank" rel="noopener">Trainer</a></strong> API æ”¯æŒå¹¿æ³›çš„è®­ç»ƒé€‰é¡¹å’ŒåŠŸèƒ½ï¼Œä¾‹å¦‚æ—¥å¿—è®°å½•ã€æ¢¯åº¦ç´¯ç§¯å’Œæ··åˆç²¾åº¦ã€‚</p>
<pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">from</span> transformers <span class="token keyword">import</span> AutoModelForSequenceClassification

model <span class="token operator">=</span> AutoModelForSequenceClassification<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span><span class="token string">"bert-base-cased"</span><span class="token punctuation">,</span> num_labels<span class="token operator">=</span><span class="token number">5</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre>
<p>Training hyperparameters</p>
<p>æ¥ä¸‹æ¥ï¼Œåˆ›å»ºä¸€ä¸ª<strong><a href="https://huggingface.co/docs/transformers/v4.18.0/en/main_classes/trainer#transformers.TrainingArguments" target="_blank" rel="noopener">TrainingArguments</a></strong>ç±»ï¼Œå…¶ä¸­åŒ…å«æ‚¨å¯ä»¥è°ƒæ•´çš„æ‰€æœ‰è¶…å‚æ•°ä»¥åŠç”¨äºæ¿€æ´»ä¸åŒè®­ç»ƒé€‰é¡¹çš„æ ‡å¿—ã€‚æ‚¨å¯ä»¥ä»é»˜è®¤çš„è®­ç»ƒ<strong><a href="https://huggingface.co/docs/transformers/main_classes/trainer#transformers.TrainingArguments" target="_blank" rel="noopener">è¶…å‚æ•°</a></strong>å¼€å§‹ï¼Œä½†å¯ä»¥éšæ„å°è¯•è¿™äº›å‚æ•°ä»¥æ‰¾åˆ°æ‚¨çš„æœ€ä½³è®¾ç½®ã€‚</p>
<pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">from</span> transformers <span class="token keyword">import</span> TrainingArguments

training_args <span class="token operator">=</span> TrainingArguments<span class="token punctuation">(</span>output_dir<span class="token operator">=</span><span class="token string">"test_trainer"</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre>
<p>Metrics</p>
<p><strong><a href="https://huggingface.co/docs/transformers/v4.18.0/en/main_classes/trainer#transformers.Trainer" target="_blank" rel="noopener">Trainer</a>\</strong>åœ¨è®­ç»ƒæœŸé—´ä¸ä¼šè‡ªåŠ¨è¯„ä¼°æ¨¡å‹æ€§èƒ½ã€‚æ‚¨éœ€è¦å‘**<a href="https://huggingface.co/docs/transformers/v4.18.0/en/main_classes/trainer#transformers.Trainer" target="_blank" rel="noopener">Trainer</a>*<em>ä¼ é€’ä¸€ä¸ªå‡½æ•°æ¥è®¡ç®—å’ŒæŠ¥å‘ŠæŒ‡æ ‡ã€‚ğŸ¤— æ•°æ®é›†åº“æä¾›äº†ä¸€ä¸ªç®€å•çš„å‡½æ•°ï¼Œæ‚¨å¯ä»¥ä½¿ç”¨ï¼ˆæœ‰å…³æ›´å¤šä¿¡æ¯ï¼Œè¯·å‚é˜…æœ¬*</em><a href="https://huggingface.co/docs/datasets/metrics.html" target="_blank" rel="noopener">æ•™ç¨‹</a><code>[accuracy](&lt;https://huggingface.co/metrics/accuracy&gt;)</code>**ï¼‰å‡½æ•°åŠ è½½ï¼š<code>load_metric</code></p>
<pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">import</span> numpy <span class="token keyword">as</span> np
<span class="token keyword">from</span> datasets <span class="token keyword">import</span> load_metric

metric <span class="token operator">=</span> load_metric<span class="token punctuation">(</span><span class="token string">"accuracy"</span><span class="token punctuation">)</span>

<span class="token keyword">from</span> transformers <span class="token keyword">import</span> TrainingArguments<span class="token punctuation">,</span> Trainer

training_args <span class="token operator">=</span> TrainingArguments<span class="token punctuation">(</span>output_dir<span class="token operator">=</span><span class="token string">"test_trainer"</span><span class="token punctuation">,</span> evaluation_strategy<span class="token operator">=</span><span class="token string">"epoch"</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>Trainer</p>
<p>ä½¿ç”¨æ‚¨çš„æ¨¡å‹ã€è®­ç»ƒå‚æ•°ã€è®­ç»ƒå’Œæµ‹è¯•æ•°æ®é›†ä»¥åŠè¯„ä¼°å‡½æ•°åˆ›å»ºä¸€ä¸ª<strong><a href="https://huggingface.co/docs/transformers/v4.18.0/en/main_classes/trainer#transformers.Trainer" target="_blank" rel="noopener">Trainerå¯¹è±¡ï¼š</a></strong></p>
<pre class="line-numbers language-python"><code class="language-python">trainer <span class="token operator">=</span> Trainer<span class="token punctuation">(</span>
    model<span class="token operator">=</span>model<span class="token punctuation">,</span>
    args<span class="token operator">=</span>training_args<span class="token punctuation">,</span>
    train_dataset<span class="token operator">=</span>small_train_dataset<span class="token punctuation">,</span>
    eval_dataset<span class="token operator">=</span>small_eval_dataset<span class="token punctuation">,</span>
    compute_metrics<span class="token operator">=</span>compute_metrics<span class="token punctuation">,</span>
<span class="token punctuation">)</span>

trainer<span class="token punctuation">.</span>train<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<h3 id="Train-in-native-PyTorch"><a href="#Train-in-native-PyTorch" class="headerlink" title="Train in native PyTorch"></a>Train in native PyTorch</h3><p><strong><a href="https://huggingface.co/docs/transformers/v4.18.0/en/main_classes/trainer#transformers.Trainer" target="_blank" rel="noopener">Trainer</a></strong>è´Ÿè´£è®­ç»ƒå¾ªç¯ï¼Œå¹¶å…è®¸æ‚¨åœ¨ä¸€è¡Œä»£ç ä¸­å¾®è°ƒæ¨¡å‹ã€‚å¯¹äºå–œæ¬¢ç¼–å†™è‡ªå·±çš„è®­ç»ƒå¾ªç¯çš„ç”¨æˆ·ï¼Œæ‚¨è¿˜å¯ä»¥åœ¨åŸç”Ÿ PyTorch ä¸­å¾®è°ƒğŸ¤— Transformers æ¨¡å‹ã€‚</p>
<pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">del</span> model
<span class="token keyword">del</span> pytorch_model
<span class="token keyword">del</span> trainer
torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>empty_cache<span class="token punctuation">(</span><span class="token punctuation">)</span>

tokenized_datasets <span class="token operator">=</span> tokenized_datasets<span class="token punctuation">.</span>remove_columns<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token string">"text"</span><span class="token punctuation">]</span><span class="token punctuation">)</span>

tokenized_datasets <span class="token operator">=</span> tokenized_datasets<span class="token punctuation">.</span>rename_column<span class="token punctuation">(</span><span class="token string">"label"</span><span class="token punctuation">,</span> <span class="token string">"labels"</span><span class="token punctuation">)</span>

tokenized_datasets<span class="token punctuation">.</span>set_format<span class="token punctuation">(</span><span class="token string">"torch"</span><span class="token punctuation">)</span>

small_train_dataset <span class="token operator">=</span> tokenized_datasets<span class="token punctuation">[</span><span class="token string">"train"</span><span class="token punctuation">]</span><span class="token punctuation">.</span>shuffle<span class="token punctuation">(</span>seed<span class="token operator">=</span><span class="token number">42</span><span class="token punctuation">)</span><span class="token punctuation">.</span>select<span class="token punctuation">(</span>range<span class="token punctuation">(</span><span class="token number">1000</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
small_eval_dataset <span class="token operator">=</span> tokenized_datasets<span class="token punctuation">[</span><span class="token string">"test"</span><span class="token punctuation">]</span><span class="token punctuation">.</span>shuffle<span class="token punctuation">(</span>seed<span class="token operator">=</span><span class="token number">42</span><span class="token punctuation">)</span><span class="token punctuation">.</span>select<span class="token punctuation">(</span>range<span class="token punctuation">(</span><span class="token number">1000</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>DataLoader</p>
<pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">from</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data <span class="token keyword">import</span> DataLoader

train_dataloader <span class="token operator">=</span> DataLoader<span class="token punctuation">(</span>small_train_dataset<span class="token punctuation">,</span> shuffle<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> batch_size<span class="token operator">=</span><span class="token number">8</span><span class="token punctuation">)</span>
eval_dataloader <span class="token operator">=</span> DataLoader<span class="token punctuation">(</span>small_eval_dataset<span class="token punctuation">,</span> batch_size<span class="token operator">=</span><span class="token number">8</span><span class="token punctuation">)</span>

<span class="token keyword">from</span> transformers <span class="token keyword">import</span> AutoModelForSequenceClassification

model <span class="token operator">=</span> AutoModelForSequenceClassification<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span><span class="token string">"bert-base-cased"</span><span class="token punctuation">,</span> num_labels<span class="token operator">=</span><span class="token number">5</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>Optimizer and learning rate scheduler</p>
<pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">from</span> torch<span class="token punctuation">.</span>optim <span class="token keyword">import</span> AdamW

optimizer <span class="token operator">=</span> AdamW<span class="token punctuation">(</span>model<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> lr<span class="token operator">=</span><span class="token number">5e</span><span class="token operator">-</span><span class="token number">5</span><span class="token punctuation">)</span>

<span class="token keyword">from</span> transformers <span class="token keyword">import</span> get_scheduler

num_epochs <span class="token operator">=</span> <span class="token number">3</span>
num_training_steps <span class="token operator">=</span> num_epochs <span class="token operator">*</span> len<span class="token punctuation">(</span>train_dataloader<span class="token punctuation">)</span>
lr_scheduler <span class="token operator">=</span> get_scheduler<span class="token punctuation">(</span>
    name<span class="token operator">=</span><span class="token string">"linear"</span><span class="token punctuation">,</span> optimizer<span class="token operator">=</span>optimizer<span class="token punctuation">,</span> num_warmup_steps<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">,</span> num_training_steps<span class="token operator">=</span>num_training_steps
<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>Training loop</p>
<pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">from</span> tqdm<span class="token punctuation">.</span>auto <span class="token keyword">import</span> tqdm

progress_bar <span class="token operator">=</span> tqdm<span class="token punctuation">(</span>range<span class="token punctuation">(</span>num_training_steps<span class="token punctuation">)</span><span class="token punctuation">)</span>

model<span class="token punctuation">.</span>train<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token keyword">for</span> epoch <span class="token keyword">in</span> range<span class="token punctuation">(</span>num_epochs<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">for</span> batch <span class="token keyword">in</span> train_dataloader<span class="token punctuation">:</span>
        batch <span class="token operator">=</span> <span class="token punctuation">{</span>k<span class="token punctuation">:</span> v<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span> <span class="token keyword">for</span> k<span class="token punctuation">,</span> v <span class="token keyword">in</span> batch<span class="token punctuation">.</span>items<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">}</span>
        outputs <span class="token operator">=</span> model<span class="token punctuation">(</span><span class="token operator">**</span>batch<span class="token punctuation">)</span>
        loss <span class="token operator">=</span> outputs<span class="token punctuation">.</span>loss
        loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>

        optimizer<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>
        lr_scheduler<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>
        optimizer<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>
        progress_bar<span class="token punctuation">.</span>update<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>Metrics</p>
<pre class="line-numbers language-python"><code class="language-python">metric <span class="token operator">=</span> load_metric<span class="token punctuation">(</span><span class="token string">"accuracy"</span><span class="token punctuation">)</span>
model<span class="token punctuation">.</span>eval<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token keyword">for</span> batch <span class="token keyword">in</span> eval_dataloader<span class="token punctuation">:</span>
    batch <span class="token operator">=</span> <span class="token punctuation">{</span>k<span class="token punctuation">:</span> v<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span> <span class="token keyword">for</span> k<span class="token punctuation">,</span> v <span class="token keyword">in</span> batch<span class="token punctuation">.</span>items<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">}</span>
    <span class="token keyword">with</span> torch<span class="token punctuation">.</span>no_grad<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        outputs <span class="token operator">=</span> model<span class="token punctuation">(</span><span class="token operator">**</span>batch<span class="token punctuation">)</span>

    logits <span class="token operator">=</span> outputs<span class="token punctuation">.</span>logits
    predictions <span class="token operator">=</span> torch<span class="token punctuation">.</span>argmax<span class="token punctuation">(</span>logits<span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>
    metric<span class="token punctuation">.</span>add_batch<span class="token punctuation">(</span>predictions<span class="token operator">=</span>predictions<span class="token punctuation">,</span> references<span class="token operator">=</span>batch<span class="token punctuation">[</span><span class="token string">"labels"</span><span class="token punctuation">]</span><span class="token punctuation">)</span>

metric<span class="token punctuation">.</span>compute<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<h2 id="Distributed-training-with-ğŸ¤—-Accelerate"><a href="#Distributed-training-with-ğŸ¤—-Accelerate" class="headerlink" title="Distributed training with ğŸ¤— Accelerate"></a>Distributed training with ğŸ¤— Accelerate</h2><p>éšç€æ¨¡å‹å˜å¾—è¶Šæ¥è¶Šå¤§ï¼Œå¹¶è¡Œæ€§å·²ç»æˆä¸ºä¸€ç§ç­–ç•¥ï¼Œå¯ä»¥åœ¨æœ‰é™çš„ç¡¬ä»¶ä¸Šè®­ç»ƒæ›´å¤§çš„æ¨¡å‹ï¼Œå¹¶å°†è®­ç»ƒé€Ÿåº¦æé«˜å‡ ä¸ªæ•°é‡çº§ã€‚åœ¨ Hugging Faceï¼Œæˆ‘ä»¬åˆ›å»ºäº†<strong><a href="https://huggingface.co/docs/accelerate/index.html" target="_blank" rel="noopener">ğŸ¤— Accelerate</a></strong>åº“ï¼Œä»¥å¸®åŠ©ç”¨æˆ·è½»æ¾åœ°åœ¨ä»»ä½•ç±»å‹çš„åˆ†å¸ƒå¼è®¾ç½®ä¸Šè®­ç»ƒ ğŸ¤— Transformers æ¨¡å‹ï¼Œæ— è®ºæ˜¯ä¸€å°æœºå™¨ä¸Šçš„å¤šä¸ª GPU è¿˜æ˜¯å¤šå°æœºå™¨ä¸Šçš„å¤šä¸ª GPUã€‚</p>
<h3 id="Setup"><a href="#Setup" class="headerlink" title="Setup"></a><strong>Setup</strong></h3><p>Get started by installing ğŸ¤— Accelerate:</p>
<pre><code>pip install accelerate</code></pre><p>Then import and create an <strong><code>[Accelerator](&lt;https://huggingface.co/docs/accelerate/accelerator.html#accelerate.Accelerator&gt;)</code></strong> object. <code>Accelerator</code> will automatically detect your type of distributed setup and initialize all the necessary components for training. You donâ€™t need to explicitly place your model on a device.</p>
<pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">from</span> accelerate <span class="token keyword">import</span> Accelerator

accelerator <span class="token operator">=</span> Accelerator<span class="token punctuation">(</span><span class="token punctuation">)</span>

train_dataloader<span class="token punctuation">,</span> eval_dataloader<span class="token punctuation">,</span> model<span class="token punctuation">,</span> optimizer <span class="token operator">=</span> accelerator<span class="token punctuation">.</span>prepare<span class="token punctuation">(</span>
    train_dataloader<span class="token punctuation">,</span> eval_dataloader<span class="token punctuation">,</span> model<span class="token punctuation">,</span> optimizer
<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<h3 id="Backward"><a href="#Backward" class="headerlink" title="Backward"></a>Backward</h3><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">for</span> epoch <span class="token keyword">in</span> range<span class="token punctuation">(</span>num_epochs<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">for</span> batch <span class="token keyword">in</span> train_dataloader<span class="token punctuation">:</span>
        outputs <span class="token operator">=</span> model<span class="token punctuation">(</span><span class="token operator">**</span>batch<span class="token punctuation">)</span>
        loss <span class="token operator">=</span> outputs<span class="token punctuation">.</span>loss
        accelerator<span class="token punctuation">.</span>backward<span class="token punctuation">(</span>loss<span class="token punctuation">)</span>

        optimizer<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>
        lr_scheduler<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>
        optimizer<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>
        progress_bar<span class="token punctuation">.</span>update<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>As you can see in the following code, you only need to add four additional lines of code to your training loop to enable distributed training!</p>
<pre class="line-numbers language-python"><code class="language-python"><span class="token operator">+</span> <span class="token keyword">from</span> accelerate <span class="token keyword">import</span> Accelerator
  <span class="token keyword">from</span> transformers <span class="token keyword">import</span> AdamW<span class="token punctuation">,</span> AutoModelForSequenceClassification<span class="token punctuation">,</span> get_scheduler

<span class="token operator">+</span> accelerator <span class="token operator">=</span> Accelerator<span class="token punctuation">(</span><span class="token punctuation">)</span>

  model <span class="token operator">=</span> AutoModelForSequenceClassification<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span>checkpoint<span class="token punctuation">,</span> num_labels<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span>
  optimizer <span class="token operator">=</span> AdamW<span class="token punctuation">(</span>model<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> lr<span class="token operator">=</span><span class="token number">3e</span><span class="token operator">-</span><span class="token number">5</span><span class="token punctuation">)</span>

<span class="token operator">-</span> device <span class="token operator">=</span> torch<span class="token punctuation">.</span>device<span class="token punctuation">(</span><span class="token string">"cuda"</span><span class="token punctuation">)</span> <span class="token keyword">if</span> torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>is_available<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">else</span> torch<span class="token punctuation">.</span>device<span class="token punctuation">(</span><span class="token string">"cpu"</span><span class="token punctuation">)</span>
<span class="token operator">-</span> model<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>

<span class="token operator">+</span> train_dataloader<span class="token punctuation">,</span> eval_dataloader<span class="token punctuation">,</span> model<span class="token punctuation">,</span> optimizer <span class="token operator">=</span> accelerator<span class="token punctuation">.</span>prepare<span class="token punctuation">(</span>
<span class="token operator">+</span>     train_dataloader<span class="token punctuation">,</span> eval_dataloader<span class="token punctuation">,</span> model<span class="token punctuation">,</span> optimizer
<span class="token operator">+</span> <span class="token punctuation">)</span>

  num_epochs <span class="token operator">=</span> <span class="token number">3</span>
  num_training_steps <span class="token operator">=</span> num_epochs <span class="token operator">*</span> len<span class="token punctuation">(</span>train_dataloader<span class="token punctuation">)</span>
  lr_scheduler <span class="token operator">=</span> get_scheduler<span class="token punctuation">(</span>
      <span class="token string">"linear"</span><span class="token punctuation">,</span>
      optimizer<span class="token operator">=</span>optimizer<span class="token punctuation">,</span>
      num_warmup_steps<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">,</span>
      num_training_steps<span class="token operator">=</span>num_training_steps
  <span class="token punctuation">)</span>

  progress_bar <span class="token operator">=</span> tqdm<span class="token punctuation">(</span>range<span class="token punctuation">(</span>num_training_steps<span class="token punctuation">)</span><span class="token punctuation">)</span>

  model<span class="token punctuation">.</span>train<span class="token punctuation">(</span><span class="token punctuation">)</span>
  <span class="token keyword">for</span> epoch <span class="token keyword">in</span> range<span class="token punctuation">(</span>num_epochs<span class="token punctuation">)</span><span class="token punctuation">:</span>
      <span class="token keyword">for</span> batch <span class="token keyword">in</span> train_dataloader<span class="token punctuation">:</span>
<span class="token operator">-</span>         batch <span class="token operator">=</span> <span class="token punctuation">{</span>k<span class="token punctuation">:</span> v<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span> <span class="token keyword">for</span> k<span class="token punctuation">,</span> v <span class="token keyword">in</span> batch<span class="token punctuation">.</span>items<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">}</span>
          outputs <span class="token operator">=</span> model<span class="token punctuation">(</span><span class="token operator">**</span>batch<span class="token punctuation">)</span>
          loss <span class="token operator">=</span> outputs<span class="token punctuation">.</span>loss
<span class="token operator">-</span>         loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token operator">+</span>         accelerator<span class="token punctuation">.</span>backward<span class="token punctuation">(</span>loss<span class="token punctuation">)</span>

          optimizer<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>
          lr_scheduler<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>
          optimizer<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>
          progress_bar<span class="token punctuation">.</span>update<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<h3 id="Train-1"><a href="#Train-1" class="headerlink" title="Train"></a>Train</h3><pre class="line-numbers language-python"><code class="language-python">accelerate config

accelerate launch train<span class="token punctuation">.</span>py

<span class="token keyword">from</span> accelerate <span class="token keyword">import</span> notebook_launcher

notebook_launcher<span class="token punctuation">(</span>training_function<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<h2 id="Support-Models"><a href="#Support-Models" class="headerlink" title="Support Models"></a>Support Models</h2><h3 id="Supported-models"><a href="#Supported-models" class="headerlink" title="Supported models"></a><strong>Supported models</strong></h3><ol>
<li><strong><a href="https://huggingface.co/docs/transformers/model_doc/albert" target="_blank" rel="noopener">ALBERT</a></strong> (from Google Research and the Toyota Technological Institute at Chicago) released with the paper <strong><a href="https://arxiv.org/abs/1909.11942" target="_blank" rel="noopener">ALBERT: A Lite BERT for Self-supervised Learning of Language Representations</a></strong>, by Zhenzhong Lan, Mingda Chen, Sebastian Goodman, Kevin Gimpel, Piyush Sharma, Radu Soricut.</li>
<li><strong><a href="https://huggingface.co/docs/transformers/model_doc/bart" target="_blank" rel="noopener">BART</a></strong> (from Facebook) released with the paper <strong><a href="https://arxiv.org/abs/1910.13461" target="_blank" rel="noopener">BART: Denoising Sequence-to-Sequence Pre-training for Natural Language Generation, Translation, and Comprehension</a></strong> by Mike Lewis, Yinhan Liu, Naman Goyal, Marjan Ghazvininejad, Abdelrahman Mohamed, Omer Levy, Ves Stoyanov and Luke Zettlemoyer.</li>
<li><strong><a href="https://huggingface.co/docs/transformers/model_doc/barthez" target="_blank" rel="noopener">BARThez</a></strong> (from Ã‰cole polytechnique) released with the paper <strong><a href="https://arxiv.org/abs/2010.12321" target="_blank" rel="noopener">BARThez: a Skilled Pretrained French Sequence-to-Sequence Model</a></strong> by Moussa Kamal Eddine, Antoine J.-P. Tixier, Michalis Vazirgiannis.</li>
<li><strong><a href="https://huggingface.co/docs/transformers/model_doc/bartpho" target="_blank" rel="noopener">BARTpho</a></strong> (from VinAI Research) released with the paper <strong><a href="https://arxiv.org/abs/2109.09701" target="_blank" rel="noopener">BARTpho: Pre-trained Sequence-to-Sequence Models for Vietnamese</a></strong> by Nguyen Luong Tran, Duong Minh Le and Dat Quoc Nguyen.</li>
<li><strong><a href="https://huggingface.co/docs/transformers/model_doc/beit" target="_blank" rel="noopener">BEiT</a></strong> (from Microsoft) released with the paper <strong><a href="https://arxiv.org/abs/2106.08254" target="_blank" rel="noopener">BEiT: BERT Pre-Training of Image Transformers</a></strong> by Hangbo Bao, Li Dong, Furu Wei.</li>
<li><strong><a href="https://huggingface.co/docs/transformers/model_doc/bert" target="_blank" rel="noopener">BERT</a></strong> (from Google) released with the paper <strong><a href="https://arxiv.org/abs/1810.04805" target="_blank" rel="noopener">BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding</a></strong> by Jacob Devlin, Ming-Wei Chang, Kenton Lee and Kristina Toutanova.</li>
<li><strong><a href="https://huggingface.co/docs/transformers/model_doc/bertweet" target="_blank" rel="noopener">BERTweet</a></strong> (from VinAI Research) released with the paper <strong><a href="https://aclanthology.org/2020.emnlp-demos.2/" target="_blank" rel="noopener">BERTweet: A pre-trained language model for English Tweets</a></strong> by Dat Quoc Nguyen, Thanh Vu and Anh Tuan Nguyen.</li>
<li><strong><a href="https://huggingface.co/docs/transformers/model_doc/bert-generation" target="_blank" rel="noopener">BERT For Sequence Generation</a></strong> (from Google) released with the paper <strong><a href="https://arxiv.org/abs/1907.12461" target="_blank" rel="noopener">Leveraging Pre-trained Checkpoints for Sequence Generation Tasks</a></strong> by Sascha Rothe, Shashi Narayan, Aliaksei Severyn.</li>
<li><strong><a href="https://huggingface.co/docs/transformers/model_doc/big_bird" target="_blank" rel="noopener">BigBird-RoBERTa</a></strong> (from Google Research) released with the paper <strong><a href="https://arxiv.org/abs/2007.14062" target="_blank" rel="noopener">Big Bird: Transformers for Longer Sequences</a></strong> by Manzil Zaheer, Guru Guruganesh, Avinava Dubey, Joshua Ainslie, Chris Alberti, Santiago Ontanon, Philip Pham, Anirudh Ravula, Qifan Wang, Li Yang, Amr Ahmed.</li>
<li><strong><a href="https://huggingface.co/docs/transformers/model_doc/bigbird_pegasus" target="_blank" rel="noopener">BigBird-Pegasus</a></strong> (from Google Research) released with the paper <strong><a href="https://arxiv.org/abs/2007.14062" target="_blank" rel="noopener">Big Bird: Transformers for Longer Sequences</a></strong> by Manzil Zaheer, Guru Guruganesh, Avinava Dubey, Joshua Ainslie, Chris Alberti, Santiago Ontanon, Philip Pham, Anirudh Ravula, Qifan Wang, Li Yang, Amr Ahmed.</li>
<li><strong><a href="https://huggingface.co/docs/transformers/model_doc/blenderbot" target="_blank" rel="noopener">Blenderbot</a></strong> (from Facebook) released with the paper <strong><a href="https://arxiv.org/abs/2004.13637" target="_blank" rel="noopener">Recipes for building an open-domain chatbot</a></strong> by Stephen Roller, Emily Dinan, Naman Goyal, Da Ju, Mary Williamson, Yinhan Liu, Jing Xu, Myle Ott, Kurt Shuster, Eric M. Smith, Y-Lan Boureau, Jason Weston.</li>
<li><strong><a href="https://huggingface.co/docs/transformers/model_doc/blenderbot-small" target="_blank" rel="noopener">BlenderbotSmall</a></strong> (from Facebook) released with the paper <strong><a href="https://arxiv.org/abs/2004.13637" target="_blank" rel="noopener">Recipes for building an open-domain chatbot</a></strong> by Stephen Roller, Emily Dinan, Naman Goyal, Da Ju, Mary Williamson, Yinhan Liu, Jing Xu, Myle Ott, Kurt Shuster, Eric M. Smith, Y-Lan Boureau, Jason Weston.</li>
<li><strong><a href="https://huggingface.co/docs/transformers/model_doc/bort" target="_blank" rel="noopener">BORT</a></strong> (from Alexa) released with the paper <strong><a href="https://arxiv.org/abs/2010.10499" target="_blank" rel="noopener">Optimal Subarchitecture Extraction For BERT</a></strong> by Adrian de Wynter and Daniel J. Perry.</li>
<li><strong><a href="https://huggingface.co/docs/transformers/model_doc/byt5" target="_blank" rel="noopener">ByT5</a></strong> (from Google Research) released with the paper <strong><a href="https://arxiv.org/abs/2105.13626" target="_blank" rel="noopener">ByT5: Towards a token-free future with pre-trained byte-to-byte models</a></strong> by Linting Xue, Aditya Barua, Noah Constant, Rami Al-Rfou, Sharan Narang, Mihir Kale, Adam Roberts, Colin Raffel.</li>
<li><strong><a href="https://huggingface.co/docs/transformers/model_doc/camembert" target="_blank" rel="noopener">CamemBERT</a></strong> (from Inria/Facebook/Sorbonne) released with the paper <strong><a href="https://arxiv.org/abs/1911.03894" target="_blank" rel="noopener">CamemBERT: a Tasty French Language Model</a></strong> by Louis Martin<em>, Benjamin Muller</em>, Pedro Javier Ortiz SuÃ¡rez*, Yoann Dupont, Laurent Romary, Ã‰ric Villemonte de la Clergerie, DjamÃ© Seddah and BenoÃ®t Sagot.</li>
<li><strong><a href="https://huggingface.co/docs/transformers/model_doc/canine" target="_blank" rel="noopener">CANINE</a></strong> (from Google Research) released with the paper <strong><a href="https://arxiv.org/abs/2103.06874" target="_blank" rel="noopener">CANINE: Pre-training an Efficient Tokenization-Free Encoder for Language Representation</a></strong> by Jonathan H. Clark, Dan Garrette, Iulia Turc, John Wieting.</li>
<li><strong><a href="https://huggingface.co/docs/transformers/model_doc/convnext" target="_blank" rel="noopener">ConvNeXT</a></strong> (from Facebook AI) released with the paper <strong><a href="https://arxiv.org/abs/2201.03545" target="_blank" rel="noopener">A ConvNet for the 2020s</a></strong> by Zhuang Liu, Hanzi Mao, Chao-Yuan Wu, Christoph Feichtenhofer, Trevor Darrell, Saining Xie.</li>
<li><strong><a href="https://huggingface.co/docs/transformers/model_doc/clip" target="_blank" rel="noopener">CLIP</a></strong> (from OpenAI) released with the paper <strong><a href="https://arxiv.org/abs/2103.00020" target="_blank" rel="noopener">Learning Transferable Visual Models From Natural Language Supervision</a></strong> by Alec Radford, Jong Wook Kim, Chris Hallacy, Aditya Ramesh, Gabriel Goh, Sandhini Agarwal, Girish Sastry, Amanda Askell, Pamela Mishkin, Jack Clark, Gretchen Krueger, Ilya Sutskever.</li>
<li><strong><a href="https://huggingface.co/docs/transformers/model_doc/convbert" target="_blank" rel="noopener">ConvBERT</a></strong> (from YituTech) released with the paper <strong><a href="https://arxiv.org/abs/2008.02496" target="_blank" rel="noopener">ConvBERT: Improving BERT with Span-based Dynamic Convolution</a></strong> by Zihang Jiang, Weihao Yu, Daquan Zhou, Yunpeng Chen, Jiashi Feng, Shuicheng Yan.</li>
<li><strong><a href="https://huggingface.co/docs/transformers/model_doc/cpm" target="_blank" rel="noopener">CPM</a></strong> (from Tsinghua University) released with the paper <strong><a href="https://arxiv.org/abs/2012.00413" target="_blank" rel="noopener">CPM: A Large-scale Generative Chinese Pre-trained Language Model</a></strong> by Zhengyan Zhang, Xu Han, Hao Zhou, Pei Ke, Yuxian Gu, Deming Ye, Yujia Qin, Yusheng Su, Haozhe Ji, Jian Guan, Fanchao Qi, Xiaozhi Wang, Yanan Zheng, Guoyang Zeng, Huanqi Cao, Shengqi Chen, Daixuan Li, Zhenbo Sun, Zhiyuan Liu, Minlie Huang, Wentao Han, Jie Tang, Juanzi Li, Xiaoyan Zhu, Maosong Sun.</li>
<li><strong><a href="https://huggingface.co/docs/transformers/model_doc/ctrl" target="_blank" rel="noopener">CTRL</a></strong> (from Salesforce) released with the paper <strong><a href="https://arxiv.org/abs/1909.05858" target="_blank" rel="noopener">CTRL: A Conditional Transformer Language Model for Controllable Generation</a></strong> by Nitish Shirish Keskar<em>, Bryan McCann</em>, Lav R. Varshney, Caiming Xiong and Richard Socher.</li>
<li><strong><a href="https://huggingface.co/docs/transformers/model_doc/data2vec" target="_blank" rel="noopener">Data2Vec</a></strong> (from Facebook) released with the paper <strong><a href="https://arxiv.org/abs/2202.03555" target="_blank" rel="noopener">Data2Vec: A General Framework for Self-supervised Learning in Speech, Vision and Language</a></strong> by Alexei Baevski, Wei-Ning Hsu, Qiantong Xu, Arun Babu, Jiatao Gu, Michael Auli.</li>
<li><strong><a href="https://huggingface.co/docs/transformers/model_doc/deberta" target="_blank" rel="noopener">DeBERTa</a></strong> (from Microsoft) released with the paper <strong><a href="https://arxiv.org/abs/2006.03654" target="_blank" rel="noopener">DeBERTa: Decoding-enhanced BERT with Disentangled Attention</a></strong> by Pengcheng He, Xiaodong Liu, Jianfeng Gao, Weizhu Chen.</li>
<li><strong><a href="https://huggingface.co/docs/transformers/model_doc/deberta-v2" target="_blank" rel="noopener">DeBERTa-v2</a></strong> (from Microsoft) released with the paper <strong><a href="https://arxiv.org/abs/2006.03654" target="_blank" rel="noopener">DeBERTa: Decoding-enhanced BERT with Disentangled Attention</a></strong> by Pengcheng He, Xiaodong Liu, Jianfeng Gao, Weizhu Chen.</li>
<li><strong><a href="https://huggingface.co/docs/transformers/model_doc/deit" target="_blank" rel="noopener">DeiT</a></strong> (from Facebook) released with the paper <strong><a href="https://arxiv.org/abs/2012.12877" target="_blank" rel="noopener">Training data-efficient image transformers &amp; distillation through attention</a></strong> by Hugo Touvron, Matthieu Cord, Matthijs Douze, Francisco Massa, Alexandre Sablayrolles, HervÃ© JÃ©gou.</li>
<li><strong><a href="https://huggingface.co/docs/transformers/model_doc/detr" target="_blank" rel="noopener">DETR</a></strong> (from Facebook) released with the paper <strong><a href="https://arxiv.org/abs/2005.12872" target="_blank" rel="noopener">End-to-End Object Detection with Transformers</a></strong> by Nicolas Carion, Francisco Massa, Gabriel Synnaeve, Nicolas Usunier, Alexander Kirillov, Sergey Zagoruyko.</li>
<li><strong><a href="https://huggingface.co/docs/transformers/model_doc/dialogpt" target="_blank" rel="noopener">DialoGPT</a></strong> (from Microsoft Research) released with the paper <strong><a href="https://arxiv.org/abs/1911.00536" target="_blank" rel="noopener">DialoGPT: Large-Scale Generative Pre-training for Conversational Response Generation</a></strong> by Yizhe Zhang, Siqi Sun, Michel Galley, Yen-Chun Chen, Chris Brockett, Xiang Gao, Jianfeng Gao, Jingjing Liu, Bill Dolan.</li>
<li><strong><a href="https://huggingface.co/docs/transformers/model_doc/distilbert" target="_blank" rel="noopener">DistilBERT</a></strong> (from HuggingFace), released together with the paper <strong><a href="https://arxiv.org/abs/1910.01108" target="_blank" rel="noopener">DistilBERT, a distilled version of BERT: smaller, faster, cheaper and lighter</a></strong> by Victor Sanh, Lysandre Debut and Thomas Wolf. The same method has been applied to compress GPT2 into <strong><a href="https://github.com/huggingface/transformers/tree/master/examples/research_projects/distillation" target="_blank" rel="noopener">DistilGPT2</a></strong>, RoBERTa into <strong><a href="https://github.com/huggingface/transformers/tree/master/examples/research_projects/distillation" target="_blank" rel="noopener">DistilRoBERTa</a></strong>, Multilingual BERT into <strong><a href="https://github.com/huggingface/transformers/tree/master/examples/research_projects/distillation" target="_blank" rel="noopener">DistilmBERT</a></strong> and a German version of DistilBERT.</li>
<li><strong><a href="https://huggingface.co/docs/transformers/model_doc/dpr" target="_blank" rel="noopener">DPR</a></strong> (from Facebook) released with the paper <strong><a href="https://arxiv.org/abs/2004.04906" target="_blank" rel="noopener">Dense Passage Retrieval for Open-Domain Question Answering</a></strong> by Vladimir Karpukhin, Barlas OÄŸuz, Sewon Min, Patrick Lewis, Ledell Wu, Sergey Edunov, Danqi Chen, and Wen-tau Yih.</li>
<li><strong><a href="https://huggingface.co/docs/transformers/model_doc/encoder-decoder" target="_blank" rel="noopener">EncoderDecoder</a></strong> (from Google Research) released with the paper <strong><a href="https://arxiv.org/abs/1907.12461" target="_blank" rel="noopener">Leveraging Pre-trained Checkpoints for Sequence Generation Tasks</a></strong> by Sascha Rothe, Shashi Narayan, Aliaksei Severyn.</li>
<li><strong><a href="https://huggingface.co/docs/transformers/model_doc/electra" target="_blank" rel="noopener">ELECTRA</a></strong> (from Google Research/Stanford University) released with the paper <strong><a href="https://arxiv.org/abs/2003.10555" target="_blank" rel="noopener">ELECTRA: Pre-training text encoders as discriminators rather than generators</a></strong> by Kevin Clark, Minh-Thang Luong, Quoc V. Le, Christopher D. Manning.</li>
<li><strong><a href="https://huggingface.co/docs/transformers/model_doc/flaubert" target="_blank" rel="noopener">FlauBERT</a></strong> (from CNRS) released with the paper <strong><a href="https://arxiv.org/abs/1912.05372" target="_blank" rel="noopener">FlauBERT: Unsupervised Language Model Pre-training for French</a></strong> by Hang Le, LoÃ¯c Vial, Jibril Frej, Vincent Segonne, Maximin Coavoux, Benjamin Lecouteux, Alexandre Allauzen, BenoÃ®t CrabbÃ©, Laurent Besacier, Didier Schwab.</li>
<li><strong><a href="https://huggingface.co/docs/transformers/model_doc/fnet" target="_blank" rel="noopener">FNet</a></strong> (from Google Research) released with the paper <strong><a href="https://arxiv.org/abs/2105.03824" target="_blank" rel="noopener">FNet: Mixing Tokens with Fourier Transforms</a></strong> by James Lee-Thorp, Joshua Ainslie, Ilya Eckstein, Santiago Ontanon.</li>
<li><strong><a href="https://huggingface.co/docs/transformers/model_doc/funnel" target="_blank" rel="noopener">Funnel Transformer</a></strong> (from CMU/Google Brain) released with the paper <strong><a href="https://arxiv.org/abs/2006.03236" target="_blank" rel="noopener">Funnel-Transformer: Filtering out Sequential Redundancy for Efficient Language Processing</a></strong> by Zihang Dai, Guokun Lai, Yiming Yang, Quoc V. Le.</li>
<li><strong><a href="https://huggingface.co/docs/transformers/model_doc/openai-gpt" target="_blank" rel="noopener">GPT</a></strong> (from OpenAI) released with the paper <strong><a href="https://blog.openai.com/language-unsupervised/" target="_blank" rel="noopener">Improving Language Understanding by Generative Pre-Training</a></strong> by Alec Radford, Karthik Narasimhan, Tim Salimans and Ilya Sutskever.</li>
<li><strong><a href="https://huggingface.co/docs/transformers/model_doc/gpt2" target="_blank" rel="noopener">GPT-2</a></strong> (from OpenAI) released with the paper <strong><a href="https://blog.openai.com/better-language-models/" target="_blank" rel="noopener">Language Models are Unsupervised Multitask Learners</a></strong> by Alec Radford<em>, Jeffrey Wu</em>, Rewon Child, David Luan, Dario Amodei<strong>and Ilya Sutskever</strong>.</li>
<li><strong><a href="https://huggingface.co/docs/transformers/model_doc/gptj" target="_blank" rel="noopener">GPT-J</a></strong> (from EleutherAI) released in the repository <strong><a href="https://github.com/kingoflolz/mesh-transformer-jax/" target="_blank" rel="noopener">kingoflolz/mesh-transformer-jax</a></strong> by Ben Wang and Aran Komatsuzaki.</li>
<li><strong><a href="https://huggingface.co/docs/transformers/model_doc/gpt_neo" target="_blank" rel="noopener">GPT Neo</a></strong> (from EleutherAI) released in the repository <strong><a href="https://github.com/EleutherAI/gpt-neo" target="_blank" rel="noopener">EleutherAI/gpt-neo</a></strong> by Sid Black, Stella Biderman, Leo Gao, Phil Wang and Connor Leahy.</li>
<li><strong><a href="https://huggingface.co/docs/transformers/model_doc/hubert" target="_blank" rel="noopener">Hubert</a></strong> (from Facebook) released with the paper <strong><a href="https://arxiv.org/abs/2106.07447" target="_blank" rel="noopener">HuBERT: Self-Supervised Speech Representation Learning by Masked Prediction of Hidden Units</a></strong> by Wei-Ning Hsu, Benjamin Bolte, Yao-Hung Hubert Tsai, Kushal Lakhotia, Ruslan Salakhutdinov, Abdelrahman Mohamed.</li>
<li><strong><a href="https://huggingface.co/docs/transformers/model_doc/ibert" target="_blank" rel="noopener">I-BERT</a></strong> (from Berkeley) released with the paper <strong><a href="https://arxiv.org/abs/2101.01321" target="_blank" rel="noopener">I-BERT: Integer-only BERT Quantization</a></strong> by Sehoon Kim, Amir Gholami, Zhewei Yao, Michael W. Mahoney, Kurt Keutzer.</li>
<li><strong><a href="https://huggingface.co/docs/transformers/model_doc/imagegpt" target="_blank" rel="noopener">ImageGPT</a></strong> (from OpenAI) released with the paper <strong><a href="https://openai.com/blog/image-gpt/" target="_blank" rel="noopener">Generative Pretraining from Pixels</a></strong> by Mark Chen, Alec Radford, Rewon Child, Jeffrey Wu, Heewoo Jun, David Luan, Ilya Sutskever.</li>
<li><strong><a href="https://huggingface.co/docs/transformers/model_doc/layoutlm" target="_blank" rel="noopener">LayoutLM</a></strong> (from Microsoft Research Asia) released with the paper <strong><a href="https://arxiv.org/abs/1912.13318" target="_blank" rel="noopener">LayoutLM: Pre-training of Text and Layout for Document Image Understanding</a></strong> by Yiheng Xu, Minghao Li, Lei Cui, Shaohan Huang, Furu Wei, Ming Zhou.</li>
<li><strong><a href="https://huggingface.co/docs/transformers/model_doc/layoutlmv2" target="_blank" rel="noopener">LayoutLMv2</a></strong> (from Microsoft Research Asia) released with the paper <strong><a href="https://arxiv.org/abs/2012.14740" target="_blank" rel="noopener">LayoutLMv2: Multi-modal Pre-training for Visually-Rich Document Understanding</a></strong> by Yang Xu, Yiheng Xu, Tengchao Lv, Lei Cui, Furu Wei, Guoxin Wang, Yijuan Lu, Dinei Florencio, Cha Zhang, Wanxiang Che, Min Zhang, Lidong Zhou.</li>
<li><strong><a href="https://huggingface.co/docs/transformers/model_doc/layoutlmv2" target="_blank" rel="noopener">LayoutXLM</a></strong> (from Microsoft Research Asia) released with the paper <strong><a href="https://arxiv.org/abs/2104.08836" target="_blank" rel="noopener">LayoutXLM: Multimodal Pre-training for Multilingual Visually-rich Document Understanding</a></strong> by Yiheng Xu, Tengchao Lv, Lei Cui, Guoxin Wang, Yijuan Lu, Dinei Florencio, Cha Zhang, Furu Wei.</li>
<li><strong><a href="https://huggingface.co/docs/transformers/model_doc/led" target="_blank" rel="noopener">LED</a></strong> (from AllenAI) released with the paper <strong><a href="https://arxiv.org/abs/2004.05150" target="_blank" rel="noopener">Longformer: The Long-Document Transformer</a></strong> by Iz Beltagy, Matthew E. Peters, Arman Cohan.</li>
<li><strong><a href="https://huggingface.co/docs/transformers/model_doc/longformer" target="_blank" rel="noopener">Longformer</a></strong> (from AllenAI) released with the paper <strong><a href="https://arxiv.org/abs/2004.05150" target="_blank" rel="noopener">Longformer: The Long-Document Transformer</a></strong> by Iz Beltagy, Matthew E. Peters, Arman Cohan.</li>
<li><strong><a href="https://huggingface.co/docs/transformers/model_doc/luke" target="_blank" rel="noopener">LUKE</a></strong> (from Studio Ousia) released with the paper <strong><a href="https://arxiv.org/abs/2010.01057" target="_blank" rel="noopener">LUKE: Deep Contextualized Entity Representations with Entity-aware Self-attention</a></strong> by Ikuya Yamada, Akari Asai, Hiroyuki Shindo, Hideaki Takeda, Yuji Matsumoto.</li>
<li><strong><a href="https://huggingface.co/docs/transformers/model_doc/mluke" target="_blank" rel="noopener">mLUKE</a></strong> (from Studio Ousia) released with the paper <strong><a href="https://arxiv.org/abs/2110.08151" target="_blank" rel="noopener">mLUKE: The Power of Entity Representations in Multilingual Pretrained Language Models</a></strong> by Ryokan Ri, Ikuya Yamada, and Yoshimasa Tsuruoka.</li>
<li><strong><a href="https://huggingface.co/docs/transformers/model_doc/lxmert" target="_blank" rel="noopener">LXMERT</a></strong> (from UNC Chapel Hill) released with the paper <strong><a href="https://arxiv.org/abs/1908.07490" target="_blank" rel="noopener">LXMERT: Learning Cross-Modality Encoder Representations from Transformers for Open-Domain Question Answering</a></strong> by Hao Tan and Mohit Bansal.</li>
<li><strong><a href="https://huggingface.co/docs/transformers/model_doc/m2m_100" target="_blank" rel="noopener">M2M100</a></strong> (from Facebook) released with the paper <strong><a href="https://arxiv.org/abs/2010.11125" target="_blank" rel="noopener">Beyond English-Centric Multilingual Machine Translation</a></strong> by Angela Fan, Shruti Bhosale, Holger Schwenk, Zhiyi Ma, Ahmed El-Kishky, Siddharth Goyal, Mandeep Baines, Onur Celebi, Guillaume Wenzek, Vishrav Chaudhary, Naman Goyal, Tom Birch, Vitaliy Liptchinsky, Sergey Edunov, Edouard Grave, Michael Auli, Armand Joulin.</li>
<li><strong><a href="https://huggingface.co/docs/transformers/model_doc/marian" target="_blank" rel="noopener">MarianMT</a></strong> Machine translation models trained using <strong><a href="http://opus.nlpl.eu/" target="_blank" rel="noopener">OPUS</a></strong> data by JÃ¶rg Tiedemann. The <strong><a href="https://marian-nmt.github.io/" target="_blank" rel="noopener">Marian Framework</a></strong> is being developed by the Microsoft Translator Team.</li>
<li><strong><a href="https://huggingface.co/docs/transformers/model_doc/maskformer" target="_blank" rel="noopener">MaskFormer</a></strong> (from Meta and UIUC) released with the paper <strong><a href="https://arxiv.org/abs/2107.06278" target="_blank" rel="noopener">Per-Pixel Classification is Not All You Need for Semantic Segmentation</a></strong> by Bowen Cheng, Alexander G. Schwing, Alexander Kirillov.</li>
<li><strong><a href="https://huggingface.co/docs/transformers/model_doc/mbart" target="_blank" rel="noopener">MBart</a></strong> (from Facebook) released with the paper <strong><a href="https://arxiv.org/abs/2001.08210" target="_blank" rel="noopener">Multilingual Denoising Pre-training for Neural Machine Translation</a></strong> by Yinhan Liu, Jiatao Gu, Naman Goyal, Xian Li, Sergey Edunov, Marjan Ghazvininejad, Mike Lewis, Luke Zettlemoyer.</li>
<li><strong><a href="https://huggingface.co/docs/transformers/model_doc/mbart" target="_blank" rel="noopener">MBart-50</a></strong> (from Facebook) released with the paper <strong><a href="https://arxiv.org/abs/2008.00401" target="_blank" rel="noopener">Multilingual Translation with Extensible Multilingual Pretraining and Finetuning</a></strong> by Yuqing Tang, Chau Tran, Xian Li, Peng-Jen Chen, Naman Goyal, Vishrav Chaudhary, Jiatao Gu, Angela Fan.</li>
<li><strong><a href="https://huggingface.co/docs/transformers/model_doc/megatron-bert" target="_blank" rel="noopener">Megatron-BERT</a></strong> (from NVIDIA) released with the paper <strong><a href="https://arxiv.org/abs/1909.08053" target="_blank" rel="noopener">Megatron-LM: Training Multi-Billion Parameter Language Models Using Model Parallelism</a></strong> by Mohammad Shoeybi, Mostofa Patwary, Raul Puri, Patrick LeGresley, Jared Casper and Bryan Catanzaro.</li>
<li><strong><a href="https://huggingface.co/docs/transformers/model_doc/megatron_gpt2" target="_blank" rel="noopener">Megatron-GPT2</a></strong> (from NVIDIA) released with the paper <strong><a href="https://arxiv.org/abs/1909.08053" target="_blank" rel="noopener">Megatron-LM: Training Multi-Billion Parameter Language Models Using Model Parallelism</a></strong> by Mohammad Shoeybi, Mostofa Patwary, Raul Puri, Patrick LeGresley, Jared Casper and Bryan Catanzaro.</li>
<li><strong><a href="https://huggingface.co/docs/transformers/model_doc/mpnet" target="_blank" rel="noopener">MPNet</a></strong> (from Microsoft Research) released with the paper <strong><a href="https://arxiv.org/abs/2004.09297" target="_blank" rel="noopener">MPNet: Masked and Permuted Pre-training for Language Understanding</a></strong> by Kaitao Song, Xu Tan, Tao Qin, Jianfeng Lu, Tie-Yan Liu.</li>
<li><strong><a href="https://huggingface.co/docs/transformers/model_doc/mt5" target="_blank" rel="noopener">MT5</a></strong> (from Google AI) released with the paper <strong><a href="https://arxiv.org/abs/2010.11934" target="_blank" rel="noopener">mT5: A massively multilingual pre-trained text-to-text transformer</a></strong> by Linting Xue, Noah Constant, Adam Roberts, Mihir Kale, Rami Al-Rfou, Aditya Siddhant, Aditya Barua, Colin Raffel.</li>
<li><strong><a href="https://huggingface.co/docs/transformers/model_doc/nystromformer" target="_blank" rel="noopener">NystrÃ¶mformer</a></strong> (from the University of Wisconsin - Madison) released with the paper <strong><a href="https://arxiv.org/abs/2102.03902" target="_blank" rel="noopener">NystrÃ¶mformer: A NystrÃ¶m-Based Algorithm for Approximating Self-Attention</a></strong> by Yunyang Xiong, Zhanpeng Zeng, Rudrasis Chakraborty, Mingxing Tan, Glenn Fung, Yin Li, Vikas Singh.</li>
<li><strong><a href="https://huggingface.co/docs/transformers/model_doc/pegasus" target="_blank" rel="noopener">Pegasus</a></strong> (from Google) released with the paper <strong><a href="https://arxiv.org/abs/1912.08777" target="_blank" rel="noopener">PEGASUS: Pre-training with Extracted Gap-sentences for Abstractive Summarization</a></strong> by Jingqing Zhang, Yao Zhao, Mohammad Saleh and Peter J. Liu.</li>
<li><strong><a href="https://huggingface.co/docs/transformers/model_doc/perceiver" target="_blank" rel="noopener">Perceiver IO</a></strong> (from Deepmind) released with the paper <strong><a href="https://arxiv.org/abs/2107.14795" target="_blank" rel="noopener">Perceiver IO: A General Architecture for Structured Inputs &amp; Outputs</a></strong> by Andrew Jaegle, Sebastian Borgeaud, Jean-Baptiste Alayrac, Carl Doersch, Catalin Ionescu, David Ding, Skanda Koppula, Daniel Zoran, Andrew Brock, Evan Shelhamer, Olivier HÃ©naff, Matthew M. Botvinick, Andrew Zisserman, Oriol Vinyals, JoÃ£o Carreira.</li>
<li><strong><a href="https://huggingface.co/docs/transformers/model_doc/phobert" target="_blank" rel="noopener">PhoBERT</a></strong> (from VinAI Research) released with the paper <strong><a href="https://www.aclweb.org/anthology/2020.findings-emnlp.92/" target="_blank" rel="noopener">PhoBERT: Pre-trained language models for Vietnamese</a></strong> by Dat Quoc Nguyen and Anh Tuan Nguyen.</li>
<li><strong><a href="https://huggingface.co/docs/transformers/model_doc/plbart" target="_blank" rel="noopener">PLBart</a></strong> (from UCLA NLP) released with the paper <strong><a href="https://arxiv.org/abs/2103.06333" target="_blank" rel="noopener">Unified Pre-training for Program Understanding and Generation</a></strong> by Wasi Uddin Ahmad, Saikat Chakraborty, Baishakhi Ray, Kai-Wei Chang.</li>
<li><strong><a href="https://huggingface.co/docs/transformers/model_doc/poolformer" target="_blank" rel="noopener">PoolFormer</a></strong> (from Sea AI Labs) released with the paper <strong><a href="https://arxiv.org/abs/2111.11418" target="_blank" rel="noopener">MetaFormer is Actually What You Need for Vision</a></strong> by Yu, Weihao and Luo, Mi and Zhou, Pan and Si, Chenyang and Zhou, Yichen and Wang, Xinchao and Feng, Jiashi and Yan, Shuicheng.</li>
<li><strong><a href="https://huggingface.co/docs/transformers/model_doc/prophetnet" target="_blank" rel="noopener">ProphetNet</a></strong> (from Microsoft Research) released with the paper <strong><a href="https://arxiv.org/abs/2001.04063" target="_blank" rel="noopener">ProphetNet: Predicting Future N-gram for Sequence-to-Sequence Pre-training</a></strong> by Yu Yan, Weizhen Qi, Yeyun Gong, Dayiheng Liu, Nan Duan, Jiusheng Chen, Ruofei Zhang and Ming Zhou.</li>
<li><strong><a href="https://huggingface.co/docs/transformers/model_doc/qdqbert" target="_blank" rel="noopener">QDQBert</a></strong> (from NVIDIA) released with the paper <strong><a href="https://arxiv.org/abs/2004.09602" target="_blank" rel="noopener">Integer Quantization for Deep Learning Inference: Principles and Empirical Evaluation</a></strong> by Hao Wu, Patrick Judd, Xiaojie Zhang, Mikhail Isaev and Paulius Micikevicius.</li>
<li><strong><a href="https://huggingface.co/transformers/model_doc/realm.html" target="_blank" rel="noopener">REALM</a></strong> (from Google Research) released with the paper <strong><a href="https://arxiv.org/abs/2002.08909" target="_blank" rel="noopener">REALM: Retrieval-Augmented Language Model Pre-Training</a></strong> by Kelvin Guu, Kenton Lee, Zora Tung, Panupong Pasupat and Ming-Wei Chang.</li>
<li><strong><a href="https://huggingface.co/docs/transformers/model_doc/reformer" target="_blank" rel="noopener">Reformer</a></strong> (from Google Research) released with the paper <strong><a href="https://arxiv.org/abs/2001.04451" target="_blank" rel="noopener">Reformer: The Efficient Transformer</a></strong> by Nikita Kitaev, Åukasz Kaiser, Anselm Levskaya.</li>
<li><strong><a href="https://huggingface.co/docs/transformers/model_doc/rembert" target="_blank" rel="noopener">RemBERT</a></strong> (from Google Research) released with the paper <strong><a href="https://arxiv.org/abs/2010.12821" target="_blank" rel="noopener">Rethinking embedding coupling in pre-trained language models</a></strong> by Hyung Won Chung, Thibault FÃ©vry, Henry Tsai, M. Johnson, Sebastian Ruder.</li>
<li><strong><a href="https://huggingface.co/docs/transformers/model_doc/roberta" target="_blank" rel="noopener">RoBERTa</a></strong> (from Facebook), released together with the paper <strong><a href="https://arxiv.org/abs/1907.11692" target="_blank" rel="noopener">RoBERTa: A Robustly Optimized BERT Pretraining Approach</a></strong> by Yinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Mandar Joshi, Danqi Chen, Omer Levy, Mike Lewis, Luke Zettlemoyer, Veselin Stoyanov.</li>
<li><strong><a href="https://huggingface.co/docs/transformers/model_doc/roformer" target="_blank" rel="noopener">RoFormer</a></strong> (from ZhuiyiTechnology), released together with the paper <strong><a href="https://arxiv.org/abs/2104.09864" target="_blank" rel="noopener">RoFormer: Enhanced Transformer with Rotary Position Embedding</a></strong> by Jianlin Su and Yu Lu and Shengfeng Pan and Bo Wen and Yunfeng Liu.</li>
<li><strong><a href="https://huggingface.co/docs/transformers/model_doc/segformer" target="_blank" rel="noopener">SegFormer</a></strong> (from NVIDIA) released with the paper <strong><a href="https://arxiv.org/abs/2105.15203" target="_blank" rel="noopener">SegFormer: Simple and Efficient Design for Semantic Segmentation with Transformers</a></strong> by Enze Xie, Wenhai Wang, Zhiding Yu, Anima Anandkumar, Jose M. Alvarez, Ping Luo.</li>
<li><strong><a href="https://huggingface.co/docs/transformers/model_doc/sew" target="_blank" rel="noopener">SEW</a></strong> (from ASAPP) released with the paper <strong><a href="https://arxiv.org/abs/2109.06870" target="_blank" rel="noopener">Performance-Efficiency Trade-offs in Unsupervised Pre-training for Speech Recognition</a></strong> by Felix Wu, Kwangyoun Kim, Jing Pan, Kyu Han, Kilian Q. Weinberger, Yoav Artzi.</li>
<li><strong><a href="https://huggingface.co/docs/transformers/model_doc/sew_d" target="_blank" rel="noopener">SEW-D</a></strong> (from ASAPP) released with the paper <strong><a href="https://arxiv.org/abs/2109.06870" target="_blank" rel="noopener">Performance-Efficiency Trade-offs in Unsupervised Pre-training for Speech Recognition</a></strong> by Felix Wu, Kwangyoun Kim, Jing Pan, Kyu Han, Kilian Q. Weinberger, Yoav Artzi.</li>
<li><strong><a href="https://huggingface.co/docs/transformers/model_doc/speech_to_text" target="_blank" rel="noopener">SpeechToTextTransformer</a></strong> (from Facebook), released together with the paper <strong><a href="https://arxiv.org/abs/2010.05171" target="_blank" rel="noopener">fairseq S2T: Fast Speech-to-Text Modeling with fairseq</a></strong> by Changhan Wang, Yun Tang, Xutai Ma, Anne Wu, Dmytro Okhonko, Juan Pino.</li>
<li><strong><a href="https://huggingface.co/docs/transformers/model_doc/speech_to_text_2" target="_blank" rel="noopener">SpeechToTextTransformer2</a></strong> (from Facebook), released together with the paper <strong><a href="https://arxiv.org/abs/2104.06678" target="_blank" rel="noopener">Large-Scale Self- and Semi-Supervised Learning for Speech Translation</a></strong> by Changhan Wang, Anne Wu, Juan Pino, Alexei Baevski, Michael Auli, Alexis Conneau.</li>
<li><strong><a href="https://huggingface.co/docs/transformers/model_doc/splinter" target="_blank" rel="noopener">Splinter</a></strong> (from Tel Aviv University), released together with the paper <strong><a href="https://arxiv.org/abs/2101.00438" target="_blank" rel="noopener">Few-Shot Question Answering by Pretraining Span Selection</a></strong> by Ori Ram, Yuval Kirstain, Jonathan Berant, Amir Globerson, Omer Levy.</li>
<li><strong><a href="https://huggingface.co/docs/transformers/model_doc/squeezebert" target="_blank" rel="noopener">SqueezeBert</a></strong> (from Berkeley) released with the paper <strong><a href="https://arxiv.org/abs/2006.11316" target="_blank" rel="noopener">SqueezeBERT: What can computer vision teach NLP about efficient neural networks?</a></strong> by Forrest N. Iandola, Albert E. Shaw, Ravi Krishna, and Kurt W. Keutzer.</li>
<li><strong><a href="https://huggingface.co/docs/transformers/model_doc/swin" target="_blank" rel="noopener">Swin Transformer</a></strong> (from Microsoft) released with the paper <strong><a href="https://arxiv.org/abs/2103.14030" target="_blank" rel="noopener">Swin Transformer: Hierarchical Vision Transformer using Shifted Windows</a></strong> by Ze Liu, Yutong Lin, Yue Cao, Han Hu, Yixuan Wei, Zheng Zhang, Stephen Lin, Baining Guo.</li>
<li><strong><a href="https://huggingface.co/docs/transformers/model_doc/t5" target="_blank" rel="noopener">T5</a></strong> (from Google AI) released with the paper <strong><a href="https://arxiv.org/abs/1910.10683" target="_blank" rel="noopener">Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer</a></strong> by Colin Raffel and Noam Shazeer and Adam Roberts and Katherine Lee and Sharan Narang and Michael Matena and Yanqi Zhou and Wei Li and Peter J. Liu.</li>
<li><strong><a href="https://huggingface.co/docs/transformers/model_doc/t5v1.1" target="_blank" rel="noopener">T5v1.1</a></strong> (from Google AI) released in the repository <strong><a href="https://github.com/google-research/text-to-text-transfer-transformer/blob/main/released_checkpoints.md#t511" target="_blank" rel="noopener">google-research/text-to-text-transfer-transformer</a></strong> by Colin Raffel and Noam Shazeer and Adam Roberts and Katherine Lee and Sharan Narang and Michael Matena and Yanqi Zhou and Wei Li and Peter J. Liu.</li>
<li><strong><a href="https://huggingface.co/docs/transformers/model_doc/tapas" target="_blank" rel="noopener">TAPAS</a></strong> (from Google AI) released with the paper <strong><a href="https://arxiv.org/abs/2004.02349" target="_blank" rel="noopener">TAPAS: Weakly Supervised Table Parsing via Pre-training</a></strong> by Jonathan Herzig, PaweÅ‚ Krzysztof Nowak, Thomas MÃ¼ller, Francesco Piccinno and Julian Martin Eisenschlos.</li>
<li><strong><a href="https://huggingface.co/docs/transformers/model_doc/transfo-xl" target="_blank" rel="noopener">Transformer-XL</a></strong> (from Google/CMU) released with the paper <strong><a href="https://arxiv.org/abs/1901.02860" target="_blank" rel="noopener">Transformer-XL: Attentive Language Models Beyond a Fixed-Length Context</a></strong> by Zihang Dai<em>, Zhilin Yang</em>, Yiming Yang, Jaime Carbonell, Quoc V. Le, Ruslan Salakhutdinov.</li>
<li><strong><a href="https://huggingface.co/docs/transformers/model_doc/trocr" target="_blank" rel="noopener">TrOCR</a></strong> (from Microsoft), released together with the paper <strong><a href="https://arxiv.org/abs/2109.10282" target="_blank" rel="noopener">TrOCR: Transformer-based Optical Character Recognition with Pre-trained Models</a></strong> by Minghao Li, Tengchao Lv, Lei Cui, Yijuan Lu, Dinei Florencio, Cha Zhang, Zhoujun Li, Furu Wei.</li>
<li><strong><a href="https://huggingface.co/docs/transformers/model_doc/unispeech" target="_blank" rel="noopener">UniSpeech</a></strong> (from Microsoft Research) released with the paper <strong><a href="https://arxiv.org/abs/2101.07597" target="_blank" rel="noopener">UniSpeech: Unified Speech Representation Learning with Labeled and Unlabeled Data</a></strong> by Chengyi Wang, Yu Wu, Yao Qian, Kenichi Kumatani, Shujie Liu, Furu Wei, Michael Zeng, Xuedong Huang.</li>
<li><strong><a href="https://huggingface.co/docs/transformers/model_doc/unispeech-sat" target="_blank" rel="noopener">UniSpeechSat</a></strong> (from Microsoft Research) released with the paper <strong><a href="https://arxiv.org/abs/2110.05752" target="_blank" rel="noopener">UNISPEECH-SAT: UNIVERSAL SPEECH REPRESENTATION LEARNING WITH SPEAKER AWARE PRE-TRAINING</a></strong> by Sanyuan Chen, Yu Wu, Chengyi Wang, Zhengyang Chen, Zhuo Chen, Shujie Liu, Jian Wu, Yao Qian, Furu Wei, Jinyu Li, Xiangzhan Yu.</li>
<li><strong><a href="https://huggingface.co/docs/transformers/model_doc/vilt" target="_blank" rel="noopener">ViLT</a></strong> (from NAVER AI Lab/Kakao Enterprise/Kakao Brain) released with the paper <strong><a href="https://arxiv.org/abs/2102.03334" target="_blank" rel="noopener">ViLT: Vision-and-Language Transformer Without Convolution or Region Supervision</a></strong> by Wonjae Kim, Bokyung Son, Ildoo Kim.</li>
<li><strong><a href="https://huggingface.co/docs/transformers/model_doc/vit" target="_blank" rel="noopener">Vision Transformer (ViT)</a></strong> (from Google AI) released with the paper <strong><a href="https://arxiv.org/abs/2010.11929" target="_blank" rel="noopener">An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale</a></strong> by Alexey Dosovitskiy, Lucas Beyer, Alexander Kolesnikov, Dirk Weissenborn, Xiaohua Zhai, Thomas Unterthiner, Mostafa Dehghani, Matthias Minderer, Georg Heigold, Sylvain Gelly, Jakob Uszkoreit, Neil Houlsby.</li>
<li><strong><a href="https://huggingface.co/docs/transformers/model_doc/vit_mae" target="_blank" rel="noopener">ViTMAE</a></strong> (from Meta AI) released with the paper <strong><a href="https://arxiv.org/abs/2111.06377" target="_blank" rel="noopener">Masked Autoencoders Are Scalable Vision Learners</a></strong> by Kaiming He, Xinlei Chen, Saining Xie, Yanghao Li, Piotr DollÃ¡r, Ross Girshick.</li>
<li><strong><a href="https://huggingface.co/docs/transformers/model_doc/visual_bert" target="_blank" rel="noopener">VisualBERT</a></strong> (from UCLA NLP) released with the paper <strong><a href="https://arxiv.org/pdf/1908.03557" target="_blank" rel="noopener">VisualBERT: A Simple and Performant Baseline for Vision and Language</a></strong> by Liunian Harold Li, Mark Yatskar, Da Yin, Cho-Jui Hsieh, Kai-Wei Chang.</li>
<li><strong><a href="https://huggingface.co/docs/transformers/model_doc/wavlm" target="_blank" rel="noopener">WavLM</a></strong> (from Microsoft Research) released with the paper <strong><a href="https://arxiv.org/abs/2110.13900" target="_blank" rel="noopener">WavLM: Large-Scale Self-Supervised Pre-Training for Full Stack Speech Processing</a></strong> by Sanyuan Chen, Chengyi Wang, Zhengyang Chen, Yu Wu, Shujie Liu, Zhuo Chen, Jinyu Li, Naoyuki Kanda, Takuya Yoshioka, Xiong Xiao, Jian Wu, Long Zhou, Shuo Ren, Yanmin Qian, Yao Qian, Jian Wu, Michael Zeng, Furu Wei.</li>
<li><strong><a href="https://huggingface.co/docs/transformers/model_doc/wav2vec2" target="_blank" rel="noopener">Wav2Vec2</a></strong> (from Facebook AI) released with the paper <strong><a href="https://arxiv.org/abs/2006.11477" target="_blank" rel="noopener">wav2vec 2.0: A Framework for Self-Supervised Learning of Speech Representations</a></strong> by Alexei Baevski, Henry Zhou, Abdelrahman Mohamed, Michael Auli.</li>
<li><strong><a href="https://huggingface.co/docs/master/transformers/model_doc/wav2vec2_phoneme" target="_blank" rel="noopener">Wav2Vec2Phoneme</a></strong> (from Facebook AI) released with the paper <strong><a href="https://arxiv.org/abs/2109.11680" target="_blank" rel="noopener">Simple and Effective Zero-shot Cross-lingual Phoneme Recognition</a></strong> by Qiantong Xu, Alexei Baevski, Michael Auli.</li>
<li><strong><a href="https://huggingface.co/docs/master/transformers/model_doc/xglm" target="_blank" rel="noopener">XGLM</a></strong> (From Facebook AI) released with the paper <strong><a href="https://arxiv.org/abs/2112.10668" target="_blank" rel="noopener">Few-shot Learning with Multilingual Language Models</a></strong> by Xi Victoria Lin, Todor Mihaylov, Mikel Artetxe, Tianlu Wang, Shuohui Chen, Daniel Simig, Myle Ott, Naman Goyal, Shruti Bhosale, Jingfei Du, Ramakanth Pasunuru, Sam Shleifer, Punit Singh Koura, Vishrav Chaudhary, Brian Oâ€™Horo, Jeff Wang, Luke Zettlemoyer, Zornitsa Kozareva, Mona Diab, Veselin Stoyanov, Xian Li.</li>
<li><strong><a href="https://huggingface.co/docs/transformers/model_doc/xlm" target="_blank" rel="noopener">XLM</a></strong> (from Facebook) released together with the paper <strong><a href="https://arxiv.org/abs/1901.07291" target="_blank" rel="noopener">Cross-lingual Language Model Pretraining</a></strong> by Guillaume Lample and Alexis Conneau.</li>
<li><strong><a href="https://huggingface.co/docs/transformers/model_doc/xlm-prophetnet" target="_blank" rel="noopener">XLM-ProphetNet</a></strong> (from Microsoft Research) released with the paper <strong><a href="https://arxiv.org/abs/2001.04063" target="_blank" rel="noopener">ProphetNet: Predicting Future N-gram for Sequence-to-Sequence Pre-training</a></strong> by Yu Yan, Weizhen Qi, Yeyun Gong, Dayiheng Liu, Nan Duan, Jiusheng Chen, Ruofei Zhang and Ming Zhou.</li>
<li><strong><a href="https://huggingface.co/docs/transformers/model_doc/xlm-roberta" target="_blank" rel="noopener">XLM-RoBERTa</a></strong> (from Facebook AI), released together with the paper <strong><a href="https://arxiv.org/abs/1911.02116" target="_blank" rel="noopener">Unsupervised Cross-lingual Representation Learning at Scale</a></strong> by Alexis Conneau<em>, Kartikay Khandelwal</em>, Naman Goyal, Vishrav Chaudhary, Guillaume Wenzek, Francisco GuzmÃ¡n, Edouard Grave, Myle Ott, Luke Zettlemoyer and Veselin Stoyanov.</li>
<li><strong><a href="https://huggingface.co/docs/transformers/model_doc/xlm-roberta-xl" target="_blank" rel="noopener">XLM-RoBERTa-XL</a></strong> (from Facebook AI), released together with the paper <strong><a href="https://arxiv.org/abs/2105.00572" target="_blank" rel="noopener">Larger-Scale Transformers for Multilingual Masked Language Modeling</a></strong> by Naman Goyal, Jingfei Du, Myle Ott, Giri Anantharaman, Alexis Conneau.</li>
<li><strong><a href="https://huggingface.co/docs/transformers/model_doc/xlnet" target="_blank" rel="noopener">XLNet</a></strong> (from Google/CMU) released with the paper <strong><a href="https://arxiv.org/abs/1906.08237" target="_blank" rel="noopener">XLNet: Generalized Autoregressive Pretraining for Language Understanding</a></strong> by Zhilin Yang<em>, Zihang Dai</em>, Yiming Yang, Jaime Carbonell, Ruslan Salakhutdinov, Quoc V. Le.</li>
<li><strong><a href="https://huggingface.co/docs/transformers/model_doc/xlsr_wav2vec2" target="_blank" rel="noopener">XLSR-Wav2Vec2</a></strong> (from Facebook AI) released with the paper <strong><a href="https://arxiv.org/abs/2006.13979" target="_blank" rel="noopener">Unsupervised Cross-Lingual Representation Learning For Speech Recognition</a></strong> by Alexis Conneau, Alexei Baevski, Ronan Collobert, Abdelrahman Mohamed, Michael Auli.</li>
<li><strong><a href="https://huggingface.co/docs/master/transformers/model_doc/xls_r" target="_blank" rel="noopener">XLS-R</a></strong> (from Facebook AI) released with the paper <strong><a href="https://arxiv.org/abs/2111.09296" target="_blank" rel="noopener">XLS-R: Self-supervised Cross-lingual Speech Representation Learning at Scale</a></strong> by Arun Babu, Changhan Wang, Andros Tjandra, Kushal Lakhotia, Qiantong Xu, Naman Goyal, Kritika Singh, Patrick von Platen, Yatharth Saraf, Juan Pino, Alexei Baevski, Alexis Conneau, Michael Auli.</li>
<li><strong><a href="https://huggingface.co/docs/transformers/model_doc/yoso" target="_blank" rel="noopener">YOSO</a></strong> (from the University of Wisconsin - Madison) released with the paper <strong><a href="https://arxiv.org/abs/2111.09714" target="_blank" rel="noopener">You Only Sample (Almost) Once: Linear Cost Self-Attention Via Bernoulli Sampling</a></strong> by Zhanpeng Zeng, Yunyang Xiong, Sathya N. Ravi, Shailesh Acharya, Glenn Fung, Vikas Singh.</li>
</ol>
<h3 id="Supported-frameworks"><a href="#Supported-frameworks" class="headerlink" title="Supported frameworks"></a><strong>Supported frameworks</strong></h3><p>The table below represents the current support in the library for each of those models, whether they have a Python tokenizer (called â€œslowâ€). A â€œfastâ€ tokenizer backed by the ğŸ¤— Tokenizers library, whether they have support in Jax (via Flax), PyTorch, and/or TensorFlow.</p>
<p><a href="https://www.notion.so/9168cdd0e2f147428b1cb1ae27d0a42c" target="_blank" rel="noopener">æ¨¡å‹å¯¹æ¯”</a></p>
<h1 id="ğŸ‘‡Downstream-Tasks"><a href="#ğŸ‘‡Downstream-Tasks" class="headerlink" title="ğŸ‘‡Downstream Tasks"></a>ğŸ‘‡Downstream Tasks</h1><h1 id="Text-classification"><a href="#Text-classification" class="headerlink" title="Text classification"></a>Text classification</h1><p>æ–‡æœ¬åˆ†ç±»æ˜¯ä¸€ç§å¸¸è§çš„ NLP ä»»åŠ¡ï¼Œå®ƒä¸ºæ–‡æœ¬åˆ†é…æ ‡ç­¾æˆ–ç±»åˆ«ã€‚å½“ä»Šä¸€äº›æœ€å¤§çš„å…¬å¸åœ¨ç”Ÿäº§ä¸­å¹¿æ³›ä½¿ç”¨æ–‡æœ¬åˆ†ç±»çš„è®¸å¤šå®é™…åº”ç”¨ã€‚æœ€æµè¡Œçš„æ–‡æœ¬åˆ†ç±»å½¢å¼ä¹‹ä¸€æ˜¯æƒ…æ„Ÿåˆ†æï¼Œå®ƒä¸ºæ–‡æœ¬åºåˆ—åˆ†é…æ­£é¢ã€è´Ÿé¢æˆ–ä¸­æ€§çš„æ ‡ç­¾ã€‚</p>
<h2 id="Load-IMDb-dataset"><a href="#Load-IMDb-dataset" class="headerlink" title="Load IMDb dataset"></a><strong>Load IMDb dataset</strong></h2><p>Load the IMDb dataset from the ğŸ¤— Datasets library:</p>
<pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">from</span> datasets <span class="token keyword">import</span> load_dataset

imdb <span class="token operator">=</span> load_dataset<span class="token punctuation">(</span><span class="token string">"imdb"</span><span class="token punctuation">)</span>
imdb<span class="token punctuation">[</span><span class="token string">"test"</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>

<span class="token punctuation">{</span>
    <span class="token string">"label"</span><span class="token punctuation">:</span> <span class="token number">0</span><span class="token punctuation">,</span>
    <span class="token string">"text"</span><span class="token punctuation">:</span> <span class="token string">"I love sci-fi and am willing to put up with a lot. Sci-fi movies/TV are usually underfunded, under-appreciated and misunderstood. I tried to like this, I really did, but it is to good TV sci-fi as Babylon 5 is to Star Trek (the original). Silly prosthetics, cheap cardboard sets, stilted dialogues, CG that doesn't match the background, and painfully one-dimensional characters cannot be overcome with a 'sci-fi' setting. (I'm sure there are those of you out there who think Babylon 5 is good sci-fi TV. It's not. It's clichÃ©d and uninspiring.) While US viewers might like emotion and character development, sci-fi is a genre that does not take itself seriously (cf. Star Trek). It may treat important issues, yet not as a serious philosophy. It's really difficult to care about the characters here as they are not simply foolish, just missing a spark of life. Their actions and reactions are wooden and predictable, often painful to watch. The makers of Earth KNOW it's rubbish as they have to always say \\"</span>Gene Roddenberry<span class="token string">'s Earth...\\" otherwise people would not continue watching. Roddenberry'</span>s ashes must be turning <span class="token keyword">in</span> their orbit <span class="token keyword">as</span> this dull<span class="token punctuation">,</span> cheap<span class="token punctuation">,</span> poorly edited <span class="token punctuation">(</span>watching it without advert breaks really brings this home<span class="token punctuation">)</span> trudging Trabant of a show lumbers into space<span class="token punctuation">.</span> Spoiler<span class="token punctuation">.</span> So<span class="token punctuation">,</span> kill off a main character<span class="token punctuation">.</span> And then bring him back <span class="token keyword">as</span> another actor<span class="token punctuation">.</span> Jeeez! Dallas all over again<span class="token punctuation">.</span>"<span class="token punctuation">,</span>
<span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>There are two fields in this dataset:</p>
<ul>
<li><code>text</code>: a string containing the text of the movie review.</li>
<li><code>label</code>: a value that can either be <code>0</code> for a negative review or <code>1</code> for a positive review.</li>
</ul>
<h2 id="Preprocess"><a href="#Preprocess" class="headerlink" title="Preprocess"></a><strong>Preprocess</strong></h2><p>Load the DistilBERT tokenizer to process the <code>text</code> field:</p>
<pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">from</span> transformers <span class="token keyword">import</span> AutoTokenizer

tokenizer <span class="token operator">=</span> AutoTokenizer<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span><span class="token string">"distilbert-base-uncased"</span><span class="token punctuation">)</span>

<span class="token operator">**</span><span class="token keyword">def</span> preprocess_function<span class="token punctuation">(</span>examples<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">return</span> tokenizer<span class="token punctuation">(</span>examples<span class="token punctuation">[</span><span class="token string">"text"</span><span class="token punctuation">]</span><span class="token punctuation">,</span> truncation<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>

tokenized_imdb <span class="token operator">=</span> imdb<span class="token punctuation">.</span>map<span class="token punctuation">(</span>preprocess_function<span class="token punctuation">,</span> batched<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token operator">**</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>ä½¿ç”¨<strong><a href="https://huggingface.co/docs/transformers/v4.18.0/en/main_classes/data_collator#transformers.DataCollatorWithPadding" target="_blank" rel="noopener">DataCollatorWithPadding</a></strong>åˆ›å»ºä¸€æ‰¹ç¤ºä¾‹ã€‚å®ƒè¿˜ä¼š<em>åŠ¨æ€åœ°å°†æ‚¨çš„æ–‡æœ¬å¡«å……</em>åˆ°å…¶æ‰¹æ¬¡ä¸­æœ€é•¿å…ƒç´ çš„é•¿åº¦ï¼Œå› æ­¤å®ƒä»¬æ˜¯ç»Ÿä¸€çš„é•¿åº¦ã€‚è™½ç„¶å¯ä»¥<code>tokenizer</code>é€šè¿‡è®¾ç½®åœ¨å‡½æ•°ä¸­å¡«å……æ–‡æœ¬ï¼Œä½†<code>padding=True</code>åŠ¨æ€å¡«å……æ›´æœ‰æ•ˆã€‚</p>
<pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">from</span> transformers <span class="token keyword">import</span> DataCollatorWithPadding

data_collator <span class="token operator">=</span> DataCollatorWithPadding<span class="token punctuation">(</span>tokenizer<span class="token operator">=</span>tokenizer<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre>
<h2 id="Train-2"><a href="#Train-2" class="headerlink" title="Train"></a>Train</h2><p>Load DistilBERT with <strong><a href="https://huggingface.co/docs/transformers/v4.18.0/en/model_doc/auto#transformers.AutoModelForSequenceClassification" target="_blank" rel="noopener">AutoModelForSequenceClassification</a></strong> along with the number of expected labels:</p>
<pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">from</span> transformers <span class="token keyword">import</span> AutoModelForSequenceClassification<span class="token punctuation">,</span> TrainingArguments<span class="token punctuation">,</span> Trainer

model <span class="token operator">=</span> AutoModelForSequenceClassification<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span><span class="token string">"distilbert-base-uncased"</span><span class="token punctuation">,</span> num_labels<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre>
<p>æ­¤æ—¶ï¼Œåªå‰©ä¸‹ä¸‰ä¸ªæ­¥éª¤ï¼š</p>
<ol>
<li><strong><a href="https://huggingface.co/docs/transformers/v4.18.0/en/main_classes/trainer#transformers.TrainingArguments" target="_blank" rel="noopener">åœ¨TrainingArguments</a></strong>ä¸­å®šä¹‰æ‚¨çš„è®­ç»ƒè¶…å‚æ•°ã€‚</li>
<li>å°†è®­ç»ƒå‚æ•°è¿åŒæ¨¡å‹ã€æ•°æ®é›†ã€æ ‡è®°å™¨å’Œæ•°æ®æ•´ç†å™¨ä¸€èµ·ä¼ é€’ç»™<strong><a href="https://huggingface.co/docs/transformers/v4.18.0/en/main_classes/trainer#transformers.Trainer" target="_blank" rel="noopener">Trainer ã€‚</a></strong></li>
<li>è°ƒç”¨<strong><a href="https://huggingface.co/docs/transformers/v4.18.0/en/main_classes/trainer#transformers.Trainer.train" target="_blank" rel="noopener">train()</a></strong>æ¥å¾®è°ƒä½ çš„æ¨¡å‹ã€‚</li>
</ol>
<pre class="line-numbers language-python"><code class="language-python">training_args <span class="token operator">=</span> TrainingArguments<span class="token punctuation">(</span>
    output_dir<span class="token operator">=</span><span class="token string">"./results"</span><span class="token punctuation">,</span>
    learning_rate<span class="token operator">=</span><span class="token number">2e</span><span class="token operator">-</span><span class="token number">5</span><span class="token punctuation">,</span>
    per_device_train_batch_size<span class="token operator">=</span><span class="token number">16</span><span class="token punctuation">,</span>
    per_device_eval_batch_size<span class="token operator">=</span><span class="token number">16</span><span class="token punctuation">,</span>
    num_train_epochs<span class="token operator">=</span><span class="token number">5</span><span class="token punctuation">,</span>
    weight_decay<span class="token operator">=</span><span class="token number">0.01</span><span class="token punctuation">,</span>
<span class="token punctuation">)</span>

trainer <span class="token operator">=</span> Trainer<span class="token punctuation">(</span>
    model<span class="token operator">=</span>model<span class="token punctuation">,</span>
    args<span class="token operator">=</span>training_args<span class="token punctuation">,</span>
    train_dataset<span class="token operator">=</span>tokenized_imdb<span class="token punctuation">[</span><span class="token string">"train"</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
    eval_dataset<span class="token operator">=</span>tokenized_imdb<span class="token punctuation">[</span><span class="token string">"test"</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
    tokenizer<span class="token operator">=</span>tokenizer<span class="token punctuation">,</span>
    data_collator<span class="token operator">=</span>data_collator<span class="token punctuation">,</span>
<span class="token punctuation">)</span>

trainer<span class="token punctuation">.</span>train<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<h1 id="Token-classification"><a href="#Token-classification" class="headerlink" title="Token classification"></a>Token classification</h1><p>æ ‡è®°åˆ†ç±»ä¸ºå¥å­ä¸­çš„å„ä¸ªæ ‡è®°åˆ†é…æ ‡ç­¾ã€‚æœ€å¸¸è§çš„ä»¤ç‰Œåˆ†ç±»ä»»åŠ¡ä¹‹ä¸€æ˜¯å‘½åå®ä½“è¯†åˆ« (NER)ã€‚NER å°è¯•ä¸ºå¥å­ä¸­çš„æ¯ä¸ªå®ä½“ï¼ˆä¾‹å¦‚äººã€ä½ç½®æˆ–ç»„ç»‡ï¼‰æŸ¥æ‰¾æ ‡ç­¾ã€‚</p>
<h2 id="Load-WNUT-17-dataset"><a href="#Load-WNUT-17-dataset" class="headerlink" title="Load WNUT 17 dataset"></a><strong>Load WNUT 17 dataset</strong></h2><p>Load the WNUT 17 dataset from the ğŸ¤— Datasets library:</p>
<pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">from</span> datasets <span class="token keyword">import</span> load_dataset

wnut <span class="token operator">=</span> load_dataset<span class="token punctuation">(</span><span class="token string">"wnut_17"</span><span class="token punctuation">)</span>

wnut<span class="token punctuation">[</span><span class="token string">"train"</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
<span class="token punctuation">{</span><span class="token string">'id'</span><span class="token punctuation">:</span> <span class="token string">'0'</span><span class="token punctuation">,</span>
 <span class="token string">'ner_tags'</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">7</span><span class="token punctuation">,</span> <span class="token number">8</span><span class="token punctuation">,</span> <span class="token number">8</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">7</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
 <span class="token string">'tokens'</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token string">'@paulwalk'</span><span class="token punctuation">,</span> <span class="token string">'It'</span><span class="token punctuation">,</span> <span class="token string">"'s"</span><span class="token punctuation">,</span> <span class="token string">'the'</span><span class="token punctuation">,</span> <span class="token string">'view'</span><span class="token punctuation">,</span> <span class="token string">'from'</span><span class="token punctuation">,</span> <span class="token string">'where'</span><span class="token punctuation">,</span> <span class="token string">'I'</span><span class="token punctuation">,</span> <span class="token string">"'m"</span><span class="token punctuation">,</span> <span class="token string">'living'</span><span class="token punctuation">,</span> <span class="token string">'for'</span><span class="token punctuation">,</span> <span class="token string">'two'</span><span class="token punctuation">,</span> <span class="token string">'weeks'</span><span class="token punctuation">,</span> <span class="token string">'.'</span><span class="token punctuation">,</span> <span class="token string">'Empire'</span><span class="token punctuation">,</span> <span class="token string">'State'</span><span class="token punctuation">,</span> <span class="token string">'Building'</span><span class="token punctuation">,</span> <span class="token string">'='</span><span class="token punctuation">,</span> <span class="token string">'ESB'</span><span class="token punctuation">,</span> <span class="token string">'.'</span><span class="token punctuation">,</span> <span class="token string">'Pretty'</span><span class="token punctuation">,</span> <span class="token string">'bad'</span><span class="token punctuation">,</span> <span class="token string">'storm'</span><span class="token punctuation">,</span> <span class="token string">'here'</span><span class="token punctuation">,</span> <span class="token string">'last'</span><span class="token punctuation">,</span> <span class="token string">'evening'</span><span class="token punctuation">,</span> <span class="token string">'.'</span><span class="token punctuation">]</span>
<span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>Each number in <code>ner_tags</code> represents an entity. Convert the number to a label name for more information:</p>
<pre class="line-numbers language-python"><code class="language-python">label_list <span class="token operator">=</span> wnut<span class="token punctuation">[</span><span class="token string">"train"</span><span class="token punctuation">]</span><span class="token punctuation">.</span>features<span class="token punctuation">[</span>f<span class="token string">"ner_tags"</span><span class="token punctuation">]</span><span class="token punctuation">.</span>feature<span class="token punctuation">.</span>names
label_list
<span class="token punctuation">[</span>
    <span class="token string">"O"</span><span class="token punctuation">,</span>
    <span class="token string">"B-corporation"</span><span class="token punctuation">,</span>
    <span class="token string">"I-corporation"</span><span class="token punctuation">,</span>
    <span class="token string">"B-creative-work"</span><span class="token punctuation">,</span>
    <span class="token string">"I-creative-work"</span><span class="token punctuation">,</span>
    <span class="token string">"B-group"</span><span class="token punctuation">,</span>
    <span class="token string">"I-group"</span><span class="token punctuation">,</span>
    <span class="token string">"B-location"</span><span class="token punctuation">,</span>
    <span class="token string">"I-location"</span><span class="token punctuation">,</span>
    <span class="token string">"B-person"</span><span class="token punctuation">,</span>
    <span class="token string">"I-person"</span><span class="token punctuation">,</span>
    <span class="token string">"B-product"</span><span class="token punctuation">,</span>
    <span class="token string">"I-product"</span><span class="token punctuation">,</span>
<span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>æè¿°<code>ner_tag</code>äº†ä¸€ä¸ªå®ä½“ï¼Œä¾‹å¦‚å…¬å¸ã€åœ°ç‚¹æˆ–ä¸ªäººã€‚æ¯ä¸ªå‰ç¼€çš„å­—æ¯<code>ner_tag</code>è¡¨ç¤ºå®ä½“çš„æ ‡è®°ä½ç½®ï¼š</p>
<ul>
<li><code>B-</code>è¡¨ç¤ºå®ä½“çš„å¼€å§‹ã€‚</li>
<li><code>I-</code>ç¤ºä»¤ç‰ŒåŒ…å«åœ¨åŒä¸€å®ä½“å†…ï¼ˆä¾‹å¦‚ï¼Œ<code>State</code>ä»¤ç‰Œæ˜¯åƒ ä¸€æ ·çš„å®ä½“çš„ä¸€éƒ¨åˆ†<code>Empire State Building</code>ï¼‰ã€‚</li>
<li><code>0</code>è¡¨ç¤ºä»¤ç‰Œä¸å¯¹åº”äºä»»ä½•å®ä½“ã€‚</li>
</ul>
<h2 id="Preprocess-1"><a href="#Preprocess-1" class="headerlink" title="Preprocess"></a>Preprocess</h2><p>Load the DistilBERT tokenizer to process the <code>tokens</code>:</p>
<pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">from</span> transformers <span class="token keyword">import</span> AutoTokenizer

tokenizer <span class="token operator">=</span> AutoTokenizer<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span><span class="token string">"distilbert-base-uncased"</span><span class="token punctuation">)</span>
tokenized_input <span class="token operator">=</span> tokenizer<span class="token punctuation">(</span>example<span class="token punctuation">[</span><span class="token string">"tokens"</span><span class="token punctuation">]</span><span class="token punctuation">,</span> is_split_into_words<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
tokens <span class="token operator">=</span> tokenizer<span class="token punctuation">.</span>convert_ids_to_tokens<span class="token punctuation">(</span>tokenized_input<span class="token punctuation">[</span><span class="token string">"input_ids"</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
tokens
<span class="token punctuation">[</span><span class="token string">'[CLS]'</span><span class="token punctuation">,</span> <span class="token string">'@'</span><span class="token punctuation">,</span> <span class="token string">'paul'</span><span class="token punctuation">,</span> <span class="token string">'##walk'</span><span class="token punctuation">,</span> <span class="token string">'it'</span><span class="token punctuation">,</span> <span class="token string">"'"</span><span class="token punctuation">,</span> <span class="token string">'s'</span><span class="token punctuation">,</span> <span class="token string">'the'</span><span class="token punctuation">,</span> <span class="token string">'view'</span><span class="token punctuation">,</span> <span class="token string">'from'</span><span class="token punctuation">,</span> <span class="token string">'where'</span><span class="token punctuation">,</span> <span class="token string">'i'</span><span class="token punctuation">,</span> <span class="token string">"'"</span><span class="token punctuation">,</span> <span class="token string">'m'</span><span class="token punctuation">,</span> <span class="token string">'living'</span><span class="token punctuation">,</span> <span class="token string">'for'</span><span class="token punctuation">,</span> <span class="token string">'two'</span><span class="token punctuation">,</span> <span class="token string">'weeks'</span><span class="token punctuation">,</span> <span class="token string">'.'</span><span class="token punctuation">,</span> <span class="token string">'empire'</span><span class="token punctuation">,</span> <span class="token string">'state'</span><span class="token punctuation">,</span> <span class="token string">'building'</span><span class="token punctuation">,</span> <span class="token string">'='</span><span class="token punctuation">,</span> <span class="token string">'es'</span><span class="token punctuation">,</span> <span class="token string">'##b'</span><span class="token punctuation">,</span> <span class="token string">'.'</span><span class="token punctuation">,</span> <span class="token string">'pretty'</span><span class="token punctuation">,</span> <span class="token string">'bad'</span><span class="token punctuation">,</span> <span class="token string">'storm'</span><span class="token punctuation">,</span> <span class="token string">'here'</span><span class="token punctuation">,</span> <span class="token string">'last'</span><span class="token punctuation">,</span> <span class="token string">'evening'</span><span class="token punctuation">,</span> <span class="token string">'.'</span><span class="token punctuation">,</span> <span class="token string">'[SEP]'</span><span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>æ·»åŠ ç‰¹æ®Šæ ‡è®°<code>[CLS]</code>å’Œ<code>[SEP]</code>å­è¯æ ‡è®°åŒ–ä¼šåœ¨è¾“å…¥å’Œæ ‡ç­¾ä¹‹é—´äº§ç”Ÿä¸åŒ¹é…ã€‚å¯¹åº”äºå•ä¸ªæ ‡ç­¾çš„å•ä¸ªè¯å¯ä»¥åˆ†æˆä¸¤ä¸ªå­è¯ã€‚æ‚¨éœ€è¦é€šè¿‡ä»¥ä¸‹æ–¹å¼é‡æ–°å¯¹é½æ ‡è®°å’Œæ ‡ç­¾ï¼š</p>
<ol>
<li>ä½¿ç”¨è¯¥æ–¹æ³•å°†æ‰€æœ‰æ ‡è®°æ˜ å°„åˆ°å…¶å¯¹åº”çš„å•è¯<strong><code>[word_ids](&lt;https://huggingface.co/docs/tokenizers/python/latest/api/reference.html#tokenizers.Encoding.word_ids&gt;)</code></strong>ã€‚</li>
<li>å°†æ ‡ç­¾åˆ†é…<code>100[CLS][SEP]</code>ç»™ç‰¹æ®Šæ ‡è®°ï¼Œå› æ­¤ PyTorch æŸå¤±å‡½æ•°ä¼šå¿½ç•¥å®ƒä»¬ã€‚</li>
<li>ä»…æ ‡è®°ç»™å®šå•è¯çš„ç¬¬ä¸€ä¸ªæ ‡è®°ã€‚åˆ†é…<code>100</code>ç»™åŒä¸€å•è¯çš„å…¶ä»–å­æ ‡è®°ã€‚</li>
</ol>
<p>ä»¥ä¸‹æ˜¯å¦‚ä½•åˆ›å»ºä¸€ä¸ªå‡½æ•°æ¥é‡æ–°å¯¹é½æ ‡è®°å’Œæ ‡ç­¾ï¼Œå¹¶å°†åºåˆ—æˆªæ–­ä¸ºä¸è¶…è¿‡ DistilBERT çš„æœ€å¤§è¾“å…¥é•¿åº¦ï¼š</p>
<pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">tokenize_and_align_labels</span><span class="token punctuation">(</span>examples<span class="token punctuation">)</span><span class="token punctuation">:</span>
    tokenized_inputs <span class="token operator">=</span> tokenizer<span class="token punctuation">(</span>examples<span class="token punctuation">[</span><span class="token string">"tokens"</span><span class="token punctuation">]</span><span class="token punctuation">,</span> truncation<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> is_split_into_words<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>

    labels <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
    <span class="token keyword">for</span> i<span class="token punctuation">,</span> label <span class="token keyword">in</span> enumerate<span class="token punctuation">(</span>examples<span class="token punctuation">[</span>f<span class="token string">"ner_tags"</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        word_ids <span class="token operator">=</span> tokenized_inputs<span class="token punctuation">.</span>word_ids<span class="token punctuation">(</span>batch_index<span class="token operator">=</span>i<span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># Map tokens to their respective word.</span>
        previous_word_idx <span class="token operator">=</span> None
        label_ids <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
        <span class="token keyword">for</span> word_idx <span class="token keyword">in</span> word_ids<span class="token punctuation">:</span>  <span class="token comment" spellcheck="true"># Set the special tokens to -100.</span>
            <span class="token keyword">if</span> word_idx <span class="token keyword">is</span> None<span class="token punctuation">:</span>
                label_ids<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">100</span><span class="token punctuation">)</span>
            <span class="token keyword">elif</span> word_idx <span class="token operator">!=</span> previous_word_idx<span class="token punctuation">:</span>  <span class="token comment" spellcheck="true"># Only label the first token of a given word.</span>
                label_ids<span class="token punctuation">.</span>append<span class="token punctuation">(</span>label<span class="token punctuation">[</span>word_idx<span class="token punctuation">]</span><span class="token punctuation">)</span>
            <span class="token keyword">else</span><span class="token punctuation">:</span>
                label_ids<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">100</span><span class="token punctuation">)</span>
            previous_word_idx <span class="token operator">=</span> word_idx
        labels<span class="token punctuation">.</span>append<span class="token punctuation">(</span>label_ids<span class="token punctuation">)</span>

    tokenized_inputs<span class="token punctuation">[</span><span class="token string">"labels"</span><span class="token punctuation">]</span> <span class="token operator">=</span> labels
    <span class="token keyword">return</span> tokenized_inputs
tokenized_wnut <span class="token operator">=</span> wnut<span class="token punctuation">.</span>map<span class="token punctuation">(</span>tokenize_and_align_labels<span class="token punctuation">,</span> batched<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
<span class="token keyword">from</span> transformers <span class="token keyword">import</span> DataCollatorForTokenClassification

data_collator <span class="token operator">=</span> DataCollatorForTokenClassification<span class="token punctuation">(</span>tokenizer<span class="token operator">=</span>tokenizer<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<h2 id="Train-3"><a href="#Train-3" class="headerlink" title="Train"></a>Train</h2><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">from</span> transformers <span class="token keyword">import</span> AutoModelForTokenClassification<span class="token punctuation">,</span> TrainingArguments<span class="token punctuation">,</span> Trainer

model <span class="token operator">=</span> AutoModelForTokenClassification<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span><span class="token string">"distilbert-base-uncased"</span><span class="token punctuation">,</span> num_labels<span class="token operator">=</span><span class="token number">14</span><span class="token punctuation">)</span>
training_args <span class="token operator">=</span> TrainingArguments<span class="token punctuation">(</span>
    output_dir<span class="token operator">=</span><span class="token string">"./results"</span><span class="token punctuation">,</span>
    evaluation_strategy<span class="token operator">=</span><span class="token string">"epoch"</span><span class="token punctuation">,</span>
    learning_rate<span class="token operator">=</span><span class="token number">2e</span><span class="token operator">-</span><span class="token number">5</span><span class="token punctuation">,</span>
    per_device_train_batch_size<span class="token operator">=</span><span class="token number">16</span><span class="token punctuation">,</span>
    per_device_eval_batch_size<span class="token operator">=</span><span class="token number">16</span><span class="token punctuation">,</span>
    num_train_epochs<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span>
    weight_decay<span class="token operator">=</span><span class="token number">0.01</span><span class="token punctuation">,</span>
<span class="token punctuation">)</span>

trainer <span class="token operator">=</span> Trainer<span class="token punctuation">(</span>
    model<span class="token operator">=</span>model<span class="token punctuation">,</span>
    args<span class="token operator">=</span>training_args<span class="token punctuation">,</span>
    train_dataset<span class="token operator">=</span>tokenized_wnut<span class="token punctuation">[</span><span class="token string">"train"</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
    eval_dataset<span class="token operator">=</span>tokenized_wnut<span class="token punctuation">[</span><span class="token string">"test"</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
    tokenizer<span class="token operator">=</span>tokenizer<span class="token punctuation">,</span>
    data_collator<span class="token operator">=</span>data_collator<span class="token punctuation">,</span>
<span class="token punctuation">)</span>

trainer<span class="token punctuation">.</span>train<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<h1 id="Question-answering"><a href="#Question-answering" class="headerlink" title="Question answering"></a>Question answering</h1><p>é—®ç­”ä»»åŠ¡è¿”å›ç»™å®šé—®é¢˜çš„ç­”æ¡ˆã€‚å¸¸è§çš„é—®ç­”å½¢å¼æœ‰ä¸¤ç§ï¼š</p>
<ul>
<li>æå–ï¼šä»ç»™å®šçš„ä¸Šä¸‹æ–‡ä¸­æå–ç­”æ¡ˆã€‚</li>
<li>æŠ½è±¡çš„ï¼šä»æ­£ç¡®å›ç­”é—®é¢˜çš„ä¸Šä¸‹æ–‡ä¸­ç”Ÿæˆç­”æ¡ˆã€‚</li>
</ul>
<h2 id="Load-SQuAD-dataset"><a href="#Load-SQuAD-dataset" class="headerlink" title="Load SQuAD dataset"></a><strong>Load SQuAD dataset</strong></h2><p>Load the SQuAD dataset from the ğŸ¤— Datasets library:</p>
<pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">from</span> datasets <span class="token keyword">import</span> load_dataset

squad <span class="token operator">=</span> load_dataset<span class="token punctuation">(</span><span class="token string">"squad"</span><span class="token punctuation">)</span>

squad<span class="token punctuation">[</span><span class="token string">"train"</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
<span class="token punctuation">{</span><span class="token string">'answers'</span><span class="token punctuation">:</span> <span class="token punctuation">{</span><span class="token string">'answer_start'</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token number">515</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token string">'text'</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token string">'Saint Bernadette Soubirous'</span><span class="token punctuation">]</span><span class="token punctuation">}</span><span class="token punctuation">,</span>
 <span class="token string">'context'</span><span class="token punctuation">:</span> <span class="token string">'Architecturally, the school has a Catholic character. Atop the Main Building\\'</span>s gold dome <span class="token keyword">is</span> a golden statue of the Virgin Mary<span class="token punctuation">.</span> Immediately <span class="token keyword">in</span> front of the Main Building <span class="token operator">and</span> facing it<span class="token punctuation">,</span> <span class="token keyword">is</span> a copper statue of Christ <span class="token keyword">with</span> arms upraised <span class="token keyword">with</span> the legend <span class="token string">"Venite Ad Me Omnes"</span><span class="token punctuation">.</span> Next to the Main Building <span class="token keyword">is</span> the Basilica of the Sacred Heart<span class="token punctuation">.</span> Immediately behind the basilica <span class="token keyword">is</span> the Grotto<span class="token punctuation">,</span> a Marian place of prayer <span class="token operator">and</span> reflection<span class="token punctuation">.</span> It <span class="token keyword">is</span> a replica of the grotto at Lourdes<span class="token punctuation">,</span> France where the Virgin Mary reputedly appeared to Saint Bernadette Soubirous <span class="token keyword">in</span> <span class="token number">1858</span><span class="token punctuation">.</span> At the end of the main drive <span class="token punctuation">(</span><span class="token operator">and</span> <span class="token keyword">in</span> a direct line that connects through <span class="token number">3</span> statues <span class="token operator">and</span> the Gold Dome<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token keyword">is</span> a simple<span class="token punctuation">,</span> modern stone statue of Mary<span class="token punctuation">.</span>'<span class="token punctuation">,</span>
 <span class="token string">'id'</span><span class="token punctuation">:</span> <span class="token string">'5733be284776f41900661182'</span><span class="token punctuation">,</span>
 <span class="token string">'question'</span><span class="token punctuation">:</span> <span class="token string">'To whom did the Virgin Mary allegedly appear in 1858 in Lourdes France?'</span><span class="token punctuation">,</span>
 <span class="token string">'title'</span><span class="token punctuation">:</span> <span class="token string">'University_of_Notre_Dame'</span>
<span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<h2 id="Preprocess-2"><a href="#Preprocess-2" class="headerlink" title="Preprocess"></a>Preprocess</h2><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">from</span> transformers <span class="token keyword">import</span> AutoTokenizer

tokenizer <span class="token operator">=</span> AutoTokenizer<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span><span class="token string">"distilbert-base-uncased"</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre>
<p>åº”è¯¥æ³¨æ„ä¸€äº›ç‰¹å®šäºé—®ç­”çš„é¢„å¤„ç†æ­¥éª¤ï¼š</p>
<ol>
<li>æ•°æ®é›†ä¸­çš„æŸäº›ç¤ºä¾‹çš„é•¿åº¦å¯èƒ½ä¼šcontextè¶…è¿‡æ¨¡å‹çš„æœ€å¤§è¾“å…¥é•¿åº¦ã€‚ä»…æˆªæ–­contextby è®¾ç½®truncation=â€only_secondâ€ã€‚</li>
<li>contextæ¥ä¸‹æ¥ï¼Œé€šè¿‡è®¾ç½® å°†ç­”æ¡ˆçš„å¼€å§‹å’Œç»“æŸä½ç½®æ˜ å°„åˆ°åŸå§‹ä½return_offset_mapping=Trueã€‚</li>
<li>æœ‰äº†æ˜ å°„ï¼Œæ‚¨å¯ä»¥æ‰¾åˆ°ç­”æ¡ˆçš„å¼€å§‹å’Œç»“æŸæ ‡è®°ã€‚ä½¿ç”¨sequence_idsæ–¹æ³•æ‰¾å‡ºåç§»é‡çš„å“ªä¸€éƒ¨åˆ†å¯¹åº”äº ï¼Œå“ªä¸€éƒ¨åˆ†questionå¯¹åº”äºcontextã€‚</li>
</ol>
<p>ä»¥ä¸‹æ˜¯å¦‚ä½•åˆ›å»ºä¸€ä¸ªå‡½æ•°æ¥æˆªæ–­å¹¶å°†ç­”æ¡ˆçš„å¼€å§‹å’Œç»“æŸæ ‡è®°æ˜ å°„åˆ°contextï¼š</p>
<pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">preprocess_function</span><span class="token punctuation">(</span>examples<span class="token punctuation">)</span><span class="token punctuation">:</span>
    questions <span class="token operator">=</span> <span class="token punctuation">[</span>q<span class="token punctuation">.</span>strip<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">for</span> q <span class="token keyword">in</span> examples<span class="token punctuation">[</span><span class="token string">"question"</span><span class="token punctuation">]</span><span class="token punctuation">]</span>
    inputs <span class="token operator">=</span> tokenizer<span class="token punctuation">(</span>
        questions<span class="token punctuation">,</span>
        examples<span class="token punctuation">[</span><span class="token string">"context"</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
        max_length<span class="token operator">=</span><span class="token number">384</span><span class="token punctuation">,</span>
        truncation<span class="token operator">=</span><span class="token string">"only_second"</span><span class="token punctuation">,</span>
        return_offsets_mapping<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>
        padding<span class="token operator">=</span><span class="token string">"max_length"</span><span class="token punctuation">,</span>
    <span class="token punctuation">)</span>

    offset_mapping <span class="token operator">=</span> inputs<span class="token punctuation">.</span>pop<span class="token punctuation">(</span><span class="token string">"offset_mapping"</span><span class="token punctuation">)</span>
    answers <span class="token operator">=</span> examples<span class="token punctuation">[</span><span class="token string">"answers"</span><span class="token punctuation">]</span>
    start_positions <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
    end_positions <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>

    <span class="token keyword">for</span> i<span class="token punctuation">,</span> offset <span class="token keyword">in</span> enumerate<span class="token punctuation">(</span>offset_mapping<span class="token punctuation">)</span><span class="token punctuation">:</span>
        answer <span class="token operator">=</span> answers<span class="token punctuation">[</span>i<span class="token punctuation">]</span>
        start_char <span class="token operator">=</span> answer<span class="token punctuation">[</span><span class="token string">"answer_start"</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
        end_char <span class="token operator">=</span> answer<span class="token punctuation">[</span><span class="token string">"answer_start"</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">+</span> len<span class="token punctuation">(</span>answer<span class="token punctuation">[</span><span class="token string">"text"</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
        sequence_ids <span class="token operator">=</span> inputs<span class="token punctuation">.</span>sequence_ids<span class="token punctuation">(</span>i<span class="token punctuation">)</span>

        <span class="token comment" spellcheck="true"># Find the start and end of the context</span>
        idx <span class="token operator">=</span> <span class="token number">0</span>
        <span class="token keyword">while</span> sequence_ids<span class="token punctuation">[</span>idx<span class="token punctuation">]</span> <span class="token operator">!=</span> <span class="token number">1</span><span class="token punctuation">:</span>
            idx <span class="token operator">+=</span> <span class="token number">1</span>
        context_start <span class="token operator">=</span> idx
        <span class="token keyword">while</span> sequence_ids<span class="token punctuation">[</span>idx<span class="token punctuation">]</span> <span class="token operator">==</span> <span class="token number">1</span><span class="token punctuation">:</span>
            idx <span class="token operator">+=</span> <span class="token number">1</span>
        context_end <span class="token operator">=</span> idx <span class="token operator">-</span> <span class="token number">1</span>

        <span class="token comment" spellcheck="true"># If the answer is not fully inside the context, label it (0, 0)</span>
        <span class="token keyword">if</span> offset<span class="token punctuation">[</span>context_start<span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">></span> end_char <span class="token operator">or</span> offset<span class="token punctuation">[</span>context_end<span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">&lt;</span> start_char<span class="token punctuation">:</span>
            start_positions<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span>
            end_positions<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span>
        <span class="token keyword">else</span><span class="token punctuation">:</span>
            <span class="token comment" spellcheck="true"># Otherwise it's the start and end token positions</span>
            idx <span class="token operator">=</span> context_start
            <span class="token keyword">while</span> idx <span class="token operator">&lt;=</span> context_end <span class="token operator">and</span> offset<span class="token punctuation">[</span>idx<span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">&lt;=</span> start_char<span class="token punctuation">:</span>
                idx <span class="token operator">+=</span> <span class="token number">1</span>
            start_positions<span class="token punctuation">.</span>append<span class="token punctuation">(</span>idx <span class="token operator">-</span> <span class="token number">1</span><span class="token punctuation">)</span>

            idx <span class="token operator">=</span> context_end
            <span class="token keyword">while</span> idx <span class="token operator">>=</span> context_start <span class="token operator">and</span> offset<span class="token punctuation">[</span>idx<span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">>=</span> end_char<span class="token punctuation">:</span>
                idx <span class="token operator">-=</span> <span class="token number">1</span>
            end_positions<span class="token punctuation">.</span>append<span class="token punctuation">(</span>idx <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">)</span>

    inputs<span class="token punctuation">[</span><span class="token string">"start_positions"</span><span class="token punctuation">]</span> <span class="token operator">=</span> start_positions
    inputs<span class="token punctuation">[</span><span class="token string">"end_positions"</span><span class="token punctuation">]</span> <span class="token operator">=</span> end_positions
    <span class="token keyword">return</span> inputs<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>ä½¿ç”¨ğŸ¤— Datasets<strong><code>[map](&lt;https://huggingface.co/docs/datasets/package_reference/main_classes.html#datasets.Dataset.map&gt;)</code></strong>å‡½æ•°å°†é¢„å¤„ç†å‡½æ•°åº”ç”¨äºæ•´ä¸ªæ•°æ®é›†ã€‚æ‚¨å¯ä»¥é€šè¿‡è®¾ç½®ä¸€æ¬¡å¤„ç†æ•°æ®é›†çš„å¤šä¸ªå…ƒç´ æ¥åŠ é€Ÿè¯¥<code>map</code>åŠŸèƒ½ã€‚<code>batched=True</code>åˆ é™¤ä¸éœ€è¦çš„åˆ—ï¼š</p>
<pre class="line-numbers language-python"><code class="language-python">tokenized_squad <span class="token operator">=</span> squad<span class="token punctuation">.</span>map<span class="token punctuation">(</span>preprocess_function<span class="token punctuation">,</span> batched<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> remove_columns<span class="token operator">=</span>squad<span class="token punctuation">[</span><span class="token string">"train"</span><span class="token punctuation">]</span><span class="token punctuation">.</span>column_names<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<p>ä½¿ç”¨<strong><a href="https://huggingface.co/docs/transformers/v4.18.0/en/main_classes/data_collator#transformers.DefaultDataCollator" target="_blank" rel="noopener">DefaultDataCollator</a></strong>åˆ›å»ºä¸€æ‰¹ç¤ºä¾‹ã€‚ä¸ğŸ¤— Transformers ä¸­çš„å…¶ä»–æ•°æ®æ•´ç†å™¨ä¸åŒï¼Œ<code>DefaultDataCollator</code>å®ƒä¸åº”ç”¨é¢å¤–çš„é¢„å¤„ç†ï¼Œä¾‹å¦‚å¡«å……ã€‚</p>
<pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">from</span> transformers <span class="token keyword">import</span> DefaultDataCollator

data_collator <span class="token operator">=</span> DefaultDataCollator<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre>
<h2 id="Train-4"><a href="#Train-4" class="headerlink" title="Train"></a>Train</h2><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">from</span> transformers <span class="token keyword">import</span> AutoModelForQuestionAnswering<span class="token punctuation">,</span> TrainingArguments<span class="token punctuation">,</span> Trainer

model <span class="token operator">=</span> AutoModelForQuestionAnswering<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span><span class="token string">"distilbert-base-uncased"</span><span class="token punctuation">)</span>
training_args <span class="token operator">=</span> TrainingArguments<span class="token punctuation">(</span>
    output_dir<span class="token operator">=</span><span class="token string">"./results"</span><span class="token punctuation">,</span>
    evaluation_strategy<span class="token operator">=</span><span class="token string">"epoch"</span><span class="token punctuation">,</span>
    learning_rate<span class="token operator">=</span><span class="token number">2e</span><span class="token operator">-</span><span class="token number">5</span><span class="token punctuation">,</span>
    per_device_train_batch_size<span class="token operator">=</span><span class="token number">16</span><span class="token punctuation">,</span>
    per_device_eval_batch_size<span class="token operator">=</span><span class="token number">16</span><span class="token punctuation">,</span>
    num_train_epochs<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span>
    weight_decay<span class="token operator">=</span><span class="token number">0.01</span><span class="token punctuation">,</span>
<span class="token punctuation">)</span>

trainer <span class="token operator">=</span> Trainer<span class="token punctuation">(</span>
    model<span class="token operator">=</span>model<span class="token punctuation">,</span>
    args<span class="token operator">=</span>training_args<span class="token punctuation">,</span>
    train_dataset<span class="token operator">=</span>tokenized_squad<span class="token punctuation">[</span><span class="token string">"train"</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
    eval_dataset<span class="token operator">=</span>tokenized_squad<span class="token punctuation">[</span><span class="token string">"validation"</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
    tokenizer<span class="token operator">=</span>tokenizer<span class="token punctuation">,</span>
    data_collator<span class="token operator">=</span>data_collator<span class="token punctuation">,</span>
<span class="token punctuation">)</span>

trainer<span class="token punctuation">.</span>train<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<h1 id="Language-modeling"><a href="#Language-modeling" class="headerlink" title="Language modeling"></a>Language modeling</h1><p>è¯­è¨€å»ºæ¨¡é¢„æµ‹å¥å­ä¸­çš„å•è¯ã€‚è¯­è¨€å»ºæ¨¡æœ‰ä¸¤ç§å½¢å¼ã€‚</p>
<ul>
<li>å› æœè¯­è¨€å»ºæ¨¡é¢„æµ‹ä¸€ç³»åˆ—tokenä¸­çš„ä¸‹ä¸€ä¸ªtokenï¼Œæ¨¡å‹åªèƒ½å…³æ³¨å·¦è¾¹çš„tokenã€‚</li>
<li>æ©è”½è¯­è¨€å»ºæ¨¡é¢„æµ‹åºåˆ—ä¸­çš„æ©è”½æ ‡è®°ï¼Œå¹¶ä¸”æ¨¡å‹å¯ä»¥åŒå‘å¤„ç†æ ‡è®°ã€‚</li>
</ul>
<h2 id="åŠ è½½-ELI5-æ•°æ®é›†"><a href="#åŠ è½½-ELI5-æ•°æ®é›†" class="headerlink" title="åŠ è½½ ELI5 æ•°æ®é›†"></a><strong>åŠ è½½ ELI5 æ•°æ®é›†</strong></h2><p>ä»…ä»ğŸ¤— Datasets åº“åŠ è½½ ELI5 æ•°æ®é›†çš„å‰ 5000 è¡Œï¼Œå› ä¸ºå®ƒéå¸¸å¤§ï¼š</p>
<pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">from</span> datasets <span class="token keyword">import</span> load_dataset

eli5 <span class="token operator">=</span> load_dataset<span class="token punctuation">(</span><span class="token string">"eli5"</span><span class="token punctuation">,</span> split<span class="token operator">=</span><span class="token string">"train_asks[:5000]"</span><span class="token punctuation">)</span>

eli5 <span class="token operator">=</span> eli5<span class="token punctuation">.</span>train_test_split<span class="token punctuation">(</span>test_size<span class="token operator">=</span><span class="token number">0.2</span><span class="token punctuation">)</span>
eli5<span class="token punctuation">[</span><span class="token string">"train"</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
<span class="token punctuation">{</span><span class="token string">'answers'</span><span class="token punctuation">:</span> <span class="token punctuation">{</span><span class="token string">'a_id'</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token string">'c3d1aib'</span><span class="token punctuation">,</span> <span class="token string">'c3d4lya'</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
  <span class="token string">'score'</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token number">6</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
  <span class="token string">'text'</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token string">"The velocity needed to remain in orbit is equal to the square root of Newton's constant times the mass of earth divided by the distance from the center of the earth. I don't know the altitude of that specific mission, but they're usually around 300 km. That means he's going 7-8 km/s.\\n\\nIn space there are no other forces acting on either the shuttle or the guy, so they stay in the same position relative to each other. If he were to become unable to return to the ship, he would presumably run out of oxygen, or slowly fall into the atmosphere and burn up."</span><span class="token punctuation">,</span>
   <span class="token string">"Hope you don't mind me asking another question, but why aren't there any stars visible in this photo?"</span><span class="token punctuation">]</span><span class="token punctuation">}</span><span class="token punctuation">,</span>
 <span class="token string">'answers_urls'</span><span class="token punctuation">:</span> <span class="token punctuation">{</span><span class="token string">'url'</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">}</span><span class="token punctuation">,</span>
 <span class="token string">'document'</span><span class="token punctuation">:</span> <span class="token string">''</span><span class="token punctuation">,</span>
 <span class="token string">'q_id'</span><span class="token punctuation">:</span> <span class="token string">'nyxfp'</span><span class="token punctuation">,</span>
 <span class="token string">'selftext'</span><span class="token punctuation">:</span> <span class="token string">'_URL_0_\\n\\nThis was on the front page earlier and I have a few questions about it. Is it possible to calculate how fast the astronaut would be orbiting the earth? Also how does he stay close to the shuttle so that he can return safely, i.e is he orbiting at the same speed and can therefore stay next to it? And finally if his propulsion system failed, would he eventually re-enter the atmosphere and presumably die?'</span><span class="token punctuation">,</span>
 <span class="token string">'selftext_urls'</span><span class="token punctuation">:</span> <span class="token punctuation">{</span><span class="token string">'url'</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token string">'&lt;http://apod.nasa.gov/apod/image/1201/freeflyer_nasa_3000.jpg>'</span><span class="token punctuation">]</span><span class="token punctuation">}</span><span class="token punctuation">,</span>
 <span class="token string">'subreddit'</span><span class="token punctuation">:</span> <span class="token string">'askscience'</span><span class="token punctuation">,</span>
 <span class="token string">'title'</span><span class="token punctuation">:</span> <span class="token string">'Few questions about this space walk photograph.'</span><span class="token punctuation">,</span>
 <span class="token string">'title_urls'</span><span class="token punctuation">:</span> <span class="token punctuation">{</span><span class="token string">'url'</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">}</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<h2 id="é¢„å¤„ç†"><a href="#é¢„å¤„ç†" class="headerlink" title="é¢„å¤„ç†"></a>é¢„å¤„ç†</h2><p>å¯¹äºå› æœè¯­è¨€å»ºæ¨¡ï¼ŒåŠ è½½ DistilGPT2 åˆ†è¯å™¨æ¥å¤„ç†<code>text</code>å­å­—æ®µï¼š</p>
<pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">from</span> transformers <span class="token keyword">import</span> AutoTokenizer

tokenizer <span class="token operator">=</span> AutoTokenizer<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span><span class="token string">"distilgpt2"</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre>
<p>å¯¹äºæ©ç è¯­è¨€å»ºæ¨¡ï¼Œè¯·æ”¹ä¸ºåŠ è½½ DistilRoBERTa æ ‡è®°å™¨ï¼š</p>
<pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">from</span> transformers <span class="token keyword">import</span> AutoTokenizer

tokenizer <span class="token operator">=</span> AutoTokenizer<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span><span class="token string">"distilroberta-base"</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre>
<p><code>text</code>ä½¿ç”¨ä»¥ä¸‹æ–¹æ³•ä»å…¶åµŒå¥—ç»“æ„ä¸­æå–å­å­—æ®µ<strong><code>[flatten](&lt;https://huggingface.co/docs/datasets/process.html#flatten&gt;)</code></strong>ï¼š</p>
<pre class="line-numbers language-python"><code class="language-python">eli5 <span class="token operator">=</span> eli5<span class="token punctuation">.</span>flatten<span class="token punctuation">(</span><span class="token punctuation">)</span>
eli5<span class="token punctuation">[</span><span class="token string">"train"</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
<span class="token punctuation">{</span><span class="token string">'answers.a_id'</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token string">'c3d1aib'</span><span class="token punctuation">,</span> <span class="token string">'c3d4lya'</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
 <span class="token string">'answers.score'</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token number">6</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
 <span class="token string">'answers.text'</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token string">"The velocity needed to remain in orbit is equal to the square root of Newton's constant times the mass of earth divided by the distance from the center of the earth. I don't know the altitude of that specific mission, but they're usually around 300 km. That means he's going 7-8 km/s.\\n\\nIn space there are no other forces acting on either the shuttle or the guy, so they stay in the same position relative to each other. If he were to become unable to return to the ship, he would presumably run out of oxygen, or slowly fall into the atmosphere and burn up."</span><span class="token punctuation">,</span>
  <span class="token string">"Hope you don't mind me asking another question, but why aren't there any stars visible in this photo?"</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
 <span class="token string">'answers_urls.url'</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
 <span class="token string">'document'</span><span class="token punctuation">:</span> <span class="token string">''</span><span class="token punctuation">,</span>
 <span class="token string">'q_id'</span><span class="token punctuation">:</span> <span class="token string">'nyxfp'</span><span class="token punctuation">,</span>
 <span class="token string">'selftext'</span><span class="token punctuation">:</span> <span class="token string">'_URL_0_\\n\\nThis was on the front page earlier and I have a few questions about it. Is it possible to calculate how fast the astronaut would be orbiting the earth? Also how does he stay close to the shuttle so that he can return safely, i.e is he orbiting at the same speed and can therefore stay next to it? And finally if his propulsion system failed, would he eventually re-enter the atmosphere and presumably die?'</span><span class="token punctuation">,</span>
 <span class="token string">'selftext_urls.url'</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token string">'&lt;http://apod.nasa.gov/apod/image/1201/freeflyer_nasa_3000.jpg>'</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
 <span class="token string">'subreddit'</span><span class="token punctuation">:</span> <span class="token string">'askscience'</span><span class="token punctuation">,</span>
 <span class="token string">'title'</span><span class="token punctuation">:</span> <span class="token string">'Few questions about this space walk photograph.'</span><span class="token punctuation">,</span>
 <span class="token string">'title_urls.url'</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>æ¯ä¸ªå­å­—æ®µç°åœ¨éƒ½æ˜¯ä¸€ä¸ªå•ç‹¬çš„åˆ—ï¼Œå¦‚<code>answers</code>å‰ç¼€æ‰€ç¤ºã€‚è¯·æ³¨æ„ï¼Œè¿™<code>answers.text</code>æ˜¯ä¸€ä¸ªåˆ—è¡¨ã€‚ä¸æ˜¯å•ç‹¬æ ‡è®°æ¯ä¸ªå¥å­ï¼Œè€Œæ˜¯å°†åˆ—è¡¨è½¬æ¢ä¸ºå­—ç¬¦ä¸²ä»¥è”åˆæ ‡è®°å®ƒä»¬ã€‚</p>
<pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">preprocess_function</span><span class="token punctuation">(</span>examples<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">return</span> tokenizer<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token string">" "</span><span class="token punctuation">.</span>join<span class="token punctuation">(</span>x<span class="token punctuation">)</span> <span class="token keyword">for</span> x <span class="token keyword">in</span> examples<span class="token punctuation">[</span><span class="token string">"answers.text"</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span> truncation<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>
<p>ä½¿ç”¨ğŸ¤— Datasets<strong><code>[map](&lt;https://huggingface.co/docs/datasets/package_reference/main_classes.html#datasets.Dataset.map&gt;)</code></strong>å‡½æ•°å°†é¢„å¤„ç†å‡½æ•°åº”ç”¨äºæ•´ä¸ªæ•°æ®é›†ã€‚æ‚¨å¯ä»¥<code>map</code>é€šè¿‡è®¾ç½®<code>batched=True</code>ä¸€æ¬¡å¤„ç†æ•°æ®é›†çš„å¤šä¸ªå…ƒç´ å¹¶ä½¿ç”¨<code>num_proc</code>. åˆ é™¤ä¸éœ€è¦çš„åˆ—ï¼š</p>
<pre class="line-numbers language-python"><code class="language-python">tokenized_eli5 <span class="token operator">=</span> eli5<span class="token punctuation">.</span>map<span class="token punctuation">(</span>
    preprocess_function<span class="token punctuation">,</span>
    batched<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>
    num_proc<span class="token operator">=</span><span class="token number">4</span><span class="token punctuation">,</span>
    remove_columns<span class="token operator">=</span>eli5<span class="token punctuation">[</span><span class="token string">"train"</span><span class="token punctuation">]</span><span class="token punctuation">.</span>column_names<span class="token punctuation">,</span>
<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>ç°åœ¨æ‚¨éœ€è¦ç¬¬äºŒä¸ªé¢„å¤„ç†å‡½æ•°æ¥æ•è·ä»ä»»ä½•å†—é•¿ç¤ºä¾‹ä¸­æˆªæ–­çš„æ–‡æœ¬ï¼Œä»¥é˜²æ­¢ä¿¡æ¯ä¸¢å¤±ã€‚è¿™ä¸ªé¢„å¤„ç†å‡½æ•°åº”è¯¥ï¼š</p>
<ul>
<li>è¿æ¥æ‰€æœ‰æ–‡æœ¬ã€‚</li>
<li>å°†è¿æ¥çš„æ–‡æœ¬æ‹†åˆ†ä¸ºç”±<code>block_size</code></li>
</ul>
<pre class="line-numbers language-python"><code class="language-python">block_size <span class="token operator">=</span> <span class="token number">128</span>

<span class="token keyword">def</span> <span class="token function">group_texts</span><span class="token punctuation">(</span>examples<span class="token punctuation">)</span><span class="token punctuation">:</span>
    concatenated_examples <span class="token operator">=</span> <span class="token punctuation">{</span>k<span class="token punctuation">:</span> sum<span class="token punctuation">(</span>examples<span class="token punctuation">[</span>k<span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token keyword">for</span> k <span class="token keyword">in</span> examples<span class="token punctuation">.</span>keys<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">}</span>
    total_length <span class="token operator">=</span> len<span class="token punctuation">(</span>concatenated_examples<span class="token punctuation">[</span>list<span class="token punctuation">(</span>examples<span class="token punctuation">.</span>keys<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
    result <span class="token operator">=</span> <span class="token punctuation">{</span>
        k<span class="token punctuation">:</span> <span class="token punctuation">[</span>t<span class="token punctuation">[</span>i <span class="token punctuation">:</span> i <span class="token operator">+</span> block_size<span class="token punctuation">]</span> <span class="token keyword">for</span> i <span class="token keyword">in</span> range<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> total_length<span class="token punctuation">,</span> block_size<span class="token punctuation">)</span><span class="token punctuation">]</span>
        <span class="token keyword">for</span> k<span class="token punctuation">,</span> t <span class="token keyword">in</span> concatenated_examples<span class="token punctuation">.</span>items<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token punctuation">}</span>
    result<span class="token punctuation">[</span><span class="token string">"labels"</span><span class="token punctuation">]</span> <span class="token operator">=</span> result<span class="token punctuation">[</span><span class="token string">"input_ids"</span><span class="token punctuation">]</span><span class="token punctuation">.</span>copy<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token keyword">return</span> result<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>å°†<code>group_texts</code>å‡½æ•°åº”ç”¨äºæ•´ä¸ªæ•°æ®é›†ï¼š</p>
<pre class="line-numbers language-python"><code class="language-python">lm_dataset <span class="token operator">=</span> tokenized_eli5<span class="token punctuation">.</span>map<span class="token punctuation">(</span>group_texts<span class="token punctuation">,</span> batched<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> num_proc<span class="token operator">=</span><span class="token number">4</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<p>å¯ä»¥ä½¿ç”¨åºåˆ—ç»“æŸæ ‡è®°ä½œä¸ºå¡«å……æ ‡è®°ï¼Œå¹¶è®¾ç½®<code>mlm=False</code>. è¿™å°†ä½¿ç”¨è¾“å…¥ä½œä¸ºå‘å³ç§»åŠ¨ä¸€ä¸ªå…ƒç´ çš„æ ‡ç­¾ï¼š</p>
<pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">from</span> transformers <span class="token keyword">import</span> DataCollatorForLanguageModeling

tokenizer<span class="token punctuation">.</span>pad_token <span class="token operator">=</span> tokenizer<span class="token punctuation">.</span>eos_token
data_collator <span class="token operator">=</span> DataCollatorForLanguageModeling<span class="token punctuation">(</span>tokenizer<span class="token operator">=</span>tokenizer<span class="token punctuation">,</span> mlm<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre>
<p>å¯¹äºæ©ç è¯­è¨€å»ºæ¨¡ï¼Œè¯·ä½¿ç”¨ç›¸åŒçš„<strong><a href="https://huggingface.co/docs/transformers/v4.18.0/en/main_classes/data_collator#transformers.DataCollatorForLanguageModeling" target="_blank" rel="noopener">DataCollatorForLanguageModeling</a></strong> ï¼Œé™¤éæ‚¨åº”æŒ‡å®š<code>mlm_probability</code>åœ¨æ¯æ¬¡è¿­ä»£æ•°æ®æ—¶éšæœºæ©ç æ ‡è®°ã€‚</p>
<pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">from</span> transformers <span class="token keyword">import</span> DataCollatorForLanguageModeling

tokenizer<span class="token punctuation">.</span>pad_token <span class="token operator">=</span> tokenizer<span class="token punctuation">.</span>eos_token
data_collator <span class="token operator">=</span> DataCollatorForLanguageModeling<span class="token punctuation">(</span>tokenizer<span class="token operator">=</span>tokenizer<span class="token punctuation">,</span> mlm_probability<span class="token operator">=</span><span class="token number">0.15</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre>
<h2 id="è®­ç»ƒ"><a href="#è®­ç»ƒ" class="headerlink" title="è®­ç»ƒ"></a>è®­ç»ƒ</h2><p>å› æœè¯­è¨€å»ºæ¨¡</p>
<pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">from</span> transformers <span class="token keyword">import</span> AutoModelForCausalLM<span class="token punctuation">,</span> TrainingArguments<span class="token punctuation">,</span> Trainer

model <span class="token operator">=</span> AutoModelForCausalLM<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span><span class="token string">"distilgpt2"</span><span class="token punctuation">)</span>
training_args <span class="token operator">=</span> TrainingArguments<span class="token punctuation">(</span>
    output_dir<span class="token operator">=</span><span class="token string">"./results"</span><span class="token punctuation">,</span>
    evaluation_strategy<span class="token operator">=</span><span class="token string">"epoch"</span><span class="token punctuation">,</span>
    learning_rate<span class="token operator">=</span><span class="token number">2e</span><span class="token operator">-</span><span class="token number">5</span><span class="token punctuation">,</span>
    weight_decay<span class="token operator">=</span><span class="token number">0.01</span><span class="token punctuation">,</span>
<span class="token punctuation">)</span>

trainer <span class="token operator">=</span> Trainer<span class="token punctuation">(</span>
    model<span class="token operator">=</span>model<span class="token punctuation">,</span>
    args<span class="token operator">=</span>training_args<span class="token punctuation">,</span>
    train_dataset<span class="token operator">=</span>lm_dataset<span class="token punctuation">[</span><span class="token string">"train"</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
    eval_dataset<span class="token operator">=</span>lm_dataset<span class="token punctuation">[</span><span class="token string">"test"</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
    data_collator<span class="token operator">=</span>data_collator<span class="token punctuation">,</span>
<span class="token punctuation">)</span>

trainer<span class="token punctuation">.</span>train<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>æ©è”½è¯­è¨€å»ºæ¨¡</p>
<pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">from</span> transformers <span class="token keyword">import</span> AutoModelForMaskedLM

model <span class="token operator">=</span> AutoModelForMaskedLM<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span><span class="token string">"distilroberta-base"</span><span class="token punctuation">)</span>
training_args <span class="token operator">=</span> TrainingArguments<span class="token punctuation">(</span>
    output_dir<span class="token operator">=</span><span class="token string">"./results"</span><span class="token punctuation">,</span>
    evaluation_strategy<span class="token operator">=</span><span class="token string">"epoch"</span><span class="token punctuation">,</span>
    learning_rate<span class="token operator">=</span><span class="token number">2e</span><span class="token operator">-</span><span class="token number">5</span><span class="token punctuation">,</span>
    num_train_epochs<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span>
    weight_decay<span class="token operator">=</span><span class="token number">0.01</span><span class="token punctuation">,</span>
<span class="token punctuation">)</span>

trainer <span class="token operator">=</span> Trainer<span class="token punctuation">(</span>
    model<span class="token operator">=</span>model<span class="token punctuation">,</span>
    args<span class="token operator">=</span>training_args<span class="token punctuation">,</span>
    train_dataset<span class="token operator">=</span>lm_dataset<span class="token punctuation">[</span><span class="token string">"train"</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
    eval_dataset<span class="token operator">=</span>lm_dataset<span class="token punctuation">[</span><span class="token string">"test"</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
    data_collator<span class="token operator">=</span>data_collator<span class="token punctuation">,</span>
<span class="token punctuation">)</span>

trainer<span class="token punctuation">.</span>train<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<h1 id="Translation"><a href="#Translation" class="headerlink" title="Translation"></a>Translation</h1><p>ç¿»è¯‘å°†ä¸€ç³»åˆ—æ–‡æœ¬ä»ä¸€ç§è¯­è¨€è½¬æ¢ä¸ºå¦ä¸€ç§è¯­è¨€ã€‚å®ƒæ˜¯æ‚¨å¯ä»¥åˆ¶å®šä¸ºåºåˆ—åˆ°åºåˆ—é—®é¢˜çš„å‡ ä¸ªä»»åŠ¡ä¹‹ä¸€ï¼Œè¿™æ˜¯ä¸€ä¸ªæ‰©å±•åˆ°è§†è§‰å’ŒéŸ³é¢‘ä»»åŠ¡çš„å¼ºå¤§æ¡†æ¶ã€‚</p>
<h2 id="åŠ è½½-OPUS-Books-æ•°æ®é›†"><a href="#åŠ è½½-OPUS-Books-æ•°æ®é›†" class="headerlink" title="åŠ è½½ OPUS Books æ•°æ®é›†"></a><strong>åŠ è½½ OPUS Books æ•°æ®é›†</strong></h2><p>ä»ğŸ¤— Datasets åº“åŠ è½½ OPUS Books æ•°æ®é›†ï¼š</p>
<pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">from</span> datasets <span class="token keyword">import</span> load_dataset

books <span class="token operator">=</span> load_dataset<span class="token punctuation">(</span><span class="token string">"opus_books"</span><span class="token punctuation">,</span> <span class="token string">"en-fr"</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre>
<p>å°†æ­¤æ•°æ®é›†æ‹†åˆ†ä¸ºè®­ç»ƒé›†å’Œæµ‹è¯•é›†ï¼š</p>
<pre class="line-numbers language-python"><code class="language-python">books <span class="token operator">=</span> books<span class="token punctuation">[</span><span class="token string">"train"</span><span class="token punctuation">]</span><span class="token punctuation">.</span>train_test_split<span class="token punctuation">(</span>test_size<span class="token operator">=</span><span class="token number">0.2</span><span class="token punctuation">)</span>
books<span class="token punctuation">[</span><span class="token string">"train"</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
<span class="token punctuation">{</span><span class="token string">'id'</span><span class="token punctuation">:</span> <span class="token string">'90560'</span><span class="token punctuation">,</span>
 <span class="token string">'translation'</span><span class="token punctuation">:</span> <span class="token punctuation">{</span><span class="token string">'en'</span><span class="token punctuation">:</span> <span class="token string">'But this lofty plateau measured only a few fathoms, and soon we reentered Our Element.'</span><span class="token punctuation">,</span>
  <span class="token string">'fr'</span><span class="token punctuation">:</span> <span class="token string">'Mais ce plateau Ã©levÃ© ne mesurait que quelques toises, et bientÃ´t nous fÃ»mes rentrÃ©s dans notre Ã©lÃ©ment.'</span><span class="token punctuation">}</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<h2 id="é¢„å¤„ç†-1"><a href="#é¢„å¤„ç†-1" class="headerlink" title="é¢„å¤„ç†"></a>é¢„å¤„ç†</h2><p>åŠ è½½ T5 æ ‡è®°å™¨ä»¥å¤„ç†è¯­è¨€å¯¹ï¼š</p>
<pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">from</span> transformers <span class="token keyword">import</span> AutoTokenizer

tokenizer <span class="token operator">=</span> AutoTokenizer<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span><span class="token string">"t5-small"</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre>
<p>é¢„å¤„ç†åŠŸèƒ½éœ€è¦ï¼š</p>
<ol>
<li>åœ¨è¾“å…¥å‰åŠ ä¸Šä¸€ä¸ªæç¤ºï¼Œä»¥ä¾¿ T5 çŸ¥é“è¿™æ˜¯ä¸€ä¸ªç¿»è¯‘ä»»åŠ¡ã€‚ä¸€äº›èƒ½å¤Ÿæ‰§è¡Œå¤šä¸ª NLP ä»»åŠ¡çš„æ¨¡å‹éœ€è¦æç¤ºç‰¹å®šä»»åŠ¡ã€‚</li>
<li>åˆ†åˆ«æ ‡è®°è¾“å…¥ï¼ˆè‹±è¯­ï¼‰å’Œç›®æ ‡ï¼ˆæ³•è¯­ï¼‰ã€‚æ‚¨æ— æ³•ä½¿ç”¨åœ¨è‹±è¯­è¯æ±‡ä¸Šé¢„è®­ç»ƒçš„åˆ†è¯å™¨å¯¹æ³•è¯­æ–‡æœ¬è¿›è¡Œåˆ†è¯ã€‚ä¸Šä¸‹æ–‡ç®¡ç†å™¨å°†å¸®åŠ©å…ˆå°†æ ‡è®°å™¨è®¾ç½®ä¸ºæ³•è¯­ï¼Œç„¶åå†å¯¹å…¶è¿›è¡Œæ ‡è®°ã€‚</li>
<li>å°†åºåˆ—æˆªæ–­ä¸ºä¸è¶…è¿‡<code>max_length</code>å‚æ•°è®¾ç½®çš„æœ€å¤§é•¿åº¦ã€‚</li>
</ol>
<pre class="line-numbers language-python"><code class="language-python">source_lang <span class="token operator">=</span> <span class="token string">"en"</span>
target_lang <span class="token operator">=</span> <span class="token string">"fr"</span>
prefix <span class="token operator">=</span> <span class="token string">"translate English to French: "</span>

<span class="token keyword">def</span> <span class="token function">preprocess_function</span><span class="token punctuation">(</span>examples<span class="token punctuation">)</span><span class="token punctuation">:</span>
    inputs <span class="token operator">=</span> <span class="token punctuation">[</span>prefix <span class="token operator">+</span> example<span class="token punctuation">[</span>source_lang<span class="token punctuation">]</span> <span class="token keyword">for</span> example <span class="token keyword">in</span> examples<span class="token punctuation">[</span><span class="token string">"translation"</span><span class="token punctuation">]</span><span class="token punctuation">]</span>
    targets <span class="token operator">=</span> <span class="token punctuation">[</span>example<span class="token punctuation">[</span>target_lang<span class="token punctuation">]</span> <span class="token keyword">for</span> example <span class="token keyword">in</span> examples<span class="token punctuation">[</span><span class="token string">"translation"</span><span class="token punctuation">]</span><span class="token punctuation">]</span>
    model_inputs <span class="token operator">=</span> tokenizer<span class="token punctuation">(</span>inputs<span class="token punctuation">,</span> max_length<span class="token operator">=</span><span class="token number">128</span><span class="token punctuation">,</span> truncation<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>

    <span class="token keyword">with</span> tokenizer<span class="token punctuation">.</span>as_target_tokenizer<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        labels <span class="token operator">=</span> tokenizer<span class="token punctuation">(</span>targets<span class="token punctuation">,</span> max_length<span class="token operator">=</span><span class="token number">128</span><span class="token punctuation">,</span> truncation<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>

    model_inputs<span class="token punctuation">[</span><span class="token string">"labels"</span><span class="token punctuation">]</span> <span class="token operator">=</span> labels<span class="token punctuation">[</span><span class="token string">"input_ids"</span><span class="token punctuation">]</span>
    <span class="token keyword">return</span> model_inputs
tokenized_books <span class="token operator">=</span> books<span class="token punctuation">.</span>map<span class="token punctuation">(</span>preprocess_function<span class="token punctuation">,</span> batched<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
<span class="token keyword">from</span> transformers <span class="token keyword">import</span> DataCollatorForSeq2Seq

data_collator <span class="token operator">=</span> DataCollatorForSeq2Seq<span class="token punctuation">(</span>tokenizer<span class="token operator">=</span>tokenizer<span class="token punctuation">,</span> model<span class="token operator">=</span>model<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<h2 id="è®­ç»ƒ-1"><a href="#è®­ç»ƒ-1" class="headerlink" title="è®­ç»ƒ"></a>è®­ç»ƒ</h2><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">from</span> transformers <span class="token keyword">import</span> AutoModelForSeq2SeqLM<span class="token punctuation">,</span> Seq2SeqTrainingArguments<span class="token punctuation">,</span> Seq2SeqTrainer

model <span class="token operator">=</span> AutoModelForSeq2SeqLM<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span><span class="token string">"t5-small"</span><span class="token punctuation">)</span>
training_args <span class="token operator">=</span> Seq2SeqTrainingArguments<span class="token punctuation">(</span>
    output_dir<span class="token operator">=</span><span class="token string">"./results"</span><span class="token punctuation">,</span>
    evaluation_strategy<span class="token operator">=</span><span class="token string">"epoch"</span><span class="token punctuation">,</span>
    learning_rate<span class="token operator">=</span><span class="token number">2e</span><span class="token operator">-</span><span class="token number">5</span><span class="token punctuation">,</span>
    per_device_train_batch_size<span class="token operator">=</span><span class="token number">16</span><span class="token punctuation">,</span>
    per_device_eval_batch_size<span class="token operator">=</span><span class="token number">16</span><span class="token punctuation">,</span>
    weight_decay<span class="token operator">=</span><span class="token number">0.01</span><span class="token punctuation">,</span>
    save_total_limit<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span>
    num_train_epochs<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span>
    fp16<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>
<span class="token punctuation">)</span>

trainer <span class="token operator">=</span> Seq2SeqTrainer<span class="token punctuation">(</span>
    model<span class="token operator">=</span>model<span class="token punctuation">,</span>
    args<span class="token operator">=</span>training_args<span class="token punctuation">,</span>
    train_dataset<span class="token operator">=</span>tokenized_books<span class="token punctuation">[</span><span class="token string">"train"</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
    eval_dataset<span class="token operator">=</span>tokenized_books<span class="token punctuation">[</span><span class="token string">"test"</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
    tokenizer<span class="token operator">=</span>tokenizer<span class="token punctuation">,</span>
    data_collator<span class="token operator">=</span>data_collator<span class="token punctuation">,</span>
<span class="token punctuation">)</span>

trainer<span class="token punctuation">.</span>train<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<h1 id="Summarization"><a href="#Summarization" class="headerlink" title="Summarization"></a>Summarization</h1><p>æ‘˜è¦åˆ›å»ºäº†ä¸€ä¸ªè¾ƒçŸ­ç‰ˆæœ¬çš„æ–‡æ¡£æˆ–æ–‡ç« ï¼Œå…¶ä¸­åŒ…å«æ‰€æœ‰é‡è¦ä¿¡æ¯ã€‚é™¤äº†ç¿»è¯‘ä¹‹å¤–ï¼Œå®ƒæ˜¯å¦ä¸€ä¸ªå¯ä»¥è¡¨è¿°ä¸ºåºåˆ—åˆ°åºåˆ—ä»»åŠ¡çš„ä»»åŠ¡ç¤ºä¾‹ã€‚æ€»ç»“å¯ä»¥æ˜¯ï¼š</p>
<ul>
<li>æå–ï¼šä»æ–‡æ¡£ä¸­æå–æœ€ç›¸å…³çš„ä¿¡æ¯ã€‚</li>
<li>æŠ½è±¡çš„ï¼šç”Ÿæˆæ•è·æœ€ç›¸å…³ä¿¡æ¯çš„æ–°æ–‡æœ¬ã€‚</li>
</ul>
<h2 id="åŠ è½½-BillSum-æ•°æ®é›†"><a href="#åŠ è½½-BillSum-æ•°æ®é›†" class="headerlink" title="åŠ è½½ BillSum æ•°æ®é›†"></a><strong>åŠ è½½ BillSum æ•°æ®é›†</strong></h2><p>ä»ğŸ¤— Datasets åº“åŠ è½½ BillSum æ•°æ®é›†ï¼š</p>
<pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">from</span> datasets <span class="token keyword">import</span> load_dataset

billsum <span class="token operator">=</span> load_dataset<span class="token punctuation">(</span><span class="token string">"billsum"</span><span class="token punctuation">,</span> split<span class="token operator">=</span><span class="token string">"ca_test"</span><span class="token punctuation">)</span>
billsum <span class="token operator">=</span> billsum<span class="token punctuation">.</span>train_test_split<span class="token punctuation">(</span>test_size<span class="token operator">=</span><span class="token number">0.2</span><span class="token punctuation">)</span>
billsum<span class="token punctuation">[</span><span class="token string">"train"</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
<span class="token punctuation">{</span><span class="token string">'summary'</span><span class="token punctuation">:</span> <span class="token string">'Existing law authorizes state agencies to enter into contracts for the acquisition of goods or services upon approval by the Department of General Services. Existing law sets forth various requirements and prohibitions for those contracts, including, but not limited to, a prohibition on entering into contracts for the acquisition of goods or services of $100,000 or more with a contractor that discriminates between spouses and domestic partners or same-sex and different-sex couples in the provision of benefits. Existing law provides that a contract entered into in violation of those requirements and prohibitions is void and authorizes the state or any person acting on behalf of the state to bring a civil action seeking a determination that a contract is in violation and therefore void. Under existing law, a willful violation of those requirements and prohibitions is a misdemeanor.\\nThis bill would also prohibit a state agency from entering into contracts for the acquisition of goods or services of $100,000 or more with a contractor that discriminates between employees on the basis of gender identity in the provision of benefits, as specified. By expanding the scope of a crime, this bill would impose a state-mandated local program.\\nThe California Constitution requires the state to reimburse local agencies and school districts for certain costs mandated by the state. Statutory provisions establish procedures for making that reimbursement.\\nThis bill would provide that no reimbursement is required by this act for a specified reason.'</span><span class="token punctuation">,</span>
 <span class="token string">'text'</span><span class="token punctuation">:</span> 'The people of the State of California do enact <span class="token keyword">as</span> follows<span class="token punctuation">:</span>\\n\\n\\nSECTION <span class="token number">1</span><span class="token punctuation">.</span>\\nSection <span class="token number">10295.35</span> <span class="token keyword">is</span> added to the Public Contract Code<span class="token punctuation">,</span> to read<span class="token punctuation">:</span>\\n10295<span class="token number">.35</span><span class="token punctuation">.</span>\\n<span class="token punctuation">(</span>a<span class="token punctuation">)</span> <span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span> Notwithstanding any other law<span class="token punctuation">,</span> a state agency shall <span class="token operator">not</span> enter into any contract <span class="token keyword">for</span> the acquisition of goods <span class="token operator">or</span> services <span class="token keyword">in</span> the amount of one hundred thousand dollars <span class="token punctuation">(</span>$<span class="token number">100</span><span class="token punctuation">,</span><span class="token number">000</span><span class="token punctuation">)</span> <span class="token operator">or</span> more wi<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p><code>text</code>å­—æ®µæ˜¯è¾“å…¥ï¼Œå­—æ®µ<code>summary</code>æ˜¯ç›®æ ‡ã€‚</p>
<h2 id="é¢„å¤„ç†-2"><a href="#é¢„å¤„ç†-2" class="headerlink" title="é¢„å¤„ç†"></a><strong>é¢„å¤„ç†</strong></h2><p>åŠ è½½ T5 æ ‡è®°å™¨ä»¥å¤„ç†<code>text</code>å’Œ<code>summary</code>ï¼š</p>
<pre><code>from transformers import AutoTokenizer

tokenizer = AutoTokenizer.from_pretrained("t5-small")</code></pre><p>é¢„å¤„ç†åŠŸèƒ½éœ€è¦ï¼š</p>
<ol>
<li>åœ¨è¾“å…¥å‰åŠ ä¸Šä¸€ä¸ªæç¤ºï¼Œä»¥ä¾¿ T5 çŸ¥é“è¿™æ˜¯ä¸€ä¸ªæ±‡æ€»ä»»åŠ¡ã€‚ä¸€äº›èƒ½å¤Ÿæ‰§è¡Œå¤šä¸ª NLP ä»»åŠ¡çš„æ¨¡å‹éœ€è¦æç¤ºç‰¹å®šä»»åŠ¡ã€‚</li>
<li>ä½¿ç”¨å…·æœ‰è¯¥<code>as_target_tokenizer()</code>åŠŸèƒ½çš„ä¸Šä¸‹æ–‡ç®¡ç†å™¨æ¥å¹¶è¡ŒåŒ–è¾“å…¥å’Œæ ‡ç­¾çš„æ ‡è®°åŒ–ã€‚</li>
<li>å°†åºåˆ—æˆªæ–­ä¸ºä¸è¶…è¿‡<code>max_length</code>å‚æ•°è®¾ç½®çš„æœ€å¤§é•¿åº¦ã€‚</li>
</ol>
<pre class="line-numbers language-python"><code class="language-python">prefix <span class="token operator">=</span> <span class="token string">"summarize: "</span>

<span class="token keyword">def</span> <span class="token function">preprocess_function</span><span class="token punctuation">(</span>examples<span class="token punctuation">)</span><span class="token punctuation">:</span>
    inputs <span class="token operator">=</span> <span class="token punctuation">[</span>prefix <span class="token operator">+</span> doc <span class="token keyword">for</span> doc <span class="token keyword">in</span> examples<span class="token punctuation">[</span><span class="token string">"text"</span><span class="token punctuation">]</span><span class="token punctuation">]</span>
    model_inputs <span class="token operator">=</span> tokenizer<span class="token punctuation">(</span>inputs<span class="token punctuation">,</span> max_length<span class="token operator">=</span><span class="token number">1024</span><span class="token punctuation">,</span> truncation<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>

    <span class="token keyword">with</span> tokenizer<span class="token punctuation">.</span>as_target_tokenizer<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        labels <span class="token operator">=</span> tokenizer<span class="token punctuation">(</span>examples<span class="token punctuation">[</span><span class="token string">"summary"</span><span class="token punctuation">]</span><span class="token punctuation">,</span> max_length<span class="token operator">=</span><span class="token number">128</span><span class="token punctuation">,</span> truncation<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>

    model_inputs<span class="token punctuation">[</span><span class="token string">"labels"</span><span class="token punctuation">]</span> <span class="token operator">=</span> labels<span class="token punctuation">[</span><span class="token string">"input_ids"</span><span class="token punctuation">]</span>
    <span class="token keyword">return</span> model_inputs
tokenized_billsum <span class="token operator">=</span> billsum<span class="token punctuation">.</span>map<span class="token punctuation">(</span>preprocess_function<span class="token punctuation">,</span> batched<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
<span class="token keyword">from</span> transformers <span class="token keyword">import</span> DataCollatorForSeq2Seq

data_collator <span class="token operator">=</span> DataCollatorForSeq2Seq<span class="token punctuation">(</span>tokenizer<span class="token operator">=</span>tokenizer<span class="token punctuation">,</span> model<span class="token operator">=</span>model<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<h2 id="è®­ç»ƒ-2"><a href="#è®­ç»ƒ-2" class="headerlink" title="è®­ç»ƒ"></a>è®­ç»ƒ</h2><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">from</span> transformers <span class="token keyword">import</span> AutoModelForSeq2SeqLM<span class="token punctuation">,</span> Seq2SeqTrainingArguments<span class="token punctuation">,</span> Seq2SeqTrainer

model <span class="token operator">=</span> AutoModelForSeq2SeqLM<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span><span class="token string">"t5-small"</span><span class="token punctuation">)</span>
training_args <span class="token operator">=</span> Seq2SeqTrainingArguments<span class="token punctuation">(</span>
    output_dir<span class="token operator">=</span><span class="token string">"./results"</span><span class="token punctuation">,</span>
    evaluation_strategy<span class="token operator">=</span><span class="token string">"epoch"</span><span class="token punctuation">,</span>
    learning_rate<span class="token operator">=</span><span class="token number">2e</span><span class="token operator">-</span><span class="token number">5</span><span class="token punctuation">,</span>
    per_device_train_batch_size<span class="token operator">=</span><span class="token number">16</span><span class="token punctuation">,</span>
    per_device_eval_batch_size<span class="token operator">=</span><span class="token number">16</span><span class="token punctuation">,</span>
    weight_decay<span class="token operator">=</span><span class="token number">0.01</span><span class="token punctuation">,</span>
    save_total_limit<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span>
    num_train_epochs<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span>
    fp16<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>
<span class="token punctuation">)</span>

trainer <span class="token operator">=</span> Seq2SeqTrainer<span class="token punctuation">(</span>
    model<span class="token operator">=</span>model<span class="token punctuation">,</span>
    args<span class="token operator">=</span>training_args<span class="token punctuation">,</span>
    train_dataset<span class="token operator">=</span>tokenized_billsum<span class="token punctuation">[</span><span class="token string">"train"</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
    eval_dataset<span class="token operator">=</span>tokenized_billsum<span class="token punctuation">[</span><span class="token string">"test"</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
    tokenizer<span class="token operator">=</span>tokenizer<span class="token punctuation">,</span>
    data_collator<span class="token operator">=</span>data_collator<span class="token punctuation">,</span>
<span class="token punctuation">)</span>

trainer<span class="token punctuation">.</span>train<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<h1 id="Multiple-choice"><a href="#Multiple-choice" class="headerlink" title="Multiple choice"></a>Multiple choice</h1><p>å¤šé¡¹é€‰æ‹©ä»»åŠ¡ç±»ä¼¼äºé—®ç­”ï¼Œé™¤äº†æä¾›å‡ ä¸ªå€™é€‰ç­”æ¡ˆä»¥åŠä¸Šä¸‹æ–‡ã€‚è¯¥æ¨¡å‹ç»è¿‡è®­ç»ƒï¼Œå¯ä»¥ä»ç»™å®šä¸Šä¸‹æ–‡çš„å¤šä¸ªè¾“å…¥ä¸­é€‰æ‹©æ­£ç¡®ç­”æ¡ˆã€‚</p>
<h2 id="åŠ è½½-SWAG-æ•°æ®é›†"><a href="#åŠ è½½-SWAG-æ•°æ®é›†" class="headerlink" title="åŠ è½½ SWAG æ•°æ®é›†"></a><strong>åŠ è½½ SWAG æ•°æ®é›†</strong></h2><p>ä»ğŸ¤— Datasets åº“åŠ è½½ SWAG æ•°æ®é›†ï¼š</p>
<pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">from</span> datasets <span class="token keyword">import</span> load_dataset

swag <span class="token operator">=</span> load_dataset<span class="token punctuation">(</span><span class="token string">"swag"</span><span class="token punctuation">,</span> <span class="token string">"regular"</span><span class="token punctuation">)</span>
swag<span class="token punctuation">[</span><span class="token string">"train"</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
<span class="token punctuation">{</span><span class="token string">'ending0'</span><span class="token punctuation">:</span> <span class="token string">'passes by walking down the street playing their instruments.'</span><span class="token punctuation">,</span>
 <span class="token string">'ending1'</span><span class="token punctuation">:</span> <span class="token string">'has heard approaching them.'</span><span class="token punctuation">,</span>
 <span class="token string">'ending2'</span><span class="token punctuation">:</span> <span class="token string">"arrives and they're outside dancing and asleep."</span><span class="token punctuation">,</span>
 <span class="token string">'ending3'</span><span class="token punctuation">:</span> <span class="token string">'turns the lead singer watches the performance.'</span><span class="token punctuation">,</span>
 <span class="token string">'fold-ind'</span><span class="token punctuation">:</span> <span class="token string">'3416'</span><span class="token punctuation">,</span>
 <span class="token string">'gold-source'</span><span class="token punctuation">:</span> <span class="token string">'gold'</span><span class="token punctuation">,</span>
 <span class="token string">'label'</span><span class="token punctuation">:</span> <span class="token number">0</span><span class="token punctuation">,</span>
 <span class="token string">'sent1'</span><span class="token punctuation">:</span> <span class="token string">'Members of the procession walk down the street holding small horn brass instruments.'</span><span class="token punctuation">,</span>
 <span class="token string">'sent2'</span><span class="token punctuation">:</span> <span class="token string">'A drum line'</span><span class="token punctuation">,</span>
 <span class="token string">'startphrase'</span><span class="token punctuation">:</span> <span class="token string">'Members of the procession walk down the street holding small horn brass instruments. A drum line'</span><span class="token punctuation">,</span>
 <span class="token string">'video-id'</span><span class="token punctuation">:</span> <span class="token string">'anetv_jkn6uvmqwh4'</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<h2 id="é¢„å¤„ç†-3"><a href="#é¢„å¤„ç†-3" class="headerlink" title="é¢„å¤„ç†"></a><strong>é¢„å¤„ç†</strong></h2><p>åŠ è½½ BERT åˆ†è¯å™¨æ¥å¤„ç†æ¯ä¸ªå¥å­çš„å¼€å¤´å’Œå››ä¸ªå¯èƒ½çš„ç»“å°¾ï¼š</p>
<pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">from</span> transformers <span class="token keyword">import</span> AutoTokenizer

tokenizer <span class="token operator">=</span> AutoTokenizer<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span><span class="token string">"bert-base-uncased"</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre>
<p>é¢„å¤„ç†åŠŸèƒ½éœ€è¦åšï¼š</p>
<ol>
<li>åˆ¶ä½œè¯¥å­—æ®µçš„å››ä»½å‰¯æœ¬ï¼Œsent1ä»¥ä¾¿æ‚¨å¯ä»¥å°†å®ƒä»¬ä¸­çš„æ¯ä¸€ä»½ç»“åˆèµ·æ¥sent2ä»¥é‡æ–°åˆ›å»ºå¥å­çš„å¼€å¤´æ–¹å¼ã€‚</li>
<li>ç»“åˆsent2å››ä¸ªå¯èƒ½çš„å¥å­ç»“å°¾ä¸­çš„æ¯ä¸€ä¸ªã€‚</li>
<li>å±•å¹³è¿™ä¸¤ä¸ªåˆ—è¡¨ï¼Œä»¥ä¾¿æ‚¨å¯ä»¥å¯¹å®ƒä»¬è¿›è¡Œæ ‡è®°ï¼Œç„¶åå†å°†å®ƒä»¬å±•å¹³ï¼Œè¿™æ ·æ¯ä¸ªç¤ºä¾‹éƒ½æœ‰ä¸€ä¸ªå¯¹åº”input_idsçš„attention_maskã€ å’Œlabelså­—æ®µã€‚</li>
</ol>
<pre class="line-numbers language-python"><code class="language-python">ending_names <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">"ending0"</span><span class="token punctuation">,</span> <span class="token string">"ending1"</span><span class="token punctuation">,</span> <span class="token string">"ending2"</span><span class="token punctuation">,</span> <span class="token string">"ending3"</span><span class="token punctuation">]</span>

<span class="token keyword">def</span> <span class="token function">preprocess_function</span><span class="token punctuation">(</span>examples<span class="token punctuation">)</span><span class="token punctuation">:</span>
    first_sentences <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">[</span>context<span class="token punctuation">]</span> <span class="token operator">*</span> <span class="token number">4</span> <span class="token keyword">for</span> context <span class="token keyword">in</span> examples<span class="token punctuation">[</span><span class="token string">"sent1"</span><span class="token punctuation">]</span><span class="token punctuation">]</span>
    question_headers <span class="token operator">=</span> examples<span class="token punctuation">[</span><span class="token string">"sent2"</span><span class="token punctuation">]</span>
    second_sentences <span class="token operator">=</span> <span class="token punctuation">[</span>
        <span class="token punctuation">[</span>f<span class="token string">"{header} {examples[end][i]}"</span> <span class="token keyword">for</span> end <span class="token keyword">in</span> ending_names<span class="token punctuation">]</span> <span class="token keyword">for</span> i<span class="token punctuation">,</span> header <span class="token keyword">in</span> enumerate<span class="token punctuation">(</span>question_headers<span class="token punctuation">)</span>
    <span class="token punctuation">]</span>

    first_sentences <span class="token operator">=</span> sum<span class="token punctuation">(</span>first_sentences<span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
    second_sentences <span class="token operator">=</span> sum<span class="token punctuation">(</span>second_sentences<span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">)</span>

    tokenized_examples <span class="token operator">=</span> tokenizer<span class="token punctuation">(</span>first_sentences<span class="token punctuation">,</span> second_sentences<span class="token punctuation">,</span> truncation<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
    <span class="token keyword">return</span> <span class="token punctuation">{</span>k<span class="token punctuation">:</span> <span class="token punctuation">[</span>v<span class="token punctuation">[</span>i <span class="token punctuation">:</span> i <span class="token operator">+</span> <span class="token number">4</span><span class="token punctuation">]</span> <span class="token keyword">for</span> i <span class="token keyword">in</span> range<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> len<span class="token punctuation">(</span>v<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token keyword">for</span> k<span class="token punctuation">,</span> v <span class="token keyword">in</span> tokenized_examples<span class="token punctuation">.</span>items<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">}</span>
tokenized_swag <span class="token operator">=</span> swag<span class="token punctuation">.</span>map<span class="token punctuation">(</span>preprocess_function<span class="token punctuation">,</span> batched<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
<span class="token keyword">from</span> dataclasses <span class="token keyword">import</span> dataclass
<span class="token keyword">from</span> transformers<span class="token punctuation">.</span>tokenization_utils_base <span class="token keyword">import</span> PreTrainedTokenizerBase<span class="token punctuation">,</span> PaddingStrategy
<span class="token keyword">from</span> typing <span class="token keyword">import</span> Optional<span class="token punctuation">,</span> Union
<span class="token keyword">import</span> torch

@dataclass
<span class="token keyword">class</span> <span class="token class-name">DataCollatorForMultipleChoice</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">"""
    Data collator that will dynamically pad the inputs for multiple choice received.
    """</span>

    tokenizer<span class="token punctuation">:</span> PreTrainedTokenizerBase
    padding<span class="token punctuation">:</span> Union<span class="token punctuation">[</span>bool<span class="token punctuation">,</span> str<span class="token punctuation">,</span> PaddingStrategy<span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token boolean">True</span>
    max_length<span class="token punctuation">:</span> Optional<span class="token punctuation">[</span>int<span class="token punctuation">]</span> <span class="token operator">=</span> None
    pad_to_multiple_of<span class="token punctuation">:</span> Optional<span class="token punctuation">[</span>int<span class="token punctuation">]</span> <span class="token operator">=</span> None

    <span class="token keyword">def</span> <span class="token function">__call__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> features<span class="token punctuation">)</span><span class="token punctuation">:</span>
        label_name <span class="token operator">=</span> <span class="token string">"label"</span> <span class="token keyword">if</span> <span class="token string">"label"</span> <span class="token keyword">in</span> features<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>keys<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">else</span> <span class="token string">"labels"</span>
        labels <span class="token operator">=</span> <span class="token punctuation">[</span>feature<span class="token punctuation">.</span>pop<span class="token punctuation">(</span>label_name<span class="token punctuation">)</span> <span class="token keyword">for</span> feature <span class="token keyword">in</span> features<span class="token punctuation">]</span>
        batch_size <span class="token operator">=</span> len<span class="token punctuation">(</span>features<span class="token punctuation">)</span>
        num_choices <span class="token operator">=</span> len<span class="token punctuation">(</span>features<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">"input_ids"</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
        flattened_features <span class="token operator">=</span> <span class="token punctuation">[</span>
            <span class="token punctuation">[</span><span class="token punctuation">{</span>k<span class="token punctuation">:</span> v<span class="token punctuation">[</span>i<span class="token punctuation">]</span> <span class="token keyword">for</span> k<span class="token punctuation">,</span> v <span class="token keyword">in</span> feature<span class="token punctuation">.</span>items<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">}</span> <span class="token keyword">for</span> i <span class="token keyword">in</span> range<span class="token punctuation">(</span>num_choices<span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token keyword">for</span> feature <span class="token keyword">in</span> features
        <span class="token punctuation">]</span>
        flattened_features <span class="token operator">=</span> sum<span class="token punctuation">(</span>flattened_features<span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">)</span>

        batch <span class="token operator">=</span> self<span class="token punctuation">.</span>tokenizer<span class="token punctuation">.</span>pad<span class="token punctuation">(</span>
            flattened_features<span class="token punctuation">,</span>
            padding<span class="token operator">=</span>self<span class="token punctuation">.</span>padding<span class="token punctuation">,</span>
            max_length<span class="token operator">=</span>self<span class="token punctuation">.</span>max_length<span class="token punctuation">,</span>
            pad_to_multiple_of<span class="token operator">=</span>self<span class="token punctuation">.</span>pad_to_multiple_of<span class="token punctuation">,</span>
            return_tensors<span class="token operator">=</span><span class="token string">"pt"</span><span class="token punctuation">,</span>
        <span class="token punctuation">)</span>

        batch <span class="token operator">=</span> <span class="token punctuation">{</span>k<span class="token punctuation">:</span> v<span class="token punctuation">.</span>view<span class="token punctuation">(</span>batch_size<span class="token punctuation">,</span> num_choices<span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span> <span class="token keyword">for</span> k<span class="token punctuation">,</span> v <span class="token keyword">in</span> batch<span class="token punctuation">.</span>items<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">}</span>
        batch<span class="token punctuation">[</span><span class="token string">"labels"</span><span class="token punctuation">]</span> <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span>labels<span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>int64<span class="token punctuation">)</span>
        <span class="token keyword">return</span> batch<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<h2 id="è®­ç»ƒ-3"><a href="#è®­ç»ƒ-3" class="headerlink" title="è®­ç»ƒ"></a>è®­ç»ƒ</h2><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">from</span> transformers <span class="token keyword">import</span> AutoModelForMultipleChoice<span class="token punctuation">,</span> TrainingArguments<span class="token punctuation">,</span> Trainer

model <span class="token operator">=</span> AutoModelForMultipleChoice<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span><span class="token string">"bert-base-uncased"</span><span class="token punctuation">)</span>
training_args <span class="token operator">=</span> TrainingArguments<span class="token punctuation">(</span>
    output_dir<span class="token operator">=</span><span class="token string">"./results"</span><span class="token punctuation">,</span>
    evaluation_strategy<span class="token operator">=</span><span class="token string">"epoch"</span><span class="token punctuation">,</span>
    learning_rate<span class="token operator">=</span><span class="token number">5e</span><span class="token operator">-</span><span class="token number">5</span><span class="token punctuation">,</span>
    per_device_train_batch_size<span class="token operator">=</span><span class="token number">16</span><span class="token punctuation">,</span>
    per_device_eval_batch_size<span class="token operator">=</span><span class="token number">16</span><span class="token punctuation">,</span>
    num_train_epochs<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span>
    weight_decay<span class="token operator">=</span><span class="token number">0.01</span><span class="token punctuation">,</span>
<span class="token punctuation">)</span>

trainer <span class="token operator">=</span> Trainer<span class="token punctuation">(</span>
    model<span class="token operator">=</span>model<span class="token punctuation">,</span>
    args<span class="token operator">=</span>training_args<span class="token punctuation">,</span>
    train_dataset<span class="token operator">=</span>tokenized_swag<span class="token punctuation">[</span><span class="token string">"train"</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
    eval_dataset<span class="token operator">=</span>tokenized_swag<span class="token punctuation">[</span><span class="token string">"validation"</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
    tokenizer<span class="token operator">=</span>tokenizer<span class="token punctuation">,</span>
    data_collator<span class="token operator">=</span>DataCollatorForMultipleChoice<span class="token punctuation">(</span>tokenizer<span class="token operator">=</span>tokenizer<span class="token punctuation">)</span><span class="token punctuation">,</span>
<span class="token punctuation">)</span>

trainer<span class="token punctuation">.</span>train<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<h1 id="ğŸ‘‡Guides"><a href="#ğŸ‘‡Guides" class="headerlink" title="ğŸ‘‡Guides"></a>ğŸ‘‡Guides</h1><h1 id="Tokenizers"><a href="#Tokenizers" class="headerlink" title="Tokenizers"></a>Tokenizers</h1><p>The <strong><a href="https://huggingface.co/docs/transformers/v4.18.0/en/main_classes/tokenizer#transformers.PreTrainedTokenizerFast" target="_blank" rel="noopener">PreTrainedTokenizerFast</a></strong> depends on the <strong><a href="https://huggingface.co/docs/tokenizers" target="_blank" rel="noopener">ğŸ¤— Tokenizers</a></strong> library. The tokenizers obtained from the ğŸ¤— Tokenizers library can be loaded very simply into ğŸ¤— Transformers.</p>
<pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">from</span> tokenizers <span class="token keyword">import</span> Tokenizer
<span class="token keyword">from</span> tokenizers<span class="token punctuation">.</span>models <span class="token keyword">import</span> BPE
<span class="token keyword">from</span> tokenizers<span class="token punctuation">.</span>trainers <span class="token keyword">import</span> BpeTrainer
<span class="token keyword">from</span> tokenizers<span class="token punctuation">.</span>pre_tokenizers <span class="token keyword">import</span> Whitespace

tokenizer <span class="token operator">=</span> Tokenizer<span class="token punctuation">(</span>BPE<span class="token punctuation">(</span>unk_token<span class="token operator">=</span><span class="token string">"[UNK]"</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
trainer <span class="token operator">=</span> BpeTrainer<span class="token punctuation">(</span>special_tokens<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">"[UNK]"</span><span class="token punctuation">,</span> <span class="token string">"[CLS]"</span><span class="token punctuation">,</span> <span class="token string">"[SEP]"</span><span class="token punctuation">,</span> <span class="token string">"[PAD]"</span><span class="token punctuation">,</span> <span class="token string">"[MASK]"</span><span class="token punctuation">]</span><span class="token punctuation">)</span>

tokenizer<span class="token punctuation">.</span>pre_tokenizer <span class="token operator">=</span> Whitespace<span class="token punctuation">(</span><span class="token punctuation">)</span>
files <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">]</span>
tokenizer<span class="token punctuation">.</span>train<span class="token punctuation">(</span>files<span class="token punctuation">,</span> trainer<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<h2 id="Loading-directly-from-the-tokenizer-object"><a href="#Loading-directly-from-the-tokenizer-object" class="headerlink" title="Loading directly from the tokenizer object"></a>Loading directly from the tokenizer object</h2><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">from</span> transformers <span class="token keyword">import</span> PreTrainedTokenizerFast

fast_tokenizer <span class="token operator">=</span> PreTrainedTokenizerFast<span class="token punctuation">(</span>tokenizer_object<span class="token operator">=</span>tokenizer<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre>
<h2 id="Loading-from-a-JSON-file"><a href="#Loading-from-a-JSON-file" class="headerlink" title="Loading from a JSON file"></a>Loading from a JSON file</h2><pre class="line-numbers language-python"><code class="language-python">tokenizer<span class="token punctuation">.</span>save<span class="token punctuation">(</span><span class="token string">"tokenizer.json"</span><span class="token punctuation">)</span>
<span class="token keyword">from</span> transformers <span class="token keyword">import</span> PreTrainedTokenizerFast

fast_tokenizer <span class="token operator">=</span> PreTrainedTokenizerFast<span class="token punctuation">(</span>tokenizer_file<span class="token operator">=</span><span class="token string">"tokenizer.json"</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre>
<h1 id="åˆ›å»ºè‡ªå®šä¹‰æ¶æ„"><a href="#åˆ›å»ºè‡ªå®šä¹‰æ¶æ„" class="headerlink" title="åˆ›å»ºè‡ªå®šä¹‰æ¶æ„"></a>åˆ›å»ºè‡ªå®šä¹‰æ¶æ„</h1><p>è‡ªåŠ¨<strong><code>[AutoClass](&lt;https://huggingface.co/docs/transformers/model_doc/auto&gt;)</code></strong>æ¨æ–­æ¨¡å‹æ¶æ„å¹¶ä¸‹è½½é¢„è®­ç»ƒçš„é…ç½®å’Œæƒé‡ã€‚é€šå¸¸ï¼Œæˆ‘ä»¬å»ºè®®ä½¿ç”¨<code>AutoClass</code>ç”Ÿæˆä¸æ£€æŸ¥ç‚¹æ— å…³çš„ä»£ç ã€‚ä½†æ˜¯æƒ³è¦æ›´å¤šåœ°æ§åˆ¶ç‰¹å®šæ¨¡å‹å‚æ•°çš„ç”¨æˆ·å¯ä»¥ä»å‡ ä¸ªåŸºç±»åˆ›å»ºä¸€ä¸ªè‡ªå®šä¹‰çš„ ğŸ¤— Transformers æ¨¡å‹ã€‚è¿™å¯¹äºä»»ä½•æœ‰å…´è¶£å­¦ä¹ ã€è®­ç»ƒæˆ–è¯•éªŒ ğŸ¤— Transformers æ¨¡å‹çš„äººæ¥è¯´å¯èƒ½ç‰¹åˆ«æœ‰ç”¨ã€‚</p>
<h2 id="Configuration"><a href="#Configuration" class="headerlink" title="Configuration"></a><strong>Configuration</strong></h2><p>A <strong><a href="https://huggingface.co/docs/transformers/main_classes/configuration" target="_blank" rel="noopener">configuration</a></strong> refers to a modelâ€™s specific attributes. Each model configuration has different attributes; for instance, all NLP models have the <code>hidden_size</code>, <code>num_attention_heads</code>, <code>num_hidden_layers</code> and <code>vocab_size</code> attributes in common. These attributes specify the number of attention heads or hidden layers to construct a model with.</p>
<p>Get a closer look at <strong><a href="https://huggingface.co/docs/transformers/model_doc/distilbert" target="_blank" rel="noopener">DistilBERT</a></strong> by accessing <strong><a href="https://huggingface.co/docs/transformers/v4.18.0/en/model_doc/distilbert#transformers.DistilBertConfig" target="_blank" rel="noopener">DistilBertConfig</a></strong> to inspect itâ€™s attributes:</p>
<pre class="line-numbers language-python"><code class="language-python">my_config <span class="token operator">=</span> DistilBertConfig<span class="token punctuation">(</span>activation<span class="token operator">=</span><span class="token string">"relu"</span><span class="token punctuation">,</span> attention_dropout<span class="token operator">=</span><span class="token number">0.4</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>my_config<span class="token punctuation">)</span>
DistilBertConfig <span class="token punctuation">{</span>
  <span class="token string">"activation"</span><span class="token punctuation">:</span> <span class="token string">"relu"</span><span class="token punctuation">,</span>
  <span class="token string">"attention_dropout"</span><span class="token punctuation">:</span> <span class="token number">0.4</span><span class="token punctuation">,</span>
  <span class="token string">"dim"</span><span class="token punctuation">:</span> <span class="token number">768</span><span class="token punctuation">,</span>
  <span class="token string">"dropout"</span><span class="token punctuation">:</span> <span class="token number">0.1</span><span class="token punctuation">,</span>
  <span class="token string">"hidden_dim"</span><span class="token punctuation">:</span> <span class="token number">3072</span><span class="token punctuation">,</span>
  <span class="token string">"initializer_range"</span><span class="token punctuation">:</span> <span class="token number">0.02</span><span class="token punctuation">,</span>
  <span class="token string">"max_position_embeddings"</span><span class="token punctuation">:</span> <span class="token number">512</span><span class="token punctuation">,</span>
  <span class="token string">"model_type"</span><span class="token punctuation">:</span> <span class="token string">"distilbert"</span><span class="token punctuation">,</span>
  <span class="token string">"n_heads"</span><span class="token punctuation">:</span> <span class="token number">12</span><span class="token punctuation">,</span>
  <span class="token string">"n_layers"</span><span class="token punctuation">:</span> <span class="token number">6</span><span class="token punctuation">,</span>
  <span class="token string">"pad_token_id"</span><span class="token punctuation">:</span> <span class="token number">0</span><span class="token punctuation">,</span>
  <span class="token string">"qa_dropout"</span><span class="token punctuation">:</span> <span class="token number">0.1</span><span class="token punctuation">,</span>
  <span class="token string">"seq_classif_dropout"</span><span class="token punctuation">:</span> <span class="token number">0.2</span><span class="token punctuation">,</span>
  <span class="token string">"sinusoidal_pos_embds"</span><span class="token punctuation">:</span> false<span class="token punctuation">,</span>
  <span class="token string">"transformers_version"</span><span class="token punctuation">:</span> <span class="token string">"4.16.2"</span><span class="token punctuation">,</span>
  <span class="token string">"vocab_size"</span><span class="token punctuation">:</span> <span class="token number">30522</span>
<span class="token punctuation">}</span>
my_config <span class="token operator">=</span> DistilBertConfig<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span><span class="token string">"distilbert-base-uncased"</span><span class="token punctuation">,</span> activation<span class="token operator">=</span><span class="token string">"relu"</span><span class="token punctuation">,</span> attention_dropout<span class="token operator">=</span><span class="token number">0.4</span><span class="token punctuation">)</span>
my_config<span class="token punctuation">.</span>save_pretrained<span class="token punctuation">(</span>save_directory<span class="token operator">=</span><span class="token string">"./your_model_save_path"</span><span class="token punctuation">)</span>
my_config <span class="token operator">=</span> DistilBertConfig<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span><span class="token string">"./your_model_save_path/my_config.json"</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<h2 id="Model"><a href="#Model" class="headerlink" title="Model"></a><strong>Model</strong></h2><p>The next step is to create a <strong><a href="https://huggingface.co/docs/transformers/main_classes/models" target="_blank" rel="noopener">model</a></strong>. The model - also loosely referred to as the architecture - defines what each layer is doing and what operations are happening. Attributes like <code>num_hidden_layers</code> from the configuration are used to define the architecture. Every model shares the base class <strong><a href="https://huggingface.co/docs/transformers/v4.18.0/en/main_classes/model#transformers.PreTrainedModel" target="_blank" rel="noopener">PreTrainedModel</a></strong> and a few common methods like resizing input embeddings and pruning self-attention heads. In addition, all models are also either a <strong><code>[torch.nn.Module](&lt;https://pytorch.org/docs/stable/generated/torch.nn.Module.html&gt;)</code></strong>, <strong><code>[tf.keras.Model](&lt;https://www.tensorflow.org/api_docs/python/tf/keras/Model&gt;)</code></strong> or <strong><code>[flax.linen.Module](&lt;https://flax.readthedocs.io/en/latest/flax.linen.html#module&gt;)</code></strong> subclass. This means models are compatible with each of their respective frameworkâ€™s usage.</p>
<pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">from</span> transformers <span class="token keyword">import</span> DistilBertModel

my_config <span class="token operator">=</span> DistilBertConfig<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span><span class="token string">"./your_model_save_path/my_config.json"</span><span class="token punctuation">)</span>
model <span class="token operator">=</span> DistilBertModel<span class="token punctuation">(</span>my_config<span class="token punctuation">)</span>
model <span class="token operator">=</span> DistilBertModel<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span><span class="token string">"distilbert-base-uncased"</span><span class="token punctuation">)</span>
model <span class="token operator">=</span> DistilBertModel<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span><span class="token string">"distilbert-base-uncased"</span><span class="token punctuation">,</span> config<span class="token operator">=</span>my_config<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<h2 id="Tokenizer"><a href="#Tokenizer" class="headerlink" title="Tokenizer"></a><strong>Tokenizer</strong></h2><p>The last base class you need before using a model for textual data is a <strong><a href="https://huggingface.co/docs/transformers/main_classes/tokenizer" target="_blank" rel="noopener">tokenizer</a></strong> to convert raw text to tensors. There are two types of tokenizers you can use with ğŸ¤— Transformers:</p>
<ul>
<li><strong><a href="https://huggingface.co/docs/transformers/v4.18.0/en/main_classes/tokenizer#transformers.PreTrainedTokenizer" target="_blank" rel="noopener">PreTrainedTokenizer</a></strong>: a Python implementation of a tokenizer.</li>
<li><strong><a href="https://huggingface.co/docs/transformers/v4.18.0/en/main_classes/tokenizer#transformers.PreTrainedTokenizerFast" target="_blank" rel="noopener">PreTrainedTokenizerFast</a></strong>: a tokenizer from our Rust-based <strong><a href="https://huggingface.co/docs/tokenizers/python/latest/" target="_blank" rel="noopener">ğŸ¤— Tokenizer</a></strong> library. This tokenizer type is significantly faster - especially during batch tokenization - due to itâ€™s Rust implementation. The fast tokenizer also offers additional methods like <em>offset mapping</em> which maps tokens to their original words or characters.</li>
</ul>
<p>Both tokenizers support common methods such as encoding and decoding, adding new tokens, and managing special tokens.</p>
<p>If you trained your own tokenizer, you can create one from your <em>vocabulary</em> file:</p>
<pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">from</span> transformers <span class="token keyword">import</span> DistilBertTokenizer

my_tokenizer <span class="token operator">=</span> DistilBertTokenizer<span class="token punctuation">(</span>vocab_file<span class="token operator">=</span><span class="token string">"my_vocab_file.txt"</span><span class="token punctuation">,</span> do_lower_case<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span> padding_side<span class="token operator">=</span><span class="token string">"left"</span><span class="token punctuation">)</span>
<span class="token keyword">from</span> transformers <span class="token keyword">import</span> DistilBertTokenizer

slow_tokenizer <span class="token operator">=</span> DistilBertTokenizer<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span><span class="token string">"distilbert-base-uncased"</span><span class="token punctuation">)</span>
<span class="token keyword">from</span> transformers <span class="token keyword">import</span> DistilBertTokenizerFast

fast_tokenizer <span class="token operator">=</span> DistilBertTokenizerFast<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span><span class="token string">"distilbert-base-uncased"</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<h2 id="Feature-Extractor"><a href="#Feature-Extractor" class="headerlink" title="Feature Extractor"></a><strong>Feature Extractor</strong></h2><p>A feature extractor processes audio or image inputs. It inherits from the base <strong><a href="https://huggingface.co/docs/transformers/v4.18.0/en/main_classes/feature_extractor#transformers.FeatureExtractionMixin" target="_blank" rel="noopener">FeatureExtractionMixin</a></strong> class, and may also inherit from the <strong><a href="https://huggingface.co/docs/transformers/v4.18.0/en/main_classes/feature_extractor#transformers.ImageFeatureExtractionMixin" target="_blank" rel="noopener">ImageFeatureExtractionMixin</a></strong> class for processing image features or the <strong><a href="https://huggingface.co/docs/transformers/v4.18.0/en/main_classes/feature_extractor#transformers.SequenceFeatureExtractor" target="_blank" rel="noopener">SequenceFeatureExtractor</a></strong> class for processing audio inputs.</p>
<p>Depending on whether you are working on an audio or vision task, create a feature extractor associated with the model youâ€™re using. For example, create a default <strong><a href="https://huggingface.co/docs/transformers/v4.18.0/en/model_doc/vit#transformers.ViTFeatureExtractor" target="_blank" rel="noopener">ViTFeatureExtractor</a></strong> if you are using <strong><a href="https://huggingface.co/docs/transformers/model_doc/vit" target="_blank" rel="noopener">ViT</a></strong> for image classification:</p>
<pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">from</span> transformers <span class="token keyword">import</span> ViTFeatureExtractor

vit_extractor <span class="token operator">=</span> ViTFeatureExtractor<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>vit_extractor<span class="token punctuation">)</span>
ViTFeatureExtractor <span class="token punctuation">{</span>
  <span class="token string">"do_normalize"</span><span class="token punctuation">:</span> true<span class="token punctuation">,</span>
  <span class="token string">"do_resize"</span><span class="token punctuation">:</span> true<span class="token punctuation">,</span>
  <span class="token string">"feature_extractor_type"</span><span class="token punctuation">:</span> <span class="token string">"ViTFeatureExtractor"</span><span class="token punctuation">,</span>
  <span class="token string">"image_mean"</span><span class="token punctuation">:</span> <span class="token punctuation">[</span>
    <span class="token number">0.5</span><span class="token punctuation">,</span>
    <span class="token number">0.5</span><span class="token punctuation">,</span>
    <span class="token number">0.5</span>
  <span class="token punctuation">]</span><span class="token punctuation">,</span>
  <span class="token string">"image_std"</span><span class="token punctuation">:</span> <span class="token punctuation">[</span>
    <span class="token number">0.5</span><span class="token punctuation">,</span>
    <span class="token number">0.5</span><span class="token punctuation">,</span>
    <span class="token number">0.5</span>
  <span class="token punctuation">]</span><span class="token punctuation">,</span>
  <span class="token string">"resample"</span><span class="token punctuation">:</span> <span class="token number">2</span><span class="token punctuation">,</span>
  <span class="token string">"size"</span><span class="token punctuation">:</span> <span class="token number">224</span>
<span class="token punctuation">}</span>
<span class="token keyword">from</span> transformers <span class="token keyword">import</span> ViTFeatureExtractor

my_vit_extractor <span class="token operator">=</span> ViTFeatureExtractor<span class="token punctuation">(</span>resample<span class="token operator">=</span><span class="token string">"PIL.Image.BOX"</span><span class="token punctuation">,</span> do_normalize<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span> image_mean<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">0.3</span><span class="token punctuation">,</span> <span class="token number">0.3</span><span class="token punctuation">,</span> <span class="token number">0.3</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>my_vit_extractor<span class="token punctuation">)</span>
ViTFeatureExtractor <span class="token punctuation">{</span>
  <span class="token string">"do_normalize"</span><span class="token punctuation">:</span> false<span class="token punctuation">,</span>
  <span class="token string">"do_resize"</span><span class="token punctuation">:</span> true<span class="token punctuation">,</span>
  <span class="token string">"feature_extractor_type"</span><span class="token punctuation">:</span> <span class="token string">"ViTFeatureExtractor"</span><span class="token punctuation">,</span>
  <span class="token string">"image_mean"</span><span class="token punctuation">:</span> <span class="token punctuation">[</span>
    <span class="token number">0.3</span><span class="token punctuation">,</span>
    <span class="token number">0.3</span><span class="token punctuation">,</span>
    <span class="token number">0.3</span>
  <span class="token punctuation">]</span><span class="token punctuation">,</span>
  <span class="token string">"image_std"</span><span class="token punctuation">:</span> <span class="token punctuation">[</span>
    <span class="token number">0.5</span><span class="token punctuation">,</span>
    <span class="token number">0.5</span><span class="token punctuation">,</span>
    <span class="token number">0.5</span>
  <span class="token punctuation">]</span><span class="token punctuation">,</span>
  <span class="token string">"resample"</span><span class="token punctuation">:</span> <span class="token string">"PIL.Image.BOX"</span><span class="token punctuation">,</span>
  <span class="token string">"size"</span><span class="token punctuation">:</span> <span class="token number">224</span>
<span class="token punctuation">}</span>
<span class="token keyword">from</span> transformers <span class="token keyword">import</span> Wav2Vec2FeatureExtractor

w2v2_extractor <span class="token operator">=</span> Wav2Vec2FeatureExtractor<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>w2v2_extractor<span class="token punctuation">)</span>
Wav2Vec2FeatureExtractor <span class="token punctuation">{</span>
  <span class="token string">"do_normalize"</span><span class="token punctuation">:</span> true<span class="token punctuation">,</span>
  <span class="token string">"feature_extractor_type"</span><span class="token punctuation">:</span> <span class="token string">"Wav2Vec2FeatureExtractor"</span><span class="token punctuation">,</span>
  <span class="token string">"feature_size"</span><span class="token punctuation">:</span> <span class="token number">1</span><span class="token punctuation">,</span>
  <span class="token string">"padding_side"</span><span class="token punctuation">:</span> <span class="token string">"right"</span><span class="token punctuation">,</span>
  <span class="token string">"padding_value"</span><span class="token punctuation">:</span> <span class="token number">0.0</span><span class="token punctuation">,</span>
  <span class="token string">"return_attention_mask"</span><span class="token punctuation">:</span> false<span class="token punctuation">,</span>
  <span class="token string">"sampling_rate"</span><span class="token punctuation">:</span> <span class="token number">16000</span>
<span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<h2 id="Processor-1"><a href="#Processor-1" class="headerlink" title="Processor"></a><strong>Processor</strong></h2><p>For models that support multimodal tasks, ğŸ¤— Transformers offers a processor class that conveniently wraps a feature extractor and tokenizer into a single object. For example, letâ€™s use the <strong><a href="https://huggingface.co/docs/transformers/v4.18.0/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor" target="_blank" rel="noopener">Wav2Vec2Processor</a></strong> for an automatic speech recognition task (ASR). ASR transcribes audio to text, so you will need a feature extractor and a tokenizer.</p>
<p>Create a feature extractor to handle the audio inputs:</p>
<pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">from</span> transformers <span class="token keyword">import</span> Wav2Vec2FeatureExtractor

feature_extractor <span class="token operator">=</span> Wav2Vec2FeatureExtractor<span class="token punctuation">(</span>padding_value<span class="token operator">=</span><span class="token number">1.0</span><span class="token punctuation">,</span> do_normalize<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
<span class="token keyword">from</span> transformers <span class="token keyword">import</span> Wav2Vec2CTCTokenizer

tokenizer <span class="token operator">=</span> Wav2Vec2CTCTokenizer<span class="token punctuation">(</span>vocab_file<span class="token operator">=</span><span class="token string">"my_vocab_file.txt"</span><span class="token punctuation">)</span>
<span class="token keyword">from</span> transformers <span class="token keyword">import</span> Wav2Vec2Processor

processor <span class="token operator">=</span> Wav2Vec2Processor<span class="token punctuation">(</span>feature_extractor<span class="token operator">=</span>feature_extractor<span class="token punctuation">,</span> tokenizer<span class="token operator">=</span>tokenizer<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<h1 id="Multilingual-models-for-inference"><a href="#Multilingual-models-for-inference" class="headerlink" title="Multilingual models for inference"></a>Multilingual models for inference</h1><p>ğŸ¤— Transformers ä¸­æœ‰å‡ ç§å¤šè¯­è¨€æ¨¡å‹ï¼Œå®ƒä»¬çš„æ¨ç†ç”¨æ³•ä¸å•è¯­è¨€æ¨¡å‹ä¸åŒã€‚ä¸è¿‡ï¼Œå¹¶é<em>æ‰€æœ‰</em>å¤šè¯­è¨€æ¨¡å‹çš„ä½¿ç”¨éƒ½ä¸åŒã€‚ä¸€äº›æ¨¡å‹ï¼Œæ¯”å¦‚<strong><a href="https://huggingface.co/bert-base-multilingual-uncased" target="_blank" rel="noopener">bert-base-multilingual-uncased</a></strong>ï¼Œå¯ä»¥åƒå•è¯­æ¨¡å‹ä¸€æ ·ä½¿ç”¨ã€‚</p>
<h2 id="XLM"><a href="#XLM" class="headerlink" title="XLM"></a><strong>XLM</strong></h2><p>XLM æœ‰åä¸ªä¸åŒçš„æ£€æŸ¥ç‚¹ï¼Œå…¶ä¸­åªæœ‰ä¸€ä¸ªæ˜¯å•è¯­çš„ã€‚å‰©ä¸‹çš„ä¹ä¸ªæ¨¡å‹æ£€æŸ¥ç‚¹å¯ä»¥åˆ†ä¸ºä¸¤ç±»ï¼šä½¿ç”¨è¯­è¨€åµŒå…¥çš„æ£€æŸ¥ç‚¹å’Œä¸ä½¿ç”¨è¯­è¨€åµŒå…¥çš„æ£€æŸ¥ç‚¹ã€‚</p>
<h3 id="å¸¦æœ‰è¯­è¨€åµŒå…¥çš„-XLM"><a href="#å¸¦æœ‰è¯­è¨€åµŒå…¥çš„-XLM" class="headerlink" title="å¸¦æœ‰è¯­è¨€åµŒå…¥çš„ XLM"></a><strong>å¸¦æœ‰è¯­è¨€åµŒå…¥çš„ XLM</strong></h3><p>ä»¥ä¸‹ XLM æ¨¡å‹ä½¿ç”¨è¯­è¨€åµŒå…¥æ¥æŒ‡å®šæ¨ç†æ—¶ä½¿ç”¨çš„è¯­è¨€ï¼š</p>
<ul>
<li><code>xlm-mlm-ende-1024</code>ï¼ˆè’™é¢è¯­è¨€å»ºæ¨¡ï¼Œè‹±è¯­-å¾·è¯­ï¼‰</li>
<li><code>xlm-mlm-enfr-1024</code>ï¼ˆè’™é¢è¯­è¨€å»ºæ¨¡ï¼Œè‹±æ³•ï¼‰</li>
<li><code>xlm-mlm-enro-1024</code>ï¼ˆè’™é¢è¯­è¨€å»ºæ¨¡ï¼Œè‹±è¯­-ç½—é©¬å°¼äºšè¯­ï¼‰</li>
<li><code>xlm-mlm-xnli15-1024</code>ï¼ˆè’™é¢è¯­è¨€å»ºæ¨¡ï¼ŒXNLI è¯­è¨€ï¼‰</li>
<li><code>xlm-mlm-tlm-xnli15-1024</code>ï¼ˆè’™é¢è¯­è¨€å»ºæ¨¡+ç¿»è¯‘ï¼ŒXNLI è¯­è¨€ï¼‰</li>
<li><code>xlm-clm-enfr-1024</code>ï¼ˆå› æœè¯­è¨€å»ºæ¨¡ï¼Œè‹±æ³•ï¼‰</li>
<li><code>xlm-clm-ende-1024</code>ï¼ˆå› æœè¯­è¨€å»ºæ¨¡ï¼Œè‹±è¯­-å¾·è¯­ï¼‰</li>
</ul>
<p><code>input_ids</code>è¯­è¨€åµŒå…¥è¡¨ç¤ºä¸ºä¸ä¼ é€’ç»™æ¨¡å‹çš„å½¢çŠ¶ç›¸åŒçš„å¼ é‡ã€‚è¿™äº›å¼ é‡ä¸­çš„å€¼å–å†³äºæ‰€ä½¿ç”¨çš„è¯­è¨€ï¼Œå¹¶ç”±åˆ†è¯å™¨<code>lang2id</code>å’Œ<code>id2lang</code>å±æ€§æ ‡è¯†ã€‚</p>
<p>åœ¨æ­¤ç¤ºä¾‹ä¸­ï¼ŒåŠ è½½<code>xlm-clm-enfr-1024</code>æ£€æŸ¥ç‚¹ï¼ˆå› æœè¯­è¨€å»ºæ¨¡ï¼Œè‹±è¯­-æ³•è¯­ï¼‰ï¼š</p>
<pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">import</span> torch
<span class="token keyword">from</span> transformers <span class="token keyword">import</span> XLMTokenizer<span class="token punctuation">,</span> XLMWithLMHeadModel

tokenizer <span class="token operator">=</span> XLMTokenizer<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span><span class="token string">"xlm-clm-enfr-1024"</span><span class="token punctuation">)</span>
model <span class="token operator">=</span> XLMWithLMHeadModel<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span><span class="token string">"xlm-clm-enfr-1024"</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>æ ‡è®°å™¨çš„<code>lang2id</code>å±æ€§æ˜¾ç¤ºæ­¤æ¨¡å‹çš„è¯­è¨€åŠå…¶ IDï¼š</p>
<pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">print</span><span class="token punctuation">(</span>tokenizer<span class="token punctuation">.</span>lang2id<span class="token punctuation">)</span>
<span class="token punctuation">{</span> <span class="token string">'en'</span> <span class="token punctuation">:</span> <span class="token number">0</span> <span class="token punctuation">,</span> <span class="token string">'fr'</span> <span class="token punctuation">:</span> <span class="token number">1</span> <span class="token punctuation">}</span>
input_ids <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span>tokenizer<span class="token punctuation">.</span>encode<span class="token punctuation">(</span><span class="token string">"Wikipedia was used to"</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># batch size of 1</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre>
<p>å°†è¯­è¨€ ID è®¾ç½®ä¸º<code>"en"</code>å¹¶ä½¿ç”¨å®ƒæ¥å®šä¹‰è¯­è¨€åµŒå…¥ã€‚è¯­è¨€åµŒå…¥æ˜¯ä¸€ä¸ªå……æ»¡çš„å¼ é‡ï¼Œ<code>0</code>å› ä¸ºå®ƒæ˜¯è‹±è¯­çš„è¯­è¨€ IDã€‚è¯¥å¼ é‡çš„å¤§å°åº”ä¸ ç›¸åŒ<code>input_ids</code>ã€‚</p>
<pre class="line-numbers language-python"><code class="language-python">language_id <span class="token operator">=</span> tokenizer<span class="token punctuation">.</span>lang2id<span class="token punctuation">[</span><span class="token string">"en"</span><span class="token punctuation">]</span>  <span class="token comment" spellcheck="true"># 0</span>
langs <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span>language_id<span class="token punctuation">]</span> <span class="token operator">*</span> input_ids<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># torch.tensor([0, 0, 0, ..., 0])</span>

<span class="token comment" spellcheck="true"># We reshape it to be of size (batch_size, sequence_length)</span>
langs <span class="token operator">=</span> langs<span class="token punctuation">.</span>view<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># is now of shape [1, sequence_length] (we have a batch size of 1)</span>
outputs <span class="token operator">=</span> model<span class="token punctuation">(</span>input_ids<span class="token punctuation">,</span> langs<span class="token operator">=</span>langs<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p><strong><a href="https://github.com/huggingface/transformers/tree/main/examples/pytorch/text-generation/run_generation.py" target="_blank" rel="noopener">run_generation.py</a></strong>è„šæœ¬å¯ä»¥ä½¿ç”¨æ£€æŸ¥ç‚¹ç”Ÿæˆå¸¦æœ‰è¯­è¨€åµŒå…¥çš„æ–‡æœ¬<code>xlm-clm</code>ã€‚</p>
<h3 id="æ²¡æœ‰è¯­è¨€åµŒå…¥çš„-XLM"><a href="#æ²¡æœ‰è¯­è¨€åµŒå…¥çš„-XLM" class="headerlink" title="æ²¡æœ‰è¯­è¨€åµŒå…¥çš„ XLM"></a><strong>æ²¡æœ‰è¯­è¨€åµŒå…¥çš„ XLM</strong></h3><p>ä»¥ä¸‹ XLM æ¨¡å‹åœ¨æ¨ç†æœŸé—´ä¸éœ€è¦è¯­è¨€åµŒå…¥ï¼š</p>
<ul>
<li><code>xlm-mlm-17-1280</code>ï¼ˆè’™é¢è¯­è¨€å»ºæ¨¡ï¼Œ17 ç§è¯­è¨€ï¼‰</li>
<li><code>xlm-mlm-100-1280</code>ï¼ˆè’™é¢è¯­è¨€å»ºæ¨¡ï¼Œ100 ç§è¯­è¨€ï¼‰</li>
</ul>
<p>ä¸ä¹‹å‰çš„ XLM æ£€æŸ¥ç‚¹ä¸åŒï¼Œè¿™äº›æ¨¡å‹ç”¨äºé€šç”¨å¥å­è¡¨ç¤ºã€‚</p>
<h2 id="BERT"><a href="#BERT" class="headerlink" title="BERT"></a><strong>BERT</strong></h2><p>ä»¥ä¸‹ BERT æ¨¡å‹å¯ç”¨äºå¤šè¯­è¨€ä»»åŠ¡ï¼š</p>
<ul>
<li><code>bert-base-multilingual-uncased</code>ï¼ˆè’™é¢è¯­è¨€å»ºæ¨¡+ä¸‹ä¸€å¥é¢„æµ‹ï¼Œ102ç§è¯­è¨€ï¼‰</li>
<li><code>bert-base-multilingual-cased</code>ï¼ˆè’™é¢è¯­è¨€å»ºæ¨¡+ä¸‹ä¸€å¥é¢„æµ‹ï¼Œ104ç§è¯­è¨€ï¼‰</li>
</ul>
<p>è¿™äº›æ¨¡å‹åœ¨æ¨ç†è¿‡ç¨‹ä¸­ä¸éœ€è¦è¯­è¨€åµŒå…¥ã€‚ä»–ä»¬åº”è¯¥ä»ä¸Šä¸‹æ–‡ä¸­è¯†åˆ«è¯­è¨€å¹¶åšå‡ºç›¸åº”çš„æ¨æ–­ã€‚</p>
<h2 id="XLM-RoBERTa"><a href="#XLM-RoBERTa" class="headerlink" title="XLM-RoBERTa"></a><strong>XLM-</strong>RoBERTa</h2><p>ä»¥ä¸‹ XLM-RoBERTa æ¨¡å‹å¯ç”¨äºå¤šè¯­è¨€ä»»åŠ¡ï¼š</p>
<ul>
<li><code>xlm-roberta-base</code>ï¼ˆè’™é¢è¯­è¨€å»ºæ¨¡ï¼Œ100 ç§è¯­è¨€ï¼‰</li>
<li><code>xlm-roberta-large</code>ï¼ˆè’™é¢è¯­è¨€å»ºæ¨¡ï¼Œ100 ç§è¯­è¨€ï¼‰</li>
</ul>
<p>XLM-RoBERTa æ¥å—äº† 100 ç§è¯­è¨€çš„ 2.5TB æ–°åˆ›å»ºå’Œæ¸…ç†çš„ CommonCrawl æ•°æ®çš„åŸ¹è®­ã€‚åœ¨åˆ†ç±»ã€åºåˆ—æ ‡è®°å’Œé—®ç­”ç­‰ä¸‹æ¸¸ä»»åŠ¡ä¸Šï¼Œå®ƒæ¯”ä»¥å‰å‘å¸ƒçš„å¤šè¯­è¨€æ¨¡å‹ï¼ˆå¦‚ mBERT æˆ– XLMï¼‰æä¾›äº†å¼ºå¤§çš„æ”¶ç›Šã€‚</p>
<h2 id="M2M100"><a href="#M2M100" class="headerlink" title="M2M100"></a><strong>M2M100</strong></h2><p>ä»¥ä¸‹ M2M100 å‹å·å¯ç”¨äºå¤šè¯­è¨€ç¿»è¯‘ï¼š</p>
<ul>
<li><code>facebook/m2m100_418M</code>ï¼ˆç¿»è¯‘ï¼‰</li>
<li><code>facebook/m2m100_1.2B</code>ï¼ˆç¿»è¯‘ï¼‰</li>
</ul>
<p>åœ¨æœ¬ä¾‹ä¸­ï¼ŒåŠ è½½<code>facebook/m2m100_418M</code>æ£€æŸ¥ç‚¹ä»¥å°†ä¸­æ–‡ç¿»è¯‘æˆè‹±æ–‡ã€‚æ‚¨å¯ä»¥åœ¨åˆ†è¯å™¨ä¸­è®¾ç½®æºè¯­è¨€ï¼š</p>
<pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">from</span> transformers <span class="token keyword">import</span> M2M100ForConditionalGeneration<span class="token punctuation">,</span> M2M100Tokenizer

en_text <span class="token operator">=</span> <span class="token string">"Do not meddle in the affairs of wizards, for they are subtle and quick to anger."</span>
chinese_text <span class="token operator">=</span> <span class="token string">"ä¸è¦æ’æ‰‹å·«å¸«çš„äº‹å‹™, å› ç‚ºä»–å€‘æ˜¯å¾®å¦™çš„, å¾ˆå¿«å°±æœƒç™¼æ€’."</span>

tokenizer <span class="token operator">=</span> M2M100Tokenizer<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span><span class="token string">"facebook/m2m100_418M"</span><span class="token punctuation">,</span> src_lang<span class="token operator">=</span><span class="token string">"zh"</span><span class="token punctuation">)</span>
model <span class="token operator">=</span> M2M100ForConditionalGeneration<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span><span class="token string">"facebook/m2m100_418M"</span><span class="token punctuation">)</span>
encoded_zh <span class="token operator">=</span> tokenizer<span class="token punctuation">(</span>chinese_text<span class="token punctuation">,</span> return_tensors<span class="token operator">=</span><span class="token string">"pt"</span><span class="token punctuation">)</span>
generated_tokens <span class="token operator">=</span> model<span class="token punctuation">.</span>generate<span class="token punctuation">(</span><span class="token operator">**</span>encoded_zh<span class="token punctuation">,</span> forced_bos_token_id<span class="token operator">=</span>tokenizer<span class="token punctuation">.</span>get_lang_id<span class="token punctuation">(</span><span class="token string">"en"</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
tokenizer<span class="token punctuation">.</span>batch_decode<span class="token punctuation">(</span>generated_tokens<span class="token punctuation">,</span> skip_special_tokens<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<h2 id="MBart"><a href="#MBart" class="headerlink" title="MBart"></a>MBart</h2><p>ä»¥ä¸‹ MBar æ¨¡å‹å¯ç”¨äºå¤šè¯­è¨€ç¿»è¯‘ï¼š</p>
<ul>
<li><code>facebook/mbart-large-50-one-to-many-mmt</code>ï¼ˆä¸€å¯¹å¤šå¤šè¯­è¨€æœºå™¨ç¿»è¯‘ï¼Œ50ç§è¯­è¨€ï¼‰</li>
<li><code>facebook/mbart-large-50-many-to-many-mmt</code>ï¼ˆå¤šå¯¹å¤šå¤šè¯­è¨€æœºå™¨ç¿»è¯‘ï¼Œ50ç§è¯­è¨€ï¼‰</li>
<li><code>facebook/mbart-large-50-many-to-one-mmt</code>ï¼ˆå¤šå¯¹ä¸€å¤šè¯­è¨€æœºå™¨ç¿»è¯‘ï¼Œ50ç§è¯­è¨€ï¼‰</li>
<li><code>facebook/mbart-large-50</code>ï¼ˆå¤šè¯­è¨€ç¿»è¯‘ï¼Œ50ç§è¯­è¨€ï¼‰</li>
<li><code>facebook/mbart-large-cc25</code></li>
</ul>
<p>åœ¨æ­¤ç¤ºä¾‹ä¸­ï¼ŒåŠ è½½<code>facebook/mbart-large-50-many-to-many-mmt</code>æ£€æŸ¥ç‚¹ä»¥å°†èŠ¬å…°è¯­ç¿»è¯‘æˆè‹±è¯­ã€‚æ‚¨å¯ä»¥åœ¨åˆ†è¯å™¨ä¸­è®¾ç½®æºè¯­è¨€ï¼š</p>
<pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">from</span> transformers <span class="token keyword">import</span> AutoTokenizer<span class="token punctuation">,</span> AutoModelForSeq2SeqLM

en_text <span class="token operator">=</span> <span class="token string">"Do not meddle in the affairs of wizards, for they are subtle and quick to anger."</span>
fi_text <span class="token operator">=</span> <span class="token string">"Ã„lÃ¤ sekaannu velhojen asioihin, sillÃ¤ ne ovat hienovaraisia ja nopeasti vihaisia."</span>

tokenizer <span class="token operator">=</span> AutoTokenizer<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span><span class="token string">"facebook/mbart-large-50-many-to-many-mmt"</span><span class="token punctuation">,</span> src_lang<span class="token operator">=</span><span class="token string">"fi_FI"</span><span class="token punctuation">)</span>
model <span class="token operator">=</span> AutoModelForSeq2SeqLM<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span><span class="token string">"facebook/mbart-large-50-many-to-many-mmt"</span><span class="token punctuation">)</span>

encoded_en <span class="token operator">=</span> tokenizer<span class="token punctuation">(</span>en_text<span class="token punctuation">,</span> return_tensors<span class="token operator">=</span><span class="token string">"pt"</span><span class="token punctuation">)</span>

generated_tokens <span class="token operator">=</span> model<span class="token punctuation">.</span>generate<span class="token punctuation">(</span><span class="token operator">**</span>encoded_en<span class="token punctuation">,</span> forced_bos_token_id<span class="token operator">=</span>tokenizer<span class="token punctuation">.</span>lang_code_to_id<span class="token punctuation">(</span><span class="token string">"en_XX"</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
tokenizer<span class="token punctuation">.</span>batch_decode<span class="token punctuation">(</span>generated_tokens<span class="token punctuation">,</span> skip_special_tokens<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<h1 id="Datasets"><a href="#Datasets" class="headerlink" title="Datasets"></a>Datasets</h1><p>å®˜æ–¹æ–‡æ¡£ï¼š<a href="https://huggingface.co/docs/datasets/index" target="_blank" rel="noopener">Datasets (huggingface.co)</a></p>
<blockquote>
<p>ä¸€èˆ¬ä¸‹è½½çš„Datasetsæ•°æ®é›†æ˜¯ä¸€ä¸ªDatasetsDictå¯¹è±¡ï¼Œé‡Œé¢ä¼šæ ¹æ®è®­ç»ƒï¼ŒéªŒè¯å’Œæµ‹è¯•é›†åˆ†æˆä¸‰ä¸ªDataSetå¯¹è±¡ã€‚æ¯ä¸ªDataSetå¯¹è±¡ä¼šæœ‰å¾ˆå¤šfeatureå±æ€§ï¼Œè¿™äº›å±æ€§ç»„æˆè¯¥DataSetçš„å­—å…¸ã€‚å…·ä½“çš„DataSetç±»çš„æ„å»ºä¸torchçš„Datasetæ„å»ºç±»ä¼¼ï¼Œä½†æ˜¯æ„å»ºè¿”å›çš„<strong><code>__getitem__</code></strong>æ˜¯ä¸ªå­—å…¸ï¼Œé‡Œé¢åŒ…å«äº†è®­ç»ƒè¾“å…¥æ•°æ®å’Œlabelï¼Œé€šè¿‡å­—å…¸çš„keyè°ƒç”¨ã€‚</p>
</blockquote>
<p>Datasetsæ˜¯ä¸€ä¸ªåº“ï¼Œç”¨äºè½»æ¾è®¿é—®å’Œå…±äº«æ•°æ®é›†ï¼Œä»¥åŠè‡ªç„¶è¯­è¨€å¤„ç† ï¼ˆNLPï¼‰ã€è®¡ç®—æœºè§†è§‰å’ŒéŸ³é¢‘ä»»åŠ¡çš„è¯„ä¼°æŒ‡æ ‡ã€‚</p>
<p>åœ¨ä¸€è¡Œä»£ç ä¸­åŠ è½½æ•°æ®é›†ï¼Œå¹¶ä½¿ç”¨æˆ‘ä»¬å¼ºå¤§çš„æ•°æ®å¤„ç†æ–¹æ³•å¿«é€Ÿå‡†å¤‡å¥½æ‚¨çš„æ•°æ®é›†ï¼Œä»¥ä¾¿åœ¨æ·±åº¦å­¦ä¹ æ¨¡å‹ä¸­è¿›è¡Œè®­ç»ƒã€‚åœ¨ Apache Arrow æ ¼å¼çš„æ”¯æŒä¸‹ï¼Œé€šè¿‡é›¶å‰¯æœ¬è¯»å–å¤„ç†å¤§å‹æ•°æ®é›†ï¼Œæ²¡æœ‰ä»»ä½•å†…å­˜é™åˆ¶ï¼Œä»¥å®ç°æœ€ä½³é€Ÿåº¦å’Œæ•ˆç‡ã€‚æˆ‘ä»¬è¿˜ä¸<strong><a href="https://huggingface.co/datasets" target="_blank" rel="noopener">Hugging Face Hub</a></strong>è¿›è¡Œäº†æ·±åº¦é›†æˆï¼Œä½¿æ‚¨å¯ä»¥è½»æ¾åŠ è½½æ•°æ®é›†å¹¶ä¸æ›´å¹¿æ³›çš„NLPç¤¾åŒºå…±äº«ã€‚ç›®å‰æœ‰è¶…è¿‡ 2658 ä¸ªæ•°æ®é›†ï¼Œä»¥åŠè¶…è¿‡ 34 ä¸ªå¯ç”¨çš„æŒ‡æ ‡ã€‚</p>
<h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="åŠ è½½æ•°æ®é›†å’Œæ¨¡å‹"><a href="#åŠ è½½æ•°æ®é›†å’Œæ¨¡å‹" class="headerlink" title="åŠ è½½æ•°æ®é›†å’Œæ¨¡å‹"></a><strong>åŠ è½½æ•°æ®é›†å’Œæ¨¡å‹</strong></h3><p>é¦–å…ˆä»<strong><a href="https://huggingface.co/datasets/glue" target="_blank" rel="noopener">ä¸€èˆ¬è¯­è¨€ç†è§£è¯„ä¼° ï¼ˆGLUEï¼‰ åŸºå‡†</a></strong>æµ‹è¯•åŠ è½½ <strong><a href="https://huggingface.co/datasets/viewer/?dataset=glue&amp;config=mrpc" target="_blank" rel="noopener">Microsoft ç ”ç©¶é™¢é‡Šä¹‰è¯­æ–™åº“ ï¼ˆMRPC</a></strong>ï¼‰ è®­ç»ƒæ•°æ®é›†ã€‚MRPC æ˜¯äººç±»æ³¨é‡Šçš„å¥å­å¯¹çš„è¯­æ–™åº“ï¼Œç”¨äºè®­ç»ƒæ¨¡å‹ä»¥ç¡®å®šå¥å­å¯¹åœ¨è¯­ä¹‰ä¸Šæ˜¯å¦ç­‰æ•ˆã€‚</p>
<pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">from</span> datasets <span class="token keyword">import</span> load_dataset
dataset <span class="token operator">=</span> load_dataset<span class="token punctuation">(</span><span class="token string">'glue'</span><span class="token punctuation">,</span> <span class="token string">'mrpc'</span><span class="token punctuation">,</span> split<span class="token operator">=</span><span class="token string">'train'</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>
<p>å¯¼å…¥åˆ†è¯å™¨æ¨¡å‹ï¼š</p>
<pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">from</span> transformers <span class="token keyword">import</span> AutoModelForSequenceClassification<span class="token punctuation">,</span> AutoTokenizer
model <span class="token operator">=</span> AutoModelForSequenceClassification<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span><span class="token string">'bert-base-cased'</span><span class="token punctuation">)</span>
tokenizer <span class="token operator">=</span> AutoTokenizer<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span><span class="token string">'bert-base-cased'</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre>
<h3 id="æ ‡è®°åŒ–æ•°æ®é›†"><a href="#æ ‡è®°åŒ–æ•°æ®é›†" class="headerlink" title="æ ‡è®°åŒ–æ•°æ®é›†"></a><strong>æ ‡è®°åŒ–æ•°æ®é›†</strong></h3><p>ä¸‹ä¸€æ­¥æ˜¯æ ‡è®°æ–‡æœ¬ï¼Œä»¥ä¾¿æ„å»ºæ¨¡å‹å¯ä»¥ç†è§£çš„æ•´æ•°åºåˆ—ã€‚ä½¿ç”¨ <strong><a href="https://huggingface.co/docs/datasets/v2.1.0/en/package_reference/main_classes#datasets.Dataset.map" target="_blank" rel="noopener">Dataset.mapï¼ˆï¼‰</a></strong> å¯¹æ•´ä¸ªæ•°æ®é›†è¿›è¡Œç¼–ç ï¼Œå¹¶å°†è¾“å…¥æˆªæ–­å¹¶å¡«å……åˆ°æ¨¡å‹çš„æœ€å¤§é•¿åº¦ã€‚è¿™ç¡®ä¿äº†æ„å»ºé€‚å½“çš„å¼ é‡æ‰¹å¤„ç†ã€‚</p>
<pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">encode</span><span class="token punctuation">(</span>examples<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">return</span> tokenizer<span class="token punctuation">(</span>examples<span class="token punctuation">[</span><span class="token string">'sentence1'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> examples<span class="token punctuation">[</span><span class="token string">'sentence2'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> truncation<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token string">'max_length'</span><span class="token punctuation">)</span>

dataset <span class="token operator">=</span> dataset<span class="token punctuation">.</span>map<span class="token punctuation">(</span>encode<span class="token punctuation">,</span> batched<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
dataset<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
<span class="token punctuation">{</span><span class="token string">'sentence1'</span><span class="token punctuation">:</span> <span class="token string">'Amrozi accused his brother , whom he called " the witness " , of deliberately distorting his evidence .'</span><span class="token punctuation">,</span>
<span class="token string">'sentence2'</span><span class="token punctuation">:</span> <span class="token string">'Referring to him as only " the witness " , Amrozi accused his brother of deliberately distorting his evidence .'</span><span class="token punctuation">,</span>
<span class="token string">'label'</span><span class="token punctuation">:</span> <span class="token number">1</span><span class="token punctuation">,</span>
<span class="token string">'idx'</span><span class="token punctuation">:</span> <span class="token number">0</span><span class="token punctuation">,</span>
<span class="token string">'input_ids'</span><span class="token punctuation">:</span> array<span class="token punctuation">(</span><span class="token punctuation">[</span>  <span class="token number">101</span><span class="token punctuation">,</span>  <span class="token number">7277</span><span class="token punctuation">,</span>  <span class="token number">2180</span><span class="token punctuation">,</span>  <span class="token number">5303</span><span class="token punctuation">,</span>  <span class="token number">4806</span><span class="token punctuation">,</span>  <span class="token number">1117</span><span class="token punctuation">,</span>  <span class="token number">1711</span><span class="token punctuation">,</span>   <span class="token number">117</span><span class="token punctuation">,</span>  <span class="token number">2292</span><span class="token punctuation">,</span> <span class="token number">1119</span><span class="token punctuation">,</span>  <span class="token number">1270</span><span class="token punctuation">,</span>   <span class="token number">107</span><span class="token punctuation">,</span>  <span class="token number">1103</span><span class="token punctuation">,</span>  <span class="token number">7737</span><span class="token punctuation">,</span>   <span class="token number">107</span><span class="token punctuation">,</span>   <span class="token number">117</span><span class="token punctuation">,</span>  <span class="token number">1104</span><span class="token punctuation">,</span>  <span class="token number">9938</span><span class="token punctuation">,</span> <span class="token number">4267</span><span class="token punctuation">,</span> <span class="token number">12223</span><span class="token punctuation">,</span> <span class="token number">21811</span><span class="token punctuation">,</span>  <span class="token number">1117</span><span class="token punctuation">,</span>  <span class="token number">2554</span><span class="token punctuation">,</span>   <span class="token number">119</span><span class="token punctuation">,</span>   <span class="token number">102</span><span class="token punctuation">,</span> <span class="token number">11336</span><span class="token punctuation">,</span>  <span class="token number">6732</span><span class="token punctuation">,</span> <span class="token number">3384</span><span class="token punctuation">,</span>  <span class="token number">1106</span><span class="token punctuation">,</span>  <span class="token number">1140</span><span class="token punctuation">,</span>  <span class="token number">1112</span><span class="token punctuation">,</span>  <span class="token number">1178</span><span class="token punctuation">,</span>   <span class="token number">107</span><span class="token punctuation">,</span>  <span class="token number">1103</span><span class="token punctuation">,</span>  <span class="token number">7737</span><span class="token punctuation">,</span>   <span class="token number">107</span><span class="token punctuation">,</span> <span class="token number">117</span><span class="token punctuation">,</span>  <span class="token number">7277</span><span class="token punctuation">,</span>  <span class="token number">2180</span><span class="token punctuation">,</span>  <span class="token number">5303</span><span class="token punctuation">,</span>  <span class="token number">4806</span><span class="token punctuation">,</span>  <span class="token number">1117</span><span class="token punctuation">,</span>  <span class="token number">1711</span><span class="token punctuation">,</span>  <span class="token number">1104</span><span class="token punctuation">,</span>  <span class="token number">9938</span><span class="token punctuation">,</span> <span class="token number">4267</span><span class="token punctuation">,</span> <span class="token number">12223</span><span class="token punctuation">,</span> <span class="token number">21811</span><span class="token punctuation">,</span>  <span class="token number">1117</span><span class="token punctuation">,</span>  <span class="token number">2554</span><span class="token punctuation">,</span>   <span class="token number">119</span><span class="token punctuation">,</span>   <span class="token number">102</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
<span class="token string">'token_type_ids'</span><span class="token punctuation">:</span> array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
<span class="token string">'attention_mask'</span><span class="token punctuation">:</span> array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>æ³¨æ„ï¼šæ•°æ®é›†å¤šäº†ä¸‰ä¸ªæ–°çš„å‚æ•°ï¼š<code>input_ids, token_type_ids, attention_mask</code></p>
<h3 id="è®¾ç½®æ•°æ®é›†çš„æ ¼å¼"><a href="#è®¾ç½®æ•°æ®é›†çš„æ ¼å¼" class="headerlink" title="è®¾ç½®æ•°æ®é›†çš„æ ¼å¼"></a><strong>è®¾ç½®æ•°æ®é›†çš„æ ¼å¼</strong></h3><p>éœ€è¦ç›¸åº”åœ°æ ¼å¼åŒ–æ•°æ®é›†ã€‚éœ€è¦å¯¹æ•°æ®é›†è¿›è¡Œä¸‰é¡¹æ›´æ”¹ï¼š</p>
<ol>
<li>å°†åˆ—é‡å‘½åä¸º <code>label</code>ï¼Œè¿™æ˜¯ <strong><a href="https://huggingface.co/transformers/model_doc/bert#transformers.BertForSequenceClassification.forward" target="_blank" rel="noopener">BertForSequenceClassification</a></strong> ä¸­é¢„æœŸçš„è¾“å…¥åç§°ï¼š<code>labels</code></li>
</ol>
<pre class="line-numbers language-python"><code class="language-python"><span class="token operator">>></span><span class="token operator">></span> dataset <span class="token operator">=</span> dataset<span class="token punctuation">.</span>map<span class="token punctuation">(</span><span class="token keyword">lambda</span> examples<span class="token punctuation">:</span> <span class="token punctuation">{</span><span class="token string">'labels'</span><span class="token punctuation">:</span> examples<span class="token punctuation">[</span><span class="token string">'label'</span><span class="token punctuation">]</span><span class="token punctuation">}</span><span class="token punctuation">,</span> batched<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<ol>
<li>ä» Dataset å¯¹è±¡æ£€ç´¢å®é™…çš„å¼ é‡ï¼Œè€Œä¸æ˜¯ä½¿ç”¨å½“å‰çš„ Python å¯¹è±¡ã€‚</li>
<li>ç­›é€‰æ•°æ®é›†ä»¥ä»…è¿”å›æ¨¡å‹è¾“å…¥ï¼š<code>input_ids</code>ã€<code>token_type_ids</code>å’Œ <code>attention_mask</code></li>
</ol>
<p><strong><a href="https://huggingface.co/docs/datasets/v2.1.0/en/package_reference/main_classes#datasets.Dataset.set_format" target="_blank" rel="noopener">Dataset.set_formatï¼ˆï¼‰</a></strong> åŠ¨æ€å®Œæˆæœ€åä¸¤ä¸ªæ­¥éª¤ã€‚è®¾ç½®æ ¼å¼åï¼Œå°†æ•°æ®é›†åŒ…è£…åœ¨ ï¼š<code>torch.utils.data.DataLoader</code></p>
<pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">import</span> torch
dataset<span class="token punctuation">.</span>set_format<span class="token punctuation">(</span>type<span class="token operator">=</span><span class="token string">'torch'</span><span class="token punctuation">,</span> columns<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">'input_ids'</span><span class="token punctuation">,</span> <span class="token string">'token_type_ids'</span><span class="token punctuation">,</span> <span class="token string">'attention_mask'</span><span class="token punctuation">,</span> <span class="token string">'labels'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
dataloader <span class="token operator">=</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data<span class="token punctuation">.</span>DataLoader<span class="token punctuation">(</span>dataset<span class="token punctuation">,</span> batch_size<span class="token operator">=</span><span class="token number">32</span><span class="token punctuation">)</span>
next<span class="token punctuation">(</span>iter<span class="token punctuation">(</span>dataloader<span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token punctuation">{</span><span class="token string">'attention_mask'</span><span class="token punctuation">:</span> tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span>  <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
                        <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span>  <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
                        <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span>  <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
                        <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">,</span>
                        <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span>  <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
                        <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span>  <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
                        <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span>  <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
<span class="token string">'input_ids'</span><span class="token punctuation">:</span> tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span>  <span class="token number">101</span><span class="token punctuation">,</span>  <span class="token number">7277</span><span class="token punctuation">,</span>  <span class="token number">2180</span><span class="token punctuation">,</span>  <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">,</span>     <span class="token number">0</span><span class="token punctuation">,</span>     <span class="token number">0</span><span class="token punctuation">,</span>     <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
                  <span class="token punctuation">[</span>  <span class="token number">101</span><span class="token punctuation">,</span> <span class="token number">10684</span><span class="token punctuation">,</span>  <span class="token number">2599</span><span class="token punctuation">,</span>  <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">,</span>     <span class="token number">0</span><span class="token punctuation">,</span>     <span class="token number">0</span><span class="token punctuation">,</span>     <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
                  <span class="token punctuation">[</span>  <span class="token number">101</span><span class="token punctuation">,</span>  <span class="token number">1220</span><span class="token punctuation">,</span>  <span class="token number">1125</span><span class="token punctuation">,</span>  <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">,</span>     <span class="token number">0</span><span class="token punctuation">,</span>     <span class="token number">0</span><span class="token punctuation">,</span>     <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
                  <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">,</span>
                  <span class="token punctuation">[</span>  <span class="token number">101</span><span class="token punctuation">,</span> <span class="token number">16944</span><span class="token punctuation">,</span>  <span class="token number">1107</span><span class="token punctuation">,</span>  <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">,</span>     <span class="token number">0</span><span class="token punctuation">,</span>     <span class="token number">0</span><span class="token punctuation">,</span>     <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
                  <span class="token punctuation">[</span>  <span class="token number">101</span><span class="token punctuation">,</span>  <span class="token number">1109</span><span class="token punctuation">,</span> <span class="token number">11896</span><span class="token punctuation">,</span>  <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">,</span>     <span class="token number">0</span><span class="token punctuation">,</span>     <span class="token number">0</span><span class="token punctuation">,</span>     <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
                  <span class="token punctuation">[</span>  <span class="token number">101</span><span class="token punctuation">,</span>  <span class="token number">1109</span><span class="token punctuation">,</span>  <span class="token number">4173</span><span class="token punctuation">,</span>  <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">,</span>     <span class="token number">0</span><span class="token punctuation">,</span>     <span class="token number">0</span><span class="token punctuation">,</span>     <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
<span class="token string">'label'</span><span class="token punctuation">:</span> tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
<span class="token string">'token_type_ids'</span><span class="token punctuation">:</span> tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span>  <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
                     <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span>  <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
                     <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span>  <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
                     <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">,</span>
                     <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span>  <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
                     <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span>  <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
                     <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span>  <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<h3 id="è®­ç»ƒæ¨¡å‹"><a href="#è®­ç»ƒæ¨¡å‹" class="headerlink" title="è®­ç»ƒæ¨¡å‹"></a>è®­ç»ƒæ¨¡å‹</h3><p>æœ€åï¼Œåˆ›å»ºä¸€ä¸ªç®€å•çš„è®­ç»ƒå¾ªç¯å¹¶å¼€å§‹è®­ç»ƒï¼š</p>
<pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">from</span> tqdm <span class="token keyword">import</span> tqdm
device <span class="token operator">=</span> <span class="token string">'cuda'</span> <span class="token keyword">if</span> torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>is_available<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">else</span> <span class="token string">'cpu'</span> 
model<span class="token punctuation">.</span>train<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>
optimizer <span class="token operator">=</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>AdamW<span class="token punctuation">(</span>params<span class="token operator">=</span>model<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> lr<span class="token operator">=</span><span class="token number">1e</span><span class="token operator">-</span><span class="token number">5</span><span class="token punctuation">)</span>
<span class="token keyword">for</span> epoch <span class="token keyword">in</span> range<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">for</span> i<span class="token punctuation">,</span> batch <span class="token keyword">in</span> enumerate<span class="token punctuation">(</span>tqdm<span class="token punctuation">(</span>dataloader<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        batch <span class="token operator">=</span> <span class="token punctuation">{</span>k<span class="token punctuation">:</span> v<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span> <span class="token keyword">for</span> k<span class="token punctuation">,</span> v <span class="token keyword">in</span> batch<span class="token punctuation">.</span>items<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">}</span>
        outputs <span class="token operator">=</span> model<span class="token punctuation">(</span><span class="token operator">**</span>batch<span class="token punctuation">)</span>
        loss <span class="token operator">=</span> outputs<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
        loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>
        optimizer<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>
        optimizer<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>
        <span class="token keyword">if</span> i <span class="token operator">%</span> <span class="token number">10</span> <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">:</span>
            <span class="token keyword">print</span><span class="token punctuation">(</span>f<span class="token string">"loss: {loss}"</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<h2 id="å®‰è£…-1"><a href="#å®‰è£…-1" class="headerlink" title="å®‰è£…"></a>å®‰è£…</h2><h3 id="pip"><a href="#pip" class="headerlink" title="pip"></a><strong>pip</strong></h3><p>The most straightforward way to install ğŸ¤— Datasets is with pip:</p>
<pre><code>pip install datasets</code></pre><h3 id="conda"><a href="#conda" class="headerlink" title="conda"></a><strong>conda</strong></h3><p>ğŸ¤— Datasets can also be installed with conda, a package management system:</p>
<pre><code>conda install -c huggingface -c conda-forge datasets</code></pre><h2 id="Hugging-Face-Hub"><a href="#Hugging-Face-Hub" class="headerlink" title="Hugging Face Hub"></a>Hugging Face Hub</h2><h3 id="Load-a-dataset"><a href="#Load-a-dataset" class="headerlink" title="Load a dataset"></a>Load a dataset</h3><p>åœ¨èŠ±æ—¶é—´ä¸‹è½½æ•°æ®é›†ä¹‹å‰ï¼Œå¿«é€Ÿè·å–æœ‰å…³æ•°æ®é›†çš„æ‰€æœ‰ç›¸å…³ä¿¡æ¯é€šå¸¸å¾ˆæœ‰å¸®åŠ©ã€‚<strong><a href="https://huggingface.co/docs/datasets/v2.1.0/en/package_reference/loading_methods#datasets.load_dataset_builder" target="_blank" rel="noopener">load_dataset_builderï¼ˆï¼‰</a></strong>æ–¹æ³•å…è®¸æ‚¨åœ¨ä¸ä¸‹è½½æ•°æ®é›†çš„æƒ…å†µä¸‹æ£€æŸ¥æ•°æ®é›†çš„å±æ€§ã€‚</p>
<pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">from</span> datasets <span class="token keyword">import</span> load_dataset_builder
dataset_builder <span class="token operator">=</span> load_dataset_builder<span class="token punctuation">(</span><span class="token string">'imdb'</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>dataset_builder<span class="token punctuation">.</span>cache_dir<span class="token punctuation">)</span>
<span class="token operator">/</span>Users<span class="token operator">/</span>thomwolf<span class="token operator">/</span><span class="token punctuation">.</span>cache<span class="token operator">/</span>huggingface<span class="token operator">/</span>datasets<span class="token operator">/</span>imdb<span class="token operator">/</span>plain_text<span class="token operator">/</span><span class="token number">1.0</span><span class="token punctuation">.</span><span class="token number">0</span><span class="token operator">/</span>fdc76b18d5506f14b0646729b8d371880ef1bc48a26d00835a7f3da44004b676
<span class="token keyword">print</span><span class="token punctuation">(</span>dataset_builder<span class="token punctuation">.</span>info<span class="token punctuation">.</span>features<span class="token punctuation">)</span>
<span class="token punctuation">{</span><span class="token string">'text'</span><span class="token punctuation">:</span> Value<span class="token punctuation">(</span>dtype<span class="token operator">=</span><span class="token string">'string'</span><span class="token punctuation">,</span> id<span class="token operator">=</span>None<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">'label'</span><span class="token punctuation">:</span> ClassLabel<span class="token punctuation">(</span>num_classes<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span> names<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">'neg'</span><span class="token punctuation">,</span> <span class="token string">'pos'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> names_file<span class="token operator">=</span>None<span class="token punctuation">,</span> id<span class="token operator">=</span>None<span class="token punctuation">)</span><span class="token punctuation">}</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>dataset_builder<span class="token punctuation">.</span>info<span class="token punctuation">.</span>splits<span class="token punctuation">)</span>
<span class="token punctuation">{</span><span class="token string">'train'</span><span class="token punctuation">:</span> SplitInfo<span class="token punctuation">(</span>name<span class="token operator">=</span><span class="token string">'train'</span><span class="token punctuation">,</span> num_bytes<span class="token operator">=</span><span class="token number">33432835</span><span class="token punctuation">,</span> num_examples<span class="token operator">=</span><span class="token number">25000</span><span class="token punctuation">,</span> dataset_name<span class="token operator">=</span><span class="token string">'imdb'</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">'test'</span><span class="token punctuation">:</span> SplitInfo<span class="token punctuation">(</span>name<span class="token operator">=</span><span class="token string">'test'</span><span class="token punctuation">,</span> num_bytes<span class="token operator">=</span><span class="token number">32650697</span><span class="token punctuation">,</span> num_examples<span class="token operator">=</span><span class="token number">25000</span><span class="token punctuation">,</span> dataset_name<span class="token operator">=</span><span class="token string">'imdb'</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">'unsupervised'</span><span class="token punctuation">:</span> SplitInfo<span class="token punctuation">(</span>name<span class="token operator">=</span><span class="token string">'unsupervised'</span><span class="token punctuation">,</span> num_bytes<span class="token operator">=</span><span class="token number">67106814</span><span class="token punctuation">,</span> num_examples<span class="token operator">=</span><span class="token number">50000</span><span class="token punctuation">,</span> dataset_name<span class="token operator">=</span><span class="token string">'imdb'</span><span class="token punctuation">)</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>å¯¹æ‰€éœ€çš„æ•°æ®é›†æ„Ÿåˆ°æ»¡æ„åï¼Œä½¿ç”¨ <strong><a href="https://huggingface.co/docs/datasets/v2.1.0/en/package_reference/loading_methods#datasets.load_dataset" target="_blank" rel="noopener">load_datasetï¼ˆï¼‰</a></strong>å°†å…¶åŠ è½½åˆ°ä¸€è¡Œä¸­ï¼š</p>
<pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">from</span> datasets <span class="token keyword">import</span> load_dataset
dataset <span class="token operator">=</span> load_dataset<span class="token punctuation">(</span><span class="token string">'glue'</span><span class="token punctuation">,</span> <span class="token string">'mrpc'</span><span class="token punctuation">,</span> split<span class="token operator">=</span><span class="token string">'train'</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>
<h2 id="é€‰æ‹©é…ç½®"><a href="#é€‰æ‹©é…ç½®" class="headerlink" title="é€‰æ‹©é…ç½®"></a><strong>é€‰æ‹©é…ç½®</strong></h2><p>æŸäº›æ•°æ®é›†ï¼ˆå¦‚<strong><a href="https://huggingface.co/datasets/glue" target="_blank" rel="noopener">é€šç”¨è¯­è¨€ç†è§£è¯„ä¼° ï¼ˆGLUEï¼‰</a></strong> åŸºå‡†æµ‹è¯•ï¼‰å®é™…ä¸Šç”±å¤šä¸ªæ•°æ®é›†ç»„æˆã€‚è¿™äº›å­æ•°æ®é›†ç§°ä¸º<strong>é…ç½®</strong>ï¼Œæ‚¨å¿…é¡»åœ¨åŠ è½½æ•°æ®é›†æ—¶æ˜¾å¼é€‰æ‹©ä¸€ä¸ªã€‚å¦‚æœæœªæä¾›é…ç½®åç§°ï¼ŒğŸ¤—åˆ™æ•°æ®é›†å°†å¼•å‘ a å¹¶æé†’æ‚¨é€‰æ‹©é…ç½®ã€‚<code>ValueError</code>ä½¿ç”¨ <strong><a href="https://huggingface.co/docs/datasets/v2.1.0/en/package_reference/loading_methods#datasets.get_dataset_config_names" target="_blank" rel="noopener">get_dataset_config_namesï¼ˆï¼‰</a></strong> å‡½æ•°æ£€ç´¢æ•°æ®é›†å¯ç”¨çš„æ‰€æœ‰å¯èƒ½é…ç½®çš„åˆ—è¡¨ï¼š</p>
<pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">from</span> datasets <span class="token keyword">import</span> get_dataset_config_names

configs <span class="token operator">=</span> get_dataset_config_names<span class="token punctuation">(</span><span class="token string">"glue"</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>configs<span class="token punctuation">)</span>
<span class="token comment" spellcheck="true"># ['cola', 'sst2', 'mrpc', 'qqp', 'stsb', 'mnli', 'mnli_mismatched', 'mnli_matched', 'qnli', 'rte', 'wnli', 'ax']</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>åŠ è½½é…ç½®çš„æ–¹å¼ä¸æ­£ç¡®ï¼š</p>
<pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">from</span> datasets <span class="token keyword">import</span> load_dataset
dataset <span class="token operator">=</span> load_dataset<span class="token punctuation">(</span><span class="token string">'glue'</span><span class="token punctuation">)</span>

ValueError<span class="token punctuation">:</span> Config name <span class="token keyword">is</span> missing<span class="token punctuation">.</span>
Please pick one among the available configs<span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token string">'cola'</span><span class="token punctuation">,</span> <span class="token string">'sst2'</span><span class="token punctuation">,</span> <span class="token string">'mrpc'</span><span class="token punctuation">,</span> <span class="token string">'qqp'</span><span class="token punctuation">,</span> <span class="token string">'stsb'</span><span class="token punctuation">,</span> <span class="token string">'mnli'</span><span class="token punctuation">,</span> <span class="token string">'mnli_mismatched'</span><span class="token punctuation">,</span> <span class="token string">'mnli_matched'</span><span class="token punctuation">,</span> <span class="token string">'qnli'</span><span class="token punctuation">,</span> <span class="token string">'rte'</span><span class="token punctuation">,</span> <span class="token string">'wnli'</span><span class="token punctuation">,</span> <span class="token string">'ax'</span><span class="token punctuation">]</span>
Example of usage<span class="token punctuation">:</span>
        <span class="token operator">*</span>load_dataset<span class="token punctuation">(</span><span class="token string">'glue'</span><span class="token punctuation">,</span> <span class="token string">'cola'</span><span class="token punctuation">)</span><span class="token operator">*</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>åŠ è½½é…ç½®çš„æ­£ç¡®æ–¹æ³•ï¼š</p>
<pre class="line-numbers language-python"><code class="language-python">dataset <span class="token operator">=</span> load_dataset<span class="token punctuation">(</span><span class="token string">'glue'</span><span class="token punctuation">,</span> <span class="token string">'sst2'</span><span class="token punctuation">)</span>
Downloading <span class="token operator">and</span> preparing dataset glue<span class="token operator">/</span>sst2 <span class="token punctuation">(</span>download<span class="token punctuation">:</span> <span class="token number">7.09</span> MiB<span class="token punctuation">,</span> generated<span class="token punctuation">:</span> <span class="token number">4.81</span> MiB<span class="token punctuation">,</span> total<span class="token punctuation">:</span> <span class="token number">11.90</span> MiB<span class="token punctuation">)</span> to <span class="token operator">/</span>Users<span class="token operator">/</span>thomwolf<span class="token operator">/</span><span class="token punctuation">.</span>cache<span class="token operator">/</span>huggingface<span class="token operator">/</span>datasets<span class="token operator">/</span>glue<span class="token operator">/</span>sst2<span class="token operator">/</span><span class="token number">1.0</span><span class="token punctuation">.</span><span class="token number">0</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>
Downloading<span class="token punctuation">:</span> <span class="token number">100</span><span class="token operator">%</span><span class="token operator">|</span>â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ<span class="token operator">|</span> <span class="token number">7.</span>44M<span class="token operator">/</span><span class="token number">7.</span>44M <span class="token punctuation">[</span><span class="token number">00</span><span class="token punctuation">:</span><span class="token number">01</span><span class="token operator">&lt;</span><span class="token number">00</span><span class="token punctuation">:</span><span class="token number">00</span><span class="token punctuation">,</span> <span class="token number">7.</span>03MB<span class="token operator">/</span>s<span class="token punctuation">]</span>
Dataset glue downloaded <span class="token operator">and</span> prepared to <span class="token operator">/</span>Users<span class="token operator">/</span>thomwolf<span class="token operator">/</span><span class="token punctuation">.</span>cache<span class="token operator">/</span>huggingface<span class="token operator">/</span>datasets<span class="token operator">/</span>glue<span class="token operator">/</span>sst2<span class="token operator">/</span><span class="token number">1.0</span><span class="token punctuation">.</span><span class="token number">0</span><span class="token punctuation">.</span> Subsequent calls will reuse this data<span class="token punctuation">.</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>dataset<span class="token punctuation">)</span>
<span class="token punctuation">{</span><span class="token string">'train'</span><span class="token punctuation">:</span> Dataset<span class="token punctuation">(</span>schema<span class="token punctuation">:</span> <span class="token punctuation">{</span><span class="token string">'sentence'</span><span class="token punctuation">:</span> <span class="token string">'string'</span><span class="token punctuation">,</span> <span class="token string">'label'</span><span class="token punctuation">:</span> <span class="token string">'int64'</span><span class="token punctuation">,</span> <span class="token string">'idx'</span><span class="token punctuation">:</span> <span class="token string">'int32'</span><span class="token punctuation">}</span><span class="token punctuation">,</span> num_rows<span class="token punctuation">:</span> <span class="token number">67349</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    <span class="token string">'validation'</span><span class="token punctuation">:</span> Dataset<span class="token punctuation">(</span>schema<span class="token punctuation">:</span> <span class="token punctuation">{</span><span class="token string">'sentence'</span><span class="token punctuation">:</span> <span class="token string">'string'</span><span class="token punctuation">,</span> <span class="token string">'label'</span><span class="token punctuation">:</span> <span class="token string">'int64'</span><span class="token punctuation">,</span> <span class="token string">'idx'</span><span class="token punctuation">:</span> <span class="token string">'int32'</span><span class="token punctuation">}</span><span class="token punctuation">,</span> num_rows<span class="token punctuation">:</span> <span class="token number">872</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    <span class="token string">'test'</span><span class="token punctuation">:</span> Dataset<span class="token punctuation">(</span>schema<span class="token punctuation">:</span> <span class="token punctuation">{</span><span class="token string">'sentence'</span><span class="token punctuation">:</span> <span class="token string">'string'</span><span class="token punctuation">,</span> <span class="token string">'label'</span><span class="token punctuation">:</span> <span class="token string">'int64'</span><span class="token punctuation">,</span> <span class="token string">'idx'</span><span class="token punctuation">:</span> <span class="token string">'int32'</span><span class="token punctuation">}</span><span class="token punctuation">,</span> num_rows<span class="token punctuation">:</span> <span class="token number">1821</span><span class="token punctuation">)</span>
<span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<h3 id="é€‰æ‹©æ‹†åˆ†"><a href="#é€‰æ‹©æ‹†åˆ†" class="headerlink" title="é€‰æ‹©æ‹†åˆ†"></a>é€‰æ‹©æ‹†åˆ†</h3><p>æ‹†åˆ†æ˜¯æ•°æ®é›†çš„ç‰¹å®šå­é›†ï¼Œå¦‚<code>train</code> å’Œ<code>testsplit</code> ã€‚è¯·ç¡®ä¿åœ¨åŠ è½½æ•°æ®é›†æ—¶é€‰æ‹©æ‹†åˆ†ã€‚å¦‚æœæœªæä¾›å‚æ•°ï¼ŒğŸ¤—åˆ™æ•°æ®é›†å°†ä»…è¿”å›åŒ…å«æ•°æ®é›†å­é›†çš„å­—å…¸ã€‚</p>
<pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">from</span> datasets <span class="token keyword">import</span> load_dataset
datasets <span class="token operator">=</span> load_dataset<span class="token punctuation">(</span><span class="token string">'glue'</span><span class="token punctuation">,</span> <span class="token string">'mrpc'</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>datasets<span class="token punctuation">)</span>
<span class="token punctuation">{</span>train<span class="token punctuation">:</span> Dataset<span class="token punctuation">(</span><span class="token punctuation">{</span>
    features<span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token string">'idx'</span><span class="token punctuation">,</span> <span class="token string">'label'</span><span class="token punctuation">,</span> <span class="token string">'sentence1'</span><span class="token punctuation">,</span> <span class="token string">'sentence2'</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
    num_rows<span class="token punctuation">:</span> <span class="token number">3668</span>
<span class="token punctuation">}</span><span class="token punctuation">)</span>
validation<span class="token punctuation">:</span> Dataset<span class="token punctuation">(</span><span class="token punctuation">{</span>
    features<span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token string">'idx'</span><span class="token punctuation">,</span> <span class="token string">'label'</span><span class="token punctuation">,</span> <span class="token string">'sentence1'</span><span class="token punctuation">,</span> <span class="token string">'sentence2'</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
    num_rows<span class="token punctuation">:</span> <span class="token number">408</span>
<span class="token punctuation">}</span><span class="token punctuation">)</span>
test<span class="token punctuation">:</span> Dataset<span class="token punctuation">(</span><span class="token punctuation">{</span>
    features<span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token string">'idx'</span><span class="token punctuation">,</span> <span class="token string">'label'</span><span class="token punctuation">,</span> <span class="token string">'sentence1'</span><span class="token punctuation">,</span> <span class="token string">'sentence2'</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
    num_rows<span class="token punctuation">:</span> <span class="token number">1725</span>
<span class="token punctuation">}</span><span class="token punctuation">)</span>
<span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>You can list the split names for a dataset, or a specific configuration, with the <strong><a href="https://huggingface.co/docs/datasets/v2.1.0/en/package_reference/loading_methods#datasets.get_dataset_split_names" target="_blank" rel="noopener">get_dataset_split_names()</a></strong> method:</p>
<pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">from</span> datasets <span class="token keyword">import</span> get_dataset_split_names
get_dataset_split_names<span class="token punctuation">(</span><span class="token string">'sent_comp'</span><span class="token punctuation">)</span>
<span class="token punctuation">[</span><span class="token string">'validation'</span><span class="token punctuation">,</span> <span class="token string">'train'</span><span class="token punctuation">]</span>
get_dataset_split_names<span class="token punctuation">(</span><span class="token string">'glue'</span><span class="token punctuation">,</span> <span class="token string">'cola'</span><span class="token punctuation">)</span>
<span class="token punctuation">[</span><span class="token string">'test'</span><span class="token punctuation">,</span> <span class="token string">'train'</span><span class="token punctuation">,</span> <span class="token string">'validation'</span><span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<h2 id="The-Dataset-object"><a href="#The-Dataset-object" class="headerlink" title="The Dataset object"></a>The Dataset object</h2><p>æœ¬éƒ¨åˆ†ç†Ÿæ‚‰<strong><a href="https://huggingface.co/docs/datasets/v2.1.0/en/package_reference/main_classes#datasets.Dataset" target="_blank" rel="noopener">æ•°æ®é›†</a></strong>å¯¹è±¡ã€‚äº†è§£å­˜å‚¨åœ¨ Dataset å¯¹è±¡ä¸­çš„å…ƒæ•°æ®ï¼Œä»¥åŠæŸ¥è¯¢ Dataset å¯¹è±¡ä»¥è¿”å›è¡Œå’Œåˆ—çš„åŸºç¡€çŸ¥è¯†ã€‚</p>
<p>åŠ è½½<strong><a href="https://huggingface.co/docs/datasets/v2.1.0/en/package_reference/main_classes#datasets.Dataset" target="_blank" rel="noopener">æ•°æ®é›†</a></strong>çš„å®ä¾‹æ—¶ï¼Œå°†è¿”å› Dataset å¯¹è±¡ã€‚æ­¤å¯¹è±¡çš„è¡Œä¸ºç±»ä¼¼äºæ™®é€šçš„ Python å®¹å™¨ã€‚</p>
<pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">from</span> datasets <span class="token keyword">import</span> load_dataset
dataset <span class="token operator">=</span> load_dataset<span class="token punctuation">(</span><span class="token string">'glue'</span><span class="token punctuation">,</span> <span class="token string">'mrpc'</span><span class="token punctuation">,</span> split<span class="token operator">=</span><span class="token string">'train'</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>
<h3 id="å…ƒæ•°æ®"><a href="#å…ƒæ•°æ®" class="headerlink" title="å…ƒæ•°æ®"></a><strong>å…ƒæ•°æ®</strong></h3><p><strong><a href="https://huggingface.co/docs/datasets/v2.1.0/en/package_reference/main_classes#datasets.Dataset" target="_blank" rel="noopener">æ•°æ®é›†</a></strong>å¯¹è±¡åŒ…å«æœ‰å…³æ•°æ®é›†çš„å¤§é‡æœ‰ç”¨ä¿¡æ¯ã€‚ä¾‹å¦‚ï¼Œè®¿é—® <strong><a href="https://huggingface.co/docs/datasets/v2.1.0/en/package_reference/main_classes#datasets.DatasetInfo" target="_blank" rel="noopener">DatasetInfo</a></strong> ä»¥è¿”å›æ•°æ®é›†ã€ä½œè€…ç”šè‡³æ•°æ®é›†å¤§å°çš„ç®€çŸ­è¯´æ˜ã€‚è¿™å°†ä¸ºæ‚¨æä¾›æ•°æ®é›†æœ€é‡è¦å±æ€§çš„å¿«é€Ÿå¿«ç…§ã€‚</p>
<pre class="line-numbers language-python"><code class="language-python">dataset<span class="token punctuation">.</span>info
DatasetInfo<span class="token punctuation">(</span>
    description<span class="token operator">=</span><span class="token string">'GLUE, the General Language Understanding Evaluation benchmark\\n(&lt;https://gluebenchmark.com/>) is a collection of resources for training,\\nevaluating, and analyzing natural language understanding systems.\\n\\n'</span><span class="token punctuation">,</span> 
    citation<span class="token operator">=</span><span class="token string">'@inproceedings{dolan2005automatically,\\n  title={Automatically constructing a corpus of sentential paraphrases},\\n  author={Dolan, William B and Brockett, Chris},\\n  booktitle={Proceedings of the Third International Workshop on Paraphrasing (IWP2005)},\\n  year={2005}\\n}\\n@inproceedings{wang2019glue,\\n  title={{GLUE}: A Multi-Task Benchmark and Analysis Platform for Natural Language Understanding},\\n  author={Wang, Alex and Singh, Amanpreet and Michael, Julian and Hill, Felix and Levy, Omer and Bowman, Samuel R.},\\n  note={In the Proceedings of ICLR.},\\n  year={2019}\\n}\\n'</span><span class="token punctuation">,</span> homepage<span class="token operator">=</span><span class="token string">'&lt;https: www.microsoft.com="" en-us="" download="" details.aspx?id="52398">'</span><span class="token punctuation">,</span> 
    license<span class="token operator">=</span><span class="token string">''</span><span class="token punctuation">,</span> 
    features<span class="token operator">=</span><span class="token punctuation">{</span><span class="token string">'sentence1'</span><span class="token punctuation">:</span> Value<span class="token punctuation">(</span>dtype<span class="token operator">=</span><span class="token string">'string'</span><span class="token punctuation">,</span> id<span class="token operator">=</span>None<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">'sentence2'</span><span class="token punctuation">:</span> Value<span class="token punctuation">(</span>dtype<span class="token operator">=</span><span class="token string">'string'</span><span class="token punctuation">,</span> id<span class="token operator">=</span>None<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">'label'</span><span class="token punctuation">:</span> ClassLabel<span class="token punctuation">(</span>num_classes<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span> names<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">'not_equivalent'</span><span class="token punctuation">,</span> <span class="token string">'equivalent'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> names_file<span class="token operator">=</span>None<span class="token punctuation">,</span> id<span class="token operator">=</span>None<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">'idx'</span><span class="token punctuation">:</span> Value<span class="token punctuation">(</span>dtype<span class="token operator">=</span><span class="token string">'int32'</span><span class="token punctuation">,</span> id<span class="token operator">=</span>None<span class="token punctuation">)</span><span class="token punctuation">}</span><span class="token punctuation">,</span> post_processed<span class="token operator">=</span>None<span class="token punctuation">,</span> supervised_keys<span class="token operator">=</span>None<span class="token punctuation">,</span> builder_name<span class="token operator">=</span><span class="token string">'glue'</span><span class="token punctuation">,</span> config_name<span class="token operator">=</span><span class="token string">'mrpc'</span><span class="token punctuation">,</span> version<span class="token operator">=</span><span class="token number">1.0</span><span class="token punctuation">.</span><span class="token number">0</span><span class="token punctuation">,</span> splits<span class="token operator">=</span><span class="token punctuation">{</span><span class="token string">'train'</span><span class="token punctuation">:</span> SplitInfo<span class="token punctuation">(</span>name<span class="token operator">=</span><span class="token string">'train'</span><span class="token punctuation">,</span> num_bytes<span class="token operator">=</span><span class="token number">943851</span><span class="token punctuation">,</span> num_examples<span class="token operator">=</span><span class="token number">3668</span><span class="token punctuation">,</span> dataset_name<span class="token operator">=</span><span class="token string">'glue'</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">'validation'</span><span class="token punctuation">:</span> SplitInfo<span class="token punctuation">(</span>name<span class="token operator">=</span><span class="token string">'validation'</span><span class="token punctuation">,</span> num_bytes<span class="token operator">=</span><span class="token number">105887</span><span class="token punctuation">,</span> num_examples<span class="token operator">=</span><span class="token number">408</span><span class="token punctuation">,</span> dataset_name<span class="token operator">=</span><span class="token string">'glue'</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">'test'</span><span class="token punctuation">:</span> SplitInfo<span class="token punctuation">(</span>name<span class="token operator">=</span><span class="token string">'test'</span><span class="token punctuation">,</span> num_bytes<span class="token operator">=</span><span class="token number">442418</span><span class="token punctuation">,</span> num_examples<span class="token operator">=</span><span class="token number">1725</span><span class="token punctuation">,</span> dataset_name<span class="token operator">=</span><span class="token string">'glue'</span><span class="token punctuation">)</span><span class="token punctuation">}</span><span class="token punctuation">,</span> 
    download_checksums<span class="token operator">=</span><span class="token punctuation">{</span><span class="token string">'&lt;https: dl.fbaipublicfiles.com="" glue="" data="" mrpc_dev_ids.tsv="">'</span><span class="token punctuation">:</span> <span class="token punctuation">{</span><span class="token string">'num_bytes'</span><span class="token punctuation">:</span> <span class="token number">6222</span><span class="token punctuation">,</span> <span class="token string">'checksum'</span><span class="token punctuation">:</span> <span class="token string">'971d7767d81b997fd9060ade0ec23c4fc31cbb226a55d1bd4a1bac474eb81dc7'</span><span class="token punctuation">}</span><span class="token punctuation">,</span> <span class="token string">'&lt;https: dl.fbaipublicfiles.com="" senteval="" senteval_data="" msr_paraphrase_train.txt="">'</span><span class="token punctuation">:</span> <span class="token punctuation">{</span><span class="token string">'num_bytes'</span><span class="token punctuation">:</span> <span class="token number">1047044</span><span class="token punctuation">,</span> <span class="token string">'checksum'</span><span class="token punctuation">:</span> <span class="token string">'60a9b09084528f0673eedee2b69cb941920f0b8cd0eeccefc464a98768457f89'</span><span class="token punctuation">}</span><span class="token punctuation">,</span> <span class="token string">'&lt;https: dl.fbaipublicfiles.com="" senteval="" senteval_data="" msr_paraphrase_test.txt="">'</span><span class="token punctuation">:</span> <span class="token punctuation">{</span><span class="token string">'num_bytes'</span><span class="token punctuation">:</span> <span class="token number">441275</span><span class="token punctuation">,</span> <span class="token string">'checksum'</span><span class="token punctuation">:</span> <span class="token string">'a04e271090879aaba6423d65b94950c089298587d9c084bf9cd7439bd785f784'</span><span class="token punctuation">}</span><span class="token punctuation">}</span><span class="token punctuation">,</span> 
    download_size<span class="token operator">=</span><span class="token number">1494541</span><span class="token punctuation">,</span> 
    post_processing_size<span class="token operator">=</span>None<span class="token punctuation">,</span> 
    dataset_size<span class="token operator">=</span><span class="token number">1492156</span><span class="token punctuation">,</span> 
    size_in_bytes<span class="token operator">=</span><span class="token number">2986697</span>
<span class="token punctuation">)</span><span class="token operator">&lt;</span><span class="token operator">/</span>https<span class="token punctuation">:</span><span class="token operator">></span><span class="token operator">&lt;</span><span class="token operator">/</span>https<span class="token punctuation">:</span><span class="token operator">></span><span class="token operator">&lt;</span><span class="token operator">/</span>https<span class="token punctuation">:</span><span class="token operator">></span><span class="token operator">&lt;</span><span class="token operator">/</span>https<span class="token punctuation">:</span><span class="token operator">></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>å¯ä»¥é€šè¿‡ç›´æ¥è°ƒç”¨æ•°æ®é›†çš„ç‰¹å®šå±æ€§æ¥è¯·æ±‚å®ƒä»¬</p>
<pre class="line-numbers language-python"><code class="language-python">dataset<span class="token punctuation">.</span>split
NamedSplit<span class="token punctuation">(</span><span class="token string">'train'</span><span class="token punctuation">)</span>
dataset<span class="token punctuation">.</span>description
<span class="token string">'GLUE, the General Language Understanding Evaluation benchmark\\n(&lt;https://gluebenchmark.com/>) is a collection of resources for training,\\nevaluating, and analyzing natural language understanding systems.\\n\\n'</span>
dataset<span class="token punctuation">.</span>citation
<span class="token string">'@inproceedings{dolan2005automatically,\\n  title={Automatically constructing a corpus of sentential paraphrases},\\n  author={Dolan, William B and Brockett, Chris},\\n  booktitle={Proceedings of the Third International Workshop on Paraphrasing (IWP2005)},\\n  year={2005}\\n}\\n@inproceedings{wang2019glue,\\n  title={{GLUE}: A Multi-Task Benchmark and Analysis Platform for Natural Language Understanding},\\n  author={Wang, Alex and Singh, Amanpreet and Michael, Julian and Hill, Felix and Levy, Omer and Bowman, Samuel R.},\\n  note={In the Proceedings of ICLR.},\\n  year={2019}\\n}\\n\\nNote that each GLUE dataset has its own citation. Please see the source to see\\nthe correct citation for each contained dataset.'</span>
dataset<span class="token punctuation">.</span>homepage
<span class="token string">'&lt;https://www.microsoft.com/en-us/download/details.aspx?id=52398>'</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<h3 id="åŠŸèƒ½å’Œåˆ—"><a href="#åŠŸèƒ½å’Œåˆ—" class="headerlink" title="åŠŸèƒ½å’Œåˆ—"></a><strong>åŠŸèƒ½å’Œåˆ—</strong></h3><p>æ•°æ®é›†æ˜¯è¡Œå’Œç±»å‹åŒ–åˆ—çš„è¡¨ã€‚æŸ¥è¯¢æ•°æ®é›†å°†è¿”å›ä¸€ä¸ª Python å­—å…¸ï¼Œå…¶ä¸­é”®å¯¹åº”äºåˆ—åï¼Œå€¼å¯¹åº”äºåˆ—å€¼ï¼š</p>
<pre class="line-numbers language-python"><code class="language-python">dataset<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
<span class="token punctuation">{</span><span class="token string">'idx'</span><span class="token punctuation">:</span> <span class="token number">0</span><span class="token punctuation">,</span>
<span class="token string">'label'</span><span class="token punctuation">:</span> <span class="token number">1</span><span class="token punctuation">,</span>
<span class="token string">'sentence1'</span><span class="token punctuation">:</span> <span class="token string">'Amrozi accused his brother , whom he called " the witness " , of deliberately distorting his evidence .'</span><span class="token punctuation">,</span>
<span class="token string">'sentence2'</span><span class="token punctuation">:</span> <span class="token string">'Referring to him as only " the witness " , Amrozi accused his brother of deliberately distorting his evidence .'</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>è¿”å›å…·æœ‰ä»¥ä¸‹æ ‡å‡†å±æ€§çš„è¡Œæ•°å’Œåˆ—æ•°ï¼š</p>
<pre class="line-numbers language-python"><code class="language-python">dataset<span class="token punctuation">.</span>shape
<span class="token punctuation">(</span><span class="token number">3668</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">)</span>
dataset<span class="token punctuation">.</span>num_columns
<span class="token number">4</span>
dataset<span class="token punctuation">.</span>num_rows
<span class="token number">3668</span>
len<span class="token punctuation">(</span>dataset<span class="token punctuation">)</span>
<span class="token number">3668</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>åˆ—å‡ºå¸¦æœ‰ <strong><a href="https://huggingface.co/docs/datasets/v2.1.0/en/package_reference/main_classes#datasets.Dataset.column_names" target="_blank" rel="noopener">Dataset.column_namesï¼ˆï¼‰ çš„</a></strong>åˆ—åç§°ï¼š</p>
<pre class="line-numbers language-python"><code class="language-python">dataset<span class="token punctuation">.</span>column_names
<span class="token punctuation">[</span><span class="token string">'idx'</span><span class="token punctuation">,</span> <span class="token string">'label'</span><span class="token punctuation">,</span> <span class="token string">'sentence1'</span><span class="token punctuation">,</span> <span class="token string">'sentence2'</span><span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>
<p>è·å–æœ‰å…³å…·æœ‰<strong><a href="https://huggingface.co/docs/datasets/v2.1.0/en/package_reference/main_classes#datasets.Features" target="_blank" rel="noopener">ä»¥ä¸‹åŠŸèƒ½</a></strong>çš„åˆ—çš„è¯¦ç»†ä¿¡æ¯ï¼š</p>
<pre class="line-numbers language-python"><code class="language-python">dataset<span class="token punctuation">.</span>features
<span class="token punctuation">{</span><span class="token string">'idx'</span><span class="token punctuation">:</span> Value<span class="token punctuation">(</span>dtype<span class="token operator">=</span><span class="token string">'int32'</span><span class="token punctuation">,</span> id<span class="token operator">=</span>None<span class="token punctuation">)</span><span class="token punctuation">,</span>
    <span class="token string">'label'</span><span class="token punctuation">:</span> ClassLabel<span class="token punctuation">(</span>num_classes<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span> names<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">'not_equivalent'</span><span class="token punctuation">,</span> <span class="token string">'equivalent'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> names_file<span class="token operator">=</span>None<span class="token punctuation">,</span> id<span class="token operator">=</span>None<span class="token punctuation">)</span><span class="token punctuation">,</span>
    <span class="token string">'sentence1'</span><span class="token punctuation">:</span> Value<span class="token punctuation">(</span>dtype<span class="token operator">=</span><span class="token string">'string'</span><span class="token punctuation">,</span> id<span class="token operator">=</span>None<span class="token punctuation">)</span><span class="token punctuation">,</span>
    <span class="token string">'sentence2'</span><span class="token punctuation">:</span> Value<span class="token punctuation">(</span>dtype<span class="token operator">=</span><span class="token string">'string'</span><span class="token punctuation">,</span> id<span class="token operator">=</span>None<span class="token punctuation">)</span><span class="token punctuation">,</span>
<span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>è¿”å›æœ‰å…³ç±»<strong><a href="https://huggingface.co/docs/datasets/v2.1.0/en/package_reference/main_classes#datasets.ClassLabel" target="_blank" rel="noopener">æ ‡ç­¾</a></strong>ç­‰è¦ç´ çš„æ›´å…·ä½“ä¿¡æ¯</p>
<pre class="line-numbers language-python"><code class="language-python">dataset<span class="token punctuation">.</span>features<span class="token punctuation">[</span><span class="token string">'label'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>num_classes
<span class="token number">2</span>
dataset<span class="token punctuation">.</span>features<span class="token punctuation">[</span><span class="token string">'label'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>names
<span class="token punctuation">[</span><span class="token string">'not_equivalent'</span><span class="token punctuation">,</span> <span class="token string">'equivalent'</span><span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre>
<h3 id="è¡Œã€åˆ‡ç‰‡ã€æ‰¹å’Œåˆ—"><a href="#è¡Œã€åˆ‡ç‰‡ã€æ‰¹å’Œåˆ—" class="headerlink" title="è¡Œã€åˆ‡ç‰‡ã€æ‰¹å’Œåˆ—"></a><strong>è¡Œã€åˆ‡ç‰‡ã€æ‰¹å’Œåˆ—</strong></h3><p>ä½¿ç”¨åˆ‡ç‰‡è¡¨ç¤ºæ³•æˆ–ç´¢å¼•åˆ—è¡¨ä¸€æ¬¡è·å–æ•°æ®é›†çš„å‡ è¡Œï¼š</p>
<pre class="line-numbers language-python"><code class="language-python">dataset<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token number">3</span><span class="token punctuation">]</span>
<span class="token punctuation">{</span><span class="token string">'idx'</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
    <span class="token string">'label'</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
    <span class="token string">'sentence1'</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token string">'Amrozi accused his brother , whom he called " the witness " , of deliberately distorting his evidence .'</span><span class="token punctuation">,</span> <span class="token string">"Yucaipa owned Dominick 's before selling the chain to Safeway in 1998 for $ 2.5 billion ."</span><span class="token punctuation">,</span> <span class="token string">'They had published an advertisement on the Internet on June 10 , offering the cargo for sale , he added .'</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
    <span class="token string">'sentence2'</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token string">'Referring to him as only " the witness " , Amrozi accused his brother of deliberately distorting his evidence .'</span><span class="token punctuation">,</span> <span class="token string">"Yucaipa bought Dominick 's in 1995 for $ 693 million and sold it to Safeway for $ 1.8 billion in 1998 ."</span><span class="token punctuation">,</span> <span class="token string">"On June 10 , the ship 's owners had published an advertisement on the Internet , offering the explosives for sale ."</span><span class="token punctuation">]</span>
<span class="token punctuation">}</span>
dataset<span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">]</span><span class="token punctuation">]</span>
<span class="token punctuation">{</span><span class="token string">'idx'</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
    <span class="token string">'label'</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> 
    <span class="token string">'sentence1'</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token string">"Yucaipa owned Dominick 's before selling the chain to Safeway in 1998 for $ 2.5 billion ."</span><span class="token punctuation">,</span> <span class="token string">'Around 0335 GMT , Tab shares were up 19 cents , or 4.4 % , at A $ 4.56 , having earlier set a record high of A $ 4.57 .'</span><span class="token punctuation">,</span> <span class="token string">'Revenue in the first quarter of the year dropped 15 percent from the same period a year earlier .'</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
    <span class="token string">'sentence2'</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token string">"Yucaipa bought Dominick 's in 1995 for $ 693 million and sold it to Safeway for $ 1.8 billion in 1998 ."</span><span class="token punctuation">,</span> <span class="token string">'Tab shares jumped 20 cents , or 4.6 % , to set a record closing high at A $ 4.57 .'</span><span class="token punctuation">,</span> <span class="token string">"With the scandal hanging over Stewart 's company , revenue the first quarter of the year dropped 15 percent from the same period a year earlier ."</span><span class="token punctuation">]</span>
<span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>æŒ‰åˆ—åæŸ¥è¯¢å°†è¿”å›å…¶å€¼ã€‚ä¾‹å¦‚ï¼Œå¦‚æœæ‚¨åªæƒ³è¿”å›å‰ä¸‰ä¸ªç¤ºä¾‹ï¼š</p>
<pre class="line-numbers language-python"><code class="language-python">dataset<span class="token punctuation">[</span><span class="token string">'sentence1'</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token number">3</span><span class="token punctuation">]</span>
<span class="token punctuation">[</span><span class="token string">'Amrozi accused his brother , whom he called " the witness " , of deliberately distorting his evidence .'</span><span class="token punctuation">,</span> <span class="token string">"Yucaipa owned Dominick 's before selling the chain to Safeway in 1998 for $ 2.5 billion ."</span><span class="token punctuation">,</span> <span class="token string">'They had published an advertisement on the Internet on June 10 , offering the cargo for sale , he added .'</span><span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>
<p>æ ¹æ®<strong><a href="https://huggingface.co/docs/datasets/v2.1.0/en/package_reference/main_classes#datasets.Dataset" target="_blank" rel="noopener">æŸ¥è¯¢ Dataset</a></strong> å¯¹è±¡çš„æ–¹å¼ï¼Œè¿”å›çš„æ ¼å¼å°†æœ‰æ‰€ä¸åŒï¼š</p>
<ul>
<li>åƒè¿™æ ·çš„å•ä¸ªè¡Œè¿”å› Python å€¼å­—å…¸ã€‚<code>dataset[0]</code></li>
<li>ç±»ä¼¼è¿™æ ·çš„æ‰¹å¤„ç†è¿”å›å€¼åˆ—è¡¨çš„ Python å­—å…¸ã€‚<code>dataset[5:10]</code></li>
<li>ç±»ä¼¼è¿™æ ·çš„åˆ—è¿”å› Python å€¼åˆ—è¡¨ã€‚<code>dataset['sentence1']</code></li>
</ul>
<h2 id="Train-with-ğŸ¤—-Datasets"><a href="#Train-with-ğŸ¤—-Datasets" class="headerlink" title="Train with ğŸ¤— Datasets"></a>Train with ğŸ¤— Datasets</h2><p>å¯¹æ•°æ®é›†è¿›è¡Œæ ‡è®°åŒ–ï¼Œå¹¶å°†æ•°æ®é›†ä¸ PyTorch æˆ– TensorFlow ç­‰æ¡†æ¶é…åˆä½¿ç”¨ã€‚é»˜è®¤æƒ…å†µä¸‹ï¼Œæ‰€æœ‰æ•°æ®é›†åˆ—éƒ½ä½œä¸º Python å¯¹è±¡è¿”å›ã€‚ä½†æ˜¯ï¼Œæ‚¨å¯ä»¥é€šè¿‡è®¾ç½®æ•°æ®é›†çš„æ ¼å¼æ¥å¼¥åˆ Python å¯¹è±¡ä¸æœºå™¨å­¦ä¹ æ¡†æ¶ä¹‹é—´çš„å·®è·ã€‚æ ¼å¼åŒ–å°†åˆ—è½¬æ¢ä¸ºå…¼å®¹çš„ PyTorch æˆ– TensorFlow ç±»å‹ã€‚</p>
<p>é€šå¸¸ï¼Œåœ¨ä½¿ç”¨æ•°æ®é›†è®­ç»ƒæ¨¡å‹ä¹‹å‰ï¼Œæ‚¨å¯èƒ½å¸Œæœ›ä¿®æ”¹æ•°æ®é›†çš„ç»“æ„å’Œå†…å®¹ã€‚ä¾‹å¦‚ï¼Œæ‚¨å¯èƒ½å¸Œæœ›åˆ é™¤åˆ—æˆ–å°†å…¶è½¬æ¢ä¸ºå…¶ä»–ç±»å‹ã€‚ğŸ¤— æ•°æ®é›†æä¾›äº†æ‰§è¡Œæ­¤æ“ä½œæ‰€éœ€çš„å·¥å…·ï¼Œä½†ç”±äºæ¯ä¸ªæ•°æ®é›†éƒ½éå¸¸ä¸åŒï¼Œå› æ­¤å¤„ç†æ–¹æ³•å°†å•ç‹¬å˜åŒ–ã€‚</p>
<h3 id="æ ‡è®°åŒ–"><a href="#æ ‡è®°åŒ–" class="headerlink" title="æ ‡è®°åŒ–"></a><strong>æ ‡è®°åŒ–</strong></h3><p>æ ‡è®°åŒ–å°†æ–‡æœ¬åˆ’åˆ†ä¸ºç§°ä¸ºæ ‡è®°çš„å•ä¸ªå•è¯ã€‚ä»¤ç‰Œè¢«è½¬æ¢ä¸ºæ•°å­—ï¼Œè¿™æ˜¯æ¨¡å‹ä½œä¸ºå…¶è¾“å…¥æ¥æ”¶çš„å†…å®¹ã€‚</p>
<p>é¦–å…ˆï¼Œå®‰è£…Transformers</p>
<pre class="line-numbers language-python"><code class="language-python">pip install transformers<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<p>æ¥ä¸‹æ¥ï¼Œå¯¼å…¥åˆ†è¯å™¨ã€‚ä½¿ç”¨ä¸æ‚¨æ­£åœ¨ä½¿ç”¨çš„æ¨¡å‹å…³è”çš„åˆ†è¯å™¨éå¸¸é‡è¦ï¼Œå› æ­¤æ–‡æœ¬å°†ä»¥ç›¸åŒçš„æ–¹å¼æ‹†åˆ†ã€‚åœ¨æ­¤ç¤ºä¾‹ä¸­ï¼ŒåŠ è½½ <strong><a href="https://huggingface.co/transformers/model_doc/bert#berttokenizerfast" target="_blank" rel="noopener">BERT åˆ†è¯å™¨ï¼Œ</a></strong>å› ä¸ºæ‚¨ä½¿ç”¨çš„æ˜¯ <strong><a href="https://huggingface.co/bert-base-cased" target="_blank" rel="noopener">BERT</a></strong>æ¨¡å‹ï¼š</p>
<pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">from</span> transformers <span class="token keyword">import</span> BertTokenizerFast
tokenizer <span class="token operator">=</span> BertTokenizerFast<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span><span class="token string">'bert-base-cased'</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>
<p>ç°åœ¨ï¼Œæ‚¨å¯ä»¥å¯¹æ•°æ®é›†çš„å­—æ®µè¿›è¡Œæ ‡è®°åŒ–ï¼š<code>sentence1</code></p>
<pre class="line-numbers language-python"><code class="language-python">encoded_dataset <span class="token operator">=</span> dataset<span class="token punctuation">.</span>map<span class="token punctuation">(</span><span class="token keyword">lambda</span> examples<span class="token punctuation">:</span> tokenizer<span class="token punctuation">(</span>examples<span class="token punctuation">[</span><span class="token string">'sentence1'</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span> batched<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
encoded_dataset<span class="token punctuation">.</span>column_names
<span class="token punctuation">[</span><span class="token string">'sentence1'</span><span class="token punctuation">,</span> <span class="token string">'sentence2'</span><span class="token punctuation">,</span> <span class="token string">'label'</span><span class="token punctuation">,</span> <span class="token string">'idx'</span><span class="token punctuation">,</span> <span class="token string">'input_ids'</span><span class="token punctuation">,</span> <span class="token string">'token_type_ids'</span><span class="token punctuation">,</span> <span class="token string">'attention_mask'</span><span class="token punctuation">]</span>
encoded_dataset<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
<span class="token punctuation">{</span><span class="token string">'sentence1'</span><span class="token punctuation">:</span> <span class="token string">'Amrozi accused his brother , whom he called " the witness " , of deliberately distorting his evidence .'</span><span class="token punctuation">,</span>
<span class="token string">'sentence2'</span><span class="token punctuation">:</span> <span class="token string">'Referring to him as only " the witness " , Amrozi accused his brother of deliberately distorting his evidence .'</span><span class="token punctuation">,</span>
<span class="token string">'label'</span><span class="token punctuation">:</span> <span class="token number">1</span><span class="token punctuation">,</span>
<span class="token string">'idx'</span><span class="token punctuation">:</span> <span class="token number">0</span><span class="token punctuation">,</span>
<span class="token string">'input_ids'</span><span class="token punctuation">:</span> <span class="token punctuation">[</span>  <span class="token number">101</span><span class="token punctuation">,</span>  <span class="token number">7277</span><span class="token punctuation">,</span>  <span class="token number">2180</span><span class="token punctuation">,</span>  <span class="token number">5303</span><span class="token punctuation">,</span>  <span class="token number">4806</span><span class="token punctuation">,</span>  <span class="token number">1117</span><span class="token punctuation">,</span>  <span class="token number">1711</span><span class="token punctuation">,</span>   <span class="token number">117</span><span class="token punctuation">,</span>  <span class="token number">2292</span><span class="token punctuation">,</span> <span class="token number">1119</span><span class="token punctuation">,</span>  <span class="token number">1270</span><span class="token punctuation">,</span>   <span class="token number">107</span><span class="token punctuation">,</span>  <span class="token number">1103</span><span class="token punctuation">,</span>  <span class="token number">7737</span><span class="token punctuation">,</span>   <span class="token number">107</span><span class="token punctuation">,</span>   <span class="token number">117</span><span class="token punctuation">,</span>  <span class="token number">1104</span><span class="token punctuation">,</span>  <span class="token number">9938</span><span class="token punctuation">,</span> <span class="token number">4267</span><span class="token punctuation">,</span> <span class="token number">12223</span><span class="token punctuation">,</span> <span class="token number">21811</span><span class="token punctuation">,</span>  <span class="token number">1117</span><span class="token punctuation">,</span>  <span class="token number">2554</span><span class="token punctuation">,</span>   <span class="token number">119</span><span class="token punctuation">,</span>   <span class="token number">102</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
<span class="token string">'token_type_ids'</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
<span class="token string">'attention_mask'</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span>
<span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>æ ‡è®°åŒ–è¿‡ç¨‹å°†åˆ›å»ºä¸‰ä¸ªæ–°åˆ—ï¼š<code>input_ids</code>ã€<code>token_type_ids</code>ã€<code>attention_mask</code> ã€‚è¿™äº›æ˜¯æ¨¡å‹çš„è¾“å…¥ã€‚</p>
<h3 id="PyTorch"><a href="#PyTorch" class="headerlink" title="PyTorch"></a><strong>PyTorch</strong></h3><p>å¦‚æœä½¿ç”¨çš„æ˜¯ PyTorchï¼Œè¯·ä½¿ç”¨ <strong><a href="https://huggingface.co/docs/datasets/v2.1.0/en/package_reference/main_classes#datasets.Dataset.set_format" target="_blank" rel="noopener">Dataset.set_formatï¼ˆï¼‰</a></strong> è®¾ç½®æ ¼å¼ï¼Œå®ƒæ¥å—ä¸¤ä¸ªä¸»è¦å‚æ•°ï¼š</p>
<ol>
<li><code>type</code>å®šä¹‰è¦å¼ºåˆ¶è½¬æ¢ä¸ºçš„åˆ—çš„ç±»å‹ã€‚ä¾‹å¦‚<code>torch</code>ï¼Œè¿”å› PyTorch å¼ é‡ã€‚</li>
<li><code>columns</code>æŒ‡å®šåº”è®¾ç½®æ ¼å¼çš„åˆ—ã€‚</li>
</ol>
<p>è®¾ç½®æ ¼å¼åï¼Œä½¿ç”¨ åŒ…è£…æ•°æ®é›†ã€‚æ‚¨çš„æ•°æ®é›†ç°åœ¨å·²å‡†å¤‡å¥½åœ¨è®­ç»ƒå¾ªç¯ä¸­ä½¿ç”¨ï¼<code>torch.utils.data.DataLoader</code></p>
<pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">import</span> torch
<span class="token keyword">from</span> datasets <span class="token keyword">import</span> load_dataset
<span class="token keyword">from</span> transformers <span class="token keyword">import</span> AutoTokenizer
dataset <span class="token operator">=</span> load_dataset<span class="token punctuation">(</span><span class="token string">'glue'</span><span class="token punctuation">,</span> <span class="token string">'mrpc'</span><span class="token punctuation">,</span> split<span class="token operator">=</span><span class="token string">'train'</span><span class="token punctuation">)</span>
tokenizer <span class="token operator">=</span> AutoTokenizer<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span><span class="token string">'bert-base-cased'</span><span class="token punctuation">)</span>
dataset <span class="token operator">=</span> dataset<span class="token punctuation">.</span>map<span class="token punctuation">(</span><span class="token keyword">lambda</span> e<span class="token punctuation">:</span> tokenizer<span class="token punctuation">(</span>e<span class="token punctuation">[</span><span class="token string">'sentence1'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> truncation<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token string">'max_length'</span><span class="token punctuation">)</span><span class="token punctuation">,</span> batched<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
dataset<span class="token punctuation">.</span>set_format<span class="token punctuation">(</span>type<span class="token operator">=</span><span class="token string">'torch'</span><span class="token punctuation">,</span> columns<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">'input_ids'</span><span class="token punctuation">,</span> <span class="token string">'token_type_ids'</span><span class="token punctuation">,</span> <span class="token string">'attention_mask'</span><span class="token punctuation">,</span> <span class="token string">'label'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
dataloader <span class="token operator">=</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data<span class="token punctuation">.</span>DataLoader<span class="token punctuation">(</span>dataset<span class="token punctuation">,</span> batch_size<span class="token operator">=</span><span class="token number">32</span><span class="token punctuation">)</span>
next<span class="token punctuation">(</span>iter<span class="token punctuation">(</span>dataloader<span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token punctuation">{</span><span class="token string">'attention_mask'</span><span class="token punctuation">:</span> tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span>  <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
                         <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">,</span>
                         <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span>  <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
<span class="token string">'input_ids'</span><span class="token punctuation">:</span> tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span>  <span class="token number">101</span><span class="token punctuation">,</span>  <span class="token number">7277</span><span class="token punctuation">,</span>  <span class="token number">2180</span><span class="token punctuation">,</span>  <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">,</span>     <span class="token number">0</span><span class="token punctuation">,</span>     <span class="token number">0</span><span class="token punctuation">,</span>     <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
                    <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">,</span>
                    <span class="token punctuation">[</span>  <span class="token number">101</span><span class="token punctuation">,</span>  <span class="token number">1109</span><span class="token punctuation">,</span>  <span class="token number">4173</span><span class="token punctuation">,</span>  <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">,</span>     <span class="token number">0</span><span class="token punctuation">,</span>     <span class="token number">0</span><span class="token punctuation">,</span>     <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
<span class="token string">'label'</span><span class="token punctuation">:</span> tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
<span class="token string">'token_type_ids'</span><span class="token punctuation">:</span> tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span>  <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
                         <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">,</span>
                         <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span>  <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<h2 id="è¯„ä¼°é¢„æµ‹ï¼ˆEvaluate-predictionsï¼‰"><a href="#è¯„ä¼°é¢„æµ‹ï¼ˆEvaluate-predictionsï¼‰" class="headerlink" title="è¯„ä¼°é¢„æµ‹ï¼ˆEvaluate predictionsï¼‰"></a>è¯„ä¼°é¢„æµ‹ï¼ˆEvaluate predictionsï¼‰</h2><p>æ•°æ®é›†æä¾›äº†å„ç§å¸¸è§å’Œç‰¹å®šäº NLP <strong><a href="https://huggingface.co/metrics" target="_blank" rel="noopener">çš„æŒ‡æ ‡</a></strong>ï¼Œä¾›æ‚¨è¡¡é‡æ¨¡å‹æ€§èƒ½ã€‚åœ¨æœ¬æ•™ç¨‹çš„æ­¤éƒ¨åˆ†ä¸­ï¼Œæ‚¨å°†åŠ è½½ä¸€ä¸ªæŒ‡æ ‡ï¼Œå¹¶ä½¿ç”¨å®ƒæ¥è¯„ä¼°æ¨¡å‹é¢„æµ‹ã€‚</p>
<p>æ‚¨å¯ä»¥æŸ¥çœ‹<strong><a href="https://huggingface.co/docs/datasets/v2.1.0/en/package_reference/loading_methods#datasets.list_metrics" target="_blank" rel="noopener">list_metricsï¼ˆï¼‰</a></strong>æä¾›äº†å“ªäº›æŒ‡æ ‡ï¼š</p>
<pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">from</span> datasets <span class="token keyword">import</span> list_metrics
metrics_list <span class="token operator">=</span> list_metrics<span class="token punctuation">(</span><span class="token punctuation">)</span>
len<span class="token punctuation">(</span>metrics_list<span class="token punctuation">)</span>
<span class="token number">28</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>metrics_list<span class="token punctuation">)</span>
<span class="token punctuation">[</span><span class="token string">'accuracy'</span><span class="token punctuation">,</span> <span class="token string">'bertscore'</span><span class="token punctuation">,</span> <span class="token string">'bleu'</span><span class="token punctuation">,</span> <span class="token string">'bleurt'</span><span class="token punctuation">,</span> <span class="token string">'cer'</span><span class="token punctuation">,</span> <span class="token string">'comet'</span><span class="token punctuation">,</span> <span class="token string">'coval'</span><span class="token punctuation">,</span> <span class="token string">'cuad'</span><span class="token punctuation">,</span> <span class="token string">'f1'</span><span class="token punctuation">,</span> <span class="token string">'gleu'</span><span class="token punctuation">,</span> <span class="token string">'glue'</span><span class="token punctuation">,</span> <span class="token string">'indic_glue'</span><span class="token punctuation">,</span> <span class="token string">'matthews_correlation'</span><span class="token punctuation">,</span> <span class="token string">'meteor'</span><span class="token punctuation">,</span> <span class="token string">'pearsonr'</span><span class="token punctuation">,</span> <span class="token string">'precision'</span><span class="token punctuation">,</span> <span class="token string">'recall'</span><span class="token punctuation">,</span> <span class="token string">'rouge'</span><span class="token punctuation">,</span> <span class="token string">'sacrebleu'</span><span class="token punctuation">,</span> <span class="token string">'sari'</span><span class="token punctuation">,</span> <span class="token string">'seqeval'</span><span class="token punctuation">,</span> <span class="token string">'spearmanr'</span><span class="token punctuation">,</span> <span class="token string">'squad'</span><span class="token punctuation">,</span> <span class="token string">'squad_v2'</span><span class="token punctuation">,</span> <span class="token string">'super_glue'</span><span class="token punctuation">,</span> <span class="token string">'wer'</span><span class="token punctuation">,</span> <span class="token string">'wiki_split'</span><span class="token punctuation">,</span> <span class="token string">'xnli'</span><span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<h3 id="è´Ÿè½½æŒ‡æ ‡"><a href="#è´Ÿè½½æŒ‡æ ‡" class="headerlink" title="è´Ÿè½½æŒ‡æ ‡"></a><strong>è´Ÿè½½æŒ‡æ ‡</strong></h3><p>ä½¿ç”¨ğŸ¤—æ•°æ®é›†åŠ è½½æŒ‡æ ‡éå¸¸å®¹æ˜“ã€‚å®é™…ä¸Šï¼Œæ‚¨ä¼šæ³¨æ„åˆ°å®ƒä¸åŠ è½½æ•°æ®é›†éå¸¸ç›¸ä¼¼ï¼ä½¿ç”¨ <strong><a href="https://huggingface.co/docs/datasets/v2.1.0/en/package_reference/loading_methods#datasets.load_metric" target="_blank" rel="noopener">load_metricï¼ˆï¼‰</a></strong>ä»ä¸­å¿ƒåŠ è½½æŒ‡æ ‡ï¼š</p>
<pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">from</span> datasets <span class="token keyword">import</span> load_metric
metric <span class="token operator">=</span> load_metric<span class="token punctuation">(</span><span class="token string">'glue'</span><span class="token punctuation">,</span> <span class="token string">'mrpc'</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>
<p>è¿™å°†ä» GLUE åŸºå‡†æµ‹è¯•åŠ è½½ä¸ MRPC æ•°æ®é›†å…³è”çš„æŒ‡æ ‡ã€‚</p>
<h3 id="é€‰æ‹©é…ç½®-1"><a href="#é€‰æ‹©é…ç½®-1" class="headerlink" title="é€‰æ‹©é…ç½®"></a><strong>é€‰æ‹©é…ç½®</strong></h3><p>å¦‚æœæ‚¨ä½¿ç”¨çš„æ˜¯åŸºå‡†æ•°æ®é›†ï¼Œåˆ™éœ€è¦é€‰æ‹©ä¸æ‰€ä½¿ç”¨çš„é…ç½®å…³è”çš„æŒ‡æ ‡ã€‚é€šè¿‡æä¾›é…ç½®åç§°æ¥é€‰æ‹©æŒ‡æ ‡é…ç½®ï¼š</p>
<pre class="line-numbers language-python"><code class="language-python">metric <span class="token operator">=</span> load_metric<span class="token punctuation">(</span><span class="token string">'glue'</span><span class="token punctuation">,</span> <span class="token string">'mrpc'</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<h3 id="è¡¡é‡æŒ‡æ ‡å¯¹è±¡"><a href="#è¡¡é‡æŒ‡æ ‡å¯¹è±¡" class="headerlink" title="è¡¡é‡æŒ‡æ ‡å¯¹è±¡"></a><strong>è¡¡é‡æŒ‡æ ‡å¯¹è±¡</strong></h3><p>åœ¨å¼€å§‹ä½¿ç”¨<strong><a href="https://huggingface.co/docs/datasets/v2.1.0/en/package_reference/main_classes#datasets.Metric" target="_blank" rel="noopener">è¡¡é‡æŒ‡æ ‡</a></strong>å¯¹è±¡ä¹‹å‰ï¼Œæ‚¨åº”è¯¥æ›´å¥½åœ°äº†è§£å®ƒã€‚ä¸æ•°æ®é›†ä¸€æ ·ï¼Œæ‚¨å¯ä»¥è¿”å›æœ‰å…³æŒ‡æ ‡çš„ä¸€äº›åŸºæœ¬ä¿¡æ¯ã€‚ä¾‹å¦‚ï¼Œè®¿é—®æ•°æ®é›†ä¸­çš„å‚æ•°<strong><a href="https://huggingface.co/docs/datasets/v2.1.0/en/package_reference/main_classes#datasets.MetricInfo" target="_blank" rel="noopener">MetricInfo</a></strong></p>
<pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">print</span><span class="token punctuation">(</span>metric<span class="token punctuation">.</span>inputs_description<span class="token punctuation">)</span>
Compute GLUE evaluation metric associated to each GLUE dataset<span class="token punctuation">.</span>
Args<span class="token punctuation">:</span>
    predictions<span class="token punctuation">:</span> list of predictions to score<span class="token punctuation">.</span>
        Each translation should be tokenized into a list of tokens<span class="token punctuation">.</span>
    references<span class="token punctuation">:</span> list of lists of references <span class="token keyword">for</span> each translation<span class="token punctuation">.</span>
        Each reference should be tokenized into a list of tokens<span class="token punctuation">.</span>
Returns<span class="token punctuation">:</span> depending on the GLUE subset<span class="token punctuation">,</span> one <span class="token operator">or</span> several of<span class="token punctuation">:</span>
    <span class="token string">"accuracy"</span><span class="token punctuation">:</span> Accuracy
    <span class="token string">"f1"</span><span class="token punctuation">:</span> F1 score
    <span class="token string">"pearson"</span><span class="token punctuation">:</span> Pearson Correlation
    <span class="token string">"spearmanr"</span><span class="token punctuation">:</span> Spearman Correlation
    <span class="token string">"matthews_correlation"</span><span class="token punctuation">:</span> Matthew Correlation
Examples<span class="token punctuation">:</span>
    <span class="token operator">>></span><span class="token operator">></span> glue_metric <span class="token operator">=</span> datasets<span class="token punctuation">.</span>load_metric<span class="token punctuation">(</span><span class="token string">'glue'</span><span class="token punctuation">,</span> <span class="token string">'sst2'</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># 'sst2' or any of ["mnli", "mnli_mismatched", "mnli_matched", "qnli", "rte", "wnli", "hans"]</span>
    <span class="token operator">>></span><span class="token operator">></span> references <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span>
    <span class="token operator">>></span><span class="token operator">></span> predictions <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span>
    <span class="token operator">>></span><span class="token operator">></span> results <span class="token operator">=</span> glue_metric<span class="token punctuation">.</span>compute<span class="token punctuation">(</span>predictions<span class="token operator">=</span>predictions<span class="token punctuation">,</span> references<span class="token operator">=</span>references<span class="token punctuation">)</span>
    <span class="token operator">>></span><span class="token operator">></span> <span class="token keyword">print</span><span class="token punctuation">(</span>results<span class="token punctuation">)</span>
    <span class="token punctuation">{</span><span class="token string">'accuracy'</span><span class="token punctuation">:</span> <span class="token number">1.0</span><span class="token punctuation">}</span>
    <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>
    <span class="token operator">>></span><span class="token operator">></span> glue_metric <span class="token operator">=</span> datasets<span class="token punctuation">.</span>load_metric<span class="token punctuation">(</span><span class="token string">'glue'</span><span class="token punctuation">,</span> <span class="token string">'mrpc'</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># 'mrpc' or 'qqp'</span>
    <span class="token operator">>></span><span class="token operator">></span> references <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span>
    <span class="token operator">>></span><span class="token operator">></span> predictions <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span>
    <span class="token operator">>></span><span class="token operator">></span> results <span class="token operator">=</span> glue_metric<span class="token punctuation">.</span>compute<span class="token punctuation">(</span>predictions<span class="token operator">=</span>predictions<span class="token punctuation">,</span> references<span class="token operator">=</span>references<span class="token punctuation">)</span>
    <span class="token operator">>></span><span class="token operator">></span> <span class="token keyword">print</span><span class="token punctuation">(</span>results<span class="token punctuation">)</span>
    <span class="token punctuation">{</span><span class="token string">'accuracy'</span><span class="token punctuation">:</span> <span class="token number">1.0</span><span class="token punctuation">,</span> <span class="token string">'f1'</span><span class="token punctuation">:</span> <span class="token number">1.0</span><span class="token punctuation">}</span>
    <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>è¯·æ³¨æ„ï¼Œå¯¹äº MRPC é…ç½®ï¼ŒæŒ‡æ ‡æœŸæœ›è¾“å…¥æ ¼å¼ä¸ºé›¶æˆ– 1ã€‚æœ‰å…³å¯éšæŒ‡æ ‡ä¸€èµ·è¿”å›çš„å±æ€§çš„å®Œæ•´åˆ—è¡¨ï¼Œè¯·æŸ¥çœ‹ <strong><a href="https://huggingface.co/docs/datasets/v2.1.0/en/package_reference/main_classes#datasets.MetricInfo" target="_blank" rel="noopener">MetricInfo</a></strong>ã€‚</p>
<h3 id="è®¡ç®—æŒ‡æ ‡"><a href="#è®¡ç®—æŒ‡æ ‡" class="headerlink" title="è®¡ç®—æŒ‡æ ‡"></a><strong>è®¡ç®—æŒ‡æ ‡</strong></h3><p>åŠ è½½æŒ‡æ ‡åï¼Œå³å¯ä½¿ç”¨å®ƒæ¥è¯„ä¼°æ¨¡å‹é¢„æµ‹ã€‚æä¾›å¯¹ <strong><a href="https://huggingface.co/docs/datasets/v2.1.0/en/package_reference/main_classes#datasets.Metric.compute" target="_blank" rel="noopener">computeï¼ˆï¼‰</a></strong> çš„æ¨¡å‹é¢„æµ‹å’Œå¼•ç”¨ï¼š</p>
<pre class="line-numbers language-python"><code class="language-python">model_predictions <span class="token operator">=</span> model<span class="token punctuation">(</span>model_inputs<span class="token punctuation">)</span>
final_score <span class="token operator">=</span> metric<span class="token punctuation">.</span>compute<span class="token punctuation">(</span>predictions<span class="token operator">=</span>model_predictions<span class="token punctuation">,</span> references<span class="token operator">=</span>gold_references<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>
<h1 id="å®è·µ-FineTune-Practice"><a href="#å®è·µ-FineTune-Practice" class="headerlink" title="å®è·µ FineTune Practice"></a>å®è·µ FineTune Practice</h1><h2 id="NER"><a href="#NER" class="headerlink" title="NER"></a>NER</h2><ul>
<li>PKUä¸­æ–‡åˆ†è¯æ•°æ®é›†å¾®è°ƒåŸºæœ¬é€»è¾‘</li>
</ul>
<pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">import</span> torch
<span class="token keyword">from</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data <span class="token keyword">import</span> Dataset<span class="token punctuation">,</span> DataLoader<span class="token punctuation">,</span> random_split
<span class="token keyword">from</span> data_process <span class="token keyword">import</span> DataGenerator
<span class="token keyword">from</span> transformers <span class="token keyword">import</span> AutoTokenizer<span class="token punctuation">,</span> BertTokenizer<span class="token punctuation">,</span> BertModel<span class="token punctuation">,</span> AutoModelForTokenClassification<span class="token punctuation">,</span> DataCollatorForTokenClassification
<span class="token keyword">from</span> transformers <span class="token keyword">import</span> TrainingArguments<span class="token punctuation">,</span> Trainer

torch<span class="token punctuation">.</span>manual_seed<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span>

<span class="token comment" spellcheck="true"># åŠ è½½é¢„è®­ç»ƒæ¨¡å‹å’Œåˆ†è¯å™¨</span>
tokenizer <span class="token operator">=</span> AutoTokenizer<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span><span class="token string">"/nfs/volume-1280-3/rushin/work/models/hfl/chinese-roberta-wwm-ext"</span><span class="token punctuation">)</span>
model <span class="token operator">=</span> AutoModelForTokenClassification<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span><span class="token string">"/nfs/volume-1280-3/rushin/work/models/hfl/chinese-roberta-wwm-ext"</span><span class="token punctuation">,</span> num_labels<span class="token operator">=</span><span class="token number">4</span><span class="token punctuation">)</span>
data_collator <span class="token operator">=</span> DataCollatorForTokenClassification<span class="token punctuation">(</span>tokenizer<span class="token operator">=</span>tokenizer<span class="token punctuation">)</span>

<span class="token comment" spellcheck="true"># Load Dataï¼ŒåŠ è½½æ–‡æœ¬æ•°æ®List(corpus)å’Œæ ‡ç­¾æ•°æ®List[list](labels)</span>
data_path <span class="token operator">=</span> <span class="token string">"../seg-data/training/pku_training.utf8"</span>
generator <span class="token operator">=</span> DataGenerator<span class="token punctuation">(</span>data_path<span class="token punctuation">)</span>
corpus<span class="token punctuation">,</span> labels <span class="token operator">=</span> generator<span class="token punctuation">.</span>generate_train_data<span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token comment" spellcheck="true"># åˆ‡åˆ†è®­ç»ƒé›†å’ŒéªŒè¯é›†</span>
l <span class="token operator">=</span> len<span class="token punctuation">(</span>corpus<span class="token punctuation">)</span>
train_size <span class="token operator">=</span> int<span class="token punctuation">(</span>l<span class="token operator">*</span><span class="token number">0.8</span><span class="token punctuation">)</span>

train_corpus <span class="token operator">=</span> corpus<span class="token punctuation">[</span><span class="token punctuation">:</span>train_size<span class="token punctuation">]</span>
valid_corpus <span class="token operator">=</span> corpus<span class="token punctuation">[</span>train_size<span class="token punctuation">:</span><span class="token punctuation">]</span>
train_labels <span class="token operator">=</span> labels<span class="token punctuation">[</span><span class="token punctuation">:</span>train_size<span class="token punctuation">]</span>
valid_labels <span class="token operator">=</span> labels<span class="token punctuation">[</span>train_size<span class="token punctuation">:</span><span class="token punctuation">]</span>

<span class="token comment" spellcheck="true"># æ„é€ è®­ç»ƒå’ŒéªŒè¯æ•°æ®å­—å…¸ï¼Œä¸»è¦éœ€è¦tokenizerè¿”å›çš„å­—å…¸æ•°æ®åŠ ä¸Šlabelså±æ€§</span>
<span class="token keyword">def</span> <span class="token function">tokenize_and_align_labels</span><span class="token punctuation">(</span>corpus<span class="token punctuation">,</span> corpus_labels<span class="token punctuation">)</span><span class="token punctuation">:</span>
    tokenized_inputs <span class="token operator">=</span> tokenizer<span class="token punctuation">(</span>corpus<span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> truncation<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> max_length<span class="token operator">=</span><span class="token number">512</span><span class="token punctuation">)</span>
    labels <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
    <span class="token keyword">for</span> i<span class="token punctuation">,</span> label <span class="token keyword">in</span> enumerate<span class="token punctuation">(</span>corpus_labels<span class="token punctuation">)</span><span class="token punctuation">:</span>
        word_ids <span class="token operator">=</span> tokenized_inputs<span class="token punctuation">.</span>word_ids<span class="token punctuation">(</span>batch_index<span class="token operator">=</span>i<span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># Map tokens to their respective word.</span>
        label_ids <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
        <span class="token keyword">for</span> word_idx <span class="token keyword">in</span> word_ids<span class="token punctuation">:</span>  <span class="token comment" spellcheck="true"># Set the special tokens to -100.</span>
            <span class="token keyword">if</span> word_idx <span class="token keyword">is</span> None<span class="token punctuation">:</span>
                label_ids<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">100</span><span class="token punctuation">)</span>
            <span class="token keyword">else</span><span class="token punctuation">:</span>
                label_ids<span class="token punctuation">.</span>append<span class="token punctuation">(</span>label<span class="token punctuation">[</span>word_idx<span class="token punctuation">]</span><span class="token punctuation">)</span>
        labels<span class="token punctuation">.</span>append<span class="token punctuation">(</span>label_ids<span class="token punctuation">)</span>

    tokenized_inputs<span class="token punctuation">[</span><span class="token string">"labels"</span><span class="token punctuation">]</span> <span class="token operator">=</span> labels
    <span class="token keyword">return</span> tokenized_inputs

train_encoding <span class="token operator">=</span> tokenize_and_align_labels<span class="token punctuation">(</span>train_corpus<span class="token punctuation">,</span> train_labels<span class="token punctuation">)</span>
valid_encoding <span class="token operator">=</span> tokenize_and_align_labels<span class="token punctuation">(</span>valid_corpus<span class="token punctuation">,</span> valid_labels<span class="token punctuation">)</span>

<span class="token comment" spellcheck="true"># æ„é€ Datasetç±»</span>
<span class="token keyword">class</span> <span class="token class-name">TokenDataset</span><span class="token punctuation">(</span>Dataset<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> encoding<span class="token punctuation">)</span><span class="token punctuation">:</span>
        super<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>encoding <span class="token operator">=</span> encoding

    <span class="token keyword">def</span> <span class="token function">__getitem__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> idx<span class="token punctuation">)</span><span class="token punctuation">:</span>
        item <span class="token operator">=</span> <span class="token punctuation">{</span>key<span class="token punctuation">:</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span>val<span class="token punctuation">[</span>idx<span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token keyword">for</span> key<span class="token punctuation">,</span> val <span class="token keyword">in</span> self<span class="token punctuation">.</span>encoding<span class="token punctuation">.</span>items<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">}</span>
        <span class="token keyword">return</span> item

    <span class="token keyword">def</span> <span class="token function">__len__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">return</span> len<span class="token punctuation">(</span>self<span class="token punctuation">.</span>encoding<span class="token punctuation">[</span><span class="token string">"labels"</span><span class="token punctuation">]</span><span class="token punctuation">)</span> 

<span class="token comment" spellcheck="true"># ç”Ÿæˆè®­ç»ƒå’ŒéªŒè¯æ•°æ®å¯¹è±¡</span>
train_data <span class="token operator">=</span> TokenDataset<span class="token punctuation">(</span>train_encoding<span class="token punctuation">)</span>
valid_data <span class="token operator">=</span> TokenDataset<span class="token punctuation">(</span>valid_encoding<span class="token punctuation">)</span>

<span class="token comment" spellcheck="true"># è®¾ç½®è®­ç»ƒå‚æ•°</span>
training_args <span class="token operator">=</span> TrainingArguments<span class="token punctuation">(</span>
    output_dir<span class="token operator">=</span><span class="token string">"./results/chinese-roberta-wwm-ext"</span><span class="token punctuation">,</span>
    evaluation_strategy<span class="token operator">=</span><span class="token string">"epoch"</span><span class="token punctuation">,</span>
    learning_rate<span class="token operator">=</span><span class="token number">2e</span><span class="token operator">-</span><span class="token number">5</span><span class="token punctuation">,</span>
    per_device_train_batch_size<span class="token operator">=</span><span class="token number">16</span><span class="token punctuation">,</span>
    per_device_eval_batch_size<span class="token operator">=</span><span class="token number">16</span><span class="token punctuation">,</span>
    num_train_epochs<span class="token operator">=</span><span class="token number">300</span><span class="token punctuation">,</span>
    weight_decay<span class="token operator">=</span><span class="token number">0.01</span><span class="token punctuation">,</span>
<span class="token punctuation">)</span>

trainer <span class="token operator">=</span> Trainer<span class="token punctuation">(</span>
    model<span class="token operator">=</span>model<span class="token punctuation">,</span>
    args<span class="token operator">=</span>training_args<span class="token punctuation">,</span>
    train_dataset<span class="token operator">=</span>train_data<span class="token punctuation">,</span>
    eval_dataset<span class="token operator">=</span>valid_data<span class="token punctuation">,</span>
    tokenizer<span class="token operator">=</span>tokenizer<span class="token punctuation">,</span>
    data_collator<span class="token operator">=</span>data_collator<span class="token punctuation">,</span>
<span class="token punctuation">)</span>

<span class="token comment" spellcheck="true"># å¼€å§‹è®­ç»ƒ</span>
trainer<span class="token punctuation">.</span>train<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<ul>
<li>æ€»ç»“ï¼šå¯¹äºé¢„è®­ç»ƒè¿‡ç¨‹<ul>
<li>é¦–å…ˆï¼Œéœ€è¦æ ¹æ®ä»»åŠ¡ç¡®è®¤æ•°æ®é›†éœ€è¦çš„å±æ€§å­—æ®µä¿¡æ¯ï¼Œæ„é€ å‡ºé’ˆå¯¹è¯¥ä»»åŠ¡çš„æ•°æ®é›†ç±»ï¼Œè¿™ä¸€æ­¥ä¹Ÿæ˜¯å…³é”®çš„ä¸€æ­¥ã€‚<ul>
<li>åˆ†ææ•°æ®é›†çš„å±æ€§ï¼Œæ ¹æ®æ–‡æœ¬è¿›è¡Œtokenizeï¼Œå°†tokenså˜æˆinput_idsï¼Œ</li>
<li>labelsæ ¹æ®åŸå§‹æ•°æ®ç”Ÿæˆæ¨¡å‹éœ€è¦çš„labelså±æ€§ã€‚</li>
</ul>
</li>
<li>æ„é€ å‡ºåŸºæœ¬æ•°æ®åï¼Œç›´æ¥æŒ‰ç…§transformersè®­ç»ƒæ¨¡æ¿è®¾ç½®å‚æ•°è®­ç»ƒå³å¯</li>
</ul>
</li>
</ul>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        æ–‡ç« ä½œè€…:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://jackhcc.github.io" rel="external nofollow noreferrer">æ°å…‹æˆ</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        æ–‡ç« é“¾æ¥:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://jackhcc.github.io/posts/transformers-lib.html">https://jackhcc.github.io/posts/transformers-lib.html</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        ç‰ˆæƒå£°æ˜:
                    </i>
                </span>
                <span class="reprint-info">
                    æœ¬åšå®¢æ‰€æœ‰æ–‡ç« é™¤ç‰¹åˆ¥å£°æ˜å¤–ï¼Œå‡é‡‡ç”¨
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    è®¸å¯åè®®ã€‚è½¬è½½è¯·æ³¨æ˜æ¥æº
                    <a href="https://jackhcc.github.io" target="_blank">æ°å…‹æˆ</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>å¤åˆ¶æˆåŠŸï¼Œè¯·éµå¾ªæœ¬æ–‡çš„è½¬è½½è§„åˆ™</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">æŸ¥çœ‹</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/tags/Deep-Learning/">
                                    <span class="chip bg-color">Deep Learning</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/libs/share/css/share.min.css">

<div id="article-share">
    
    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>å¾®ä¿¡æ‰«ä¸€æ‰«å³å¯åˆ†äº«ï¼</p>"></div>
    <script src="https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
                <style>
    #reward {
        margin: 40px 0;
        text-align: center;
    }

    #reward .reward-link {
        font-size: 1.4rem;
        line-height: 38px;
    }

    #reward .btn-floating:hover {
        box-shadow: 0 6px 12px rgba(0, 0, 0, 0.2), 0 5px 15px rgba(0, 0, 0, 0.2);
    }

    #rewardModal {
        width: 320px;
        height: 350px;
    }

    #rewardModal .reward-title {
        margin: 15px auto;
        padding-bottom: 5px;
    }

    #rewardModal .modal-content {
        padding: 10px;
    }

    #rewardModal .close {
        position: absolute;
        right: 15px;
        top: 15px;
        color: rgba(0, 0, 0, 0.5);
        font-size: 1.3rem;
        line-height: 20px;
        cursor: pointer;
    }

    #rewardModal .close:hover {
        color: #ef5350;
        transform: scale(1.3);
        -moz-transform:scale(1.3);
        -webkit-transform:scale(1.3);
        -o-transform:scale(1.3);
    }

    #rewardModal .reward-tabs {
        margin: 0 auto;
        width: 210px;
    }

    .reward-tabs .tabs {
        height: 38px;
        margin: 10px auto;
        padding-left: 0;
    }

    .reward-content ul {
        padding-left: 0 !important;
    }

    .reward-tabs .tabs .tab {
        height: 38px;
        line-height: 38px;
    }

    .reward-tabs .tab a {
        color: #fff;
        background-color: #ccc;
    }

    .reward-tabs .tab a:hover {
        background-color: #ccc;
        color: #fff;
    }

    .reward-tabs .wechat-tab .active {
        color: #fff !important;
        background-color: #22AB38 !important;
    }

    .reward-tabs .alipay-tab .active {
        color: #fff !important;
        background-color: #019FE8 !important;
    }

    .reward-tabs .reward-img {
        width: 210px;
        height: 210px;
    }
</style>

<div id="reward">
    <a href="#rewardModal" class="reward-link modal-trigger btn-floating btn-medium waves-effect waves-light red">èµ</a>

    <!-- Modal Structure -->
    <div id="rewardModal" class="modal">
        <div class="modal-content">
            <a class="close modal-close"><i class="fas fa-times"></i></a>
            <h4 class="reward-title">ä½ çš„èµè¯†æ˜¯æˆ‘å‰è¿›çš„åŠ¨åŠ›</h4>
            <div class="reward-content">
                <div class="reward-tabs">
                    <ul class="tabs row">
                        <li class="tab col s6 alipay-tab waves-effect waves-light"><a href="#alipay">æ”¯ä»˜å®</a></li>
                        <li class="tab col s6 wechat-tab waves-effect waves-light"><a href="#wechat">å¾® ä¿¡</a></li>
                    </ul>
                    <div id="alipay">
                        <img src="/images/loading.gif" data-original="https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/medias/reward/aliqr.png" class="reward-img" alt="æ”¯ä»˜å®æ‰“èµäºŒç»´ç ">
                    </div>
                    <div id="wechat">
                        <img src="/images/loading.gif" data-original="https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/medias/reward/wxqr.png" class="reward-img" alt="å¾®ä¿¡æ‰“èµäºŒç»´ç ">
                    </div>
                </div>
            </div>
        </div>
    </div>
</div>

<script>
    $(function () {
        $('.tabs').tabs();
    });
</script>
            
        </div>
    </div>

    
        <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/libs/gitalk/gitalk.css">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/css/my-gitalk.css">

<div class="card gitalk-card" data-aos="fade-up">
    <div class="comment_headling" style="font-size: 20px; font-weight: 700; position: relative; left: 20px; top: 15px; padding-bottom: 5px;">
        <i class="fas fa-comments fa-fw" aria-hidden="true"></i>
        <span>è¯„è®º</span>
    </div>
    <div id="gitalk-container" class="card-content"></div>
</div>

<script src="https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/libs/gitalk/gitalk.min.js"></script>
<script>
    let gitalk = new Gitalk({
        clientID: '3821a0bbb773038a51fc',
        clientSecret: '4b30b507d67ec5497ec0e77f43f80cb3e0d7dd3a',
        repo: 'JackHCC.github.io',
        owner: 'JackHCC',
        admin: "JackHCC",
        id: '2022-05-01T10-33-13',
        distractionFreeMode: false  // Facebook-like distraction free mode
    });

    gitalk.render('gitalk-container');
</script>
    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="far fa-dot-circle"></i>&nbsp;æœ¬ç¯‡
            </div>
            <div class="card">
                <a href="/posts/transformers-lib.html">
                    <div class="card-image">
                        
                        
                        <img src="/images/loading.gif" data-original="https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/medias/featureimages/0.jpg" class="responsive-img" alt="TransformersåŒ…è¯¦è§£">
                        
                        <span class="card-title">TransformersåŒ…è¯¦è§£</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            Transformerså®è·µæ‰‹å†Œ
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2022-05-01
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/categories/Transformers/" class="post-category">
                                    Transformers
                                </a>
                            
                            
                        </span>
                    </div>
                </div>

                
                <div class="card-action article-tags">
                    
                    <a href="/tags/Deep-Learning/">
                        <span class="chip bg-color">Deep Learning</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                ä¸‹ä¸€ç¯‡&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/posts/neo4j.html">
                    <div class="card-image">
                        
                        
                        <img src="/images/loading.gif" data-original="https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/medias/featureimages/12.jpg" class="responsive-img" alt="neo4jåŸºç¡€">
                        
                        <span class="card-title">neo4jåŸºç¡€</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            neo4jå­¦ä¹ ç¬”è®°
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2022-04-30
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/categories/Database/" class="post-category">
                                    Database
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/tags/Neo4j/">
                        <span class="chip bg-color">Neo4j</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- ä»£ç å—åŠŸèƒ½ä¾èµ– -->
<script type="text/javascript" src="https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/libs/codeBlock/codeBlockFuction.js"></script>

<!-- ä»£ç è¯­è¨€ -->

<script type="text/javascript" src="https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/libs/codeBlock/codeLang.js"></script>


<!-- ä»£ç å—å¤åˆ¶ -->

<script type="text/javascript" src="https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/libs/codeBlock/codeCopy.js"></script>


<!-- ä»£ç å—æ”¶ç¼© -->

<script type="text/javascript" src="https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/libs/codeBlock/codeShrink.js"></script>


<!-- ä»£ç å—æŠ˜è¡Œ -->

<style type="text/css">
code[class*="language-"], pre[class*="language-"] { white-space: pre !important; }
</style>


    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;ç›®å½•</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC æ‚¬æµ®æŒ‰é’®. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('4'),
            headingSelector: 'h1, h2, h3, h4'
        });

        // modify the toc link href to support Chinese.
        let i = 0;
        let tocHeading = 'toc-heading-';
        $('#toc-content a').each(function () {
            $(this).attr('href', '#' + tocHeading + (++i));
        });

        // modify the heading title id to support Chinese.
        i = 0;
        $('#articleContent').children('h1, h2, h3, h4').each(function () {
            $(this).attr('id', tocHeading + (++i));
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* ä¿®å¤æ–‡ç« å¡ç‰‡ div çš„å®½åº¦. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // åˆ‡æ¢TOCç›®å½•å±•å¼€æ”¶ç¼©çš„ç›¸å…³æ“ä½œ.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>

    

</main>



    <footer class="page-footer bg-color">
    <div class="container row center-align" style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            <span id="year">2020</span>
            <a href="https://jackhcc.github.io" target="_blank">æ°å…‹æˆ</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            <br>
            
            &nbsp;<i class="fas fa-chart-area"></i>&nbsp;ç«™ç‚¹æ€»å­—æ•°:&nbsp;<span
                class="white-color">3591.2k</span>&nbsp;å­—
            
            
            
            
            
            
            <span id="busuanzi_container_site_pv">
                |&nbsp;<i class="far fa-eye"></i>&nbsp;æ€»è®¿é—®é‡:&nbsp;<span id="busuanzi_value_site_pv"
                    class="white-color"></span>&nbsp;æ¬¡
            </span>
            
            
            <span id="busuanzi_container_site_uv">
                |&nbsp;<i class="fas fa-users"></i>&nbsp;æ€»è®¿é—®äººæ•°:&nbsp;<span id="busuanzi_value_site_uv"
                    class="white-color"></span>&nbsp;äºº
            </span>
            
            <br>
            
            <span id="sitetime">è½½å…¥è¿è¡Œæ—¶é—´...</span>
            <script>
                function siteTime() {
                    var seconds = 1000;
                    var minutes = seconds * 60;
                    var hours = minutes * 60;
                    var days = hours * 24;
                    var years = days * 365;
                    var today = new Date();
                    var startYear = "2020";
                    var startMonth = "2";
                    var startDate = "27";
                    var startHour = "6";
                    var startMinute = "30";
                    var startSecond = "0";
                    var todayYear = today.getFullYear();
                    var todayMonth = today.getMonth() + 1;
                    var todayDate = today.getDate();
                    var todayHour = today.getHours();
                    var todayMinute = today.getMinutes();
                    var todaySecond = today.getSeconds();
                    var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                    var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                    var diff = t2 - t1;
                    var diffYears = Math.floor(diff / years);
                    var diffDays = Math.floor((diff / days) - diffYears * 365);
                    var diffHours = Math.floor((diff - (diffYears * 365 + diffDays) * days) / hours);
                    var diffMinutes = Math.floor((diff - (diffYears * 365 + diffDays) * days - diffHours * hours) /
                        minutes);
                    var diffSeconds = Math.floor((diff - (diffYears * 365 + diffDays) * days - diffHours * hours -
                        diffMinutes * minutes) / seconds);
                    if (startYear == todayYear) {
                        document.getElementById("year").innerHTML = todayYear;
                        document.getElementById("sitetime").innerHTML = "æœ¬ç«™å·²å®‰å…¨è¿è¡Œ " + diffDays + " å¤© " + diffHours +
                            " å°æ—¶ " + diffMinutes + " åˆ†é’Ÿ " + diffSeconds + " ç§’";
                    } else {
                        document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                        document.getElementById("sitetime").innerHTML = "æœ¬ç«™å·²å®‰å…¨è¿è¡Œ " + diffYears + " å¹´ " + diffDays +
                            " å¤© " + diffHours + " å°æ—¶ " + diffMinutes + " åˆ†é’Ÿ " + diffSeconds + " ç§’";
                    }
                }
                setInterval(siteTime, 1000);
            </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/JackHCC" class="tooltipped" target="_blank" data-tooltip="è®¿é—®æˆ‘çš„GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:jackcc0701@163.com" class="tooltipped" target="_blank" data-tooltip="é‚®ä»¶è”ç³»æˆ‘" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>



    <a href="https://www.facebook.com/profile.php?id=100046343443643" class="tooltipped" target="_blank" data-tooltip="å…³æ³¨æˆ‘çš„Facebook: https://www.facebook.com/profile.php?id=100046343443643" data-position="top" data-delay="50">
        <i class="fab fa-facebook-f"></i>
    </a>



    <a href="https://twitter.com/JackChe66021834" class="tooltipped" target="_blank" data-tooltip="å…³æ³¨æˆ‘çš„Twitter: https://twitter.com/JackChe66021834" data-position="top" data-delay="50">
        <i class="fab fa-twitter"></i>
    </a>



    <a href="tencent://AddContact/?fromId=50&fromSubId=1&subcmd=all&uin=2508074836" class="tooltipped" target="_blank" data-tooltip="QQè”ç³»æˆ‘: 2508074836" data-position="top" data-delay="50">
        <i class="fab fa-qq"></i>
    </a>



    <a href="https://weibo.com/u/6885584679" class="tooltipped" target="_blank" data-tooltip="å…³æ³¨æˆ‘çš„å¾®åš: https://weibo.com/u/6885584679" data-position="top" data-delay="50">
        <i class="fab fa-weibo"></i>
    </a>



    <a href="https://www.zhihu.com/people/8f8482f01f0d6a04e844efe32e0f0710" class="tooltipped" target="_blank" data-tooltip="å…³æ³¨æˆ‘çš„çŸ¥ä¹: https://www.zhihu.com/people/8f8482f01f0d6a04e844efe32e0f0710" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">çŸ¥</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- æœç´¢é®ç½©æ¡† -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;æœç´¢</span>
            <input type="search" id="searchInput" name="s" placeholder="è¯·è¾“å…¥æœç´¢çš„å…³é”®å­—"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script src="https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/js/search.js"></script>
<script type="text/javascript">
$(function () {
    searchFunc("https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/" + "search.xml", 'searchInput', 'searchResult');
});
</script>
    <!-- å›åˆ°é¡¶éƒ¨æŒ‰é’® -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/libs/materialize/materialize.min.js"></script>
    <script src="https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/libs/aos/aos.js"></script>
    <script src="https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/js/matery.js"></script>

    <canvas class="fireworks" style="position: fixed;left: 0;top: 0;z-index: 1; pointer-events: none;" ></canvas>
    <script type="text/javascript" src="//cdn.bootcss.com/animejs/2.2.0/anime.min.js"></script>
    <script type="text/javascript" src="/js/fireworks.js"></script>

    <script type="text/javascript">
        //åªåœ¨æ¡Œé¢ç‰ˆç½‘é¡µå¯ç”¨ç‰¹æ•ˆ
        var windowWidth = $(window).width();
        if (windowWidth > 768) {
            document.write('<script type="text/javascript" src="/js/sakura.js"><\/script>'); }
    </script>

    <!-- weather -->
	<script type="text/javascript">
	WIDGET = {FID: 'TToslpmkVO'}
	</script>
	<script type="text/javascript" src="https://apip.weatherdt.com/float/static/js/r.js?v=1111"></script>


    <!-- Global site tag (gtag.js) - Google Analytics -->


    <!-- Baidu Analytics -->

<script>
    var _hmt = _hmt || [];
    (function () {
        var hm = document.createElement("script");
        hm.src = "https://hm.baidu.com/hm.js?";
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(hm, s);
    })();
</script>

    <!-- Baidu Push -->

    
    
    <script async src="https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/libs/others/busuanzi.pure.mini.js"></script>
    

    
        <script src="//code.tidio.co/kqhlkxviiccyoa0czpfpu4ijuey9hfre.js"></script>
        <script> 
            $(document).ready(function () {
                setInterval(change_Tidio, 50);  
                function change_Tidio() { 
                    var tidio=$("#tidio-chat iframe");
                    if(tidio.css("display")=="block"&& $(window).width()>977 ){
                        document.getElementById("tidio-chat-iframe").style.bottom= ($("div#backTop.top-scroll").css("display")=="none" &&$(window).width()>977)>0? "-40px" : ($("div.toc-title").length&&$(window).width()>977)>0?"85px":"20px";   
                        document.getElementById("tidio-chat-iframe").style.right="-15px";   
                        document.getElementById("tidio-chat-iframe").style.height=parseInt(tidio.css("height"))>=520?"520px":tidio.css("height");
                        document.getElementById("tidio-chat-iframe").style.zIndex="997";
                    } 
                    else if(tidio.css("display")=="block"&&$(window).width()>601 &&$(window).width()<992 ){
                        document.getElementById("tidio-chat-iframe").style.bottom= ($("div#backTop.top-scroll").css("display")=="none" && 601< $(window).width()<992)>0? "-40px":"20px" ;   
                        document.getElementById("tidio-chat-iframe").style.right="-15px"; 
                        document.getElementById("tidio-chat-iframe").style.zIndex="997";
                    }
                    else if(tidio.css("display")=="block"&&$(window).width()<601 && parseInt(tidio.css("height"))<230){
                        document.getElementById("tidio-chat-iframe").style.bottom= ($("div#backTop.top-scroll").css("display")=="none" && $(window).width()<601)>0? "-10px":"45px" ;   
                        document.getElementById("tidio-chat-iframe").style.zIndex="997";
                    }
                    if( tidio.css("display")=="block"&&$(window).width()<601 && parseInt(tidio.css("height"))>=230){
                        document.getElementById("tidio-chat-iframe").style.zIndex="998";
                    }
                } 
            }); 
        </script>
    

    

    
    <script type="text/javascript" color="0,0,255"
        pointColor="0,0,255" opacity='0.7'
        zIndex="-1" count="99"
        src="https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/libs/background/canvas-nest.js"></script>
    

    

    
    <script type="text/javascript" src="https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/libs/background/ribbon-dynamic.js" async="async"></script>
    
    
    
    <script src="https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/libs/instantpage/instantpage.js" type="module"></script>
    

        <script src="//cdn.jsdelivr.net/npm/js-base64/base64.min.js"></script>
        <script>
        $('a').each(function() {
          const $this = $(this);
          const href = $this.attr('href');
          if (href && href.match('^((http|https|thunder|qqdl|ed2k|Flashget|qbrowser|ftp|rtsp|mms)://)')) {
            const strs = href.split('/');
            if (strs.length >= 3) {
                const host = strs[2];
                if (host !== 'your_domain' || window.location.host) {
                    $this.attr('href', '/go.html?u='+Base64.encode(href)+'').attr('rel', 'external nofollow noopener noreferrer');
                    if (true) {
                        $this.attr('target', '_blank');
                    }
                }
            }
          }
        });
        </script><script>!function(e){var c=Array.prototype.slice.call(document.querySelectorAll("img[data-original]"));function i(){for(var r=0;r<c.length;r++)t=c[r],0<=(n=t.getBoundingClientRect()).bottom&&0<=n.left&&n.top<=(e.innerHeight||document.documentElement.clientHeight)&&function(){var t,n,e,i,o=c[r];t=o,n=function(){c=c.filter(function(t){return o!==t})},e=new Image,i=t.getAttribute("data-original"),e.onload=function(){t.src=i,n&&n()},e.src=i}();var t,n}i(),e.addEventListener("scroll",function(){var t,n;t=i,n=e,clearTimeout(t.tId),t.tId=setTimeout(function(){t.call(n)},500)})}(this);</script><script>window.addEventListener("load",function(){var t=/\.(gif|jpg|jpeg|tiff|png)$/i,r=/^data:image\/[a-z]+;base64,/;Array.prototype.slice.call(document.querySelectorAll("img[data-original]")).forEach(function(a){var e=a.parentNode;"A"===e.tagName&&(e.href.match(t)||e.href.match(r))&&(e.href=a.dataset.original)})});</script></body>

</html>

