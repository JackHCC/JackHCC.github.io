<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="Transformers包详解, JackHCC">
    <meta name="description" content="Transformers实践手册">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <title>Transformers包详解 | JackHCC</title>
    <link rel="icon" type="image/png" href="https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/medias/favicon.png">

    <link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/libs/awesome/css/all.css">
    <link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/libs/materialize/materialize.min.css">
    <link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/libs/aos/aos.css">
    <link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/libs/animate/animate.min.css">
    <link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/libs/lightGallery/css/lightgallery.min.css">
    <link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/css/matery.css">
    <link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/css/my.css">
    
    <script src="https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/libs/jquery/jquery.min.js"></script>
    
<meta name="generator" content="Hexo 4.2.0"><link rel="alternate" href="/atom.xml" title="JackHCC" type="application/atom+xml">
<link rel="stylesheet" href="/css/prism-hopscotch.css" type="text/css">
<link rel="stylesheet" href="/css/prism-line-numbers.css" type="text/css"></head>


<body>
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper head-container">
            <div class="brand-logo">
                <a href="/" class="waves-effect waves-light">
                    
                    <img src="/images/loading.gif" data-original="https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/medias/me.jpg" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">JackHCC</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>首页</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>标签</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>分类</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>归档</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="" class="waves-effect waves-light">

      
      <i class="fas fa-list" style="zoom: 0.6;"></i>
      
      <span>Tools</span>
      <i class="fas fa-chevron-down" aria-hidden="true" style="zoom: 0.6;"></i>
    </a>
    <ul class="sub-nav menus_item_child ">
      
      <li>
        <a href="https://creativecc.cn/" target="_blank" rel="noopener">
          
          <i class="fas fa-book" style="margin-top: -20px; zoom: 0.6;"></i>
          
          <span>Creative工具导航</span>
        </a>
      </li>
      
      <li>
        <a href="https://blog.creativecc.cn/Arxiv-NLP-Reporter/" target="_blank" rel="noopener">
          
          <i class="fas fa-film" style="margin-top: -20px; zoom: 0.6;"></i>
          
          <span>NLP每日论文</span>
        </a>
      </li>
      
      <li>
        <a href="http://chat.creativecc.cn/" target="_blank" rel="noopener">
          
          <i class="fas fa-music" style="margin-top: -20px; zoom: 0.6;"></i>
          
          <span>RocketChat聊天室</span>
        </a>
      </li>
      
      <li>
        <a href="/contact">
          
          <i class="fas fa-comments" style="margin-top: -20px; zoom: 0.6;"></i>
          
          <span>Contact留言板</span>
        </a>
      </li>
      
    </ul>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/friends" class="waves-effect waves-light">
      
      <i class="fas fa-address-book" style="zoom: 0.6;"></i>
      
      <span>友情链接</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/about" class="waves-effect waves-light">
      
      <i class="fas fa-user-circle" style="zoom: 0.6;"></i>
      
      <span>关于</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="搜索" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>

<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/images/loading.gif" data-original="https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/medias/me.jpg" class="logo-img circle responsive-img">
        
        <div class="logo-name">JackHCC</div>
        <div class="logo-desc">
            
            Make the world betterrrr!!!
            
        </div>
    </div>

    

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			首页
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			标签
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			分类
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			归档
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="javascript:;">
			
				<i class="fa-fw fas fa-list"></i>
			
			Tools
			<span class="m-icon"><i class="fas fa-chevron-right"></i></span>
		</a>
            <ul  style="background:  ;" >
              
                <li>   
				
                  <a href="https://creativecc.cn/ " target="_blank" rel="noopener" style="margin-left:75px";>
				  
				   <i class="fa fas fa-book" style="position: absolute;left:50px" ></i>
			      
		          <span>Creative工具导航</span>
                  </a>
                </li>
              
                <li>   
				
                  <a href="https://blog.creativecc.cn/Arxiv-NLP-Reporter/ " target="_blank" rel="noopener" style="margin-left:75px";>
				  
				   <i class="fa fas fa-film" style="position: absolute;left:50px" ></i>
			      
		          <span>NLP每日论文</span>
                  </a>
                </li>
              
                <li>   
				
                  <a href="http://chat.creativecc.cn/ " target="_blank" rel="noopener" style="margin-left:75px";>
				  
				   <i class="fa fas fa-music" style="position: absolute;left:50px" ></i>
			      
		          <span>RocketChat聊天室</span>
                  </a>
                </li>
              
                <li>   
				
                  <a href="/contact " style="margin-left:75px";>
				  
				   <i class="fa fas fa-comments" style="position: absolute;left:50px" ></i>
			      
		          <span>Contact留言板</span>
                  </a>
                </li>
               
            </ul>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/friends" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-address-book"></i>
			
			友情链接
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/about" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-user-circle"></i>
			
			关于
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/JackHCC/JackHCC.github.io" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>

        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/JackHCC/JackHCC.github.io" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    
<script src="https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/libs/cryptojs/crypto-js.min.js"></script>
<script>
    (function() {
        let pwd = '';
        if (pwd && pwd.length > 0) {
            if (pwd !== CryptoJS.SHA256(prompt('请输入访问本文章的密码')).toString(CryptoJS.enc.Hex)) {
                alert('密码错误，将返回主页！');
                location.href = '/';
            }
        }
    })();
</script>




<div class="bg-cover pd-header post-cover" style="background-image: url('https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/medias/featureimages/0.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">Transformers包详解</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/libs/tocbot/tocbot.css">
<style>
    #articleContent h1::before,
    #articleContent h2::before,
    #articleContent h3::before,
    #articleContent h4::before,
    #articleContent h5::before,
    #articleContent h6::before {
        display: block;
        content: " ";
        height: 100px;
        margin-top: -100px;
        visibility: hidden;
    }

    #articleContent :focus {
        outline: none;
    }

    .toc-fixed {
        position: fixed;
        top: 64px;
    }

    .toc-widget {
        width: 345px;
        padding-left: 20px;
    }

    .toc-widget .toc-title {
        margin: 35px 0 15px 0;
        padding-left: 17px;
        font-size: 1.5rem;
        font-weight: bold;
        line-height: 1.5rem;
    }

    .toc-widget ol {
        padding: 0;
        list-style: none;
    }

    #toc-content {
        height: calc(100vh - 250px);
        overflow: auto;
    }

    #toc-content ol {
        padding-left: 10px;
    }

    #toc-content ol li {
        padding-left: 10px;
    }

    #toc-content .toc-link:hover {
        color: #42b983;
        font-weight: 700;
        text-decoration: underline;
    }

    #toc-content .toc-link::before {
        background-color: transparent;
        max-height: 25px;
    }

    #toc-content .is-active-link {
        color: #42b983;
    }

    #toc-content .is-active-link::before {
        background-color: #42b983;
    }

    #floating-toc-btn {
        position: fixed;
        right: 30px;
        bottom: 146px;
        padding-top: 15px;
        margin-bottom: 0;
        z-index: 998;
    }

    #floating-toc-btn .btn-floating {
        width: 48px;
        height: 48px;
    }

    #floating-toc-btn .btn-floating i {
        line-height: 48px;
        font-size: 1.4rem;
    }
</style>
<div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- 文章内容详情 -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/tags/Deep-Learning/">
                                <span class="chip bg-color">Deep Learning</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/categories/Transformers/" class="post-category">
                                Transformers
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>发布日期:&nbsp;&nbsp;
                    2022-05-01
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>更新日期:&nbsp;&nbsp;
                    2022-05-01
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>文章字数:&nbsp;&nbsp;
                    19.1k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>阅读时长:&nbsp;&nbsp;
                    100 分
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>阅读次数:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>

        </div>
        <hr class="clearfix">
        <div class="card-content article-card-content">
            <div id="articleContent">
                <h1 id="Transformers"><a href="#Transformers" class="headerlink" title="Transformers"></a>Transformers</h1><p><strong>官方文档：</strong><a href="https://huggingface.co/docs/transformers/index" target="_blank" rel="noopener">https://huggingface.co/docs/transformers/index</a></p>
<p>🤗 Transformers provides APIs to easily download and train state-of-the-art pretrained models. Using pretrained models can reduce your compute costs, carbon footprint, and save you time from training a model from scratch. The models can be used across different modalities such as:</p>
<ul>
<li>📝 Text: text classification, information extraction, question answering, summarization, translation, and text generation in over 100 languages.</li>
<li>🖼️ Images: image classification, object detection, and segmentation.</li>
<li>🗣️ Audio: speech recognition and audio classification.</li>
<li>🐙 Multimodal: table question answering, optical character recognition, information extraction from scanned documents, video classification, and visual question answering.</li>
</ul>
<h2 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h2><h3 id="Pip"><a href="#Pip" class="headerlink" title="Pip"></a>Pip</h3><pre class="line-numbers language-python"><code class="language-python">pip install transformers<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<h3 id="Conda"><a href="#Conda" class="headerlink" title="Conda"></a>Conda</h3><pre class="line-numbers language-python"><code class="language-python">conda install <span class="token operator">-</span>c huggingface transformers<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<h2 id="Pipeline-usage"><a href="#Pipeline-usage" class="headerlink" title="Pipeline usage"></a>Pipeline usage</h2><h3 id="Pipeline"><a href="#Pipeline" class="headerlink" title="Pipeline"></a>Pipeline</h3><ol>
<li>Start by creating a <strong><a href="https://huggingface.co/docs/transformers/v4.18.0/en/main_classes/pipelines#transformers.pipeline" target="_blank" rel="noopener">pipeline()</a></strong> and specify an inference task:</li>
</ol>
<pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">from</span> transformers <span class="token keyword">import</span> pipeline

generator <span class="token operator">=</span> pipeline<span class="token punctuation">(</span>task<span class="token operator">=</span><span class="token string">"text-generation"</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre>
<ol>
<li>Pass your input text to the <strong><a href="https://huggingface.co/docs/transformers/v4.18.0/en/main_classes/pipelines#transformers.pipeline" target="_blank" rel="noopener">pipeline()</a></strong>:</li>
</ol>
<pre class="line-numbers language-python"><code class="language-python">generator<span class="token punctuation">(</span><span class="token string">"Three Rings for the Elven-kings under the sky, Seven for the Dwarf-lords in their halls of stone"</span><span class="token punctuation">)</span>
<span class="token punctuation">[</span><span class="token punctuation">{</span><span class="token string">'generated_text'</span><span class="token punctuation">:</span> <span class="token string">'Three Rings for the Elven-kings under the sky, Seven for the Dwarf-lords in their halls of stone, Seven for the Iron-priests at the door to the east, and thirteen for the Lord Kings at the end of the mountain'</span><span class="token punctuation">}</span><span class="token punctuation">]</span>

generator<span class="token punctuation">(</span>
    <span class="token punctuation">[</span>
        <span class="token string">"Three Rings for the Elven-kings under the sky, Seven for the Dwarf-lords in their halls of stone"</span><span class="token punctuation">,</span>
        <span class="token string">"Nine for Mortal Men, doomed to die, One for the Dark Lord on his dark throne"</span><span class="token punctuation">,</span>
    <span class="token punctuation">]</span>
<span class="token punctuation">)</span>

generator<span class="token punctuation">(</span>
    <span class="token string">"Three Rings for the Elven-kings under the sky, Seven for the Dwarf-lords in their halls of stone"</span><span class="token punctuation">,</span>
    num_return_sequences<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span>
<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<h3 id="Choose-a-model-and-tokenizer"><a href="#Choose-a-model-and-tokenizer" class="headerlink" title="Choose a model and tokenizer"></a>Choose a model and tokenizer</h3><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">from</span> transformers <span class="token keyword">import</span> AutoTokenizer<span class="token punctuation">,</span> AutoModelForCausalLM

tokenizer <span class="token operator">=</span> AutoTokenizer<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span><span class="token string">"distilgpt2"</span><span class="token punctuation">)</span>
model <span class="token operator">=</span> AutoModelForCausalLM<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span><span class="token string">"distilgpt2"</span><span class="token punctuation">)</span>

<span class="token keyword">from</span> transformers <span class="token keyword">import</span> pipeline

generator <span class="token operator">=</span> pipeline<span class="token punctuation">(</span>task<span class="token operator">=</span><span class="token string">"text-generation"</span><span class="token punctuation">,</span> model<span class="token operator">=</span>model<span class="token punctuation">,</span> tokenizer<span class="token operator">=</span>tokenizer<span class="token punctuation">)</span>

generator<span class="token punctuation">(</span><span class="token string">"Three Rings for the Elven-kings under the sky, Seven for the Dwarf-lords in their halls of stone"</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<h3 id="Audio-pipeline"><a href="#Audio-pipeline" class="headerlink" title="Audio pipeline"></a>Audio pipeline</h3><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">from</span> transformers <span class="token keyword">import</span> pipeline

audio_classifier <span class="token operator">=</span> pipeline<span class="token punctuation">(</span>
    task<span class="token operator">=</span><span class="token string">"audio-classification"</span><span class="token punctuation">,</span> model<span class="token operator">=</span><span class="token string">"ehcalabres/wav2vec2-lg-xlsr-en-speech-emotion-recognition"</span>
<span class="token punctuation">)</span>

audio_classifier<span class="token punctuation">(</span><span class="token string">"jfk_moon_speech.wav"</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<h3 id="Vision-pipeline"><a href="#Vision-pipeline" class="headerlink" title="Vision pipeline"></a>Vision pipeline</h3><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">from</span> transformers <span class="token keyword">import</span> pipeline

vision_classifier <span class="token operator">=</span> pipeline<span class="token punctuation">(</span>task<span class="token operator">=</span><span class="token string">"image-classification"</span><span class="token punctuation">)</span>
vision_classifier<span class="token punctuation">(</span>
    images<span class="token operator">=</span><span class="token string">"&lt;https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/pipeline-cat-chonk.jpeg>"</span>
<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<h2 id="Load-pretrained-instances-with-an-AutoClass"><a href="#Load-pretrained-instances-with-an-AutoClass" class="headerlink" title="Load pretrained instances with an AutoClass"></a>Load pretrained instances with an AutoClass</h2><h3 id="AutoTokenizer"><a href="#AutoTokenizer" class="headerlink" title="AutoTokenizer"></a>AutoTokenizer</h3><p>几乎每个 NLP 任务都从分词器开始。分词器将您的输入转换为模型可以处理的格式。</p>
<p>Load a tokenizer with <strong><a href="https://huggingface.co/docs/transformers/v4.18.0/en/model_doc/auto#transformers.AutoTokenizer.from_pretrained" target="_blank" rel="noopener">AutoTokenizer.from_pretrained()</a></strong></p>
<pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">from</span> transformers <span class="token keyword">import</span> AutoTokenizer

tokenizer <span class="token operator">=</span> AutoTokenizer<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span><span class="token string">"bert-base-uncased"</span><span class="token punctuation">)</span>

sequence <span class="token operator">=</span> <span class="token string">"In a hole in the ground there lived a hobbit."</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>tokenizer<span class="token punctuation">(</span>sequence<span class="token punctuation">)</span><span class="token punctuation">)</span>

<span class="token punctuation">{</span><span class="token string">'input_ids'</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token number">101</span><span class="token punctuation">,</span> <span class="token number">1999</span><span class="token punctuation">,</span> <span class="token number">1037</span><span class="token punctuation">,</span> <span class="token number">4920</span><span class="token punctuation">,</span> <span class="token number">1999</span><span class="token punctuation">,</span> <span class="token number">1996</span><span class="token punctuation">,</span> <span class="token number">2598</span><span class="token punctuation">,</span> <span class="token number">2045</span><span class="token punctuation">,</span> <span class="token number">2973</span><span class="token punctuation">,</span> <span class="token number">1037</span><span class="token punctuation">,</span> <span class="token number">7570</span><span class="token punctuation">,</span> <span class="token number">10322</span><span class="token punctuation">,</span> <span class="token number">4183</span><span class="token punctuation">,</span> <span class="token number">1012</span><span class="token punctuation">,</span> <span class="token number">102</span><span class="token punctuation">]</span><span class="token punctuation">,</span> 
 <span class="token string">'token_type_ids'</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> 
 <span class="token string">'attention_mask'</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<h3 id="AutoFeatureExtractor"><a href="#AutoFeatureExtractor" class="headerlink" title="AutoFeatureExtractor"></a>AutoFeatureExtractor</h3><p>对于音频和视觉任务，特征提取器将音频信号或图像处理为正确的输入格式。</p>
<p>Load a feature extractor with <strong><a href="https://huggingface.co/docs/transformers/v4.18.0/en/model_doc/auto#transformers.AutoFeatureExtractor.from_pretrained" target="_blank" rel="noopener">AutoFeatureExtractor.from_pretrained()</a></strong></p>
<pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">from</span> transformers <span class="token keyword">import</span> AutoFeatureExtractor

feature_extractor <span class="token operator">=</span> AutoFeatureExtractor<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span>
    <span class="token string">"ehcalabres/wav2vec2-lg-xlsr-en-speech-emotion-recognition"</span>
<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<h3 id="AutoProcessor"><a href="#AutoProcessor" class="headerlink" title="AutoProcessor"></a>AutoProcessor</h3><p>多模式任务需要结合两种预处理工具的处理器。例如，<strong><a href="https://huggingface.co/docs/transformers/model_doc/layoutlmv2" target="_blank" rel="noopener">LayoutLMV2</a></strong>模型需要一个特征提取器来处理图像和一个分词器来处理文本；处理器将两者结合在一起。</p>
<p>Load a processor with <strong><a href="https://huggingface.co/docs/transformers/v4.18.0/en/model_doc/auto#transformers.AutoProcessor.from_pretrained" target="_blank" rel="noopener">AutoProcessor.from_pretrained()</a></strong></p>
<pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">from</span> transformers <span class="token keyword">import</span> AutoProcessor

processor <span class="token operator">=</span> AutoProcessor<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span><span class="token string">"microsoft/layoutlmv2-base-uncased"</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre>
<h3 id="AutoModel"><a href="#AutoModel" class="headerlink" title="AutoModel"></a>AutoModel</h3><p>最后，这些<code>AutoModelFor</code>类允许您为给定任务加载预训练模型（有关可用任务的完整列表，请参见<strong><a href="https://huggingface.co/docs/transformers/model_doc/auto" target="_blank" rel="noopener">此处</a></strong>）。例如，使用<strong><a href="https://huggingface.co/docs/transformers/v4.18.0/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained" target="_blank" rel="noopener">AutoModelForSequenceClassification.from_pretrained()</a></strong>加载序列分类模型：</p>
<pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">from</span> transformers <span class="token keyword">import</span> AutoModelForSequenceClassification

model <span class="token operator">=</span> AutoModelForSequenceClassification<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span><span class="token string">"distilbert-base-uncased"</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre>
<p>轻松重用相同的检查点来为不同的任务加载架构：</p>
<pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">from</span> transformers <span class="token keyword">import</span> AutoModelForTokenClassification

model <span class="token operator">=</span> AutoModelForTokenClassification<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span><span class="token string">"distilbert-base-uncased"</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre>
<p>通常，我们建议使用<code>AutoTokenizer</code>类和<code>AutoModelFor</code>类来加载模型的预训练实例。这将确保您每次都加载正确的架构。</p>
<h2 id="Preprocess【预处理】"><a href="#Preprocess【预处理】" class="headerlink" title="Preprocess【预处理】"></a>Preprocess【预处理】</h2><p>在您可以在模型中使用数据之前，需要将数据处理为模型可接受的格式。模型不理解原始文本、图像或音频。这些输入需要转换成数字并组装成张量。</p>
<ul>
<li>使用分词器预处理文本数据。</li>
<li>使用特征提取器预处理图像或音频数据。</li>
<li>使用处理器预处理多模式任务的数据。</li>
</ul>
<h3 id="NLP"><a href="#NLP" class="headerlink" title="NLP"></a>NLP</h3><p>处理文本数据的主要工具是<strong><a href="https://huggingface.co/docs/transformers/main_classes/tokenizer" target="_blank" rel="noopener">分词</a></strong>器。标记器首先根据一组规则将文本拆分为<em>标记。</em>标记被转换为数字，用于构建张量作为模型的输入。模型所需的任何其他输入也由标记器添加。</p>
<p>如果您计划使用预训练模型，请务必使用相关的预训练标记器。这确保文本以与预训练语料库相同的方式拆分，并在预训练期间使用相同的相应标记到索引（通常称为<em>vocab</em>）。</p>
<p><strong><a href="https://huggingface.co/docs/transformers/v4.18.0/en/model_doc/auto#transformers.AutoTokenizer" target="_blank" rel="noopener">通过使用AutoTokenizer</a></strong>类加载预训练的分词器来快速开始。这会下载模型预训练时使用的<em>词汇</em>。</p>
<h3 id="Tokenize"><a href="#Tokenize" class="headerlink" title="Tokenize"></a>Tokenize</h3><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">from</span> transformers <span class="token keyword">import</span> AutoTokenizer

tokenizer <span class="token operator">=</span> AutoTokenizer<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span><span class="token string">"bert-base-cased"</span><span class="token punctuation">)</span>

encoded_input <span class="token operator">=</span> tokenizer<span class="token punctuation">(</span><span class="token string">"Do not meddle in the affairs of wizards, for they are subtle and quick to anger."</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>encoded_input<span class="token punctuation">)</span>
<span class="token punctuation">{</span><span class="token string">'input_ids'</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token number">101</span><span class="token punctuation">,</span> <span class="token number">2079</span><span class="token punctuation">,</span> <span class="token number">2025</span><span class="token punctuation">,</span> <span class="token number">19960</span><span class="token punctuation">,</span> <span class="token number">10362</span><span class="token punctuation">,</span> <span class="token number">1999</span><span class="token punctuation">,</span> <span class="token number">1996</span><span class="token punctuation">,</span> <span class="token number">3821</span><span class="token punctuation">,</span> <span class="token number">1997</span><span class="token punctuation">,</span> <span class="token number">16657</span><span class="token punctuation">,</span> <span class="token number">1010</span><span class="token punctuation">,</span> <span class="token number">2005</span><span class="token punctuation">,</span> <span class="token number">2027</span><span class="token punctuation">,</span> <span class="token number">2024</span><span class="token punctuation">,</span> <span class="token number">11259</span><span class="token punctuation">,</span> <span class="token number">1998</span><span class="token punctuation">,</span> <span class="token number">4248</span><span class="token punctuation">,</span> <span class="token number">2000</span><span class="token punctuation">,</span> <span class="token number">4963</span><span class="token punctuation">,</span> <span class="token number">1012</span><span class="token punctuation">,</span> <span class="token number">102</span><span class="token punctuation">]</span><span class="token punctuation">,</span> 
 <span class="token string">'token_type_ids'</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> 
 <span class="token string">'attention_mask'</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>分词器返回一个包含三个重要项目的字典：</p>
<ul>
<li><strong><a href="https://huggingface.co/docs/transformers/glossary#input-ids" target="_blank" rel="noopener">input_ids</a></strong>是句子中每个标记对应的索引。</li>
<li><strong><a href="https://huggingface.co/docs/transformers/glossary#attention-mask" target="_blank" rel="noopener">attention_mask</a></strong>指示是否应注意令牌。</li>
<li>当有多个序列时，<strong><a href="https://huggingface.co/docs/transformers/glossary#token-type-ids" target="_blank" rel="noopener">token_type_ids标识令牌属于哪个序列。</a></strong></li>
</ul>
<pre class="line-numbers language-python"><code class="language-python">tokenizer<span class="token punctuation">.</span>decode<span class="token punctuation">(</span>encoded_input<span class="token punctuation">[</span><span class="token string">"input_ids"</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
batch_sentences <span class="token operator">=</span> <span class="token punctuation">[</span>
    <span class="token string">"But what about second breakfast?"</span><span class="token punctuation">,</span>
    <span class="token string">"Don't think he knows about second breakfast, Pip."</span><span class="token punctuation">,</span>
    <span class="token string">"What about elevensies?"</span><span class="token punctuation">,</span>
<span class="token punctuation">]</span>
encoded_inputs <span class="token operator">=</span> tokenizer<span class="token punctuation">(</span>batch_sentences<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>encoded_inputs<span class="token punctuation">)</span>
<span class="token punctuation">{</span><span class="token string">'input_ids'</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">101</span><span class="token punctuation">,</span> <span class="token number">1252</span><span class="token punctuation">,</span> <span class="token number">1184</span><span class="token punctuation">,</span> <span class="token number">1164</span><span class="token punctuation">,</span> <span class="token number">1248</span><span class="token punctuation">,</span> <span class="token number">6462</span><span class="token punctuation">,</span> <span class="token number">136</span><span class="token punctuation">,</span> <span class="token number">102</span><span class="token punctuation">]</span><span class="token punctuation">,</span> 
               <span class="token punctuation">[</span><span class="token number">101</span><span class="token punctuation">,</span> <span class="token number">1790</span><span class="token punctuation">,</span> <span class="token number">112</span><span class="token punctuation">,</span> <span class="token number">189</span><span class="token punctuation">,</span> <span class="token number">1341</span><span class="token punctuation">,</span> <span class="token number">1119</span><span class="token punctuation">,</span> <span class="token number">3520</span><span class="token punctuation">,</span> <span class="token number">1164</span><span class="token punctuation">,</span> <span class="token number">1248</span><span class="token punctuation">,</span> <span class="token number">6462</span><span class="token punctuation">,</span> <span class="token number">117</span><span class="token punctuation">,</span> <span class="token number">21902</span><span class="token punctuation">,</span> <span class="token number">1643</span><span class="token punctuation">,</span> <span class="token number">119</span><span class="token punctuation">,</span> <span class="token number">102</span><span class="token punctuation">]</span><span class="token punctuation">,</span> 
               <span class="token punctuation">[</span><span class="token number">101</span><span class="token punctuation">,</span> <span class="token number">1327</span><span class="token punctuation">,</span> <span class="token number">1164</span><span class="token punctuation">,</span> <span class="token number">5450</span><span class="token punctuation">,</span> <span class="token number">23434</span><span class="token punctuation">,</span> <span class="token number">136</span><span class="token punctuation">,</span> <span class="token number">102</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span> 
 <span class="token string">'token_type_ids'</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> 
                    <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> 
                    <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span> 
 <span class="token string">'attention_mask'</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> 
                    <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> 
                    <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<h3 id="Pad"><a href="#Pad" class="headerlink" title="Pad"></a>Pad</h3><p>这给我们带来了一个重要的话题。当您处理一批句子时，它们的长度并不总是相同的。这是一个问题，因为作为模型输入的张量需要具有统一的形状。填充是一种通过向具有较少标记的句子添加特殊<em>填充标记</em>来确保张量是矩形的策略。</p>
<p>将<code>padding</code>参数设置<code>True</code>为填充批次中较短的序列以匹配最长的序列：</p>
<pre class="line-numbers language-python"><code class="language-python">batch_sentences <span class="token operator">=</span> <span class="token punctuation">[</span>
    <span class="token string">"But what about second breakfast?"</span><span class="token punctuation">,</span>
    <span class="token string">"Don't think he knows about second breakfast, Pip."</span><span class="token punctuation">,</span>
    <span class="token string">"What about elevensies?"</span><span class="token punctuation">,</span>
<span class="token punctuation">]</span>
encoded_input <span class="token operator">=</span> tokenizer<span class="token punctuation">(</span>batch_sentences<span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>encoded_input<span class="token punctuation">)</span>
<span class="token punctuation">{</span><span class="token string">'input_ids'</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">101</span><span class="token punctuation">,</span> <span class="token number">1252</span><span class="token punctuation">,</span> <span class="token number">1184</span><span class="token punctuation">,</span> <span class="token number">1164</span><span class="token punctuation">,</span> <span class="token number">1248</span><span class="token punctuation">,</span> <span class="token number">6462</span><span class="token punctuation">,</span> <span class="token number">136</span><span class="token punctuation">,</span> <span class="token number">102</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> 
               <span class="token punctuation">[</span><span class="token number">101</span><span class="token punctuation">,</span> <span class="token number">1790</span><span class="token punctuation">,</span> <span class="token number">112</span><span class="token punctuation">,</span> <span class="token number">189</span><span class="token punctuation">,</span> <span class="token number">1341</span><span class="token punctuation">,</span> <span class="token number">1119</span><span class="token punctuation">,</span> <span class="token number">3520</span><span class="token punctuation">,</span> <span class="token number">1164</span><span class="token punctuation">,</span> <span class="token number">1248</span><span class="token punctuation">,</span> <span class="token number">6462</span><span class="token punctuation">,</span> <span class="token number">117</span><span class="token punctuation">,</span> <span class="token number">21902</span><span class="token punctuation">,</span> <span class="token number">1643</span><span class="token punctuation">,</span> <span class="token number">119</span><span class="token punctuation">,</span> <span class="token number">102</span><span class="token punctuation">]</span><span class="token punctuation">,</span> 
               <span class="token punctuation">[</span><span class="token number">101</span><span class="token punctuation">,</span> <span class="token number">1327</span><span class="token punctuation">,</span> <span class="token number">1164</span><span class="token punctuation">,</span> <span class="token number">5450</span><span class="token punctuation">,</span> <span class="token number">23434</span><span class="token punctuation">,</span> <span class="token number">136</span><span class="token punctuation">,</span> <span class="token number">102</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span> 
 <span class="token string">'token_type_ids'</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> 
                    <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> 
                    <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span> 
 <span class="token string">'attention_mask'</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> 
                    <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> 
                    <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<h3 id="Truncation"><a href="#Truncation" class="headerlink" title="Truncation"></a>Truncation</h3><p>另一方面，有时序列可能太长，模型无法处理。在这种情况下，您需要将序列截断为更短的长度。</p>
<p>将<code>truncation</code>参数设置<code>True</code>为将序列截断为模型接受的最大长度：</p>
<pre class="line-numbers language-python"><code class="language-python">batch_sentences <span class="token operator">=</span> <span class="token punctuation">[</span>
    <span class="token string">"But what about second breakfast?"</span><span class="token punctuation">,</span>
    <span class="token string">"Don't think he knows about second breakfast, Pip."</span><span class="token punctuation">,</span>
    <span class="token string">"What about elevensies?"</span><span class="token punctuation">,</span>
<span class="token punctuation">]</span>
encoded_input <span class="token operator">=</span> tokenizer<span class="token punctuation">(</span>batch_sentences<span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> truncation<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>encoded_input<span class="token punctuation">)</span>
<span class="token punctuation">{</span><span class="token string">'input_ids'</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">101</span><span class="token punctuation">,</span> <span class="token number">1252</span><span class="token punctuation">,</span> <span class="token number">1184</span><span class="token punctuation">,</span> <span class="token number">1164</span><span class="token punctuation">,</span> <span class="token number">1248</span><span class="token punctuation">,</span> <span class="token number">6462</span><span class="token punctuation">,</span> <span class="token number">136</span><span class="token punctuation">,</span> <span class="token number">102</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> 
               <span class="token punctuation">[</span><span class="token number">101</span><span class="token punctuation">,</span> <span class="token number">1790</span><span class="token punctuation">,</span> <span class="token number">112</span><span class="token punctuation">,</span> <span class="token number">189</span><span class="token punctuation">,</span> <span class="token number">1341</span><span class="token punctuation">,</span> <span class="token number">1119</span><span class="token punctuation">,</span> <span class="token number">3520</span><span class="token punctuation">,</span> <span class="token number">1164</span><span class="token punctuation">,</span> <span class="token number">1248</span><span class="token punctuation">,</span> <span class="token number">6462</span><span class="token punctuation">,</span> <span class="token number">117</span><span class="token punctuation">,</span> <span class="token number">21902</span><span class="token punctuation">,</span> <span class="token number">1643</span><span class="token punctuation">,</span> <span class="token number">119</span><span class="token punctuation">,</span> <span class="token number">102</span><span class="token punctuation">]</span><span class="token punctuation">,</span> 
               <span class="token punctuation">[</span><span class="token number">101</span><span class="token punctuation">,</span> <span class="token number">1327</span><span class="token punctuation">,</span> <span class="token number">1164</span><span class="token punctuation">,</span> <span class="token number">5450</span><span class="token punctuation">,</span> <span class="token number">23434</span><span class="token punctuation">,</span> <span class="token number">136</span><span class="token punctuation">,</span> <span class="token number">102</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span> 
 <span class="token string">'token_type_ids'</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> 
                    <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> 
                    <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span> 
 <span class="token string">'attention_mask'</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> 
                    <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> 
                    <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<h3 id="Build-tensors"><a href="#Build-tensors" class="headerlink" title="Build tensors"></a>Build tensors</h3><p>最后，希望标记器返回馈送到模型的实际张量。</p>
<p>将<code>return_tensors</code>参数设置<code>pt</code>为 PyTorch 或<code>tf</code>TensorFlow：</p>
<pre class="line-numbers language-python"><code class="language-python">batch_sentences <span class="token operator">=</span> <span class="token punctuation">[</span>
    <span class="token string">"But what about second breakfast?"</span><span class="token punctuation">,</span>
    <span class="token string">"Don't think he knows about second breakfast, Pip."</span><span class="token punctuation">,</span>
    <span class="token string">"What about elevensies?"</span><span class="token punctuation">,</span>
<span class="token punctuation">]</span>
encoded_input <span class="token operator">=</span> tokenizer<span class="token punctuation">(</span>batch<span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> truncation<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> return_tensors<span class="token operator">=</span><span class="token string">"pt"</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>encoded_input<span class="token punctuation">)</span>
<span class="token punctuation">{</span><span class="token string">'input_ids'</span><span class="token punctuation">:</span> tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span>  <span class="token number">101</span><span class="token punctuation">,</span>   <span class="token number">153</span><span class="token punctuation">,</span>  <span class="token number">7719</span><span class="token punctuation">,</span> <span class="token number">21490</span><span class="token punctuation">,</span>  <span class="token number">1122</span><span class="token punctuation">,</span>  <span class="token number">1114</span><span class="token punctuation">,</span>  <span class="token number">9582</span><span class="token punctuation">,</span>  <span class="token number">1623</span><span class="token punctuation">,</span>   <span class="token number">102</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
                      <span class="token punctuation">[</span>  <span class="token number">101</span><span class="token punctuation">,</span>  <span class="token number">5226</span><span class="token punctuation">,</span>  <span class="token number">1122</span><span class="token punctuation">,</span>  <span class="token number">9649</span><span class="token punctuation">,</span>  <span class="token number">1199</span><span class="token punctuation">,</span>  <span class="token number">2610</span><span class="token punctuation">,</span>  <span class="token number">1236</span><span class="token punctuation">,</span>   <span class="token number">102</span><span class="token punctuation">,</span>     <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span> 
 <span class="token string">'token_type_ids'</span><span class="token punctuation">:</span> tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
                           <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span> 
 <span class="token string">'attention_mask'</span><span class="token punctuation">:</span> tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
                           <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<h3 id="Audio"><a href="#Audio" class="headerlink" title="Audio"></a>Audio</h3><p>音频输入的预处理与文本输入不同，但最终目标保持不变：创建模型可以理解的数字序列。<strong><a href="https://huggingface.co/docs/transformers/main_classes/feature_extractor" target="_blank" rel="noopener">特征提取器</a></strong>旨在从原始图像或音频数据中提取特征并将其转换为张量。</p>
<pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">from</span> datasets <span class="token keyword">import</span> load_dataset<span class="token punctuation">,</span> Audio

dataset <span class="token operator">=</span> load_dataset<span class="token punctuation">(</span><span class="token string">"superb"</span><span class="token punctuation">,</span> <span class="token string">"ks"</span><span class="token punctuation">)</span>

dataset<span class="token punctuation">[</span><span class="token string">"train"</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">"audio"</span><span class="token punctuation">]</span>
<span class="token punctuation">{</span><span class="token string">'array'</span><span class="token punctuation">:</span> array<span class="token punctuation">(</span><span class="token punctuation">[</span> <span class="token number">0</span><span class="token punctuation">.</span>        <span class="token punctuation">,</span>  <span class="token number">0</span><span class="token punctuation">.</span>        <span class="token punctuation">,</span>  <span class="token number">0</span><span class="token punctuation">.</span>        <span class="token punctuation">,</span> <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.00592041</span><span class="token punctuation">,</span>
        <span class="token operator">-</span><span class="token number">0.00405884</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.00253296</span><span class="token punctuation">]</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>float32<span class="token punctuation">)</span><span class="token punctuation">,</span>
 <span class="token string">'path'</span><span class="token punctuation">:</span> <span class="token string">'/root/.cache/huggingface/datasets/downloads/extracted/05734a36d88019a09725c20cc024e1c4e7982e37d7d55c0c1ca1742ea1cdd47f/_background_noise_/doing_the_dishes.wav'</span><span class="token punctuation">,</span>
 <span class="token string">'sampling_rate'</span><span class="token punctuation">:</span> <span class="token number">16000</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>这将返回三个项目：</p>
<ul>
<li><code>array</code>是将语音信号加载 - 并可能重新采样 - 作为一维数组。</li>
<li><code>path</code>指向音频文件的位置。</li>
<li><code>sampling_rate</code>指每秒测量语音信号中的数据点数。</li>
</ul>
<h3 id="Resample"><a href="#Resample" class="headerlink" title="Resample"></a>Resample</h3><pre class="line-numbers language-python"><code class="language-python">lj_speech <span class="token operator">=</span> load_dataset<span class="token punctuation">(</span><span class="token string">"lj_speech"</span><span class="token punctuation">,</span> split<span class="token operator">=</span><span class="token string">"train"</span><span class="token punctuation">)</span>
lj_speech<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">"audio"</span><span class="token punctuation">]</span>

lj_speech <span class="token operator">=</span> lj_speech<span class="token punctuation">.</span>cast_column<span class="token punctuation">(</span><span class="token string">"audio"</span><span class="token punctuation">,</span> Audio<span class="token punctuation">(</span>sampling_rate<span class="token operator">=</span>16_000<span class="token punctuation">)</span><span class="token punctuation">)</span>

lj_speech<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">"audio"</span><span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<h3 id="Feature-extractor"><a href="#Feature-extractor" class="headerlink" title="Feature extractor"></a>Feature extractor</h3><p>下一步是加载一个特征提取器来规范化和填充输入。填充文本数据时，<code>0</code>为较短的序列添加 a。同样的想法也适用于音频数据，音频特征提取器将添加一个<code>0</code>- 解释为静音 - 到<code>array</code>.</p>
<pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">from</span> transformers <span class="token keyword">import</span> AutoFeatureExtractor

feature_extractor <span class="token operator">=</span> AutoFeatureExtractor<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span><span class="token string">"facebook/wav2vec2-base"</span><span class="token punctuation">)</span>
audio_input <span class="token operator">=</span> <span class="token punctuation">[</span>dataset<span class="token punctuation">[</span><span class="token string">"train"</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">"audio"</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">"array"</span><span class="token punctuation">]</span><span class="token punctuation">]</span>
feature_extractor<span class="token punctuation">(</span>audio_input<span class="token punctuation">,</span> sampling_rate<span class="token operator">=</span><span class="token number">16000</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<h3 id="Pad-and-truncate"><a href="#Pad-and-truncate" class="headerlink" title="Pad and truncate"></a>Pad and truncate</h3><pre class="line-numbers language-python"><code class="language-python">dataset<span class="token punctuation">[</span><span class="token string">"train"</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">"audio"</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">"array"</span><span class="token punctuation">]</span><span class="token punctuation">.</span>shape

dataset<span class="token punctuation">[</span><span class="token string">"train"</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">"audio"</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">"array"</span><span class="token punctuation">]</span><span class="token punctuation">.</span>shape

<span class="token keyword">def</span> <span class="token function">preprocess_function</span><span class="token punctuation">(</span>examples<span class="token punctuation">)</span><span class="token punctuation">:</span>
    audio_arrays <span class="token operator">=</span> <span class="token punctuation">[</span>x<span class="token punctuation">[</span><span class="token string">"array"</span><span class="token punctuation">]</span> <span class="token keyword">for</span> x <span class="token keyword">in</span> examples<span class="token punctuation">[</span><span class="token string">"audio"</span><span class="token punctuation">]</span><span class="token punctuation">]</span>
    inputs <span class="token operator">=</span> feature_extractor<span class="token punctuation">(</span>
        audio_arrays<span class="token punctuation">,</span>
        sampling_rate<span class="token operator">=</span><span class="token number">16000</span><span class="token punctuation">,</span>
        padding<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>
        max_length<span class="token operator">=</span><span class="token number">1000000</span><span class="token punctuation">,</span>
        truncation<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>
    <span class="token punctuation">)</span>
    <span class="token keyword">return</span> inputs

processed_dataset <span class="token operator">=</span> preprocess_function<span class="token punctuation">(</span>dataset<span class="token punctuation">[</span><span class="token string">"train"</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token number">5</span><span class="token punctuation">]</span><span class="token punctuation">)</span>

processed_dataset<span class="token punctuation">[</span><span class="token string">"input_values"</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>shape

processed_dataset<span class="token punctuation">[</span><span class="token string">"input_values"</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">.</span>shape<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<h3 id="Vision"><a href="#Vision" class="headerlink" title="Vision"></a>Vision</h3><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">from</span> datasets <span class="token keyword">import</span> load_dataset

dataset <span class="token operator">=</span> load_dataset<span class="token punctuation">(</span><span class="token string">"food101"</span><span class="token punctuation">,</span> split<span class="token operator">=</span><span class="token string">"train[:100]"</span><span class="token punctuation">)</span>

dataset<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">"image"</span><span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<h3 id="Feature-extractor-1"><a href="#Feature-extractor-1" class="headerlink" title="Feature extractor"></a>Feature extractor</h3><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">from</span> transformers <span class="token keyword">import</span> AutoFeatureExtractor

feature_extractor <span class="token operator">=</span> AutoFeatureExtractor<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span><span class="token string">"google/vit-base-patch16-224"</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre>
<h3 id="Data-augmentation"><a href="#Data-augmentation" class="headerlink" title="Data augmentation"></a>Data augmentation</h3><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">from</span> torchvision<span class="token punctuation">.</span>transforms <span class="token keyword">import</span> Compose<span class="token punctuation">,</span> Normalize<span class="token punctuation">,</span> RandomResizedCrop<span class="token punctuation">,</span> ColorJitter<span class="token punctuation">,</span> ToTensor

normalize <span class="token operator">=</span> Normalize<span class="token punctuation">(</span>mean<span class="token operator">=</span>feature_extractor<span class="token punctuation">.</span>image_mean<span class="token punctuation">,</span> std<span class="token operator">=</span>feature_extractor<span class="token punctuation">.</span>image_std<span class="token punctuation">)</span>
_transforms <span class="token operator">=</span> Compose<span class="token punctuation">(</span>
    <span class="token punctuation">[</span>RandomResizedCrop<span class="token punctuation">(</span>feature_extractor<span class="token punctuation">.</span>size<span class="token punctuation">)</span><span class="token punctuation">,</span> ColorJitter<span class="token punctuation">(</span>brightness<span class="token operator">=</span><span class="token number">0.5</span><span class="token punctuation">,</span> hue<span class="token operator">=</span><span class="token number">0.5</span><span class="token punctuation">)</span><span class="token punctuation">,</span> ToTensor<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> normalize<span class="token punctuation">]</span>
<span class="token punctuation">)</span>

<span class="token keyword">def</span> <span class="token function">transforms</span><span class="token punctuation">(</span>examples<span class="token punctuation">)</span><span class="token punctuation">:</span>
    examples<span class="token punctuation">[</span><span class="token string">"pixel_values"</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token punctuation">[</span>_transforms<span class="token punctuation">(</span>image<span class="token punctuation">.</span>convert<span class="token punctuation">(</span><span class="token string">"RGB"</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token keyword">for</span> image <span class="token keyword">in</span> examples<span class="token punctuation">[</span><span class="token string">"image"</span><span class="token punctuation">]</span><span class="token punctuation">]</span>
    <span class="token keyword">return</span> examples

dataset<span class="token punctuation">.</span>set_transform<span class="token punctuation">(</span>transforms<span class="token punctuation">)</span>

dataset<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">"image"</span><span class="token punctuation">]</span>

<span class="token punctuation">{</span><span class="token string">'image'</span><span class="token punctuation">:</span> <span class="token operator">&lt;</span>PIL<span class="token punctuation">.</span>JpegImagePlugin<span class="token punctuation">.</span>JpegImageFile image mode<span class="token operator">=</span>RGB size<span class="token operator">=</span>384x512 at <span class="token number">0x7F1A7B0630D0</span><span class="token operator">></span><span class="token punctuation">,</span>
 <span class="token string">'label'</span><span class="token punctuation">:</span> <span class="token number">6</span><span class="token punctuation">,</span>
 <span class="token string">'pixel_values'</span><span class="token punctuation">:</span> tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token punctuation">[</span> <span class="token number">0.0353</span><span class="token punctuation">,</span>  <span class="token number">0.0745</span><span class="token punctuation">,</span>  <span class="token number">0.1216</span><span class="token punctuation">,</span>  <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.9922</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.9922</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.9922</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
          <span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">0.0196</span><span class="token punctuation">,</span>  <span class="token number">0.0667</span><span class="token punctuation">,</span>  <span class="token number">0.1294</span><span class="token punctuation">,</span>  <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.9765</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.9843</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.9922</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
          <span class="token punctuation">[</span> <span class="token number">0.0196</span><span class="token punctuation">,</span>  <span class="token number">0.0824</span><span class="token punctuation">,</span>  <span class="token number">0.1137</span><span class="token punctuation">,</span>  <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.9765</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.9686</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.8667</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
          <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">,</span>
          <span class="token punctuation">[</span> <span class="token number">0.0275</span><span class="token punctuation">,</span>  <span class="token number">0.0745</span><span class="token punctuation">,</span>  <span class="token number">0.0510</span><span class="token punctuation">,</span>  <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.1137</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.1216</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.0824</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
          <span class="token punctuation">[</span> <span class="token number">0.0667</span><span class="token punctuation">,</span>  <span class="token number">0.0824</span><span class="token punctuation">,</span>  <span class="token number">0.0667</span><span class="token punctuation">,</span>  <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.0588</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.0745</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.0980</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
          <span class="token punctuation">[</span> <span class="token number">0.0353</span><span class="token punctuation">,</span>  <span class="token number">0.0353</span><span class="token punctuation">,</span>  <span class="token number">0.0431</span><span class="token punctuation">,</span>  <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.0039</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.0039</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.0588</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span>

         <span class="token punctuation">[</span><span class="token punctuation">[</span> <span class="token number">0.2078</span><span class="token punctuation">,</span>  <span class="token number">0.2471</span><span class="token punctuation">,</span>  <span class="token number">0.2863</span><span class="token punctuation">,</span>  <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.9451</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.9373</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.9451</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
          <span class="token punctuation">[</span> <span class="token number">0.1608</span><span class="token punctuation">,</span>  <span class="token number">0.2471</span><span class="token punctuation">,</span>  <span class="token number">0.3098</span><span class="token punctuation">,</span>  <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.9373</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.9451</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.9373</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
          <span class="token punctuation">[</span> <span class="token number">0.2078</span><span class="token punctuation">,</span>  <span class="token number">0.2706</span><span class="token punctuation">,</span>  <span class="token number">0.3020</span><span class="token punctuation">,</span>  <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.9608</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.9373</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.8275</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
          <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">,</span>
          <span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">0.0353</span><span class="token punctuation">,</span>  <span class="token number">0.0118</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.0039</span><span class="token punctuation">,</span>  <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.2392</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.2471</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.2078</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
          <span class="token punctuation">[</span> <span class="token number">0.0196</span><span class="token punctuation">,</span>  <span class="token number">0.0353</span><span class="token punctuation">,</span>  <span class="token number">0.0196</span><span class="token punctuation">,</span>  <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.1843</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.2000</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.2235</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
          <span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">0.0118</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.0039</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.0039</span><span class="token punctuation">,</span>  <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.0980</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.0980</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.1529</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span>

         <span class="token punctuation">[</span><span class="token punctuation">[</span> <span class="token number">0.3961</span><span class="token punctuation">,</span>  <span class="token number">0.4431</span><span class="token punctuation">,</span>  <span class="token number">0.4980</span><span class="token punctuation">,</span>  <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.9216</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.9137</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.9216</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
          <span class="token punctuation">[</span> <span class="token number">0.3569</span><span class="token punctuation">,</span>  <span class="token number">0.4510</span><span class="token punctuation">,</span>  <span class="token number">0.5216</span><span class="token punctuation">,</span>  <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.9059</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.9137</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.9137</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
          <span class="token punctuation">[</span> <span class="token number">0.4118</span><span class="token punctuation">,</span>  <span class="token number">0.4745</span><span class="token punctuation">,</span>  <span class="token number">0.5216</span><span class="token punctuation">,</span>  <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.9137</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.8902</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.7804</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
          <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">,</span>
          <span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">0.2314</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.1922</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.2078</span><span class="token punctuation">,</span>  <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.4196</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.4275</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.3882</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
          <span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">0.1843</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.1686</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.2000</span><span class="token punctuation">,</span>  <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.3647</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.3804</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.4039</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
          <span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">0.1922</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.1922</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.1922</span><span class="token punctuation">,</span>  <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.2941</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.2863</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.3412</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<h3 id="Multimodal"><a href="#Multimodal" class="headerlink" title="Multimodal"></a>Multimodal</h3><p>用于多模式任务。您将结合迄今为止所学的所有知识，并将您的技能应用于自动语音识别 (ASR) 任务。这意味着您将需要：</p>
<ul>
<li>用于预处理音频数据的特征提取器。</li>
<li>用于处理文本的标记器。</li>
</ul>
<pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">from</span> datasets <span class="token keyword">import</span> load_dataset

lj_speech <span class="token operator">=</span> load_dataset<span class="token punctuation">(</span><span class="token string">"lj_speech"</span><span class="token punctuation">,</span> split<span class="token operator">=</span><span class="token string">"train"</span><span class="token punctuation">)</span>

lj_speech <span class="token operator">=</span> lj_speech<span class="token punctuation">.</span>map<span class="token punctuation">(</span>remove_columns<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">"file"</span><span class="token punctuation">,</span> <span class="token string">"id"</span><span class="token punctuation">,</span> <span class="token string">"normalized_text"</span><span class="token punctuation">]</span><span class="token punctuation">)</span>

lj_speech<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">"audio"</span><span class="token punctuation">]</span>

lj_speech<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">"text"</span><span class="token punctuation">]</span>

lj_speech <span class="token operator">=</span> lj_speech<span class="token punctuation">.</span>cast_column<span class="token punctuation">(</span><span class="token string">"audio"</span><span class="token punctuation">,</span> Audio<span class="token punctuation">(</span>sampling_rate<span class="token operator">=</span>16_000<span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<h3 id="Processor"><a href="#Processor" class="headerlink" title="Processor"></a>Processor</h3><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">from</span> transformers <span class="token keyword">import</span> AutoProcessor

processor <span class="token operator">=</span> AutoProcessor<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span><span class="token string">"facebook/wav2vec2-base-960h"</span><span class="token punctuation">)</span>

<span class="token keyword">def</span> <span class="token function">prepare_dataset</span><span class="token punctuation">(</span>example<span class="token punctuation">)</span><span class="token punctuation">:</span>
    audio <span class="token operator">=</span> example<span class="token punctuation">[</span><span class="token string">"audio"</span><span class="token punctuation">]</span>

    example<span class="token punctuation">[</span><span class="token string">"input_values"</span><span class="token punctuation">]</span> <span class="token operator">=</span> processor<span class="token punctuation">(</span>audio<span class="token punctuation">[</span><span class="token string">"array"</span><span class="token punctuation">]</span><span class="token punctuation">,</span> sampling_rate<span class="token operator">=</span><span class="token number">16000</span><span class="token punctuation">)</span>

    <span class="token keyword">with</span> processor<span class="token punctuation">.</span>as_target_processor<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        example<span class="token punctuation">[</span><span class="token string">"labels"</span><span class="token punctuation">]</span> <span class="token operator">=</span> processor<span class="token punctuation">(</span>example<span class="token punctuation">[</span><span class="token string">"text"</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">.</span>input_ids
    <span class="token keyword">return</span> example

prepare_dataset<span class="token punctuation">(</span>lj_speech<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<h2 id="Fine-tune-a-pretrained-model【微调】"><a href="#Fine-tune-a-pretrained-model【微调】" class="headerlink" title="Fine-tune a pretrained model【微调】"></a>Fine-tune a pretrained model【微调】</h2><p>使用预训练模型有很多好处。它降低了计算成本和碳足迹，并允许您使用最先进的模型，而无需从头开始训练。🤗 Transformers 为各种任务提供了对数千个预训练模型的访问。当您使用预训练模型时，您可以在特定于您的任务的数据集上对其进行训练。这被称为微调，一种非常强大的训练技术。</p>
<p>在微调预训练模型之前，请下载数据集并为训练做好准备</p>
<pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">from</span> datasets <span class="token keyword">import</span> load_dataset

dataset <span class="token operator">=</span> load_dataset<span class="token punctuation">(</span><span class="token string">"yelp_review_full"</span><span class="token punctuation">)</span>
dataset<span class="token punctuation">[</span><span class="token string">"train"</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">100</span><span class="token punctuation">]</span>

<span class="token punctuation">{</span><span class="token string">'label'</span><span class="token punctuation">:</span> <span class="token number">0</span><span class="token punctuation">,</span>
 <span class="token string">'text'</span><span class="token punctuation">:</span> <span class="token string">'My expectations for McDonalds are t rarely high. But for one to still fail so spectacularly...that takes something special!\\\\nThe cashier took my friends\\'</span>s order<span class="token punctuation">,</span> then promptly ignored me<span class="token punctuation">.</span> I had to force myself <span class="token keyword">in</span> front of a cashier who opened his register to wait on the person BEHIND me<span class="token punctuation">.</span> I waited over five minutes <span class="token keyword">for</span> a gigantic order that included precisely one kid\\<span class="token string">'s meal. After watching two people who ordered after me be handed their food, I asked where mine was. The manager started yelling at the cashiers for \\\\"serving off their orders\\\\" when they didn\\'</span>t have their food<span class="token punctuation">.</span> But neither cashier was anywhere near those controls<span class="token punctuation">,</span> <span class="token operator">and</span> the manager was the one serving food to customers <span class="token operator">and</span> clearing the boards<span class="token punctuation">.</span>\\\\nThe manager was rude when giving me my order<span class="token punctuation">.</span> She didn\\<span class="token string">'t make sure that I had everything ON MY RECEIPT, and never even had the decency to apologize that I felt I was getting poor service.\\\\nI\\'</span>ve eaten at various McDonalds restaurants <span class="token keyword">for</span> over <span class="token number">30</span> years<span class="token punctuation">.</span> I\\<span class="token string">'ve worked at more than one location. I expect bad days, bad moods, and the occasional mistake. But I have yet to have a decent experience at this store. It will remain a place I avoid unless someone in my party needs to avoid illness from low blood sugar. Perhaps I should go back to the racially biased service of Steak n Shake instead!'</span><span class="token punctuation">}</span>

<span class="token keyword">from</span> transformers <span class="token keyword">import</span> AutoTokenizer

tokenizer <span class="token operator">=</span> AutoTokenizer<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span><span class="token string">"bert-base-cased"</span><span class="token punctuation">)</span>

<span class="token keyword">def</span> <span class="token function">tokenize_function</span><span class="token punctuation">(</span>examples<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">return</span> tokenizer<span class="token punctuation">(</span>examples<span class="token punctuation">[</span><span class="token string">"text"</span><span class="token punctuation">]</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token string">"max_length"</span><span class="token punctuation">,</span> truncation<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>

tokenized_datasets <span class="token operator">=</span> dataset<span class="token punctuation">.</span>map<span class="token punctuation">(</span>tokenize_function<span class="token punctuation">,</span> batched<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>

small_train_dataset <span class="token operator">=</span> tokenized_datasets<span class="token punctuation">[</span><span class="token string">"train"</span><span class="token punctuation">]</span><span class="token punctuation">.</span>shuffle<span class="token punctuation">(</span>seed<span class="token operator">=</span><span class="token number">42</span><span class="token punctuation">)</span><span class="token punctuation">.</span>select<span class="token punctuation">(</span>range<span class="token punctuation">(</span><span class="token number">1000</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
small_eval_dataset <span class="token operator">=</span> tokenized_datasets<span class="token punctuation">[</span><span class="token string">"test"</span><span class="token punctuation">]</span><span class="token punctuation">.</span>shuffle<span class="token punctuation">(</span>seed<span class="token operator">=</span><span class="token number">42</span><span class="token punctuation">)</span><span class="token punctuation">.</span>select<span class="token punctuation">(</span>range<span class="token punctuation">(</span><span class="token number">1000</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<h3 id="Train"><a href="#Train" class="headerlink" title="Train"></a>Train</h3><p>Transformers 提供了一个针对训练优化的<strong><a href="https://huggingface.co/docs/transformers/v4.18.0/en/main_classes/trainer#transformers.Trainer" target="_blank" rel="noopener">Trainer</a></strong>类 🤗 Transformers 模型，无需手动编写自己的训练循环即可更轻松地开始训练。<strong><a href="https://huggingface.co/docs/transformers/v4.18.0/en/main_classes/trainer#transformers.Trainer" target="_blank" rel="noopener">Trainer</a></strong> API 支持广泛的训练选项和功能，例如日志记录、梯度累积和混合精度。</p>
<pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">from</span> transformers <span class="token keyword">import</span> AutoModelForSequenceClassification

model <span class="token operator">=</span> AutoModelForSequenceClassification<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span><span class="token string">"bert-base-cased"</span><span class="token punctuation">,</span> num_labels<span class="token operator">=</span><span class="token number">5</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre>
<p>Training hyperparameters</p>
<p>接下来，创建一个<strong><a href="https://huggingface.co/docs/transformers/v4.18.0/en/main_classes/trainer#transformers.TrainingArguments" target="_blank" rel="noopener">TrainingArguments</a></strong>类，其中包含您可以调整的所有超参数以及用于激活不同训练选项的标志。您可以从默认的训练<strong><a href="https://huggingface.co/docs/transformers/main_classes/trainer#transformers.TrainingArguments" target="_blank" rel="noopener">超参数</a></strong>开始，但可以随意尝试这些参数以找到您的最佳设置。</p>
<pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">from</span> transformers <span class="token keyword">import</span> TrainingArguments

training_args <span class="token operator">=</span> TrainingArguments<span class="token punctuation">(</span>output_dir<span class="token operator">=</span><span class="token string">"test_trainer"</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre>
<p>Metrics</p>
<p><strong><a href="https://huggingface.co/docs/transformers/v4.18.0/en/main_classes/trainer#transformers.Trainer" target="_blank" rel="noopener">Trainer</a>\</strong>在训练期间不会自动评估模型性能。您需要向**<a href="https://huggingface.co/docs/transformers/v4.18.0/en/main_classes/trainer#transformers.Trainer" target="_blank" rel="noopener">Trainer</a>*<em>传递一个函数来计算和报告指标。🤗 数据集库提供了一个简单的函数，您可以使用（有关更多信息，请参阅本*</em><a href="https://huggingface.co/docs/datasets/metrics.html" target="_blank" rel="noopener">教程</a><code>[accuracy](&lt;https://huggingface.co/metrics/accuracy&gt;)</code>**）函数加载：<code>load_metric</code></p>
<pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">import</span> numpy <span class="token keyword">as</span> np
<span class="token keyword">from</span> datasets <span class="token keyword">import</span> load_metric

metric <span class="token operator">=</span> load_metric<span class="token punctuation">(</span><span class="token string">"accuracy"</span><span class="token punctuation">)</span>

<span class="token keyword">from</span> transformers <span class="token keyword">import</span> TrainingArguments<span class="token punctuation">,</span> Trainer

training_args <span class="token operator">=</span> TrainingArguments<span class="token punctuation">(</span>output_dir<span class="token operator">=</span><span class="token string">"test_trainer"</span><span class="token punctuation">,</span> evaluation_strategy<span class="token operator">=</span><span class="token string">"epoch"</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>Trainer</p>
<p>使用您的模型、训练参数、训练和测试数据集以及评估函数创建一个<strong><a href="https://huggingface.co/docs/transformers/v4.18.0/en/main_classes/trainer#transformers.Trainer" target="_blank" rel="noopener">Trainer对象：</a></strong></p>
<pre class="line-numbers language-python"><code class="language-python">trainer <span class="token operator">=</span> Trainer<span class="token punctuation">(</span>
    model<span class="token operator">=</span>model<span class="token punctuation">,</span>
    args<span class="token operator">=</span>training_args<span class="token punctuation">,</span>
    train_dataset<span class="token operator">=</span>small_train_dataset<span class="token punctuation">,</span>
    eval_dataset<span class="token operator">=</span>small_eval_dataset<span class="token punctuation">,</span>
    compute_metrics<span class="token operator">=</span>compute_metrics<span class="token punctuation">,</span>
<span class="token punctuation">)</span>

trainer<span class="token punctuation">.</span>train<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<h3 id="Train-in-native-PyTorch"><a href="#Train-in-native-PyTorch" class="headerlink" title="Train in native PyTorch"></a>Train in native PyTorch</h3><p><strong><a href="https://huggingface.co/docs/transformers/v4.18.0/en/main_classes/trainer#transformers.Trainer" target="_blank" rel="noopener">Trainer</a></strong>负责训练循环，并允许您在一行代码中微调模型。对于喜欢编写自己的训练循环的用户，您还可以在原生 PyTorch 中微调🤗 Transformers 模型。</p>
<pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">del</span> model
<span class="token keyword">del</span> pytorch_model
<span class="token keyword">del</span> trainer
torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>empty_cache<span class="token punctuation">(</span><span class="token punctuation">)</span>

tokenized_datasets <span class="token operator">=</span> tokenized_datasets<span class="token punctuation">.</span>remove_columns<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token string">"text"</span><span class="token punctuation">]</span><span class="token punctuation">)</span>

tokenized_datasets <span class="token operator">=</span> tokenized_datasets<span class="token punctuation">.</span>rename_column<span class="token punctuation">(</span><span class="token string">"label"</span><span class="token punctuation">,</span> <span class="token string">"labels"</span><span class="token punctuation">)</span>

tokenized_datasets<span class="token punctuation">.</span>set_format<span class="token punctuation">(</span><span class="token string">"torch"</span><span class="token punctuation">)</span>

small_train_dataset <span class="token operator">=</span> tokenized_datasets<span class="token punctuation">[</span><span class="token string">"train"</span><span class="token punctuation">]</span><span class="token punctuation">.</span>shuffle<span class="token punctuation">(</span>seed<span class="token operator">=</span><span class="token number">42</span><span class="token punctuation">)</span><span class="token punctuation">.</span>select<span class="token punctuation">(</span>range<span class="token punctuation">(</span><span class="token number">1000</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
small_eval_dataset <span class="token operator">=</span> tokenized_datasets<span class="token punctuation">[</span><span class="token string">"test"</span><span class="token punctuation">]</span><span class="token punctuation">.</span>shuffle<span class="token punctuation">(</span>seed<span class="token operator">=</span><span class="token number">42</span><span class="token punctuation">)</span><span class="token punctuation">.</span>select<span class="token punctuation">(</span>range<span class="token punctuation">(</span><span class="token number">1000</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>DataLoader</p>
<pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">from</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data <span class="token keyword">import</span> DataLoader

train_dataloader <span class="token operator">=</span> DataLoader<span class="token punctuation">(</span>small_train_dataset<span class="token punctuation">,</span> shuffle<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> batch_size<span class="token operator">=</span><span class="token number">8</span><span class="token punctuation">)</span>
eval_dataloader <span class="token operator">=</span> DataLoader<span class="token punctuation">(</span>small_eval_dataset<span class="token punctuation">,</span> batch_size<span class="token operator">=</span><span class="token number">8</span><span class="token punctuation">)</span>

<span class="token keyword">from</span> transformers <span class="token keyword">import</span> AutoModelForSequenceClassification

model <span class="token operator">=</span> AutoModelForSequenceClassification<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span><span class="token string">"bert-base-cased"</span><span class="token punctuation">,</span> num_labels<span class="token operator">=</span><span class="token number">5</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>Optimizer and learning rate scheduler</p>
<pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">from</span> torch<span class="token punctuation">.</span>optim <span class="token keyword">import</span> AdamW

optimizer <span class="token operator">=</span> AdamW<span class="token punctuation">(</span>model<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> lr<span class="token operator">=</span><span class="token number">5e</span><span class="token operator">-</span><span class="token number">5</span><span class="token punctuation">)</span>

<span class="token keyword">from</span> transformers <span class="token keyword">import</span> get_scheduler

num_epochs <span class="token operator">=</span> <span class="token number">3</span>
num_training_steps <span class="token operator">=</span> num_epochs <span class="token operator">*</span> len<span class="token punctuation">(</span>train_dataloader<span class="token punctuation">)</span>
lr_scheduler <span class="token operator">=</span> get_scheduler<span class="token punctuation">(</span>
    name<span class="token operator">=</span><span class="token string">"linear"</span><span class="token punctuation">,</span> optimizer<span class="token operator">=</span>optimizer<span class="token punctuation">,</span> num_warmup_steps<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">,</span> num_training_steps<span class="token operator">=</span>num_training_steps
<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>Training loop</p>
<pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">from</span> tqdm<span class="token punctuation">.</span>auto <span class="token keyword">import</span> tqdm

progress_bar <span class="token operator">=</span> tqdm<span class="token punctuation">(</span>range<span class="token punctuation">(</span>num_training_steps<span class="token punctuation">)</span><span class="token punctuation">)</span>

model<span class="token punctuation">.</span>train<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token keyword">for</span> epoch <span class="token keyword">in</span> range<span class="token punctuation">(</span>num_epochs<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">for</span> batch <span class="token keyword">in</span> train_dataloader<span class="token punctuation">:</span>
        batch <span class="token operator">=</span> <span class="token punctuation">{</span>k<span class="token punctuation">:</span> v<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span> <span class="token keyword">for</span> k<span class="token punctuation">,</span> v <span class="token keyword">in</span> batch<span class="token punctuation">.</span>items<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">}</span>
        outputs <span class="token operator">=</span> model<span class="token punctuation">(</span><span class="token operator">**</span>batch<span class="token punctuation">)</span>
        loss <span class="token operator">=</span> outputs<span class="token punctuation">.</span>loss
        loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>

        optimizer<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>
        lr_scheduler<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>
        optimizer<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>
        progress_bar<span class="token punctuation">.</span>update<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>Metrics</p>
<pre class="line-numbers language-python"><code class="language-python">metric <span class="token operator">=</span> load_metric<span class="token punctuation">(</span><span class="token string">"accuracy"</span><span class="token punctuation">)</span>
model<span class="token punctuation">.</span>eval<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token keyword">for</span> batch <span class="token keyword">in</span> eval_dataloader<span class="token punctuation">:</span>
    batch <span class="token operator">=</span> <span class="token punctuation">{</span>k<span class="token punctuation">:</span> v<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span> <span class="token keyword">for</span> k<span class="token punctuation">,</span> v <span class="token keyword">in</span> batch<span class="token punctuation">.</span>items<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">}</span>
    <span class="token keyword">with</span> torch<span class="token punctuation">.</span>no_grad<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        outputs <span class="token operator">=</span> model<span class="token punctuation">(</span><span class="token operator">**</span>batch<span class="token punctuation">)</span>

    logits <span class="token operator">=</span> outputs<span class="token punctuation">.</span>logits
    predictions <span class="token operator">=</span> torch<span class="token punctuation">.</span>argmax<span class="token punctuation">(</span>logits<span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>
    metric<span class="token punctuation">.</span>add_batch<span class="token punctuation">(</span>predictions<span class="token operator">=</span>predictions<span class="token punctuation">,</span> references<span class="token operator">=</span>batch<span class="token punctuation">[</span><span class="token string">"labels"</span><span class="token punctuation">]</span><span class="token punctuation">)</span>

metric<span class="token punctuation">.</span>compute<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<h2 id="Distributed-training-with-🤗-Accelerate"><a href="#Distributed-training-with-🤗-Accelerate" class="headerlink" title="Distributed training with 🤗 Accelerate"></a>Distributed training with 🤗 Accelerate</h2><p>随着模型变得越来越大，并行性已经成为一种策略，可以在有限的硬件上训练更大的模型，并将训练速度提高几个数量级。在 Hugging Face，我们创建了<strong><a href="https://huggingface.co/docs/accelerate/index.html" target="_blank" rel="noopener">🤗 Accelerate</a></strong>库，以帮助用户轻松地在任何类型的分布式设置上训练 🤗 Transformers 模型，无论是一台机器上的多个 GPU 还是多台机器上的多个 GPU。</p>
<h3 id="Setup"><a href="#Setup" class="headerlink" title="Setup"></a><strong>Setup</strong></h3><p>Get started by installing 🤗 Accelerate:</p>
<pre><code>pip install accelerate</code></pre><p>Then import and create an <strong><code>[Accelerator](&lt;https://huggingface.co/docs/accelerate/accelerator.html#accelerate.Accelerator&gt;)</code></strong> object. <code>Accelerator</code> will automatically detect your type of distributed setup and initialize all the necessary components for training. You don’t need to explicitly place your model on a device.</p>
<pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">from</span> accelerate <span class="token keyword">import</span> Accelerator

accelerator <span class="token operator">=</span> Accelerator<span class="token punctuation">(</span><span class="token punctuation">)</span>

train_dataloader<span class="token punctuation">,</span> eval_dataloader<span class="token punctuation">,</span> model<span class="token punctuation">,</span> optimizer <span class="token operator">=</span> accelerator<span class="token punctuation">.</span>prepare<span class="token punctuation">(</span>
    train_dataloader<span class="token punctuation">,</span> eval_dataloader<span class="token punctuation">,</span> model<span class="token punctuation">,</span> optimizer
<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<h3 id="Backward"><a href="#Backward" class="headerlink" title="Backward"></a>Backward</h3><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">for</span> epoch <span class="token keyword">in</span> range<span class="token punctuation">(</span>num_epochs<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">for</span> batch <span class="token keyword">in</span> train_dataloader<span class="token punctuation">:</span>
        outputs <span class="token operator">=</span> model<span class="token punctuation">(</span><span class="token operator">**</span>batch<span class="token punctuation">)</span>
        loss <span class="token operator">=</span> outputs<span class="token punctuation">.</span>loss
        accelerator<span class="token punctuation">.</span>backward<span class="token punctuation">(</span>loss<span class="token punctuation">)</span>

        optimizer<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>
        lr_scheduler<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>
        optimizer<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>
        progress_bar<span class="token punctuation">.</span>update<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>As you can see in the following code, you only need to add four additional lines of code to your training loop to enable distributed training!</p>
<pre class="line-numbers language-python"><code class="language-python"><span class="token operator">+</span> <span class="token keyword">from</span> accelerate <span class="token keyword">import</span> Accelerator
  <span class="token keyword">from</span> transformers <span class="token keyword">import</span> AdamW<span class="token punctuation">,</span> AutoModelForSequenceClassification<span class="token punctuation">,</span> get_scheduler

<span class="token operator">+</span> accelerator <span class="token operator">=</span> Accelerator<span class="token punctuation">(</span><span class="token punctuation">)</span>

  model <span class="token operator">=</span> AutoModelForSequenceClassification<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span>checkpoint<span class="token punctuation">,</span> num_labels<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span>
  optimizer <span class="token operator">=</span> AdamW<span class="token punctuation">(</span>model<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> lr<span class="token operator">=</span><span class="token number">3e</span><span class="token operator">-</span><span class="token number">5</span><span class="token punctuation">)</span>

<span class="token operator">-</span> device <span class="token operator">=</span> torch<span class="token punctuation">.</span>device<span class="token punctuation">(</span><span class="token string">"cuda"</span><span class="token punctuation">)</span> <span class="token keyword">if</span> torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>is_available<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">else</span> torch<span class="token punctuation">.</span>device<span class="token punctuation">(</span><span class="token string">"cpu"</span><span class="token punctuation">)</span>
<span class="token operator">-</span> model<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>

<span class="token operator">+</span> train_dataloader<span class="token punctuation">,</span> eval_dataloader<span class="token punctuation">,</span> model<span class="token punctuation">,</span> optimizer <span class="token operator">=</span> accelerator<span class="token punctuation">.</span>prepare<span class="token punctuation">(</span>
<span class="token operator">+</span>     train_dataloader<span class="token punctuation">,</span> eval_dataloader<span class="token punctuation">,</span> model<span class="token punctuation">,</span> optimizer
<span class="token operator">+</span> <span class="token punctuation">)</span>

  num_epochs <span class="token operator">=</span> <span class="token number">3</span>
  num_training_steps <span class="token operator">=</span> num_epochs <span class="token operator">*</span> len<span class="token punctuation">(</span>train_dataloader<span class="token punctuation">)</span>
  lr_scheduler <span class="token operator">=</span> get_scheduler<span class="token punctuation">(</span>
      <span class="token string">"linear"</span><span class="token punctuation">,</span>
      optimizer<span class="token operator">=</span>optimizer<span class="token punctuation">,</span>
      num_warmup_steps<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">,</span>
      num_training_steps<span class="token operator">=</span>num_training_steps
  <span class="token punctuation">)</span>

  progress_bar <span class="token operator">=</span> tqdm<span class="token punctuation">(</span>range<span class="token punctuation">(</span>num_training_steps<span class="token punctuation">)</span><span class="token punctuation">)</span>

  model<span class="token punctuation">.</span>train<span class="token punctuation">(</span><span class="token punctuation">)</span>
  <span class="token keyword">for</span> epoch <span class="token keyword">in</span> range<span class="token punctuation">(</span>num_epochs<span class="token punctuation">)</span><span class="token punctuation">:</span>
      <span class="token keyword">for</span> batch <span class="token keyword">in</span> train_dataloader<span class="token punctuation">:</span>
<span class="token operator">-</span>         batch <span class="token operator">=</span> <span class="token punctuation">{</span>k<span class="token punctuation">:</span> v<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span> <span class="token keyword">for</span> k<span class="token punctuation">,</span> v <span class="token keyword">in</span> batch<span class="token punctuation">.</span>items<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">}</span>
          outputs <span class="token operator">=</span> model<span class="token punctuation">(</span><span class="token operator">**</span>batch<span class="token punctuation">)</span>
          loss <span class="token operator">=</span> outputs<span class="token punctuation">.</span>loss
<span class="token operator">-</span>         loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token operator">+</span>         accelerator<span class="token punctuation">.</span>backward<span class="token punctuation">(</span>loss<span class="token punctuation">)</span>

          optimizer<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>
          lr_scheduler<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>
          optimizer<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>
          progress_bar<span class="token punctuation">.</span>update<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<h3 id="Train-1"><a href="#Train-1" class="headerlink" title="Train"></a>Train</h3><pre class="line-numbers language-python"><code class="language-python">accelerate config

accelerate launch train<span class="token punctuation">.</span>py

<span class="token keyword">from</span> accelerate <span class="token keyword">import</span> notebook_launcher

notebook_launcher<span class="token punctuation">(</span>training_function<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<h2 id="Support-Models"><a href="#Support-Models" class="headerlink" title="Support Models"></a>Support Models</h2><h3 id="Supported-models"><a href="#Supported-models" class="headerlink" title="Supported models"></a><strong>Supported models</strong></h3><ol>
<li><strong><a href="https://huggingface.co/docs/transformers/model_doc/albert" target="_blank" rel="noopener">ALBERT</a></strong> (from Google Research and the Toyota Technological Institute at Chicago) released with the paper <strong><a href="https://arxiv.org/abs/1909.11942" target="_blank" rel="noopener">ALBERT: A Lite BERT for Self-supervised Learning of Language Representations</a></strong>, by Zhenzhong Lan, Mingda Chen, Sebastian Goodman, Kevin Gimpel, Piyush Sharma, Radu Soricut.</li>
<li><strong><a href="https://huggingface.co/docs/transformers/model_doc/bart" target="_blank" rel="noopener">BART</a></strong> (from Facebook) released with the paper <strong><a href="https://arxiv.org/abs/1910.13461" target="_blank" rel="noopener">BART: Denoising Sequence-to-Sequence Pre-training for Natural Language Generation, Translation, and Comprehension</a></strong> by Mike Lewis, Yinhan Liu, Naman Goyal, Marjan Ghazvininejad, Abdelrahman Mohamed, Omer Levy, Ves Stoyanov and Luke Zettlemoyer.</li>
<li><strong><a href="https://huggingface.co/docs/transformers/model_doc/barthez" target="_blank" rel="noopener">BARThez</a></strong> (from École polytechnique) released with the paper <strong><a href="https://arxiv.org/abs/2010.12321" target="_blank" rel="noopener">BARThez: a Skilled Pretrained French Sequence-to-Sequence Model</a></strong> by Moussa Kamal Eddine, Antoine J.-P. Tixier, Michalis Vazirgiannis.</li>
<li><strong><a href="https://huggingface.co/docs/transformers/model_doc/bartpho" target="_blank" rel="noopener">BARTpho</a></strong> (from VinAI Research) released with the paper <strong><a href="https://arxiv.org/abs/2109.09701" target="_blank" rel="noopener">BARTpho: Pre-trained Sequence-to-Sequence Models for Vietnamese</a></strong> by Nguyen Luong Tran, Duong Minh Le and Dat Quoc Nguyen.</li>
<li><strong><a href="https://huggingface.co/docs/transformers/model_doc/beit" target="_blank" rel="noopener">BEiT</a></strong> (from Microsoft) released with the paper <strong><a href="https://arxiv.org/abs/2106.08254" target="_blank" rel="noopener">BEiT: BERT Pre-Training of Image Transformers</a></strong> by Hangbo Bao, Li Dong, Furu Wei.</li>
<li><strong><a href="https://huggingface.co/docs/transformers/model_doc/bert" target="_blank" rel="noopener">BERT</a></strong> (from Google) released with the paper <strong><a href="https://arxiv.org/abs/1810.04805" target="_blank" rel="noopener">BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding</a></strong> by Jacob Devlin, Ming-Wei Chang, Kenton Lee and Kristina Toutanova.</li>
<li><strong><a href="https://huggingface.co/docs/transformers/model_doc/bertweet" target="_blank" rel="noopener">BERTweet</a></strong> (from VinAI Research) released with the paper <strong><a href="https://aclanthology.org/2020.emnlp-demos.2/" target="_blank" rel="noopener">BERTweet: A pre-trained language model for English Tweets</a></strong> by Dat Quoc Nguyen, Thanh Vu and Anh Tuan Nguyen.</li>
<li><strong><a href="https://huggingface.co/docs/transformers/model_doc/bert-generation" target="_blank" rel="noopener">BERT For Sequence Generation</a></strong> (from Google) released with the paper <strong><a href="https://arxiv.org/abs/1907.12461" target="_blank" rel="noopener">Leveraging Pre-trained Checkpoints for Sequence Generation Tasks</a></strong> by Sascha Rothe, Shashi Narayan, Aliaksei Severyn.</li>
<li><strong><a href="https://huggingface.co/docs/transformers/model_doc/big_bird" target="_blank" rel="noopener">BigBird-RoBERTa</a></strong> (from Google Research) released with the paper <strong><a href="https://arxiv.org/abs/2007.14062" target="_blank" rel="noopener">Big Bird: Transformers for Longer Sequences</a></strong> by Manzil Zaheer, Guru Guruganesh, Avinava Dubey, Joshua Ainslie, Chris Alberti, Santiago Ontanon, Philip Pham, Anirudh Ravula, Qifan Wang, Li Yang, Amr Ahmed.</li>
<li><strong><a href="https://huggingface.co/docs/transformers/model_doc/bigbird_pegasus" target="_blank" rel="noopener">BigBird-Pegasus</a></strong> (from Google Research) released with the paper <strong><a href="https://arxiv.org/abs/2007.14062" target="_blank" rel="noopener">Big Bird: Transformers for Longer Sequences</a></strong> by Manzil Zaheer, Guru Guruganesh, Avinava Dubey, Joshua Ainslie, Chris Alberti, Santiago Ontanon, Philip Pham, Anirudh Ravula, Qifan Wang, Li Yang, Amr Ahmed.</li>
<li><strong><a href="https://huggingface.co/docs/transformers/model_doc/blenderbot" target="_blank" rel="noopener">Blenderbot</a></strong> (from Facebook) released with the paper <strong><a href="https://arxiv.org/abs/2004.13637" target="_blank" rel="noopener">Recipes for building an open-domain chatbot</a></strong> by Stephen Roller, Emily Dinan, Naman Goyal, Da Ju, Mary Williamson, Yinhan Liu, Jing Xu, Myle Ott, Kurt Shuster, Eric M. Smith, Y-Lan Boureau, Jason Weston.</li>
<li><strong><a href="https://huggingface.co/docs/transformers/model_doc/blenderbot-small" target="_blank" rel="noopener">BlenderbotSmall</a></strong> (from Facebook) released with the paper <strong><a href="https://arxiv.org/abs/2004.13637" target="_blank" rel="noopener">Recipes for building an open-domain chatbot</a></strong> by Stephen Roller, Emily Dinan, Naman Goyal, Da Ju, Mary Williamson, Yinhan Liu, Jing Xu, Myle Ott, Kurt Shuster, Eric M. Smith, Y-Lan Boureau, Jason Weston.</li>
<li><strong><a href="https://huggingface.co/docs/transformers/model_doc/bort" target="_blank" rel="noopener">BORT</a></strong> (from Alexa) released with the paper <strong><a href="https://arxiv.org/abs/2010.10499" target="_blank" rel="noopener">Optimal Subarchitecture Extraction For BERT</a></strong> by Adrian de Wynter and Daniel J. Perry.</li>
<li><strong><a href="https://huggingface.co/docs/transformers/model_doc/byt5" target="_blank" rel="noopener">ByT5</a></strong> (from Google Research) released with the paper <strong><a href="https://arxiv.org/abs/2105.13626" target="_blank" rel="noopener">ByT5: Towards a token-free future with pre-trained byte-to-byte models</a></strong> by Linting Xue, Aditya Barua, Noah Constant, Rami Al-Rfou, Sharan Narang, Mihir Kale, Adam Roberts, Colin Raffel.</li>
<li><strong><a href="https://huggingface.co/docs/transformers/model_doc/camembert" target="_blank" rel="noopener">CamemBERT</a></strong> (from Inria/Facebook/Sorbonne) released with the paper <strong><a href="https://arxiv.org/abs/1911.03894" target="_blank" rel="noopener">CamemBERT: a Tasty French Language Model</a></strong> by Louis Martin<em>, Benjamin Muller</em>, Pedro Javier Ortiz Suárez*, Yoann Dupont, Laurent Romary, Éric Villemonte de la Clergerie, Djamé Seddah and Benoît Sagot.</li>
<li><strong><a href="https://huggingface.co/docs/transformers/model_doc/canine" target="_blank" rel="noopener">CANINE</a></strong> (from Google Research) released with the paper <strong><a href="https://arxiv.org/abs/2103.06874" target="_blank" rel="noopener">CANINE: Pre-training an Efficient Tokenization-Free Encoder for Language Representation</a></strong> by Jonathan H. Clark, Dan Garrette, Iulia Turc, John Wieting.</li>
<li><strong><a href="https://huggingface.co/docs/transformers/model_doc/convnext" target="_blank" rel="noopener">ConvNeXT</a></strong> (from Facebook AI) released with the paper <strong><a href="https://arxiv.org/abs/2201.03545" target="_blank" rel="noopener">A ConvNet for the 2020s</a></strong> by Zhuang Liu, Hanzi Mao, Chao-Yuan Wu, Christoph Feichtenhofer, Trevor Darrell, Saining Xie.</li>
<li><strong><a href="https://huggingface.co/docs/transformers/model_doc/clip" target="_blank" rel="noopener">CLIP</a></strong> (from OpenAI) released with the paper <strong><a href="https://arxiv.org/abs/2103.00020" target="_blank" rel="noopener">Learning Transferable Visual Models From Natural Language Supervision</a></strong> by Alec Radford, Jong Wook Kim, Chris Hallacy, Aditya Ramesh, Gabriel Goh, Sandhini Agarwal, Girish Sastry, Amanda Askell, Pamela Mishkin, Jack Clark, Gretchen Krueger, Ilya Sutskever.</li>
<li><strong><a href="https://huggingface.co/docs/transformers/model_doc/convbert" target="_blank" rel="noopener">ConvBERT</a></strong> (from YituTech) released with the paper <strong><a href="https://arxiv.org/abs/2008.02496" target="_blank" rel="noopener">ConvBERT: Improving BERT with Span-based Dynamic Convolution</a></strong> by Zihang Jiang, Weihao Yu, Daquan Zhou, Yunpeng Chen, Jiashi Feng, Shuicheng Yan.</li>
<li><strong><a href="https://huggingface.co/docs/transformers/model_doc/cpm" target="_blank" rel="noopener">CPM</a></strong> (from Tsinghua University) released with the paper <strong><a href="https://arxiv.org/abs/2012.00413" target="_blank" rel="noopener">CPM: A Large-scale Generative Chinese Pre-trained Language Model</a></strong> by Zhengyan Zhang, Xu Han, Hao Zhou, Pei Ke, Yuxian Gu, Deming Ye, Yujia Qin, Yusheng Su, Haozhe Ji, Jian Guan, Fanchao Qi, Xiaozhi Wang, Yanan Zheng, Guoyang Zeng, Huanqi Cao, Shengqi Chen, Daixuan Li, Zhenbo Sun, Zhiyuan Liu, Minlie Huang, Wentao Han, Jie Tang, Juanzi Li, Xiaoyan Zhu, Maosong Sun.</li>
<li><strong><a href="https://huggingface.co/docs/transformers/model_doc/ctrl" target="_blank" rel="noopener">CTRL</a></strong> (from Salesforce) released with the paper <strong><a href="https://arxiv.org/abs/1909.05858" target="_blank" rel="noopener">CTRL: A Conditional Transformer Language Model for Controllable Generation</a></strong> by Nitish Shirish Keskar<em>, Bryan McCann</em>, Lav R. Varshney, Caiming Xiong and Richard Socher.</li>
<li><strong><a href="https://huggingface.co/docs/transformers/model_doc/data2vec" target="_blank" rel="noopener">Data2Vec</a></strong> (from Facebook) released with the paper <strong><a href="https://arxiv.org/abs/2202.03555" target="_blank" rel="noopener">Data2Vec: A General Framework for Self-supervised Learning in Speech, Vision and Language</a></strong> by Alexei Baevski, Wei-Ning Hsu, Qiantong Xu, Arun Babu, Jiatao Gu, Michael Auli.</li>
<li><strong><a href="https://huggingface.co/docs/transformers/model_doc/deberta" target="_blank" rel="noopener">DeBERTa</a></strong> (from Microsoft) released with the paper <strong><a href="https://arxiv.org/abs/2006.03654" target="_blank" rel="noopener">DeBERTa: Decoding-enhanced BERT with Disentangled Attention</a></strong> by Pengcheng He, Xiaodong Liu, Jianfeng Gao, Weizhu Chen.</li>
<li><strong><a href="https://huggingface.co/docs/transformers/model_doc/deberta-v2" target="_blank" rel="noopener">DeBERTa-v2</a></strong> (from Microsoft) released with the paper <strong><a href="https://arxiv.org/abs/2006.03654" target="_blank" rel="noopener">DeBERTa: Decoding-enhanced BERT with Disentangled Attention</a></strong> by Pengcheng He, Xiaodong Liu, Jianfeng Gao, Weizhu Chen.</li>
<li><strong><a href="https://huggingface.co/docs/transformers/model_doc/deit" target="_blank" rel="noopener">DeiT</a></strong> (from Facebook) released with the paper <strong><a href="https://arxiv.org/abs/2012.12877" target="_blank" rel="noopener">Training data-efficient image transformers &amp; distillation through attention</a></strong> by Hugo Touvron, Matthieu Cord, Matthijs Douze, Francisco Massa, Alexandre Sablayrolles, Hervé Jégou.</li>
<li><strong><a href="https://huggingface.co/docs/transformers/model_doc/detr" target="_blank" rel="noopener">DETR</a></strong> (from Facebook) released with the paper <strong><a href="https://arxiv.org/abs/2005.12872" target="_blank" rel="noopener">End-to-End Object Detection with Transformers</a></strong> by Nicolas Carion, Francisco Massa, Gabriel Synnaeve, Nicolas Usunier, Alexander Kirillov, Sergey Zagoruyko.</li>
<li><strong><a href="https://huggingface.co/docs/transformers/model_doc/dialogpt" target="_blank" rel="noopener">DialoGPT</a></strong> (from Microsoft Research) released with the paper <strong><a href="https://arxiv.org/abs/1911.00536" target="_blank" rel="noopener">DialoGPT: Large-Scale Generative Pre-training for Conversational Response Generation</a></strong> by Yizhe Zhang, Siqi Sun, Michel Galley, Yen-Chun Chen, Chris Brockett, Xiang Gao, Jianfeng Gao, Jingjing Liu, Bill Dolan.</li>
<li><strong><a href="https://huggingface.co/docs/transformers/model_doc/distilbert" target="_blank" rel="noopener">DistilBERT</a></strong> (from HuggingFace), released together with the paper <strong><a href="https://arxiv.org/abs/1910.01108" target="_blank" rel="noopener">DistilBERT, a distilled version of BERT: smaller, faster, cheaper and lighter</a></strong> by Victor Sanh, Lysandre Debut and Thomas Wolf. The same method has been applied to compress GPT2 into <strong><a href="https://github.com/huggingface/transformers/tree/master/examples/research_projects/distillation" target="_blank" rel="noopener">DistilGPT2</a></strong>, RoBERTa into <strong><a href="https://github.com/huggingface/transformers/tree/master/examples/research_projects/distillation" target="_blank" rel="noopener">DistilRoBERTa</a></strong>, Multilingual BERT into <strong><a href="https://github.com/huggingface/transformers/tree/master/examples/research_projects/distillation" target="_blank" rel="noopener">DistilmBERT</a></strong> and a German version of DistilBERT.</li>
<li><strong><a href="https://huggingface.co/docs/transformers/model_doc/dpr" target="_blank" rel="noopener">DPR</a></strong> (from Facebook) released with the paper <strong><a href="https://arxiv.org/abs/2004.04906" target="_blank" rel="noopener">Dense Passage Retrieval for Open-Domain Question Answering</a></strong> by Vladimir Karpukhin, Barlas Oğuz, Sewon Min, Patrick Lewis, Ledell Wu, Sergey Edunov, Danqi Chen, and Wen-tau Yih.</li>
<li><strong><a href="https://huggingface.co/docs/transformers/model_doc/encoder-decoder" target="_blank" rel="noopener">EncoderDecoder</a></strong> (from Google Research) released with the paper <strong><a href="https://arxiv.org/abs/1907.12461" target="_blank" rel="noopener">Leveraging Pre-trained Checkpoints for Sequence Generation Tasks</a></strong> by Sascha Rothe, Shashi Narayan, Aliaksei Severyn.</li>
<li><strong><a href="https://huggingface.co/docs/transformers/model_doc/electra" target="_blank" rel="noopener">ELECTRA</a></strong> (from Google Research/Stanford University) released with the paper <strong><a href="https://arxiv.org/abs/2003.10555" target="_blank" rel="noopener">ELECTRA: Pre-training text encoders as discriminators rather than generators</a></strong> by Kevin Clark, Minh-Thang Luong, Quoc V. Le, Christopher D. Manning.</li>
<li><strong><a href="https://huggingface.co/docs/transformers/model_doc/flaubert" target="_blank" rel="noopener">FlauBERT</a></strong> (from CNRS) released with the paper <strong><a href="https://arxiv.org/abs/1912.05372" target="_blank" rel="noopener">FlauBERT: Unsupervised Language Model Pre-training for French</a></strong> by Hang Le, Loïc Vial, Jibril Frej, Vincent Segonne, Maximin Coavoux, Benjamin Lecouteux, Alexandre Allauzen, Benoît Crabbé, Laurent Besacier, Didier Schwab.</li>
<li><strong><a href="https://huggingface.co/docs/transformers/model_doc/fnet" target="_blank" rel="noopener">FNet</a></strong> (from Google Research) released with the paper <strong><a href="https://arxiv.org/abs/2105.03824" target="_blank" rel="noopener">FNet: Mixing Tokens with Fourier Transforms</a></strong> by James Lee-Thorp, Joshua Ainslie, Ilya Eckstein, Santiago Ontanon.</li>
<li><strong><a href="https://huggingface.co/docs/transformers/model_doc/funnel" target="_blank" rel="noopener">Funnel Transformer</a></strong> (from CMU/Google Brain) released with the paper <strong><a href="https://arxiv.org/abs/2006.03236" target="_blank" rel="noopener">Funnel-Transformer: Filtering out Sequential Redundancy for Efficient Language Processing</a></strong> by Zihang Dai, Guokun Lai, Yiming Yang, Quoc V. Le.</li>
<li><strong><a href="https://huggingface.co/docs/transformers/model_doc/openai-gpt" target="_blank" rel="noopener">GPT</a></strong> (from OpenAI) released with the paper <strong><a href="https://blog.openai.com/language-unsupervised/" target="_blank" rel="noopener">Improving Language Understanding by Generative Pre-Training</a></strong> by Alec Radford, Karthik Narasimhan, Tim Salimans and Ilya Sutskever.</li>
<li><strong><a href="https://huggingface.co/docs/transformers/model_doc/gpt2" target="_blank" rel="noopener">GPT-2</a></strong> (from OpenAI) released with the paper <strong><a href="https://blog.openai.com/better-language-models/" target="_blank" rel="noopener">Language Models are Unsupervised Multitask Learners</a></strong> by Alec Radford<em>, Jeffrey Wu</em>, Rewon Child, David Luan, Dario Amodei<strong>and Ilya Sutskever</strong>.</li>
<li><strong><a href="https://huggingface.co/docs/transformers/model_doc/gptj" target="_blank" rel="noopener">GPT-J</a></strong> (from EleutherAI) released in the repository <strong><a href="https://github.com/kingoflolz/mesh-transformer-jax/" target="_blank" rel="noopener">kingoflolz/mesh-transformer-jax</a></strong> by Ben Wang and Aran Komatsuzaki.</li>
<li><strong><a href="https://huggingface.co/docs/transformers/model_doc/gpt_neo" target="_blank" rel="noopener">GPT Neo</a></strong> (from EleutherAI) released in the repository <strong><a href="https://github.com/EleutherAI/gpt-neo" target="_blank" rel="noopener">EleutherAI/gpt-neo</a></strong> by Sid Black, Stella Biderman, Leo Gao, Phil Wang and Connor Leahy.</li>
<li><strong><a href="https://huggingface.co/docs/transformers/model_doc/hubert" target="_blank" rel="noopener">Hubert</a></strong> (from Facebook) released with the paper <strong><a href="https://arxiv.org/abs/2106.07447" target="_blank" rel="noopener">HuBERT: Self-Supervised Speech Representation Learning by Masked Prediction of Hidden Units</a></strong> by Wei-Ning Hsu, Benjamin Bolte, Yao-Hung Hubert Tsai, Kushal Lakhotia, Ruslan Salakhutdinov, Abdelrahman Mohamed.</li>
<li><strong><a href="https://huggingface.co/docs/transformers/model_doc/ibert" target="_blank" rel="noopener">I-BERT</a></strong> (from Berkeley) released with the paper <strong><a href="https://arxiv.org/abs/2101.01321" target="_blank" rel="noopener">I-BERT: Integer-only BERT Quantization</a></strong> by Sehoon Kim, Amir Gholami, Zhewei Yao, Michael W. Mahoney, Kurt Keutzer.</li>
<li><strong><a href="https://huggingface.co/docs/transformers/model_doc/imagegpt" target="_blank" rel="noopener">ImageGPT</a></strong> (from OpenAI) released with the paper <strong><a href="https://openai.com/blog/image-gpt/" target="_blank" rel="noopener">Generative Pretraining from Pixels</a></strong> by Mark Chen, Alec Radford, Rewon Child, Jeffrey Wu, Heewoo Jun, David Luan, Ilya Sutskever.</li>
<li><strong><a href="https://huggingface.co/docs/transformers/model_doc/layoutlm" target="_blank" rel="noopener">LayoutLM</a></strong> (from Microsoft Research Asia) released with the paper <strong><a href="https://arxiv.org/abs/1912.13318" target="_blank" rel="noopener">LayoutLM: Pre-training of Text and Layout for Document Image Understanding</a></strong> by Yiheng Xu, Minghao Li, Lei Cui, Shaohan Huang, Furu Wei, Ming Zhou.</li>
<li><strong><a href="https://huggingface.co/docs/transformers/model_doc/layoutlmv2" target="_blank" rel="noopener">LayoutLMv2</a></strong> (from Microsoft Research Asia) released with the paper <strong><a href="https://arxiv.org/abs/2012.14740" target="_blank" rel="noopener">LayoutLMv2: Multi-modal Pre-training for Visually-Rich Document Understanding</a></strong> by Yang Xu, Yiheng Xu, Tengchao Lv, Lei Cui, Furu Wei, Guoxin Wang, Yijuan Lu, Dinei Florencio, Cha Zhang, Wanxiang Che, Min Zhang, Lidong Zhou.</li>
<li><strong><a href="https://huggingface.co/docs/transformers/model_doc/layoutlmv2" target="_blank" rel="noopener">LayoutXLM</a></strong> (from Microsoft Research Asia) released with the paper <strong><a href="https://arxiv.org/abs/2104.08836" target="_blank" rel="noopener">LayoutXLM: Multimodal Pre-training for Multilingual Visually-rich Document Understanding</a></strong> by Yiheng Xu, Tengchao Lv, Lei Cui, Guoxin Wang, Yijuan Lu, Dinei Florencio, Cha Zhang, Furu Wei.</li>
<li><strong><a href="https://huggingface.co/docs/transformers/model_doc/led" target="_blank" rel="noopener">LED</a></strong> (from AllenAI) released with the paper <strong><a href="https://arxiv.org/abs/2004.05150" target="_blank" rel="noopener">Longformer: The Long-Document Transformer</a></strong> by Iz Beltagy, Matthew E. Peters, Arman Cohan.</li>
<li><strong><a href="https://huggingface.co/docs/transformers/model_doc/longformer" target="_blank" rel="noopener">Longformer</a></strong> (from AllenAI) released with the paper <strong><a href="https://arxiv.org/abs/2004.05150" target="_blank" rel="noopener">Longformer: The Long-Document Transformer</a></strong> by Iz Beltagy, Matthew E. Peters, Arman Cohan.</li>
<li><strong><a href="https://huggingface.co/docs/transformers/model_doc/luke" target="_blank" rel="noopener">LUKE</a></strong> (from Studio Ousia) released with the paper <strong><a href="https://arxiv.org/abs/2010.01057" target="_blank" rel="noopener">LUKE: Deep Contextualized Entity Representations with Entity-aware Self-attention</a></strong> by Ikuya Yamada, Akari Asai, Hiroyuki Shindo, Hideaki Takeda, Yuji Matsumoto.</li>
<li><strong><a href="https://huggingface.co/docs/transformers/model_doc/mluke" target="_blank" rel="noopener">mLUKE</a></strong> (from Studio Ousia) released with the paper <strong><a href="https://arxiv.org/abs/2110.08151" target="_blank" rel="noopener">mLUKE: The Power of Entity Representations in Multilingual Pretrained Language Models</a></strong> by Ryokan Ri, Ikuya Yamada, and Yoshimasa Tsuruoka.</li>
<li><strong><a href="https://huggingface.co/docs/transformers/model_doc/lxmert" target="_blank" rel="noopener">LXMERT</a></strong> (from UNC Chapel Hill) released with the paper <strong><a href="https://arxiv.org/abs/1908.07490" target="_blank" rel="noopener">LXMERT: Learning Cross-Modality Encoder Representations from Transformers for Open-Domain Question Answering</a></strong> by Hao Tan and Mohit Bansal.</li>
<li><strong><a href="https://huggingface.co/docs/transformers/model_doc/m2m_100" target="_blank" rel="noopener">M2M100</a></strong> (from Facebook) released with the paper <strong><a href="https://arxiv.org/abs/2010.11125" target="_blank" rel="noopener">Beyond English-Centric Multilingual Machine Translation</a></strong> by Angela Fan, Shruti Bhosale, Holger Schwenk, Zhiyi Ma, Ahmed El-Kishky, Siddharth Goyal, Mandeep Baines, Onur Celebi, Guillaume Wenzek, Vishrav Chaudhary, Naman Goyal, Tom Birch, Vitaliy Liptchinsky, Sergey Edunov, Edouard Grave, Michael Auli, Armand Joulin.</li>
<li><strong><a href="https://huggingface.co/docs/transformers/model_doc/marian" target="_blank" rel="noopener">MarianMT</a></strong> Machine translation models trained using <strong><a href="http://opus.nlpl.eu/" target="_blank" rel="noopener">OPUS</a></strong> data by Jörg Tiedemann. The <strong><a href="https://marian-nmt.github.io/" target="_blank" rel="noopener">Marian Framework</a></strong> is being developed by the Microsoft Translator Team.</li>
<li><strong><a href="https://huggingface.co/docs/transformers/model_doc/maskformer" target="_blank" rel="noopener">MaskFormer</a></strong> (from Meta and UIUC) released with the paper <strong><a href="https://arxiv.org/abs/2107.06278" target="_blank" rel="noopener">Per-Pixel Classification is Not All You Need for Semantic Segmentation</a></strong> by Bowen Cheng, Alexander G. Schwing, Alexander Kirillov.</li>
<li><strong><a href="https://huggingface.co/docs/transformers/model_doc/mbart" target="_blank" rel="noopener">MBart</a></strong> (from Facebook) released with the paper <strong><a href="https://arxiv.org/abs/2001.08210" target="_blank" rel="noopener">Multilingual Denoising Pre-training for Neural Machine Translation</a></strong> by Yinhan Liu, Jiatao Gu, Naman Goyal, Xian Li, Sergey Edunov, Marjan Ghazvininejad, Mike Lewis, Luke Zettlemoyer.</li>
<li><strong><a href="https://huggingface.co/docs/transformers/model_doc/mbart" target="_blank" rel="noopener">MBart-50</a></strong> (from Facebook) released with the paper <strong><a href="https://arxiv.org/abs/2008.00401" target="_blank" rel="noopener">Multilingual Translation with Extensible Multilingual Pretraining and Finetuning</a></strong> by Yuqing Tang, Chau Tran, Xian Li, Peng-Jen Chen, Naman Goyal, Vishrav Chaudhary, Jiatao Gu, Angela Fan.</li>
<li><strong><a href="https://huggingface.co/docs/transformers/model_doc/megatron-bert" target="_blank" rel="noopener">Megatron-BERT</a></strong> (from NVIDIA) released with the paper <strong><a href="https://arxiv.org/abs/1909.08053" target="_blank" rel="noopener">Megatron-LM: Training Multi-Billion Parameter Language Models Using Model Parallelism</a></strong> by Mohammad Shoeybi, Mostofa Patwary, Raul Puri, Patrick LeGresley, Jared Casper and Bryan Catanzaro.</li>
<li><strong><a href="https://huggingface.co/docs/transformers/model_doc/megatron_gpt2" target="_blank" rel="noopener">Megatron-GPT2</a></strong> (from NVIDIA) released with the paper <strong><a href="https://arxiv.org/abs/1909.08053" target="_blank" rel="noopener">Megatron-LM: Training Multi-Billion Parameter Language Models Using Model Parallelism</a></strong> by Mohammad Shoeybi, Mostofa Patwary, Raul Puri, Patrick LeGresley, Jared Casper and Bryan Catanzaro.</li>
<li><strong><a href="https://huggingface.co/docs/transformers/model_doc/mpnet" target="_blank" rel="noopener">MPNet</a></strong> (from Microsoft Research) released with the paper <strong><a href="https://arxiv.org/abs/2004.09297" target="_blank" rel="noopener">MPNet: Masked and Permuted Pre-training for Language Understanding</a></strong> by Kaitao Song, Xu Tan, Tao Qin, Jianfeng Lu, Tie-Yan Liu.</li>
<li><strong><a href="https://huggingface.co/docs/transformers/model_doc/mt5" target="_blank" rel="noopener">MT5</a></strong> (from Google AI) released with the paper <strong><a href="https://arxiv.org/abs/2010.11934" target="_blank" rel="noopener">mT5: A massively multilingual pre-trained text-to-text transformer</a></strong> by Linting Xue, Noah Constant, Adam Roberts, Mihir Kale, Rami Al-Rfou, Aditya Siddhant, Aditya Barua, Colin Raffel.</li>
<li><strong><a href="https://huggingface.co/docs/transformers/model_doc/nystromformer" target="_blank" rel="noopener">Nyströmformer</a></strong> (from the University of Wisconsin - Madison) released with the paper <strong><a href="https://arxiv.org/abs/2102.03902" target="_blank" rel="noopener">Nyströmformer: A Nyström-Based Algorithm for Approximating Self-Attention</a></strong> by Yunyang Xiong, Zhanpeng Zeng, Rudrasis Chakraborty, Mingxing Tan, Glenn Fung, Yin Li, Vikas Singh.</li>
<li><strong><a href="https://huggingface.co/docs/transformers/model_doc/pegasus" target="_blank" rel="noopener">Pegasus</a></strong> (from Google) released with the paper <strong><a href="https://arxiv.org/abs/1912.08777" target="_blank" rel="noopener">PEGASUS: Pre-training with Extracted Gap-sentences for Abstractive Summarization</a></strong> by Jingqing Zhang, Yao Zhao, Mohammad Saleh and Peter J. Liu.</li>
<li><strong><a href="https://huggingface.co/docs/transformers/model_doc/perceiver" target="_blank" rel="noopener">Perceiver IO</a></strong> (from Deepmind) released with the paper <strong><a href="https://arxiv.org/abs/2107.14795" target="_blank" rel="noopener">Perceiver IO: A General Architecture for Structured Inputs &amp; Outputs</a></strong> by Andrew Jaegle, Sebastian Borgeaud, Jean-Baptiste Alayrac, Carl Doersch, Catalin Ionescu, David Ding, Skanda Koppula, Daniel Zoran, Andrew Brock, Evan Shelhamer, Olivier Hénaff, Matthew M. Botvinick, Andrew Zisserman, Oriol Vinyals, João Carreira.</li>
<li><strong><a href="https://huggingface.co/docs/transformers/model_doc/phobert" target="_blank" rel="noopener">PhoBERT</a></strong> (from VinAI Research) released with the paper <strong><a href="https://www.aclweb.org/anthology/2020.findings-emnlp.92/" target="_blank" rel="noopener">PhoBERT: Pre-trained language models for Vietnamese</a></strong> by Dat Quoc Nguyen and Anh Tuan Nguyen.</li>
<li><strong><a href="https://huggingface.co/docs/transformers/model_doc/plbart" target="_blank" rel="noopener">PLBart</a></strong> (from UCLA NLP) released with the paper <strong><a href="https://arxiv.org/abs/2103.06333" target="_blank" rel="noopener">Unified Pre-training for Program Understanding and Generation</a></strong> by Wasi Uddin Ahmad, Saikat Chakraborty, Baishakhi Ray, Kai-Wei Chang.</li>
<li><strong><a href="https://huggingface.co/docs/transformers/model_doc/poolformer" target="_blank" rel="noopener">PoolFormer</a></strong> (from Sea AI Labs) released with the paper <strong><a href="https://arxiv.org/abs/2111.11418" target="_blank" rel="noopener">MetaFormer is Actually What You Need for Vision</a></strong> by Yu, Weihao and Luo, Mi and Zhou, Pan and Si, Chenyang and Zhou, Yichen and Wang, Xinchao and Feng, Jiashi and Yan, Shuicheng.</li>
<li><strong><a href="https://huggingface.co/docs/transformers/model_doc/prophetnet" target="_blank" rel="noopener">ProphetNet</a></strong> (from Microsoft Research) released with the paper <strong><a href="https://arxiv.org/abs/2001.04063" target="_blank" rel="noopener">ProphetNet: Predicting Future N-gram for Sequence-to-Sequence Pre-training</a></strong> by Yu Yan, Weizhen Qi, Yeyun Gong, Dayiheng Liu, Nan Duan, Jiusheng Chen, Ruofei Zhang and Ming Zhou.</li>
<li><strong><a href="https://huggingface.co/docs/transformers/model_doc/qdqbert" target="_blank" rel="noopener">QDQBert</a></strong> (from NVIDIA) released with the paper <strong><a href="https://arxiv.org/abs/2004.09602" target="_blank" rel="noopener">Integer Quantization for Deep Learning Inference: Principles and Empirical Evaluation</a></strong> by Hao Wu, Patrick Judd, Xiaojie Zhang, Mikhail Isaev and Paulius Micikevicius.</li>
<li><strong><a href="https://huggingface.co/transformers/model_doc/realm.html" target="_blank" rel="noopener">REALM</a></strong> (from Google Research) released with the paper <strong><a href="https://arxiv.org/abs/2002.08909" target="_blank" rel="noopener">REALM: Retrieval-Augmented Language Model Pre-Training</a></strong> by Kelvin Guu, Kenton Lee, Zora Tung, Panupong Pasupat and Ming-Wei Chang.</li>
<li><strong><a href="https://huggingface.co/docs/transformers/model_doc/reformer" target="_blank" rel="noopener">Reformer</a></strong> (from Google Research) released with the paper <strong><a href="https://arxiv.org/abs/2001.04451" target="_blank" rel="noopener">Reformer: The Efficient Transformer</a></strong> by Nikita Kitaev, Łukasz Kaiser, Anselm Levskaya.</li>
<li><strong><a href="https://huggingface.co/docs/transformers/model_doc/rembert" target="_blank" rel="noopener">RemBERT</a></strong> (from Google Research) released with the paper <strong><a href="https://arxiv.org/abs/2010.12821" target="_blank" rel="noopener">Rethinking embedding coupling in pre-trained language models</a></strong> by Hyung Won Chung, Thibault Févry, Henry Tsai, M. Johnson, Sebastian Ruder.</li>
<li><strong><a href="https://huggingface.co/docs/transformers/model_doc/roberta" target="_blank" rel="noopener">RoBERTa</a></strong> (from Facebook), released together with the paper <strong><a href="https://arxiv.org/abs/1907.11692" target="_blank" rel="noopener">RoBERTa: A Robustly Optimized BERT Pretraining Approach</a></strong> by Yinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Mandar Joshi, Danqi Chen, Omer Levy, Mike Lewis, Luke Zettlemoyer, Veselin Stoyanov.</li>
<li><strong><a href="https://huggingface.co/docs/transformers/model_doc/roformer" target="_blank" rel="noopener">RoFormer</a></strong> (from ZhuiyiTechnology), released together with the paper <strong><a href="https://arxiv.org/abs/2104.09864" target="_blank" rel="noopener">RoFormer: Enhanced Transformer with Rotary Position Embedding</a></strong> by Jianlin Su and Yu Lu and Shengfeng Pan and Bo Wen and Yunfeng Liu.</li>
<li><strong><a href="https://huggingface.co/docs/transformers/model_doc/segformer" target="_blank" rel="noopener">SegFormer</a></strong> (from NVIDIA) released with the paper <strong><a href="https://arxiv.org/abs/2105.15203" target="_blank" rel="noopener">SegFormer: Simple and Efficient Design for Semantic Segmentation with Transformers</a></strong> by Enze Xie, Wenhai Wang, Zhiding Yu, Anima Anandkumar, Jose M. Alvarez, Ping Luo.</li>
<li><strong><a href="https://huggingface.co/docs/transformers/model_doc/sew" target="_blank" rel="noopener">SEW</a></strong> (from ASAPP) released with the paper <strong><a href="https://arxiv.org/abs/2109.06870" target="_blank" rel="noopener">Performance-Efficiency Trade-offs in Unsupervised Pre-training for Speech Recognition</a></strong> by Felix Wu, Kwangyoun Kim, Jing Pan, Kyu Han, Kilian Q. Weinberger, Yoav Artzi.</li>
<li><strong><a href="https://huggingface.co/docs/transformers/model_doc/sew_d" target="_blank" rel="noopener">SEW-D</a></strong> (from ASAPP) released with the paper <strong><a href="https://arxiv.org/abs/2109.06870" target="_blank" rel="noopener">Performance-Efficiency Trade-offs in Unsupervised Pre-training for Speech Recognition</a></strong> by Felix Wu, Kwangyoun Kim, Jing Pan, Kyu Han, Kilian Q. Weinberger, Yoav Artzi.</li>
<li><strong><a href="https://huggingface.co/docs/transformers/model_doc/speech_to_text" target="_blank" rel="noopener">SpeechToTextTransformer</a></strong> (from Facebook), released together with the paper <strong><a href="https://arxiv.org/abs/2010.05171" target="_blank" rel="noopener">fairseq S2T: Fast Speech-to-Text Modeling with fairseq</a></strong> by Changhan Wang, Yun Tang, Xutai Ma, Anne Wu, Dmytro Okhonko, Juan Pino.</li>
<li><strong><a href="https://huggingface.co/docs/transformers/model_doc/speech_to_text_2" target="_blank" rel="noopener">SpeechToTextTransformer2</a></strong> (from Facebook), released together with the paper <strong><a href="https://arxiv.org/abs/2104.06678" target="_blank" rel="noopener">Large-Scale Self- and Semi-Supervised Learning for Speech Translation</a></strong> by Changhan Wang, Anne Wu, Juan Pino, Alexei Baevski, Michael Auli, Alexis Conneau.</li>
<li><strong><a href="https://huggingface.co/docs/transformers/model_doc/splinter" target="_blank" rel="noopener">Splinter</a></strong> (from Tel Aviv University), released together with the paper <strong><a href="https://arxiv.org/abs/2101.00438" target="_blank" rel="noopener">Few-Shot Question Answering by Pretraining Span Selection</a></strong> by Ori Ram, Yuval Kirstain, Jonathan Berant, Amir Globerson, Omer Levy.</li>
<li><strong><a href="https://huggingface.co/docs/transformers/model_doc/squeezebert" target="_blank" rel="noopener">SqueezeBert</a></strong> (from Berkeley) released with the paper <strong><a href="https://arxiv.org/abs/2006.11316" target="_blank" rel="noopener">SqueezeBERT: What can computer vision teach NLP about efficient neural networks?</a></strong> by Forrest N. Iandola, Albert E. Shaw, Ravi Krishna, and Kurt W. Keutzer.</li>
<li><strong><a href="https://huggingface.co/docs/transformers/model_doc/swin" target="_blank" rel="noopener">Swin Transformer</a></strong> (from Microsoft) released with the paper <strong><a href="https://arxiv.org/abs/2103.14030" target="_blank" rel="noopener">Swin Transformer: Hierarchical Vision Transformer using Shifted Windows</a></strong> by Ze Liu, Yutong Lin, Yue Cao, Han Hu, Yixuan Wei, Zheng Zhang, Stephen Lin, Baining Guo.</li>
<li><strong><a href="https://huggingface.co/docs/transformers/model_doc/t5" target="_blank" rel="noopener">T5</a></strong> (from Google AI) released with the paper <strong><a href="https://arxiv.org/abs/1910.10683" target="_blank" rel="noopener">Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer</a></strong> by Colin Raffel and Noam Shazeer and Adam Roberts and Katherine Lee and Sharan Narang and Michael Matena and Yanqi Zhou and Wei Li and Peter J. Liu.</li>
<li><strong><a href="https://huggingface.co/docs/transformers/model_doc/t5v1.1" target="_blank" rel="noopener">T5v1.1</a></strong> (from Google AI) released in the repository <strong><a href="https://github.com/google-research/text-to-text-transfer-transformer/blob/main/released_checkpoints.md#t511" target="_blank" rel="noopener">google-research/text-to-text-transfer-transformer</a></strong> by Colin Raffel and Noam Shazeer and Adam Roberts and Katherine Lee and Sharan Narang and Michael Matena and Yanqi Zhou and Wei Li and Peter J. Liu.</li>
<li><strong><a href="https://huggingface.co/docs/transformers/model_doc/tapas" target="_blank" rel="noopener">TAPAS</a></strong> (from Google AI) released with the paper <strong><a href="https://arxiv.org/abs/2004.02349" target="_blank" rel="noopener">TAPAS: Weakly Supervised Table Parsing via Pre-training</a></strong> by Jonathan Herzig, Paweł Krzysztof Nowak, Thomas Müller, Francesco Piccinno and Julian Martin Eisenschlos.</li>
<li><strong><a href="https://huggingface.co/docs/transformers/model_doc/transfo-xl" target="_blank" rel="noopener">Transformer-XL</a></strong> (from Google/CMU) released with the paper <strong><a href="https://arxiv.org/abs/1901.02860" target="_blank" rel="noopener">Transformer-XL: Attentive Language Models Beyond a Fixed-Length Context</a></strong> by Zihang Dai<em>, Zhilin Yang</em>, Yiming Yang, Jaime Carbonell, Quoc V. Le, Ruslan Salakhutdinov.</li>
<li><strong><a href="https://huggingface.co/docs/transformers/model_doc/trocr" target="_blank" rel="noopener">TrOCR</a></strong> (from Microsoft), released together with the paper <strong><a href="https://arxiv.org/abs/2109.10282" target="_blank" rel="noopener">TrOCR: Transformer-based Optical Character Recognition with Pre-trained Models</a></strong> by Minghao Li, Tengchao Lv, Lei Cui, Yijuan Lu, Dinei Florencio, Cha Zhang, Zhoujun Li, Furu Wei.</li>
<li><strong><a href="https://huggingface.co/docs/transformers/model_doc/unispeech" target="_blank" rel="noopener">UniSpeech</a></strong> (from Microsoft Research) released with the paper <strong><a href="https://arxiv.org/abs/2101.07597" target="_blank" rel="noopener">UniSpeech: Unified Speech Representation Learning with Labeled and Unlabeled Data</a></strong> by Chengyi Wang, Yu Wu, Yao Qian, Kenichi Kumatani, Shujie Liu, Furu Wei, Michael Zeng, Xuedong Huang.</li>
<li><strong><a href="https://huggingface.co/docs/transformers/model_doc/unispeech-sat" target="_blank" rel="noopener">UniSpeechSat</a></strong> (from Microsoft Research) released with the paper <strong><a href="https://arxiv.org/abs/2110.05752" target="_blank" rel="noopener">UNISPEECH-SAT: UNIVERSAL SPEECH REPRESENTATION LEARNING WITH SPEAKER AWARE PRE-TRAINING</a></strong> by Sanyuan Chen, Yu Wu, Chengyi Wang, Zhengyang Chen, Zhuo Chen, Shujie Liu, Jian Wu, Yao Qian, Furu Wei, Jinyu Li, Xiangzhan Yu.</li>
<li><strong><a href="https://huggingface.co/docs/transformers/model_doc/vilt" target="_blank" rel="noopener">ViLT</a></strong> (from NAVER AI Lab/Kakao Enterprise/Kakao Brain) released with the paper <strong><a href="https://arxiv.org/abs/2102.03334" target="_blank" rel="noopener">ViLT: Vision-and-Language Transformer Without Convolution or Region Supervision</a></strong> by Wonjae Kim, Bokyung Son, Ildoo Kim.</li>
<li><strong><a href="https://huggingface.co/docs/transformers/model_doc/vit" target="_blank" rel="noopener">Vision Transformer (ViT)</a></strong> (from Google AI) released with the paper <strong><a href="https://arxiv.org/abs/2010.11929" target="_blank" rel="noopener">An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale</a></strong> by Alexey Dosovitskiy, Lucas Beyer, Alexander Kolesnikov, Dirk Weissenborn, Xiaohua Zhai, Thomas Unterthiner, Mostafa Dehghani, Matthias Minderer, Georg Heigold, Sylvain Gelly, Jakob Uszkoreit, Neil Houlsby.</li>
<li><strong><a href="https://huggingface.co/docs/transformers/model_doc/vit_mae" target="_blank" rel="noopener">ViTMAE</a></strong> (from Meta AI) released with the paper <strong><a href="https://arxiv.org/abs/2111.06377" target="_blank" rel="noopener">Masked Autoencoders Are Scalable Vision Learners</a></strong> by Kaiming He, Xinlei Chen, Saining Xie, Yanghao Li, Piotr Dollár, Ross Girshick.</li>
<li><strong><a href="https://huggingface.co/docs/transformers/model_doc/visual_bert" target="_blank" rel="noopener">VisualBERT</a></strong> (from UCLA NLP) released with the paper <strong><a href="https://arxiv.org/pdf/1908.03557" target="_blank" rel="noopener">VisualBERT: A Simple and Performant Baseline for Vision and Language</a></strong> by Liunian Harold Li, Mark Yatskar, Da Yin, Cho-Jui Hsieh, Kai-Wei Chang.</li>
<li><strong><a href="https://huggingface.co/docs/transformers/model_doc/wavlm" target="_blank" rel="noopener">WavLM</a></strong> (from Microsoft Research) released with the paper <strong><a href="https://arxiv.org/abs/2110.13900" target="_blank" rel="noopener">WavLM: Large-Scale Self-Supervised Pre-Training for Full Stack Speech Processing</a></strong> by Sanyuan Chen, Chengyi Wang, Zhengyang Chen, Yu Wu, Shujie Liu, Zhuo Chen, Jinyu Li, Naoyuki Kanda, Takuya Yoshioka, Xiong Xiao, Jian Wu, Long Zhou, Shuo Ren, Yanmin Qian, Yao Qian, Jian Wu, Michael Zeng, Furu Wei.</li>
<li><strong><a href="https://huggingface.co/docs/transformers/model_doc/wav2vec2" target="_blank" rel="noopener">Wav2Vec2</a></strong> (from Facebook AI) released with the paper <strong><a href="https://arxiv.org/abs/2006.11477" target="_blank" rel="noopener">wav2vec 2.0: A Framework for Self-Supervised Learning of Speech Representations</a></strong> by Alexei Baevski, Henry Zhou, Abdelrahman Mohamed, Michael Auli.</li>
<li><strong><a href="https://huggingface.co/docs/master/transformers/model_doc/wav2vec2_phoneme" target="_blank" rel="noopener">Wav2Vec2Phoneme</a></strong> (from Facebook AI) released with the paper <strong><a href="https://arxiv.org/abs/2109.11680" target="_blank" rel="noopener">Simple and Effective Zero-shot Cross-lingual Phoneme Recognition</a></strong> by Qiantong Xu, Alexei Baevski, Michael Auli.</li>
<li><strong><a href="https://huggingface.co/docs/master/transformers/model_doc/xglm" target="_blank" rel="noopener">XGLM</a></strong> (From Facebook AI) released with the paper <strong><a href="https://arxiv.org/abs/2112.10668" target="_blank" rel="noopener">Few-shot Learning with Multilingual Language Models</a></strong> by Xi Victoria Lin, Todor Mihaylov, Mikel Artetxe, Tianlu Wang, Shuohui Chen, Daniel Simig, Myle Ott, Naman Goyal, Shruti Bhosale, Jingfei Du, Ramakanth Pasunuru, Sam Shleifer, Punit Singh Koura, Vishrav Chaudhary, Brian O’Horo, Jeff Wang, Luke Zettlemoyer, Zornitsa Kozareva, Mona Diab, Veselin Stoyanov, Xian Li.</li>
<li><strong><a href="https://huggingface.co/docs/transformers/model_doc/xlm" target="_blank" rel="noopener">XLM</a></strong> (from Facebook) released together with the paper <strong><a href="https://arxiv.org/abs/1901.07291" target="_blank" rel="noopener">Cross-lingual Language Model Pretraining</a></strong> by Guillaume Lample and Alexis Conneau.</li>
<li><strong><a href="https://huggingface.co/docs/transformers/model_doc/xlm-prophetnet" target="_blank" rel="noopener">XLM-ProphetNet</a></strong> (from Microsoft Research) released with the paper <strong><a href="https://arxiv.org/abs/2001.04063" target="_blank" rel="noopener">ProphetNet: Predicting Future N-gram for Sequence-to-Sequence Pre-training</a></strong> by Yu Yan, Weizhen Qi, Yeyun Gong, Dayiheng Liu, Nan Duan, Jiusheng Chen, Ruofei Zhang and Ming Zhou.</li>
<li><strong><a href="https://huggingface.co/docs/transformers/model_doc/xlm-roberta" target="_blank" rel="noopener">XLM-RoBERTa</a></strong> (from Facebook AI), released together with the paper <strong><a href="https://arxiv.org/abs/1911.02116" target="_blank" rel="noopener">Unsupervised Cross-lingual Representation Learning at Scale</a></strong> by Alexis Conneau<em>, Kartikay Khandelwal</em>, Naman Goyal, Vishrav Chaudhary, Guillaume Wenzek, Francisco Guzmán, Edouard Grave, Myle Ott, Luke Zettlemoyer and Veselin Stoyanov.</li>
<li><strong><a href="https://huggingface.co/docs/transformers/model_doc/xlm-roberta-xl" target="_blank" rel="noopener">XLM-RoBERTa-XL</a></strong> (from Facebook AI), released together with the paper <strong><a href="https://arxiv.org/abs/2105.00572" target="_blank" rel="noopener">Larger-Scale Transformers for Multilingual Masked Language Modeling</a></strong> by Naman Goyal, Jingfei Du, Myle Ott, Giri Anantharaman, Alexis Conneau.</li>
<li><strong><a href="https://huggingface.co/docs/transformers/model_doc/xlnet" target="_blank" rel="noopener">XLNet</a></strong> (from Google/CMU) released with the paper <strong><a href="https://arxiv.org/abs/1906.08237" target="_blank" rel="noopener">XLNet: Generalized Autoregressive Pretraining for Language Understanding</a></strong> by Zhilin Yang<em>, Zihang Dai</em>, Yiming Yang, Jaime Carbonell, Ruslan Salakhutdinov, Quoc V. Le.</li>
<li><strong><a href="https://huggingface.co/docs/transformers/model_doc/xlsr_wav2vec2" target="_blank" rel="noopener">XLSR-Wav2Vec2</a></strong> (from Facebook AI) released with the paper <strong><a href="https://arxiv.org/abs/2006.13979" target="_blank" rel="noopener">Unsupervised Cross-Lingual Representation Learning For Speech Recognition</a></strong> by Alexis Conneau, Alexei Baevski, Ronan Collobert, Abdelrahman Mohamed, Michael Auli.</li>
<li><strong><a href="https://huggingface.co/docs/master/transformers/model_doc/xls_r" target="_blank" rel="noopener">XLS-R</a></strong> (from Facebook AI) released with the paper <strong><a href="https://arxiv.org/abs/2111.09296" target="_blank" rel="noopener">XLS-R: Self-supervised Cross-lingual Speech Representation Learning at Scale</a></strong> by Arun Babu, Changhan Wang, Andros Tjandra, Kushal Lakhotia, Qiantong Xu, Naman Goyal, Kritika Singh, Patrick von Platen, Yatharth Saraf, Juan Pino, Alexei Baevski, Alexis Conneau, Michael Auli.</li>
<li><strong><a href="https://huggingface.co/docs/transformers/model_doc/yoso" target="_blank" rel="noopener">YOSO</a></strong> (from the University of Wisconsin - Madison) released with the paper <strong><a href="https://arxiv.org/abs/2111.09714" target="_blank" rel="noopener">You Only Sample (Almost) Once: Linear Cost Self-Attention Via Bernoulli Sampling</a></strong> by Zhanpeng Zeng, Yunyang Xiong, Sathya N. Ravi, Shailesh Acharya, Glenn Fung, Vikas Singh.</li>
</ol>
<h3 id="Supported-frameworks"><a href="#Supported-frameworks" class="headerlink" title="Supported frameworks"></a><strong>Supported frameworks</strong></h3><p>The table below represents the current support in the library for each of those models, whether they have a Python tokenizer (called “slow”). A “fast” tokenizer backed by the 🤗 Tokenizers library, whether they have support in Jax (via Flax), PyTorch, and/or TensorFlow.</p>
<p><a href="https://www.notion.so/9168cdd0e2f147428b1cb1ae27d0a42c" target="_blank" rel="noopener">模型对比</a></p>
<h1 id="👇Downstream-Tasks"><a href="#👇Downstream-Tasks" class="headerlink" title="👇Downstream Tasks"></a>👇Downstream Tasks</h1><h1 id="Text-classification"><a href="#Text-classification" class="headerlink" title="Text classification"></a>Text classification</h1><p>文本分类是一种常见的 NLP 任务，它为文本分配标签或类别。当今一些最大的公司在生产中广泛使用文本分类的许多实际应用。最流行的文本分类形式之一是情感分析，它为文本序列分配正面、负面或中性的标签。</p>
<h2 id="Load-IMDb-dataset"><a href="#Load-IMDb-dataset" class="headerlink" title="Load IMDb dataset"></a><strong>Load IMDb dataset</strong></h2><p>Load the IMDb dataset from the 🤗 Datasets library:</p>
<pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">from</span> datasets <span class="token keyword">import</span> load_dataset

imdb <span class="token operator">=</span> load_dataset<span class="token punctuation">(</span><span class="token string">"imdb"</span><span class="token punctuation">)</span>
imdb<span class="token punctuation">[</span><span class="token string">"test"</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>

<span class="token punctuation">{</span>
    <span class="token string">"label"</span><span class="token punctuation">:</span> <span class="token number">0</span><span class="token punctuation">,</span>
    <span class="token string">"text"</span><span class="token punctuation">:</span> <span class="token string">"I love sci-fi and am willing to put up with a lot. Sci-fi movies/TV are usually underfunded, under-appreciated and misunderstood. I tried to like this, I really did, but it is to good TV sci-fi as Babylon 5 is to Star Trek (the original). Silly prosthetics, cheap cardboard sets, stilted dialogues, CG that doesn't match the background, and painfully one-dimensional characters cannot be overcome with a 'sci-fi' setting. (I'm sure there are those of you out there who think Babylon 5 is good sci-fi TV. It's not. It's clichéd and uninspiring.) While US viewers might like emotion and character development, sci-fi is a genre that does not take itself seriously (cf. Star Trek). It may treat important issues, yet not as a serious philosophy. It's really difficult to care about the characters here as they are not simply foolish, just missing a spark of life. Their actions and reactions are wooden and predictable, often painful to watch. The makers of Earth KNOW it's rubbish as they have to always say \\"</span>Gene Roddenberry<span class="token string">'s Earth...\\" otherwise people would not continue watching. Roddenberry'</span>s ashes must be turning <span class="token keyword">in</span> their orbit <span class="token keyword">as</span> this dull<span class="token punctuation">,</span> cheap<span class="token punctuation">,</span> poorly edited <span class="token punctuation">(</span>watching it without advert breaks really brings this home<span class="token punctuation">)</span> trudging Trabant of a show lumbers into space<span class="token punctuation">.</span> Spoiler<span class="token punctuation">.</span> So<span class="token punctuation">,</span> kill off a main character<span class="token punctuation">.</span> And then bring him back <span class="token keyword">as</span> another actor<span class="token punctuation">.</span> Jeeez! Dallas all over again<span class="token punctuation">.</span>"<span class="token punctuation">,</span>
<span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>There are two fields in this dataset:</p>
<ul>
<li><code>text</code>: a string containing the text of the movie review.</li>
<li><code>label</code>: a value that can either be <code>0</code> for a negative review or <code>1</code> for a positive review.</li>
</ul>
<h2 id="Preprocess"><a href="#Preprocess" class="headerlink" title="Preprocess"></a><strong>Preprocess</strong></h2><p>Load the DistilBERT tokenizer to process the <code>text</code> field:</p>
<pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">from</span> transformers <span class="token keyword">import</span> AutoTokenizer

tokenizer <span class="token operator">=</span> AutoTokenizer<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span><span class="token string">"distilbert-base-uncased"</span><span class="token punctuation">)</span>

<span class="token operator">**</span><span class="token keyword">def</span> preprocess_function<span class="token punctuation">(</span>examples<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">return</span> tokenizer<span class="token punctuation">(</span>examples<span class="token punctuation">[</span><span class="token string">"text"</span><span class="token punctuation">]</span><span class="token punctuation">,</span> truncation<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>

tokenized_imdb <span class="token operator">=</span> imdb<span class="token punctuation">.</span>map<span class="token punctuation">(</span>preprocess_function<span class="token punctuation">,</span> batched<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token operator">**</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>使用<strong><a href="https://huggingface.co/docs/transformers/v4.18.0/en/main_classes/data_collator#transformers.DataCollatorWithPadding" target="_blank" rel="noopener">DataCollatorWithPadding</a></strong>创建一批示例。它还会<em>动态地将您的文本填充</em>到其批次中最长元素的长度，因此它们是统一的长度。虽然可以<code>tokenizer</code>通过设置在函数中填充文本，但<code>padding=True</code>动态填充更有效。</p>
<pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">from</span> transformers <span class="token keyword">import</span> DataCollatorWithPadding

data_collator <span class="token operator">=</span> DataCollatorWithPadding<span class="token punctuation">(</span>tokenizer<span class="token operator">=</span>tokenizer<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre>
<h2 id="Train-2"><a href="#Train-2" class="headerlink" title="Train"></a>Train</h2><p>Load DistilBERT with <strong><a href="https://huggingface.co/docs/transformers/v4.18.0/en/model_doc/auto#transformers.AutoModelForSequenceClassification" target="_blank" rel="noopener">AutoModelForSequenceClassification</a></strong> along with the number of expected labels:</p>
<pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">from</span> transformers <span class="token keyword">import</span> AutoModelForSequenceClassification<span class="token punctuation">,</span> TrainingArguments<span class="token punctuation">,</span> Trainer

model <span class="token operator">=</span> AutoModelForSequenceClassification<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span><span class="token string">"distilbert-base-uncased"</span><span class="token punctuation">,</span> num_labels<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre>
<p>此时，只剩下三个步骤：</p>
<ol>
<li><strong><a href="https://huggingface.co/docs/transformers/v4.18.0/en/main_classes/trainer#transformers.TrainingArguments" target="_blank" rel="noopener">在TrainingArguments</a></strong>中定义您的训练超参数。</li>
<li>将训练参数连同模型、数据集、标记器和数据整理器一起传递给<strong><a href="https://huggingface.co/docs/transformers/v4.18.0/en/main_classes/trainer#transformers.Trainer" target="_blank" rel="noopener">Trainer 。</a></strong></li>
<li>调用<strong><a href="https://huggingface.co/docs/transformers/v4.18.0/en/main_classes/trainer#transformers.Trainer.train" target="_blank" rel="noopener">train()</a></strong>来微调你的模型。</li>
</ol>
<pre class="line-numbers language-python"><code class="language-python">training_args <span class="token operator">=</span> TrainingArguments<span class="token punctuation">(</span>
    output_dir<span class="token operator">=</span><span class="token string">"./results"</span><span class="token punctuation">,</span>
    learning_rate<span class="token operator">=</span><span class="token number">2e</span><span class="token operator">-</span><span class="token number">5</span><span class="token punctuation">,</span>
    per_device_train_batch_size<span class="token operator">=</span><span class="token number">16</span><span class="token punctuation">,</span>
    per_device_eval_batch_size<span class="token operator">=</span><span class="token number">16</span><span class="token punctuation">,</span>
    num_train_epochs<span class="token operator">=</span><span class="token number">5</span><span class="token punctuation">,</span>
    weight_decay<span class="token operator">=</span><span class="token number">0.01</span><span class="token punctuation">,</span>
<span class="token punctuation">)</span>

trainer <span class="token operator">=</span> Trainer<span class="token punctuation">(</span>
    model<span class="token operator">=</span>model<span class="token punctuation">,</span>
    args<span class="token operator">=</span>training_args<span class="token punctuation">,</span>
    train_dataset<span class="token operator">=</span>tokenized_imdb<span class="token punctuation">[</span><span class="token string">"train"</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
    eval_dataset<span class="token operator">=</span>tokenized_imdb<span class="token punctuation">[</span><span class="token string">"test"</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
    tokenizer<span class="token operator">=</span>tokenizer<span class="token punctuation">,</span>
    data_collator<span class="token operator">=</span>data_collator<span class="token punctuation">,</span>
<span class="token punctuation">)</span>

trainer<span class="token punctuation">.</span>train<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<h1 id="Token-classification"><a href="#Token-classification" class="headerlink" title="Token classification"></a>Token classification</h1><p>标记分类为句子中的各个标记分配标签。最常见的令牌分类任务之一是命名实体识别 (NER)。NER 尝试为句子中的每个实体（例如人、位置或组织）查找标签。</p>
<h2 id="Load-WNUT-17-dataset"><a href="#Load-WNUT-17-dataset" class="headerlink" title="Load WNUT 17 dataset"></a><strong>Load WNUT 17 dataset</strong></h2><p>Load the WNUT 17 dataset from the 🤗 Datasets library:</p>
<pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">from</span> datasets <span class="token keyword">import</span> load_dataset

wnut <span class="token operator">=</span> load_dataset<span class="token punctuation">(</span><span class="token string">"wnut_17"</span><span class="token punctuation">)</span>

wnut<span class="token punctuation">[</span><span class="token string">"train"</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
<span class="token punctuation">{</span><span class="token string">'id'</span><span class="token punctuation">:</span> <span class="token string">'0'</span><span class="token punctuation">,</span>
 <span class="token string">'ner_tags'</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">7</span><span class="token punctuation">,</span> <span class="token number">8</span><span class="token punctuation">,</span> <span class="token number">8</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">7</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
 <span class="token string">'tokens'</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token string">'@paulwalk'</span><span class="token punctuation">,</span> <span class="token string">'It'</span><span class="token punctuation">,</span> <span class="token string">"'s"</span><span class="token punctuation">,</span> <span class="token string">'the'</span><span class="token punctuation">,</span> <span class="token string">'view'</span><span class="token punctuation">,</span> <span class="token string">'from'</span><span class="token punctuation">,</span> <span class="token string">'where'</span><span class="token punctuation">,</span> <span class="token string">'I'</span><span class="token punctuation">,</span> <span class="token string">"'m"</span><span class="token punctuation">,</span> <span class="token string">'living'</span><span class="token punctuation">,</span> <span class="token string">'for'</span><span class="token punctuation">,</span> <span class="token string">'two'</span><span class="token punctuation">,</span> <span class="token string">'weeks'</span><span class="token punctuation">,</span> <span class="token string">'.'</span><span class="token punctuation">,</span> <span class="token string">'Empire'</span><span class="token punctuation">,</span> <span class="token string">'State'</span><span class="token punctuation">,</span> <span class="token string">'Building'</span><span class="token punctuation">,</span> <span class="token string">'='</span><span class="token punctuation">,</span> <span class="token string">'ESB'</span><span class="token punctuation">,</span> <span class="token string">'.'</span><span class="token punctuation">,</span> <span class="token string">'Pretty'</span><span class="token punctuation">,</span> <span class="token string">'bad'</span><span class="token punctuation">,</span> <span class="token string">'storm'</span><span class="token punctuation">,</span> <span class="token string">'here'</span><span class="token punctuation">,</span> <span class="token string">'last'</span><span class="token punctuation">,</span> <span class="token string">'evening'</span><span class="token punctuation">,</span> <span class="token string">'.'</span><span class="token punctuation">]</span>
<span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>Each number in <code>ner_tags</code> represents an entity. Convert the number to a label name for more information:</p>
<pre class="line-numbers language-python"><code class="language-python">label_list <span class="token operator">=</span> wnut<span class="token punctuation">[</span><span class="token string">"train"</span><span class="token punctuation">]</span><span class="token punctuation">.</span>features<span class="token punctuation">[</span>f<span class="token string">"ner_tags"</span><span class="token punctuation">]</span><span class="token punctuation">.</span>feature<span class="token punctuation">.</span>names
label_list
<span class="token punctuation">[</span>
    <span class="token string">"O"</span><span class="token punctuation">,</span>
    <span class="token string">"B-corporation"</span><span class="token punctuation">,</span>
    <span class="token string">"I-corporation"</span><span class="token punctuation">,</span>
    <span class="token string">"B-creative-work"</span><span class="token punctuation">,</span>
    <span class="token string">"I-creative-work"</span><span class="token punctuation">,</span>
    <span class="token string">"B-group"</span><span class="token punctuation">,</span>
    <span class="token string">"I-group"</span><span class="token punctuation">,</span>
    <span class="token string">"B-location"</span><span class="token punctuation">,</span>
    <span class="token string">"I-location"</span><span class="token punctuation">,</span>
    <span class="token string">"B-person"</span><span class="token punctuation">,</span>
    <span class="token string">"I-person"</span><span class="token punctuation">,</span>
    <span class="token string">"B-product"</span><span class="token punctuation">,</span>
    <span class="token string">"I-product"</span><span class="token punctuation">,</span>
<span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>描述<code>ner_tag</code>了一个实体，例如公司、地点或个人。每个前缀的字母<code>ner_tag</code>表示实体的标记位置：</p>
<ul>
<li><code>B-</code>表示实体的开始。</li>
<li><code>I-</code>示令牌包含在同一实体内（例如，<code>State</code>令牌是像 一样的实体的一部分<code>Empire State Building</code>）。</li>
<li><code>0</code>表示令牌不对应于任何实体。</li>
</ul>
<h2 id="Preprocess-1"><a href="#Preprocess-1" class="headerlink" title="Preprocess"></a>Preprocess</h2><p>Load the DistilBERT tokenizer to process the <code>tokens</code>:</p>
<pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">from</span> transformers <span class="token keyword">import</span> AutoTokenizer

tokenizer <span class="token operator">=</span> AutoTokenizer<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span><span class="token string">"distilbert-base-uncased"</span><span class="token punctuation">)</span>
tokenized_input <span class="token operator">=</span> tokenizer<span class="token punctuation">(</span>example<span class="token punctuation">[</span><span class="token string">"tokens"</span><span class="token punctuation">]</span><span class="token punctuation">,</span> is_split_into_words<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
tokens <span class="token operator">=</span> tokenizer<span class="token punctuation">.</span>convert_ids_to_tokens<span class="token punctuation">(</span>tokenized_input<span class="token punctuation">[</span><span class="token string">"input_ids"</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
tokens
<span class="token punctuation">[</span><span class="token string">'[CLS]'</span><span class="token punctuation">,</span> <span class="token string">'@'</span><span class="token punctuation">,</span> <span class="token string">'paul'</span><span class="token punctuation">,</span> <span class="token string">'##walk'</span><span class="token punctuation">,</span> <span class="token string">'it'</span><span class="token punctuation">,</span> <span class="token string">"'"</span><span class="token punctuation">,</span> <span class="token string">'s'</span><span class="token punctuation">,</span> <span class="token string">'the'</span><span class="token punctuation">,</span> <span class="token string">'view'</span><span class="token punctuation">,</span> <span class="token string">'from'</span><span class="token punctuation">,</span> <span class="token string">'where'</span><span class="token punctuation">,</span> <span class="token string">'i'</span><span class="token punctuation">,</span> <span class="token string">"'"</span><span class="token punctuation">,</span> <span class="token string">'m'</span><span class="token punctuation">,</span> <span class="token string">'living'</span><span class="token punctuation">,</span> <span class="token string">'for'</span><span class="token punctuation">,</span> <span class="token string">'two'</span><span class="token punctuation">,</span> <span class="token string">'weeks'</span><span class="token punctuation">,</span> <span class="token string">'.'</span><span class="token punctuation">,</span> <span class="token string">'empire'</span><span class="token punctuation">,</span> <span class="token string">'state'</span><span class="token punctuation">,</span> <span class="token string">'building'</span><span class="token punctuation">,</span> <span class="token string">'='</span><span class="token punctuation">,</span> <span class="token string">'es'</span><span class="token punctuation">,</span> <span class="token string">'##b'</span><span class="token punctuation">,</span> <span class="token string">'.'</span><span class="token punctuation">,</span> <span class="token string">'pretty'</span><span class="token punctuation">,</span> <span class="token string">'bad'</span><span class="token punctuation">,</span> <span class="token string">'storm'</span><span class="token punctuation">,</span> <span class="token string">'here'</span><span class="token punctuation">,</span> <span class="token string">'last'</span><span class="token punctuation">,</span> <span class="token string">'evening'</span><span class="token punctuation">,</span> <span class="token string">'.'</span><span class="token punctuation">,</span> <span class="token string">'[SEP]'</span><span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>添加特殊标记<code>[CLS]</code>和<code>[SEP]</code>子词标记化会在输入和标签之间产生不匹配。对应于单个标签的单个词可以分成两个子词。您需要通过以下方式重新对齐标记和标签：</p>
<ol>
<li>使用该方法将所有标记映射到其对应的单词<strong><code>[word_ids](&lt;https://huggingface.co/docs/tokenizers/python/latest/api/reference.html#tokenizers.Encoding.word_ids&gt;)</code></strong>。</li>
<li>将标签分配<code>100[CLS][SEP]</code>给特殊标记，因此 PyTorch 损失函数会忽略它们。</li>
<li>仅标记给定单词的第一个标记。分配<code>100</code>给同一单词的其他子标记。</li>
</ol>
<p>以下是如何创建一个函数来重新对齐标记和标签，并将序列截断为不超过 DistilBERT 的最大输入长度：</p>
<pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">tokenize_and_align_labels</span><span class="token punctuation">(</span>examples<span class="token punctuation">)</span><span class="token punctuation">:</span>
    tokenized_inputs <span class="token operator">=</span> tokenizer<span class="token punctuation">(</span>examples<span class="token punctuation">[</span><span class="token string">"tokens"</span><span class="token punctuation">]</span><span class="token punctuation">,</span> truncation<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> is_split_into_words<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>

    labels <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
    <span class="token keyword">for</span> i<span class="token punctuation">,</span> label <span class="token keyword">in</span> enumerate<span class="token punctuation">(</span>examples<span class="token punctuation">[</span>f<span class="token string">"ner_tags"</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        word_ids <span class="token operator">=</span> tokenized_inputs<span class="token punctuation">.</span>word_ids<span class="token punctuation">(</span>batch_index<span class="token operator">=</span>i<span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># Map tokens to their respective word.</span>
        previous_word_idx <span class="token operator">=</span> None
        label_ids <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
        <span class="token keyword">for</span> word_idx <span class="token keyword">in</span> word_ids<span class="token punctuation">:</span>  <span class="token comment" spellcheck="true"># Set the special tokens to -100.</span>
            <span class="token keyword">if</span> word_idx <span class="token keyword">is</span> None<span class="token punctuation">:</span>
                label_ids<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">100</span><span class="token punctuation">)</span>
            <span class="token keyword">elif</span> word_idx <span class="token operator">!=</span> previous_word_idx<span class="token punctuation">:</span>  <span class="token comment" spellcheck="true"># Only label the first token of a given word.</span>
                label_ids<span class="token punctuation">.</span>append<span class="token punctuation">(</span>label<span class="token punctuation">[</span>word_idx<span class="token punctuation">]</span><span class="token punctuation">)</span>
            <span class="token keyword">else</span><span class="token punctuation">:</span>
                label_ids<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">100</span><span class="token punctuation">)</span>
            previous_word_idx <span class="token operator">=</span> word_idx
        labels<span class="token punctuation">.</span>append<span class="token punctuation">(</span>label_ids<span class="token punctuation">)</span>

    tokenized_inputs<span class="token punctuation">[</span><span class="token string">"labels"</span><span class="token punctuation">]</span> <span class="token operator">=</span> labels
    <span class="token keyword">return</span> tokenized_inputs
tokenized_wnut <span class="token operator">=</span> wnut<span class="token punctuation">.</span>map<span class="token punctuation">(</span>tokenize_and_align_labels<span class="token punctuation">,</span> batched<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
<span class="token keyword">from</span> transformers <span class="token keyword">import</span> DataCollatorForTokenClassification

data_collator <span class="token operator">=</span> DataCollatorForTokenClassification<span class="token punctuation">(</span>tokenizer<span class="token operator">=</span>tokenizer<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<h2 id="Train-3"><a href="#Train-3" class="headerlink" title="Train"></a>Train</h2><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">from</span> transformers <span class="token keyword">import</span> AutoModelForTokenClassification<span class="token punctuation">,</span> TrainingArguments<span class="token punctuation">,</span> Trainer

model <span class="token operator">=</span> AutoModelForTokenClassification<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span><span class="token string">"distilbert-base-uncased"</span><span class="token punctuation">,</span> num_labels<span class="token operator">=</span><span class="token number">14</span><span class="token punctuation">)</span>
training_args <span class="token operator">=</span> TrainingArguments<span class="token punctuation">(</span>
    output_dir<span class="token operator">=</span><span class="token string">"./results"</span><span class="token punctuation">,</span>
    evaluation_strategy<span class="token operator">=</span><span class="token string">"epoch"</span><span class="token punctuation">,</span>
    learning_rate<span class="token operator">=</span><span class="token number">2e</span><span class="token operator">-</span><span class="token number">5</span><span class="token punctuation">,</span>
    per_device_train_batch_size<span class="token operator">=</span><span class="token number">16</span><span class="token punctuation">,</span>
    per_device_eval_batch_size<span class="token operator">=</span><span class="token number">16</span><span class="token punctuation">,</span>
    num_train_epochs<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span>
    weight_decay<span class="token operator">=</span><span class="token number">0.01</span><span class="token punctuation">,</span>
<span class="token punctuation">)</span>

trainer <span class="token operator">=</span> Trainer<span class="token punctuation">(</span>
    model<span class="token operator">=</span>model<span class="token punctuation">,</span>
    args<span class="token operator">=</span>training_args<span class="token punctuation">,</span>
    train_dataset<span class="token operator">=</span>tokenized_wnut<span class="token punctuation">[</span><span class="token string">"train"</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
    eval_dataset<span class="token operator">=</span>tokenized_wnut<span class="token punctuation">[</span><span class="token string">"test"</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
    tokenizer<span class="token operator">=</span>tokenizer<span class="token punctuation">,</span>
    data_collator<span class="token operator">=</span>data_collator<span class="token punctuation">,</span>
<span class="token punctuation">)</span>

trainer<span class="token punctuation">.</span>train<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<h1 id="Question-answering"><a href="#Question-answering" class="headerlink" title="Question answering"></a>Question answering</h1><p>问答任务返回给定问题的答案。常见的问答形式有两种：</p>
<ul>
<li>提取：从给定的上下文中提取答案。</li>
<li>抽象的：从正确回答问题的上下文中生成答案。</li>
</ul>
<h2 id="Load-SQuAD-dataset"><a href="#Load-SQuAD-dataset" class="headerlink" title="Load SQuAD dataset"></a><strong>Load SQuAD dataset</strong></h2><p>Load the SQuAD dataset from the 🤗 Datasets library:</p>
<pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">from</span> datasets <span class="token keyword">import</span> load_dataset

squad <span class="token operator">=</span> load_dataset<span class="token punctuation">(</span><span class="token string">"squad"</span><span class="token punctuation">)</span>

squad<span class="token punctuation">[</span><span class="token string">"train"</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
<span class="token punctuation">{</span><span class="token string">'answers'</span><span class="token punctuation">:</span> <span class="token punctuation">{</span><span class="token string">'answer_start'</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token number">515</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token string">'text'</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token string">'Saint Bernadette Soubirous'</span><span class="token punctuation">]</span><span class="token punctuation">}</span><span class="token punctuation">,</span>
 <span class="token string">'context'</span><span class="token punctuation">:</span> <span class="token string">'Architecturally, the school has a Catholic character. Atop the Main Building\\'</span>s gold dome <span class="token keyword">is</span> a golden statue of the Virgin Mary<span class="token punctuation">.</span> Immediately <span class="token keyword">in</span> front of the Main Building <span class="token operator">and</span> facing it<span class="token punctuation">,</span> <span class="token keyword">is</span> a copper statue of Christ <span class="token keyword">with</span> arms upraised <span class="token keyword">with</span> the legend <span class="token string">"Venite Ad Me Omnes"</span><span class="token punctuation">.</span> Next to the Main Building <span class="token keyword">is</span> the Basilica of the Sacred Heart<span class="token punctuation">.</span> Immediately behind the basilica <span class="token keyword">is</span> the Grotto<span class="token punctuation">,</span> a Marian place of prayer <span class="token operator">and</span> reflection<span class="token punctuation">.</span> It <span class="token keyword">is</span> a replica of the grotto at Lourdes<span class="token punctuation">,</span> France where the Virgin Mary reputedly appeared to Saint Bernadette Soubirous <span class="token keyword">in</span> <span class="token number">1858</span><span class="token punctuation">.</span> At the end of the main drive <span class="token punctuation">(</span><span class="token operator">and</span> <span class="token keyword">in</span> a direct line that connects through <span class="token number">3</span> statues <span class="token operator">and</span> the Gold Dome<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token keyword">is</span> a simple<span class="token punctuation">,</span> modern stone statue of Mary<span class="token punctuation">.</span>'<span class="token punctuation">,</span>
 <span class="token string">'id'</span><span class="token punctuation">:</span> <span class="token string">'5733be284776f41900661182'</span><span class="token punctuation">,</span>
 <span class="token string">'question'</span><span class="token punctuation">:</span> <span class="token string">'To whom did the Virgin Mary allegedly appear in 1858 in Lourdes France?'</span><span class="token punctuation">,</span>
 <span class="token string">'title'</span><span class="token punctuation">:</span> <span class="token string">'University_of_Notre_Dame'</span>
<span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<h2 id="Preprocess-2"><a href="#Preprocess-2" class="headerlink" title="Preprocess"></a>Preprocess</h2><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">from</span> transformers <span class="token keyword">import</span> AutoTokenizer

tokenizer <span class="token operator">=</span> AutoTokenizer<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span><span class="token string">"distilbert-base-uncased"</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre>
<p>应该注意一些特定于问答的预处理步骤：</p>
<ol>
<li>数据集中的某些示例的长度可能会context超过模型的最大输入长度。仅截断contextby 设置truncation=”only_second”。</li>
<li>context接下来，通过设置 将答案的开始和结束位置映射到原始位return_offset_mapping=True。</li>
<li>有了映射，您可以找到答案的开始和结束标记。使用sequence_ids方法找出偏移量的哪一部分对应于 ，哪一部分question对应于context。</li>
</ol>
<p>以下是如何创建一个函数来截断并将答案的开始和结束标记映射到context：</p>
<pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">preprocess_function</span><span class="token punctuation">(</span>examples<span class="token punctuation">)</span><span class="token punctuation">:</span>
    questions <span class="token operator">=</span> <span class="token punctuation">[</span>q<span class="token punctuation">.</span>strip<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">for</span> q <span class="token keyword">in</span> examples<span class="token punctuation">[</span><span class="token string">"question"</span><span class="token punctuation">]</span><span class="token punctuation">]</span>
    inputs <span class="token operator">=</span> tokenizer<span class="token punctuation">(</span>
        questions<span class="token punctuation">,</span>
        examples<span class="token punctuation">[</span><span class="token string">"context"</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
        max_length<span class="token operator">=</span><span class="token number">384</span><span class="token punctuation">,</span>
        truncation<span class="token operator">=</span><span class="token string">"only_second"</span><span class="token punctuation">,</span>
        return_offsets_mapping<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>
        padding<span class="token operator">=</span><span class="token string">"max_length"</span><span class="token punctuation">,</span>
    <span class="token punctuation">)</span>

    offset_mapping <span class="token operator">=</span> inputs<span class="token punctuation">.</span>pop<span class="token punctuation">(</span><span class="token string">"offset_mapping"</span><span class="token punctuation">)</span>
    answers <span class="token operator">=</span> examples<span class="token punctuation">[</span><span class="token string">"answers"</span><span class="token punctuation">]</span>
    start_positions <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
    end_positions <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>

    <span class="token keyword">for</span> i<span class="token punctuation">,</span> offset <span class="token keyword">in</span> enumerate<span class="token punctuation">(</span>offset_mapping<span class="token punctuation">)</span><span class="token punctuation">:</span>
        answer <span class="token operator">=</span> answers<span class="token punctuation">[</span>i<span class="token punctuation">]</span>
        start_char <span class="token operator">=</span> answer<span class="token punctuation">[</span><span class="token string">"answer_start"</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
        end_char <span class="token operator">=</span> answer<span class="token punctuation">[</span><span class="token string">"answer_start"</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">+</span> len<span class="token punctuation">(</span>answer<span class="token punctuation">[</span><span class="token string">"text"</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
        sequence_ids <span class="token operator">=</span> inputs<span class="token punctuation">.</span>sequence_ids<span class="token punctuation">(</span>i<span class="token punctuation">)</span>

        <span class="token comment" spellcheck="true"># Find the start and end of the context</span>
        idx <span class="token operator">=</span> <span class="token number">0</span>
        <span class="token keyword">while</span> sequence_ids<span class="token punctuation">[</span>idx<span class="token punctuation">]</span> <span class="token operator">!=</span> <span class="token number">1</span><span class="token punctuation">:</span>
            idx <span class="token operator">+=</span> <span class="token number">1</span>
        context_start <span class="token operator">=</span> idx
        <span class="token keyword">while</span> sequence_ids<span class="token punctuation">[</span>idx<span class="token punctuation">]</span> <span class="token operator">==</span> <span class="token number">1</span><span class="token punctuation">:</span>
            idx <span class="token operator">+=</span> <span class="token number">1</span>
        context_end <span class="token operator">=</span> idx <span class="token operator">-</span> <span class="token number">1</span>

        <span class="token comment" spellcheck="true"># If the answer is not fully inside the context, label it (0, 0)</span>
        <span class="token keyword">if</span> offset<span class="token punctuation">[</span>context_start<span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">></span> end_char <span class="token operator">or</span> offset<span class="token punctuation">[</span>context_end<span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">&lt;</span> start_char<span class="token punctuation">:</span>
            start_positions<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span>
            end_positions<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span>
        <span class="token keyword">else</span><span class="token punctuation">:</span>
            <span class="token comment" spellcheck="true"># Otherwise it's the start and end token positions</span>
            idx <span class="token operator">=</span> context_start
            <span class="token keyword">while</span> idx <span class="token operator">&lt;=</span> context_end <span class="token operator">and</span> offset<span class="token punctuation">[</span>idx<span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">&lt;=</span> start_char<span class="token punctuation">:</span>
                idx <span class="token operator">+=</span> <span class="token number">1</span>
            start_positions<span class="token punctuation">.</span>append<span class="token punctuation">(</span>idx <span class="token operator">-</span> <span class="token number">1</span><span class="token punctuation">)</span>

            idx <span class="token operator">=</span> context_end
            <span class="token keyword">while</span> idx <span class="token operator">>=</span> context_start <span class="token operator">and</span> offset<span class="token punctuation">[</span>idx<span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">>=</span> end_char<span class="token punctuation">:</span>
                idx <span class="token operator">-=</span> <span class="token number">1</span>
            end_positions<span class="token punctuation">.</span>append<span class="token punctuation">(</span>idx <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">)</span>

    inputs<span class="token punctuation">[</span><span class="token string">"start_positions"</span><span class="token punctuation">]</span> <span class="token operator">=</span> start_positions
    inputs<span class="token punctuation">[</span><span class="token string">"end_positions"</span><span class="token punctuation">]</span> <span class="token operator">=</span> end_positions
    <span class="token keyword">return</span> inputs<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>使用🤗 Datasets<strong><code>[map](&lt;https://huggingface.co/docs/datasets/package_reference/main_classes.html#datasets.Dataset.map&gt;)</code></strong>函数将预处理函数应用于整个数据集。您可以通过设置一次处理数据集的多个元素来加速该<code>map</code>功能。<code>batched=True</code>删除不需要的列：</p>
<pre class="line-numbers language-python"><code class="language-python">tokenized_squad <span class="token operator">=</span> squad<span class="token punctuation">.</span>map<span class="token punctuation">(</span>preprocess_function<span class="token punctuation">,</span> batched<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> remove_columns<span class="token operator">=</span>squad<span class="token punctuation">[</span><span class="token string">"train"</span><span class="token punctuation">]</span><span class="token punctuation">.</span>column_names<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<p>使用<strong><a href="https://huggingface.co/docs/transformers/v4.18.0/en/main_classes/data_collator#transformers.DefaultDataCollator" target="_blank" rel="noopener">DefaultDataCollator</a></strong>创建一批示例。与🤗 Transformers 中的其他数据整理器不同，<code>DefaultDataCollator</code>它不应用额外的预处理，例如填充。</p>
<pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">from</span> transformers <span class="token keyword">import</span> DefaultDataCollator

data_collator <span class="token operator">=</span> DefaultDataCollator<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre>
<h2 id="Train-4"><a href="#Train-4" class="headerlink" title="Train"></a>Train</h2><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">from</span> transformers <span class="token keyword">import</span> AutoModelForQuestionAnswering<span class="token punctuation">,</span> TrainingArguments<span class="token punctuation">,</span> Trainer

model <span class="token operator">=</span> AutoModelForQuestionAnswering<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span><span class="token string">"distilbert-base-uncased"</span><span class="token punctuation">)</span>
training_args <span class="token operator">=</span> TrainingArguments<span class="token punctuation">(</span>
    output_dir<span class="token operator">=</span><span class="token string">"./results"</span><span class="token punctuation">,</span>
    evaluation_strategy<span class="token operator">=</span><span class="token string">"epoch"</span><span class="token punctuation">,</span>
    learning_rate<span class="token operator">=</span><span class="token number">2e</span><span class="token operator">-</span><span class="token number">5</span><span class="token punctuation">,</span>
    per_device_train_batch_size<span class="token operator">=</span><span class="token number">16</span><span class="token punctuation">,</span>
    per_device_eval_batch_size<span class="token operator">=</span><span class="token number">16</span><span class="token punctuation">,</span>
    num_train_epochs<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span>
    weight_decay<span class="token operator">=</span><span class="token number">0.01</span><span class="token punctuation">,</span>
<span class="token punctuation">)</span>

trainer <span class="token operator">=</span> Trainer<span class="token punctuation">(</span>
    model<span class="token operator">=</span>model<span class="token punctuation">,</span>
    args<span class="token operator">=</span>training_args<span class="token punctuation">,</span>
    train_dataset<span class="token operator">=</span>tokenized_squad<span class="token punctuation">[</span><span class="token string">"train"</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
    eval_dataset<span class="token operator">=</span>tokenized_squad<span class="token punctuation">[</span><span class="token string">"validation"</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
    tokenizer<span class="token operator">=</span>tokenizer<span class="token punctuation">,</span>
    data_collator<span class="token operator">=</span>data_collator<span class="token punctuation">,</span>
<span class="token punctuation">)</span>

trainer<span class="token punctuation">.</span>train<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<h1 id="Language-modeling"><a href="#Language-modeling" class="headerlink" title="Language modeling"></a>Language modeling</h1><p>语言建模预测句子中的单词。语言建模有两种形式。</p>
<ul>
<li>因果语言建模预测一系列token中的下一个token，模型只能关注左边的token。</li>
<li>掩蔽语言建模预测序列中的掩蔽标记，并且模型可以双向处理标记。</li>
</ul>
<h2 id="加载-ELI5-数据集"><a href="#加载-ELI5-数据集" class="headerlink" title="加载 ELI5 数据集"></a><strong>加载 ELI5 数据集</strong></h2><p>仅从🤗 Datasets 库加载 ELI5 数据集的前 5000 行，因为它非常大：</p>
<pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">from</span> datasets <span class="token keyword">import</span> load_dataset

eli5 <span class="token operator">=</span> load_dataset<span class="token punctuation">(</span><span class="token string">"eli5"</span><span class="token punctuation">,</span> split<span class="token operator">=</span><span class="token string">"train_asks[:5000]"</span><span class="token punctuation">)</span>

eli5 <span class="token operator">=</span> eli5<span class="token punctuation">.</span>train_test_split<span class="token punctuation">(</span>test_size<span class="token operator">=</span><span class="token number">0.2</span><span class="token punctuation">)</span>
eli5<span class="token punctuation">[</span><span class="token string">"train"</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
<span class="token punctuation">{</span><span class="token string">'answers'</span><span class="token punctuation">:</span> <span class="token punctuation">{</span><span class="token string">'a_id'</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token string">'c3d1aib'</span><span class="token punctuation">,</span> <span class="token string">'c3d4lya'</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
  <span class="token string">'score'</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token number">6</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
  <span class="token string">'text'</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token string">"The velocity needed to remain in orbit is equal to the square root of Newton's constant times the mass of earth divided by the distance from the center of the earth. I don't know the altitude of that specific mission, but they're usually around 300 km. That means he's going 7-8 km/s.\\n\\nIn space there are no other forces acting on either the shuttle or the guy, so they stay in the same position relative to each other. If he were to become unable to return to the ship, he would presumably run out of oxygen, or slowly fall into the atmosphere and burn up."</span><span class="token punctuation">,</span>
   <span class="token string">"Hope you don't mind me asking another question, but why aren't there any stars visible in this photo?"</span><span class="token punctuation">]</span><span class="token punctuation">}</span><span class="token punctuation">,</span>
 <span class="token string">'answers_urls'</span><span class="token punctuation">:</span> <span class="token punctuation">{</span><span class="token string">'url'</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">}</span><span class="token punctuation">,</span>
 <span class="token string">'document'</span><span class="token punctuation">:</span> <span class="token string">''</span><span class="token punctuation">,</span>
 <span class="token string">'q_id'</span><span class="token punctuation">:</span> <span class="token string">'nyxfp'</span><span class="token punctuation">,</span>
 <span class="token string">'selftext'</span><span class="token punctuation">:</span> <span class="token string">'_URL_0_\\n\\nThis was on the front page earlier and I have a few questions about it. Is it possible to calculate how fast the astronaut would be orbiting the earth? Also how does he stay close to the shuttle so that he can return safely, i.e is he orbiting at the same speed and can therefore stay next to it? And finally if his propulsion system failed, would he eventually re-enter the atmosphere and presumably die?'</span><span class="token punctuation">,</span>
 <span class="token string">'selftext_urls'</span><span class="token punctuation">:</span> <span class="token punctuation">{</span><span class="token string">'url'</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token string">'&lt;http://apod.nasa.gov/apod/image/1201/freeflyer_nasa_3000.jpg>'</span><span class="token punctuation">]</span><span class="token punctuation">}</span><span class="token punctuation">,</span>
 <span class="token string">'subreddit'</span><span class="token punctuation">:</span> <span class="token string">'askscience'</span><span class="token punctuation">,</span>
 <span class="token string">'title'</span><span class="token punctuation">:</span> <span class="token string">'Few questions about this space walk photograph.'</span><span class="token punctuation">,</span>
 <span class="token string">'title_urls'</span><span class="token punctuation">:</span> <span class="token punctuation">{</span><span class="token string">'url'</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">}</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<h2 id="预处理"><a href="#预处理" class="headerlink" title="预处理"></a>预处理</h2><p>对于因果语言建模，加载 DistilGPT2 分词器来处理<code>text</code>子字段：</p>
<pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">from</span> transformers <span class="token keyword">import</span> AutoTokenizer

tokenizer <span class="token operator">=</span> AutoTokenizer<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span><span class="token string">"distilgpt2"</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre>
<p>对于掩码语言建模，请改为加载 DistilRoBERTa 标记器：</p>
<pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">from</span> transformers <span class="token keyword">import</span> AutoTokenizer

tokenizer <span class="token operator">=</span> AutoTokenizer<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span><span class="token string">"distilroberta-base"</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre>
<p><code>text</code>使用以下方法从其嵌套结构中提取子字段<strong><code>[flatten](&lt;https://huggingface.co/docs/datasets/process.html#flatten&gt;)</code></strong>：</p>
<pre class="line-numbers language-python"><code class="language-python">eli5 <span class="token operator">=</span> eli5<span class="token punctuation">.</span>flatten<span class="token punctuation">(</span><span class="token punctuation">)</span>
eli5<span class="token punctuation">[</span><span class="token string">"train"</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
<span class="token punctuation">{</span><span class="token string">'answers.a_id'</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token string">'c3d1aib'</span><span class="token punctuation">,</span> <span class="token string">'c3d4lya'</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
 <span class="token string">'answers.score'</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token number">6</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
 <span class="token string">'answers.text'</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token string">"The velocity needed to remain in orbit is equal to the square root of Newton's constant times the mass of earth divided by the distance from the center of the earth. I don't know the altitude of that specific mission, but they're usually around 300 km. That means he's going 7-8 km/s.\\n\\nIn space there are no other forces acting on either the shuttle or the guy, so they stay in the same position relative to each other. If he were to become unable to return to the ship, he would presumably run out of oxygen, or slowly fall into the atmosphere and burn up."</span><span class="token punctuation">,</span>
  <span class="token string">"Hope you don't mind me asking another question, but why aren't there any stars visible in this photo?"</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
 <span class="token string">'answers_urls.url'</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
 <span class="token string">'document'</span><span class="token punctuation">:</span> <span class="token string">''</span><span class="token punctuation">,</span>
 <span class="token string">'q_id'</span><span class="token punctuation">:</span> <span class="token string">'nyxfp'</span><span class="token punctuation">,</span>
 <span class="token string">'selftext'</span><span class="token punctuation">:</span> <span class="token string">'_URL_0_\\n\\nThis was on the front page earlier and I have a few questions about it. Is it possible to calculate how fast the astronaut would be orbiting the earth? Also how does he stay close to the shuttle so that he can return safely, i.e is he orbiting at the same speed and can therefore stay next to it? And finally if his propulsion system failed, would he eventually re-enter the atmosphere and presumably die?'</span><span class="token punctuation">,</span>
 <span class="token string">'selftext_urls.url'</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token string">'&lt;http://apod.nasa.gov/apod/image/1201/freeflyer_nasa_3000.jpg>'</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
 <span class="token string">'subreddit'</span><span class="token punctuation">:</span> <span class="token string">'askscience'</span><span class="token punctuation">,</span>
 <span class="token string">'title'</span><span class="token punctuation">:</span> <span class="token string">'Few questions about this space walk photograph.'</span><span class="token punctuation">,</span>
 <span class="token string">'title_urls.url'</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>每个子字段现在都是一个单独的列，如<code>answers</code>前缀所示。请注意，这<code>answers.text</code>是一个列表。不是单独标记每个句子，而是将列表转换为字符串以联合标记它们。</p>
<pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">preprocess_function</span><span class="token punctuation">(</span>examples<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">return</span> tokenizer<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token string">" "</span><span class="token punctuation">.</span>join<span class="token punctuation">(</span>x<span class="token punctuation">)</span> <span class="token keyword">for</span> x <span class="token keyword">in</span> examples<span class="token punctuation">[</span><span class="token string">"answers.text"</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span> truncation<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>
<p>使用🤗 Datasets<strong><code>[map](&lt;https://huggingface.co/docs/datasets/package_reference/main_classes.html#datasets.Dataset.map&gt;)</code></strong>函数将预处理函数应用于整个数据集。您可以<code>map</code>通过设置<code>batched=True</code>一次处理数据集的多个元素并使用<code>num_proc</code>. 删除不需要的列：</p>
<pre class="line-numbers language-python"><code class="language-python">tokenized_eli5 <span class="token operator">=</span> eli5<span class="token punctuation">.</span>map<span class="token punctuation">(</span>
    preprocess_function<span class="token punctuation">,</span>
    batched<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>
    num_proc<span class="token operator">=</span><span class="token number">4</span><span class="token punctuation">,</span>
    remove_columns<span class="token operator">=</span>eli5<span class="token punctuation">[</span><span class="token string">"train"</span><span class="token punctuation">]</span><span class="token punctuation">.</span>column_names<span class="token punctuation">,</span>
<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>现在您需要第二个预处理函数来捕获从任何冗长示例中截断的文本，以防止信息丢失。这个预处理函数应该：</p>
<ul>
<li>连接所有文本。</li>
<li>将连接的文本拆分为由<code>block_size</code></li>
</ul>
<pre class="line-numbers language-python"><code class="language-python">block_size <span class="token operator">=</span> <span class="token number">128</span>

<span class="token keyword">def</span> <span class="token function">group_texts</span><span class="token punctuation">(</span>examples<span class="token punctuation">)</span><span class="token punctuation">:</span>
    concatenated_examples <span class="token operator">=</span> <span class="token punctuation">{</span>k<span class="token punctuation">:</span> sum<span class="token punctuation">(</span>examples<span class="token punctuation">[</span>k<span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token keyword">for</span> k <span class="token keyword">in</span> examples<span class="token punctuation">.</span>keys<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">}</span>
    total_length <span class="token operator">=</span> len<span class="token punctuation">(</span>concatenated_examples<span class="token punctuation">[</span>list<span class="token punctuation">(</span>examples<span class="token punctuation">.</span>keys<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
    result <span class="token operator">=</span> <span class="token punctuation">{</span>
        k<span class="token punctuation">:</span> <span class="token punctuation">[</span>t<span class="token punctuation">[</span>i <span class="token punctuation">:</span> i <span class="token operator">+</span> block_size<span class="token punctuation">]</span> <span class="token keyword">for</span> i <span class="token keyword">in</span> range<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> total_length<span class="token punctuation">,</span> block_size<span class="token punctuation">)</span><span class="token punctuation">]</span>
        <span class="token keyword">for</span> k<span class="token punctuation">,</span> t <span class="token keyword">in</span> concatenated_examples<span class="token punctuation">.</span>items<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token punctuation">}</span>
    result<span class="token punctuation">[</span><span class="token string">"labels"</span><span class="token punctuation">]</span> <span class="token operator">=</span> result<span class="token punctuation">[</span><span class="token string">"input_ids"</span><span class="token punctuation">]</span><span class="token punctuation">.</span>copy<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token keyword">return</span> result<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>将<code>group_texts</code>函数应用于整个数据集：</p>
<pre class="line-numbers language-python"><code class="language-python">lm_dataset <span class="token operator">=</span> tokenized_eli5<span class="token punctuation">.</span>map<span class="token punctuation">(</span>group_texts<span class="token punctuation">,</span> batched<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> num_proc<span class="token operator">=</span><span class="token number">4</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<p>可以使用序列结束标记作为填充标记，并设置<code>mlm=False</code>. 这将使用输入作为向右移动一个元素的标签：</p>
<pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">from</span> transformers <span class="token keyword">import</span> DataCollatorForLanguageModeling

tokenizer<span class="token punctuation">.</span>pad_token <span class="token operator">=</span> tokenizer<span class="token punctuation">.</span>eos_token
data_collator <span class="token operator">=</span> DataCollatorForLanguageModeling<span class="token punctuation">(</span>tokenizer<span class="token operator">=</span>tokenizer<span class="token punctuation">,</span> mlm<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre>
<p>对于掩码语言建模，请使用相同的<strong><a href="https://huggingface.co/docs/transformers/v4.18.0/en/main_classes/data_collator#transformers.DataCollatorForLanguageModeling" target="_blank" rel="noopener">DataCollatorForLanguageModeling</a></strong> ，除非您应指定<code>mlm_probability</code>在每次迭代数据时随机掩码标记。</p>
<pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">from</span> transformers <span class="token keyword">import</span> DataCollatorForLanguageModeling

tokenizer<span class="token punctuation">.</span>pad_token <span class="token operator">=</span> tokenizer<span class="token punctuation">.</span>eos_token
data_collator <span class="token operator">=</span> DataCollatorForLanguageModeling<span class="token punctuation">(</span>tokenizer<span class="token operator">=</span>tokenizer<span class="token punctuation">,</span> mlm_probability<span class="token operator">=</span><span class="token number">0.15</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre>
<h2 id="训练"><a href="#训练" class="headerlink" title="训练"></a>训练</h2><p>因果语言建模</p>
<pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">from</span> transformers <span class="token keyword">import</span> AutoModelForCausalLM<span class="token punctuation">,</span> TrainingArguments<span class="token punctuation">,</span> Trainer

model <span class="token operator">=</span> AutoModelForCausalLM<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span><span class="token string">"distilgpt2"</span><span class="token punctuation">)</span>
training_args <span class="token operator">=</span> TrainingArguments<span class="token punctuation">(</span>
    output_dir<span class="token operator">=</span><span class="token string">"./results"</span><span class="token punctuation">,</span>
    evaluation_strategy<span class="token operator">=</span><span class="token string">"epoch"</span><span class="token punctuation">,</span>
    learning_rate<span class="token operator">=</span><span class="token number">2e</span><span class="token operator">-</span><span class="token number">5</span><span class="token punctuation">,</span>
    weight_decay<span class="token operator">=</span><span class="token number">0.01</span><span class="token punctuation">,</span>
<span class="token punctuation">)</span>

trainer <span class="token operator">=</span> Trainer<span class="token punctuation">(</span>
    model<span class="token operator">=</span>model<span class="token punctuation">,</span>
    args<span class="token operator">=</span>training_args<span class="token punctuation">,</span>
    train_dataset<span class="token operator">=</span>lm_dataset<span class="token punctuation">[</span><span class="token string">"train"</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
    eval_dataset<span class="token operator">=</span>lm_dataset<span class="token punctuation">[</span><span class="token string">"test"</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
    data_collator<span class="token operator">=</span>data_collator<span class="token punctuation">,</span>
<span class="token punctuation">)</span>

trainer<span class="token punctuation">.</span>train<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>掩蔽语言建模</p>
<pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">from</span> transformers <span class="token keyword">import</span> AutoModelForMaskedLM

model <span class="token operator">=</span> AutoModelForMaskedLM<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span><span class="token string">"distilroberta-base"</span><span class="token punctuation">)</span>
training_args <span class="token operator">=</span> TrainingArguments<span class="token punctuation">(</span>
    output_dir<span class="token operator">=</span><span class="token string">"./results"</span><span class="token punctuation">,</span>
    evaluation_strategy<span class="token operator">=</span><span class="token string">"epoch"</span><span class="token punctuation">,</span>
    learning_rate<span class="token operator">=</span><span class="token number">2e</span><span class="token operator">-</span><span class="token number">5</span><span class="token punctuation">,</span>
    num_train_epochs<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span>
    weight_decay<span class="token operator">=</span><span class="token number">0.01</span><span class="token punctuation">,</span>
<span class="token punctuation">)</span>

trainer <span class="token operator">=</span> Trainer<span class="token punctuation">(</span>
    model<span class="token operator">=</span>model<span class="token punctuation">,</span>
    args<span class="token operator">=</span>training_args<span class="token punctuation">,</span>
    train_dataset<span class="token operator">=</span>lm_dataset<span class="token punctuation">[</span><span class="token string">"train"</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
    eval_dataset<span class="token operator">=</span>lm_dataset<span class="token punctuation">[</span><span class="token string">"test"</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
    data_collator<span class="token operator">=</span>data_collator<span class="token punctuation">,</span>
<span class="token punctuation">)</span>

trainer<span class="token punctuation">.</span>train<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<h1 id="Translation"><a href="#Translation" class="headerlink" title="Translation"></a>Translation</h1><p>翻译将一系列文本从一种语言转换为另一种语言。它是您可以制定为序列到序列问题的几个任务之一，这是一个扩展到视觉和音频任务的强大框架。</p>
<h2 id="加载-OPUS-Books-数据集"><a href="#加载-OPUS-Books-数据集" class="headerlink" title="加载 OPUS Books 数据集"></a><strong>加载 OPUS Books 数据集</strong></h2><p>从🤗 Datasets 库加载 OPUS Books 数据集：</p>
<pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">from</span> datasets <span class="token keyword">import</span> load_dataset

books <span class="token operator">=</span> load_dataset<span class="token punctuation">(</span><span class="token string">"opus_books"</span><span class="token punctuation">,</span> <span class="token string">"en-fr"</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre>
<p>将此数据集拆分为训练集和测试集：</p>
<pre class="line-numbers language-python"><code class="language-python">books <span class="token operator">=</span> books<span class="token punctuation">[</span><span class="token string">"train"</span><span class="token punctuation">]</span><span class="token punctuation">.</span>train_test_split<span class="token punctuation">(</span>test_size<span class="token operator">=</span><span class="token number">0.2</span><span class="token punctuation">)</span>
books<span class="token punctuation">[</span><span class="token string">"train"</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
<span class="token punctuation">{</span><span class="token string">'id'</span><span class="token punctuation">:</span> <span class="token string">'90560'</span><span class="token punctuation">,</span>
 <span class="token string">'translation'</span><span class="token punctuation">:</span> <span class="token punctuation">{</span><span class="token string">'en'</span><span class="token punctuation">:</span> <span class="token string">'But this lofty plateau measured only a few fathoms, and soon we reentered Our Element.'</span><span class="token punctuation">,</span>
  <span class="token string">'fr'</span><span class="token punctuation">:</span> <span class="token string">'Mais ce plateau élevé ne mesurait que quelques toises, et bientôt nous fûmes rentrés dans notre élément.'</span><span class="token punctuation">}</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<h2 id="预处理-1"><a href="#预处理-1" class="headerlink" title="预处理"></a>预处理</h2><p>加载 T5 标记器以处理语言对：</p>
<pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">from</span> transformers <span class="token keyword">import</span> AutoTokenizer

tokenizer <span class="token operator">=</span> AutoTokenizer<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span><span class="token string">"t5-small"</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre>
<p>预处理功能需要：</p>
<ol>
<li>在输入前加上一个提示，以便 T5 知道这是一个翻译任务。一些能够执行多个 NLP 任务的模型需要提示特定任务。</li>
<li>分别标记输入（英语）和目标（法语）。您无法使用在英语词汇上预训练的分词器对法语文本进行分词。上下文管理器将帮助先将标记器设置为法语，然后再对其进行标记。</li>
<li>将序列截断为不超过<code>max_length</code>参数设置的最大长度。</li>
</ol>
<pre class="line-numbers language-python"><code class="language-python">source_lang <span class="token operator">=</span> <span class="token string">"en"</span>
target_lang <span class="token operator">=</span> <span class="token string">"fr"</span>
prefix <span class="token operator">=</span> <span class="token string">"translate English to French: "</span>

<span class="token keyword">def</span> <span class="token function">preprocess_function</span><span class="token punctuation">(</span>examples<span class="token punctuation">)</span><span class="token punctuation">:</span>
    inputs <span class="token operator">=</span> <span class="token punctuation">[</span>prefix <span class="token operator">+</span> example<span class="token punctuation">[</span>source_lang<span class="token punctuation">]</span> <span class="token keyword">for</span> example <span class="token keyword">in</span> examples<span class="token punctuation">[</span><span class="token string">"translation"</span><span class="token punctuation">]</span><span class="token punctuation">]</span>
    targets <span class="token operator">=</span> <span class="token punctuation">[</span>example<span class="token punctuation">[</span>target_lang<span class="token punctuation">]</span> <span class="token keyword">for</span> example <span class="token keyword">in</span> examples<span class="token punctuation">[</span><span class="token string">"translation"</span><span class="token punctuation">]</span><span class="token punctuation">]</span>
    model_inputs <span class="token operator">=</span> tokenizer<span class="token punctuation">(</span>inputs<span class="token punctuation">,</span> max_length<span class="token operator">=</span><span class="token number">128</span><span class="token punctuation">,</span> truncation<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>

    <span class="token keyword">with</span> tokenizer<span class="token punctuation">.</span>as_target_tokenizer<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        labels <span class="token operator">=</span> tokenizer<span class="token punctuation">(</span>targets<span class="token punctuation">,</span> max_length<span class="token operator">=</span><span class="token number">128</span><span class="token punctuation">,</span> truncation<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>

    model_inputs<span class="token punctuation">[</span><span class="token string">"labels"</span><span class="token punctuation">]</span> <span class="token operator">=</span> labels<span class="token punctuation">[</span><span class="token string">"input_ids"</span><span class="token punctuation">]</span>
    <span class="token keyword">return</span> model_inputs
tokenized_books <span class="token operator">=</span> books<span class="token punctuation">.</span>map<span class="token punctuation">(</span>preprocess_function<span class="token punctuation">,</span> batched<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
<span class="token keyword">from</span> transformers <span class="token keyword">import</span> DataCollatorForSeq2Seq

data_collator <span class="token operator">=</span> DataCollatorForSeq2Seq<span class="token punctuation">(</span>tokenizer<span class="token operator">=</span>tokenizer<span class="token punctuation">,</span> model<span class="token operator">=</span>model<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<h2 id="训练-1"><a href="#训练-1" class="headerlink" title="训练"></a>训练</h2><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">from</span> transformers <span class="token keyword">import</span> AutoModelForSeq2SeqLM<span class="token punctuation">,</span> Seq2SeqTrainingArguments<span class="token punctuation">,</span> Seq2SeqTrainer

model <span class="token operator">=</span> AutoModelForSeq2SeqLM<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span><span class="token string">"t5-small"</span><span class="token punctuation">)</span>
training_args <span class="token operator">=</span> Seq2SeqTrainingArguments<span class="token punctuation">(</span>
    output_dir<span class="token operator">=</span><span class="token string">"./results"</span><span class="token punctuation">,</span>
    evaluation_strategy<span class="token operator">=</span><span class="token string">"epoch"</span><span class="token punctuation">,</span>
    learning_rate<span class="token operator">=</span><span class="token number">2e</span><span class="token operator">-</span><span class="token number">5</span><span class="token punctuation">,</span>
    per_device_train_batch_size<span class="token operator">=</span><span class="token number">16</span><span class="token punctuation">,</span>
    per_device_eval_batch_size<span class="token operator">=</span><span class="token number">16</span><span class="token punctuation">,</span>
    weight_decay<span class="token operator">=</span><span class="token number">0.01</span><span class="token punctuation">,</span>
    save_total_limit<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span>
    num_train_epochs<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span>
    fp16<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>
<span class="token punctuation">)</span>

trainer <span class="token operator">=</span> Seq2SeqTrainer<span class="token punctuation">(</span>
    model<span class="token operator">=</span>model<span class="token punctuation">,</span>
    args<span class="token operator">=</span>training_args<span class="token punctuation">,</span>
    train_dataset<span class="token operator">=</span>tokenized_books<span class="token punctuation">[</span><span class="token string">"train"</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
    eval_dataset<span class="token operator">=</span>tokenized_books<span class="token punctuation">[</span><span class="token string">"test"</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
    tokenizer<span class="token operator">=</span>tokenizer<span class="token punctuation">,</span>
    data_collator<span class="token operator">=</span>data_collator<span class="token punctuation">,</span>
<span class="token punctuation">)</span>

trainer<span class="token punctuation">.</span>train<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<h1 id="Summarization"><a href="#Summarization" class="headerlink" title="Summarization"></a>Summarization</h1><p>摘要创建了一个较短版本的文档或文章，其中包含所有重要信息。除了翻译之外，它是另一个可以表述为序列到序列任务的任务示例。总结可以是：</p>
<ul>
<li>提取：从文档中提取最相关的信息。</li>
<li>抽象的：生成捕获最相关信息的新文本。</li>
</ul>
<h2 id="加载-BillSum-数据集"><a href="#加载-BillSum-数据集" class="headerlink" title="加载 BillSum 数据集"></a><strong>加载 BillSum 数据集</strong></h2><p>从🤗 Datasets 库加载 BillSum 数据集：</p>
<pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">from</span> datasets <span class="token keyword">import</span> load_dataset

billsum <span class="token operator">=</span> load_dataset<span class="token punctuation">(</span><span class="token string">"billsum"</span><span class="token punctuation">,</span> split<span class="token operator">=</span><span class="token string">"ca_test"</span><span class="token punctuation">)</span>
billsum <span class="token operator">=</span> billsum<span class="token punctuation">.</span>train_test_split<span class="token punctuation">(</span>test_size<span class="token operator">=</span><span class="token number">0.2</span><span class="token punctuation">)</span>
billsum<span class="token punctuation">[</span><span class="token string">"train"</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
<span class="token punctuation">{</span><span class="token string">'summary'</span><span class="token punctuation">:</span> <span class="token string">'Existing law authorizes state agencies to enter into contracts for the acquisition of goods or services upon approval by the Department of General Services. Existing law sets forth various requirements and prohibitions for those contracts, including, but not limited to, a prohibition on entering into contracts for the acquisition of goods or services of $100,000 or more with a contractor that discriminates between spouses and domestic partners or same-sex and different-sex couples in the provision of benefits. Existing law provides that a contract entered into in violation of those requirements and prohibitions is void and authorizes the state or any person acting on behalf of the state to bring a civil action seeking a determination that a contract is in violation and therefore void. Under existing law, a willful violation of those requirements and prohibitions is a misdemeanor.\\nThis bill would also prohibit a state agency from entering into contracts for the acquisition of goods or services of $100,000 or more with a contractor that discriminates between employees on the basis of gender identity in the provision of benefits, as specified. By expanding the scope of a crime, this bill would impose a state-mandated local program.\\nThe California Constitution requires the state to reimburse local agencies and school districts for certain costs mandated by the state. Statutory provisions establish procedures for making that reimbursement.\\nThis bill would provide that no reimbursement is required by this act for a specified reason.'</span><span class="token punctuation">,</span>
 <span class="token string">'text'</span><span class="token punctuation">:</span> 'The people of the State of California do enact <span class="token keyword">as</span> follows<span class="token punctuation">:</span>\\n\\n\\nSECTION <span class="token number">1</span><span class="token punctuation">.</span>\\nSection <span class="token number">10295.35</span> <span class="token keyword">is</span> added to the Public Contract Code<span class="token punctuation">,</span> to read<span class="token punctuation">:</span>\\n10295<span class="token number">.35</span><span class="token punctuation">.</span>\\n<span class="token punctuation">(</span>a<span class="token punctuation">)</span> <span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span> Notwithstanding any other law<span class="token punctuation">,</span> a state agency shall <span class="token operator">not</span> enter into any contract <span class="token keyword">for</span> the acquisition of goods <span class="token operator">or</span> services <span class="token keyword">in</span> the amount of one hundred thousand dollars <span class="token punctuation">(</span>$<span class="token number">100</span><span class="token punctuation">,</span><span class="token number">000</span><span class="token punctuation">)</span> <span class="token operator">or</span> more wi<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p><code>text</code>字段是输入，字段<code>summary</code>是目标。</p>
<h2 id="预处理-2"><a href="#预处理-2" class="headerlink" title="预处理"></a><strong>预处理</strong></h2><p>加载 T5 标记器以处理<code>text</code>和<code>summary</code>：</p>
<pre><code>from transformers import AutoTokenizer

tokenizer = AutoTokenizer.from_pretrained("t5-small")</code></pre><p>预处理功能需要：</p>
<ol>
<li>在输入前加上一个提示，以便 T5 知道这是一个汇总任务。一些能够执行多个 NLP 任务的模型需要提示特定任务。</li>
<li>使用具有该<code>as_target_tokenizer()</code>功能的上下文管理器来并行化输入和标签的标记化。</li>
<li>将序列截断为不超过<code>max_length</code>参数设置的最大长度。</li>
</ol>
<pre class="line-numbers language-python"><code class="language-python">prefix <span class="token operator">=</span> <span class="token string">"summarize: "</span>

<span class="token keyword">def</span> <span class="token function">preprocess_function</span><span class="token punctuation">(</span>examples<span class="token punctuation">)</span><span class="token punctuation">:</span>
    inputs <span class="token operator">=</span> <span class="token punctuation">[</span>prefix <span class="token operator">+</span> doc <span class="token keyword">for</span> doc <span class="token keyword">in</span> examples<span class="token punctuation">[</span><span class="token string">"text"</span><span class="token punctuation">]</span><span class="token punctuation">]</span>
    model_inputs <span class="token operator">=</span> tokenizer<span class="token punctuation">(</span>inputs<span class="token punctuation">,</span> max_length<span class="token operator">=</span><span class="token number">1024</span><span class="token punctuation">,</span> truncation<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>

    <span class="token keyword">with</span> tokenizer<span class="token punctuation">.</span>as_target_tokenizer<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        labels <span class="token operator">=</span> tokenizer<span class="token punctuation">(</span>examples<span class="token punctuation">[</span><span class="token string">"summary"</span><span class="token punctuation">]</span><span class="token punctuation">,</span> max_length<span class="token operator">=</span><span class="token number">128</span><span class="token punctuation">,</span> truncation<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>

    model_inputs<span class="token punctuation">[</span><span class="token string">"labels"</span><span class="token punctuation">]</span> <span class="token operator">=</span> labels<span class="token punctuation">[</span><span class="token string">"input_ids"</span><span class="token punctuation">]</span>
    <span class="token keyword">return</span> model_inputs
tokenized_billsum <span class="token operator">=</span> billsum<span class="token punctuation">.</span>map<span class="token punctuation">(</span>preprocess_function<span class="token punctuation">,</span> batched<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
<span class="token keyword">from</span> transformers <span class="token keyword">import</span> DataCollatorForSeq2Seq

data_collator <span class="token operator">=</span> DataCollatorForSeq2Seq<span class="token punctuation">(</span>tokenizer<span class="token operator">=</span>tokenizer<span class="token punctuation">,</span> model<span class="token operator">=</span>model<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<h2 id="训练-2"><a href="#训练-2" class="headerlink" title="训练"></a>训练</h2><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">from</span> transformers <span class="token keyword">import</span> AutoModelForSeq2SeqLM<span class="token punctuation">,</span> Seq2SeqTrainingArguments<span class="token punctuation">,</span> Seq2SeqTrainer

model <span class="token operator">=</span> AutoModelForSeq2SeqLM<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span><span class="token string">"t5-small"</span><span class="token punctuation">)</span>
training_args <span class="token operator">=</span> Seq2SeqTrainingArguments<span class="token punctuation">(</span>
    output_dir<span class="token operator">=</span><span class="token string">"./results"</span><span class="token punctuation">,</span>
    evaluation_strategy<span class="token operator">=</span><span class="token string">"epoch"</span><span class="token punctuation">,</span>
    learning_rate<span class="token operator">=</span><span class="token number">2e</span><span class="token operator">-</span><span class="token number">5</span><span class="token punctuation">,</span>
    per_device_train_batch_size<span class="token operator">=</span><span class="token number">16</span><span class="token punctuation">,</span>
    per_device_eval_batch_size<span class="token operator">=</span><span class="token number">16</span><span class="token punctuation">,</span>
    weight_decay<span class="token operator">=</span><span class="token number">0.01</span><span class="token punctuation">,</span>
    save_total_limit<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span>
    num_train_epochs<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span>
    fp16<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>
<span class="token punctuation">)</span>

trainer <span class="token operator">=</span> Seq2SeqTrainer<span class="token punctuation">(</span>
    model<span class="token operator">=</span>model<span class="token punctuation">,</span>
    args<span class="token operator">=</span>training_args<span class="token punctuation">,</span>
    train_dataset<span class="token operator">=</span>tokenized_billsum<span class="token punctuation">[</span><span class="token string">"train"</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
    eval_dataset<span class="token operator">=</span>tokenized_billsum<span class="token punctuation">[</span><span class="token string">"test"</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
    tokenizer<span class="token operator">=</span>tokenizer<span class="token punctuation">,</span>
    data_collator<span class="token operator">=</span>data_collator<span class="token punctuation">,</span>
<span class="token punctuation">)</span>

trainer<span class="token punctuation">.</span>train<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<h1 id="Multiple-choice"><a href="#Multiple-choice" class="headerlink" title="Multiple choice"></a>Multiple choice</h1><p>多项选择任务类似于问答，除了提供几个候选答案以及上下文。该模型经过训练，可以从给定上下文的多个输入中选择正确答案。</p>
<h2 id="加载-SWAG-数据集"><a href="#加载-SWAG-数据集" class="headerlink" title="加载 SWAG 数据集"></a><strong>加载 SWAG 数据集</strong></h2><p>从🤗 Datasets 库加载 SWAG 数据集：</p>
<pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">from</span> datasets <span class="token keyword">import</span> load_dataset

swag <span class="token operator">=</span> load_dataset<span class="token punctuation">(</span><span class="token string">"swag"</span><span class="token punctuation">,</span> <span class="token string">"regular"</span><span class="token punctuation">)</span>
swag<span class="token punctuation">[</span><span class="token string">"train"</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
<span class="token punctuation">{</span><span class="token string">'ending0'</span><span class="token punctuation">:</span> <span class="token string">'passes by walking down the street playing their instruments.'</span><span class="token punctuation">,</span>
 <span class="token string">'ending1'</span><span class="token punctuation">:</span> <span class="token string">'has heard approaching them.'</span><span class="token punctuation">,</span>
 <span class="token string">'ending2'</span><span class="token punctuation">:</span> <span class="token string">"arrives and they're outside dancing and asleep."</span><span class="token punctuation">,</span>
 <span class="token string">'ending3'</span><span class="token punctuation">:</span> <span class="token string">'turns the lead singer watches the performance.'</span><span class="token punctuation">,</span>
 <span class="token string">'fold-ind'</span><span class="token punctuation">:</span> <span class="token string">'3416'</span><span class="token punctuation">,</span>
 <span class="token string">'gold-source'</span><span class="token punctuation">:</span> <span class="token string">'gold'</span><span class="token punctuation">,</span>
 <span class="token string">'label'</span><span class="token punctuation">:</span> <span class="token number">0</span><span class="token punctuation">,</span>
 <span class="token string">'sent1'</span><span class="token punctuation">:</span> <span class="token string">'Members of the procession walk down the street holding small horn brass instruments.'</span><span class="token punctuation">,</span>
 <span class="token string">'sent2'</span><span class="token punctuation">:</span> <span class="token string">'A drum line'</span><span class="token punctuation">,</span>
 <span class="token string">'startphrase'</span><span class="token punctuation">:</span> <span class="token string">'Members of the procession walk down the street holding small horn brass instruments. A drum line'</span><span class="token punctuation">,</span>
 <span class="token string">'video-id'</span><span class="token punctuation">:</span> <span class="token string">'anetv_jkn6uvmqwh4'</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<h2 id="预处理-3"><a href="#预处理-3" class="headerlink" title="预处理"></a><strong>预处理</strong></h2><p>加载 BERT 分词器来处理每个句子的开头和四个可能的结尾：</p>
<pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">from</span> transformers <span class="token keyword">import</span> AutoTokenizer

tokenizer <span class="token operator">=</span> AutoTokenizer<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span><span class="token string">"bert-base-uncased"</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre>
<p>预处理功能需要做：</p>
<ol>
<li>制作该字段的四份副本，sent1以便您可以将它们中的每一份结合起来sent2以重新创建句子的开头方式。</li>
<li>结合sent2四个可能的句子结尾中的每一个。</li>
<li>展平这两个列表，以便您可以对它们进行标记，然后再将它们展平，这样每个示例都有一个对应input_ids的attention_mask、 和labels字段。</li>
</ol>
<pre class="line-numbers language-python"><code class="language-python">ending_names <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">"ending0"</span><span class="token punctuation">,</span> <span class="token string">"ending1"</span><span class="token punctuation">,</span> <span class="token string">"ending2"</span><span class="token punctuation">,</span> <span class="token string">"ending3"</span><span class="token punctuation">]</span>

<span class="token keyword">def</span> <span class="token function">preprocess_function</span><span class="token punctuation">(</span>examples<span class="token punctuation">)</span><span class="token punctuation">:</span>
    first_sentences <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">[</span>context<span class="token punctuation">]</span> <span class="token operator">*</span> <span class="token number">4</span> <span class="token keyword">for</span> context <span class="token keyword">in</span> examples<span class="token punctuation">[</span><span class="token string">"sent1"</span><span class="token punctuation">]</span><span class="token punctuation">]</span>
    question_headers <span class="token operator">=</span> examples<span class="token punctuation">[</span><span class="token string">"sent2"</span><span class="token punctuation">]</span>
    second_sentences <span class="token operator">=</span> <span class="token punctuation">[</span>
        <span class="token punctuation">[</span>f<span class="token string">"{header} {examples[end][i]}"</span> <span class="token keyword">for</span> end <span class="token keyword">in</span> ending_names<span class="token punctuation">]</span> <span class="token keyword">for</span> i<span class="token punctuation">,</span> header <span class="token keyword">in</span> enumerate<span class="token punctuation">(</span>question_headers<span class="token punctuation">)</span>
    <span class="token punctuation">]</span>

    first_sentences <span class="token operator">=</span> sum<span class="token punctuation">(</span>first_sentences<span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
    second_sentences <span class="token operator">=</span> sum<span class="token punctuation">(</span>second_sentences<span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">)</span>

    tokenized_examples <span class="token operator">=</span> tokenizer<span class="token punctuation">(</span>first_sentences<span class="token punctuation">,</span> second_sentences<span class="token punctuation">,</span> truncation<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
    <span class="token keyword">return</span> <span class="token punctuation">{</span>k<span class="token punctuation">:</span> <span class="token punctuation">[</span>v<span class="token punctuation">[</span>i <span class="token punctuation">:</span> i <span class="token operator">+</span> <span class="token number">4</span><span class="token punctuation">]</span> <span class="token keyword">for</span> i <span class="token keyword">in</span> range<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> len<span class="token punctuation">(</span>v<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token keyword">for</span> k<span class="token punctuation">,</span> v <span class="token keyword">in</span> tokenized_examples<span class="token punctuation">.</span>items<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">}</span>
tokenized_swag <span class="token operator">=</span> swag<span class="token punctuation">.</span>map<span class="token punctuation">(</span>preprocess_function<span class="token punctuation">,</span> batched<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
<span class="token keyword">from</span> dataclasses <span class="token keyword">import</span> dataclass
<span class="token keyword">from</span> transformers<span class="token punctuation">.</span>tokenization_utils_base <span class="token keyword">import</span> PreTrainedTokenizerBase<span class="token punctuation">,</span> PaddingStrategy
<span class="token keyword">from</span> typing <span class="token keyword">import</span> Optional<span class="token punctuation">,</span> Union
<span class="token keyword">import</span> torch

@dataclass
<span class="token keyword">class</span> <span class="token class-name">DataCollatorForMultipleChoice</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">"""
    Data collator that will dynamically pad the inputs for multiple choice received.
    """</span>

    tokenizer<span class="token punctuation">:</span> PreTrainedTokenizerBase
    padding<span class="token punctuation">:</span> Union<span class="token punctuation">[</span>bool<span class="token punctuation">,</span> str<span class="token punctuation">,</span> PaddingStrategy<span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token boolean">True</span>
    max_length<span class="token punctuation">:</span> Optional<span class="token punctuation">[</span>int<span class="token punctuation">]</span> <span class="token operator">=</span> None
    pad_to_multiple_of<span class="token punctuation">:</span> Optional<span class="token punctuation">[</span>int<span class="token punctuation">]</span> <span class="token operator">=</span> None

    <span class="token keyword">def</span> <span class="token function">__call__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> features<span class="token punctuation">)</span><span class="token punctuation">:</span>
        label_name <span class="token operator">=</span> <span class="token string">"label"</span> <span class="token keyword">if</span> <span class="token string">"label"</span> <span class="token keyword">in</span> features<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>keys<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">else</span> <span class="token string">"labels"</span>
        labels <span class="token operator">=</span> <span class="token punctuation">[</span>feature<span class="token punctuation">.</span>pop<span class="token punctuation">(</span>label_name<span class="token punctuation">)</span> <span class="token keyword">for</span> feature <span class="token keyword">in</span> features<span class="token punctuation">]</span>
        batch_size <span class="token operator">=</span> len<span class="token punctuation">(</span>features<span class="token punctuation">)</span>
        num_choices <span class="token operator">=</span> len<span class="token punctuation">(</span>features<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">"input_ids"</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
        flattened_features <span class="token operator">=</span> <span class="token punctuation">[</span>
            <span class="token punctuation">[</span><span class="token punctuation">{</span>k<span class="token punctuation">:</span> v<span class="token punctuation">[</span>i<span class="token punctuation">]</span> <span class="token keyword">for</span> k<span class="token punctuation">,</span> v <span class="token keyword">in</span> feature<span class="token punctuation">.</span>items<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">}</span> <span class="token keyword">for</span> i <span class="token keyword">in</span> range<span class="token punctuation">(</span>num_choices<span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token keyword">for</span> feature <span class="token keyword">in</span> features
        <span class="token punctuation">]</span>
        flattened_features <span class="token operator">=</span> sum<span class="token punctuation">(</span>flattened_features<span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">)</span>

        batch <span class="token operator">=</span> self<span class="token punctuation">.</span>tokenizer<span class="token punctuation">.</span>pad<span class="token punctuation">(</span>
            flattened_features<span class="token punctuation">,</span>
            padding<span class="token operator">=</span>self<span class="token punctuation">.</span>padding<span class="token punctuation">,</span>
            max_length<span class="token operator">=</span>self<span class="token punctuation">.</span>max_length<span class="token punctuation">,</span>
            pad_to_multiple_of<span class="token operator">=</span>self<span class="token punctuation">.</span>pad_to_multiple_of<span class="token punctuation">,</span>
            return_tensors<span class="token operator">=</span><span class="token string">"pt"</span><span class="token punctuation">,</span>
        <span class="token punctuation">)</span>

        batch <span class="token operator">=</span> <span class="token punctuation">{</span>k<span class="token punctuation">:</span> v<span class="token punctuation">.</span>view<span class="token punctuation">(</span>batch_size<span class="token punctuation">,</span> num_choices<span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span> <span class="token keyword">for</span> k<span class="token punctuation">,</span> v <span class="token keyword">in</span> batch<span class="token punctuation">.</span>items<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">}</span>
        batch<span class="token punctuation">[</span><span class="token string">"labels"</span><span class="token punctuation">]</span> <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span>labels<span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>int64<span class="token punctuation">)</span>
        <span class="token keyword">return</span> batch<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<h2 id="训练-3"><a href="#训练-3" class="headerlink" title="训练"></a>训练</h2><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">from</span> transformers <span class="token keyword">import</span> AutoModelForMultipleChoice<span class="token punctuation">,</span> TrainingArguments<span class="token punctuation">,</span> Trainer

model <span class="token operator">=</span> AutoModelForMultipleChoice<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span><span class="token string">"bert-base-uncased"</span><span class="token punctuation">)</span>
training_args <span class="token operator">=</span> TrainingArguments<span class="token punctuation">(</span>
    output_dir<span class="token operator">=</span><span class="token string">"./results"</span><span class="token punctuation">,</span>
    evaluation_strategy<span class="token operator">=</span><span class="token string">"epoch"</span><span class="token punctuation">,</span>
    learning_rate<span class="token operator">=</span><span class="token number">5e</span><span class="token operator">-</span><span class="token number">5</span><span class="token punctuation">,</span>
    per_device_train_batch_size<span class="token operator">=</span><span class="token number">16</span><span class="token punctuation">,</span>
    per_device_eval_batch_size<span class="token operator">=</span><span class="token number">16</span><span class="token punctuation">,</span>
    num_train_epochs<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span>
    weight_decay<span class="token operator">=</span><span class="token number">0.01</span><span class="token punctuation">,</span>
<span class="token punctuation">)</span>

trainer <span class="token operator">=</span> Trainer<span class="token punctuation">(</span>
    model<span class="token operator">=</span>model<span class="token punctuation">,</span>
    args<span class="token operator">=</span>training_args<span class="token punctuation">,</span>
    train_dataset<span class="token operator">=</span>tokenized_swag<span class="token punctuation">[</span><span class="token string">"train"</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
    eval_dataset<span class="token operator">=</span>tokenized_swag<span class="token punctuation">[</span><span class="token string">"validation"</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
    tokenizer<span class="token operator">=</span>tokenizer<span class="token punctuation">,</span>
    data_collator<span class="token operator">=</span>DataCollatorForMultipleChoice<span class="token punctuation">(</span>tokenizer<span class="token operator">=</span>tokenizer<span class="token punctuation">)</span><span class="token punctuation">,</span>
<span class="token punctuation">)</span>

trainer<span class="token punctuation">.</span>train<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<h1 id="👇Guides"><a href="#👇Guides" class="headerlink" title="👇Guides"></a>👇Guides</h1><h1 id="Tokenizers"><a href="#Tokenizers" class="headerlink" title="Tokenizers"></a>Tokenizers</h1><p>The <strong><a href="https://huggingface.co/docs/transformers/v4.18.0/en/main_classes/tokenizer#transformers.PreTrainedTokenizerFast" target="_blank" rel="noopener">PreTrainedTokenizerFast</a></strong> depends on the <strong><a href="https://huggingface.co/docs/tokenizers" target="_blank" rel="noopener">🤗 Tokenizers</a></strong> library. The tokenizers obtained from the 🤗 Tokenizers library can be loaded very simply into 🤗 Transformers.</p>
<pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">from</span> tokenizers <span class="token keyword">import</span> Tokenizer
<span class="token keyword">from</span> tokenizers<span class="token punctuation">.</span>models <span class="token keyword">import</span> BPE
<span class="token keyword">from</span> tokenizers<span class="token punctuation">.</span>trainers <span class="token keyword">import</span> BpeTrainer
<span class="token keyword">from</span> tokenizers<span class="token punctuation">.</span>pre_tokenizers <span class="token keyword">import</span> Whitespace

tokenizer <span class="token operator">=</span> Tokenizer<span class="token punctuation">(</span>BPE<span class="token punctuation">(</span>unk_token<span class="token operator">=</span><span class="token string">"[UNK]"</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
trainer <span class="token operator">=</span> BpeTrainer<span class="token punctuation">(</span>special_tokens<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">"[UNK]"</span><span class="token punctuation">,</span> <span class="token string">"[CLS]"</span><span class="token punctuation">,</span> <span class="token string">"[SEP]"</span><span class="token punctuation">,</span> <span class="token string">"[PAD]"</span><span class="token punctuation">,</span> <span class="token string">"[MASK]"</span><span class="token punctuation">]</span><span class="token punctuation">)</span>

tokenizer<span class="token punctuation">.</span>pre_tokenizer <span class="token operator">=</span> Whitespace<span class="token punctuation">(</span><span class="token punctuation">)</span>
files <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">]</span>
tokenizer<span class="token punctuation">.</span>train<span class="token punctuation">(</span>files<span class="token punctuation">,</span> trainer<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<h2 id="Loading-directly-from-the-tokenizer-object"><a href="#Loading-directly-from-the-tokenizer-object" class="headerlink" title="Loading directly from the tokenizer object"></a>Loading directly from the tokenizer object</h2><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">from</span> transformers <span class="token keyword">import</span> PreTrainedTokenizerFast

fast_tokenizer <span class="token operator">=</span> PreTrainedTokenizerFast<span class="token punctuation">(</span>tokenizer_object<span class="token operator">=</span>tokenizer<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre>
<h2 id="Loading-from-a-JSON-file"><a href="#Loading-from-a-JSON-file" class="headerlink" title="Loading from a JSON file"></a>Loading from a JSON file</h2><pre class="line-numbers language-python"><code class="language-python">tokenizer<span class="token punctuation">.</span>save<span class="token punctuation">(</span><span class="token string">"tokenizer.json"</span><span class="token punctuation">)</span>
<span class="token keyword">from</span> transformers <span class="token keyword">import</span> PreTrainedTokenizerFast

fast_tokenizer <span class="token operator">=</span> PreTrainedTokenizerFast<span class="token punctuation">(</span>tokenizer_file<span class="token operator">=</span><span class="token string">"tokenizer.json"</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre>
<h1 id="创建自定义架构"><a href="#创建自定义架构" class="headerlink" title="创建自定义架构"></a>创建自定义架构</h1><p>自动<strong><code>[AutoClass](&lt;https://huggingface.co/docs/transformers/model_doc/auto&gt;)</code></strong>推断模型架构并下载预训练的配置和权重。通常，我们建议使用<code>AutoClass</code>生成与检查点无关的代码。但是想要更多地控制特定模型参数的用户可以从几个基类创建一个自定义的 🤗 Transformers 模型。这对于任何有兴趣学习、训练或试验 🤗 Transformers 模型的人来说可能特别有用。</p>
<h2 id="Configuration"><a href="#Configuration" class="headerlink" title="Configuration"></a><strong>Configuration</strong></h2><p>A <strong><a href="https://huggingface.co/docs/transformers/main_classes/configuration" target="_blank" rel="noopener">configuration</a></strong> refers to a model’s specific attributes. Each model configuration has different attributes; for instance, all NLP models have the <code>hidden_size</code>, <code>num_attention_heads</code>, <code>num_hidden_layers</code> and <code>vocab_size</code> attributes in common. These attributes specify the number of attention heads or hidden layers to construct a model with.</p>
<p>Get a closer look at <strong><a href="https://huggingface.co/docs/transformers/model_doc/distilbert" target="_blank" rel="noopener">DistilBERT</a></strong> by accessing <strong><a href="https://huggingface.co/docs/transformers/v4.18.0/en/model_doc/distilbert#transformers.DistilBertConfig" target="_blank" rel="noopener">DistilBertConfig</a></strong> to inspect it’s attributes:</p>
<pre class="line-numbers language-python"><code class="language-python">my_config <span class="token operator">=</span> DistilBertConfig<span class="token punctuation">(</span>activation<span class="token operator">=</span><span class="token string">"relu"</span><span class="token punctuation">,</span> attention_dropout<span class="token operator">=</span><span class="token number">0.4</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>my_config<span class="token punctuation">)</span>
DistilBertConfig <span class="token punctuation">{</span>
  <span class="token string">"activation"</span><span class="token punctuation">:</span> <span class="token string">"relu"</span><span class="token punctuation">,</span>
  <span class="token string">"attention_dropout"</span><span class="token punctuation">:</span> <span class="token number">0.4</span><span class="token punctuation">,</span>
  <span class="token string">"dim"</span><span class="token punctuation">:</span> <span class="token number">768</span><span class="token punctuation">,</span>
  <span class="token string">"dropout"</span><span class="token punctuation">:</span> <span class="token number">0.1</span><span class="token punctuation">,</span>
  <span class="token string">"hidden_dim"</span><span class="token punctuation">:</span> <span class="token number">3072</span><span class="token punctuation">,</span>
  <span class="token string">"initializer_range"</span><span class="token punctuation">:</span> <span class="token number">0.02</span><span class="token punctuation">,</span>
  <span class="token string">"max_position_embeddings"</span><span class="token punctuation">:</span> <span class="token number">512</span><span class="token punctuation">,</span>
  <span class="token string">"model_type"</span><span class="token punctuation">:</span> <span class="token string">"distilbert"</span><span class="token punctuation">,</span>
  <span class="token string">"n_heads"</span><span class="token punctuation">:</span> <span class="token number">12</span><span class="token punctuation">,</span>
  <span class="token string">"n_layers"</span><span class="token punctuation">:</span> <span class="token number">6</span><span class="token punctuation">,</span>
  <span class="token string">"pad_token_id"</span><span class="token punctuation">:</span> <span class="token number">0</span><span class="token punctuation">,</span>
  <span class="token string">"qa_dropout"</span><span class="token punctuation">:</span> <span class="token number">0.1</span><span class="token punctuation">,</span>
  <span class="token string">"seq_classif_dropout"</span><span class="token punctuation">:</span> <span class="token number">0.2</span><span class="token punctuation">,</span>
  <span class="token string">"sinusoidal_pos_embds"</span><span class="token punctuation">:</span> false<span class="token punctuation">,</span>
  <span class="token string">"transformers_version"</span><span class="token punctuation">:</span> <span class="token string">"4.16.2"</span><span class="token punctuation">,</span>
  <span class="token string">"vocab_size"</span><span class="token punctuation">:</span> <span class="token number">30522</span>
<span class="token punctuation">}</span>
my_config <span class="token operator">=</span> DistilBertConfig<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span><span class="token string">"distilbert-base-uncased"</span><span class="token punctuation">,</span> activation<span class="token operator">=</span><span class="token string">"relu"</span><span class="token punctuation">,</span> attention_dropout<span class="token operator">=</span><span class="token number">0.4</span><span class="token punctuation">)</span>
my_config<span class="token punctuation">.</span>save_pretrained<span class="token punctuation">(</span>save_directory<span class="token operator">=</span><span class="token string">"./your_model_save_path"</span><span class="token punctuation">)</span>
my_config <span class="token operator">=</span> DistilBertConfig<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span><span class="token string">"./your_model_save_path/my_config.json"</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<h2 id="Model"><a href="#Model" class="headerlink" title="Model"></a><strong>Model</strong></h2><p>The next step is to create a <strong><a href="https://huggingface.co/docs/transformers/main_classes/models" target="_blank" rel="noopener">model</a></strong>. The model - also loosely referred to as the architecture - defines what each layer is doing and what operations are happening. Attributes like <code>num_hidden_layers</code> from the configuration are used to define the architecture. Every model shares the base class <strong><a href="https://huggingface.co/docs/transformers/v4.18.0/en/main_classes/model#transformers.PreTrainedModel" target="_blank" rel="noopener">PreTrainedModel</a></strong> and a few common methods like resizing input embeddings and pruning self-attention heads. In addition, all models are also either a <strong><code>[torch.nn.Module](&lt;https://pytorch.org/docs/stable/generated/torch.nn.Module.html&gt;)</code></strong>, <strong><code>[tf.keras.Model](&lt;https://www.tensorflow.org/api_docs/python/tf/keras/Model&gt;)</code></strong> or <strong><code>[flax.linen.Module](&lt;https://flax.readthedocs.io/en/latest/flax.linen.html#module&gt;)</code></strong> subclass. This means models are compatible with each of their respective framework’s usage.</p>
<pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">from</span> transformers <span class="token keyword">import</span> DistilBertModel

my_config <span class="token operator">=</span> DistilBertConfig<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span><span class="token string">"./your_model_save_path/my_config.json"</span><span class="token punctuation">)</span>
model <span class="token operator">=</span> DistilBertModel<span class="token punctuation">(</span>my_config<span class="token punctuation">)</span>
model <span class="token operator">=</span> DistilBertModel<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span><span class="token string">"distilbert-base-uncased"</span><span class="token punctuation">)</span>
model <span class="token operator">=</span> DistilBertModel<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span><span class="token string">"distilbert-base-uncased"</span><span class="token punctuation">,</span> config<span class="token operator">=</span>my_config<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<h2 id="Tokenizer"><a href="#Tokenizer" class="headerlink" title="Tokenizer"></a><strong>Tokenizer</strong></h2><p>The last base class you need before using a model for textual data is a <strong><a href="https://huggingface.co/docs/transformers/main_classes/tokenizer" target="_blank" rel="noopener">tokenizer</a></strong> to convert raw text to tensors. There are two types of tokenizers you can use with 🤗 Transformers:</p>
<ul>
<li><strong><a href="https://huggingface.co/docs/transformers/v4.18.0/en/main_classes/tokenizer#transformers.PreTrainedTokenizer" target="_blank" rel="noopener">PreTrainedTokenizer</a></strong>: a Python implementation of a tokenizer.</li>
<li><strong><a href="https://huggingface.co/docs/transformers/v4.18.0/en/main_classes/tokenizer#transformers.PreTrainedTokenizerFast" target="_blank" rel="noopener">PreTrainedTokenizerFast</a></strong>: a tokenizer from our Rust-based <strong><a href="https://huggingface.co/docs/tokenizers/python/latest/" target="_blank" rel="noopener">🤗 Tokenizer</a></strong> library. This tokenizer type is significantly faster - especially during batch tokenization - due to it’s Rust implementation. The fast tokenizer also offers additional methods like <em>offset mapping</em> which maps tokens to their original words or characters.</li>
</ul>
<p>Both tokenizers support common methods such as encoding and decoding, adding new tokens, and managing special tokens.</p>
<p>If you trained your own tokenizer, you can create one from your <em>vocabulary</em> file:</p>
<pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">from</span> transformers <span class="token keyword">import</span> DistilBertTokenizer

my_tokenizer <span class="token operator">=</span> DistilBertTokenizer<span class="token punctuation">(</span>vocab_file<span class="token operator">=</span><span class="token string">"my_vocab_file.txt"</span><span class="token punctuation">,</span> do_lower_case<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span> padding_side<span class="token operator">=</span><span class="token string">"left"</span><span class="token punctuation">)</span>
<span class="token keyword">from</span> transformers <span class="token keyword">import</span> DistilBertTokenizer

slow_tokenizer <span class="token operator">=</span> DistilBertTokenizer<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span><span class="token string">"distilbert-base-uncased"</span><span class="token punctuation">)</span>
<span class="token keyword">from</span> transformers <span class="token keyword">import</span> DistilBertTokenizerFast

fast_tokenizer <span class="token operator">=</span> DistilBertTokenizerFast<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span><span class="token string">"distilbert-base-uncased"</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<h2 id="Feature-Extractor"><a href="#Feature-Extractor" class="headerlink" title="Feature Extractor"></a><strong>Feature Extractor</strong></h2><p>A feature extractor processes audio or image inputs. It inherits from the base <strong><a href="https://huggingface.co/docs/transformers/v4.18.0/en/main_classes/feature_extractor#transformers.FeatureExtractionMixin" target="_blank" rel="noopener">FeatureExtractionMixin</a></strong> class, and may also inherit from the <strong><a href="https://huggingface.co/docs/transformers/v4.18.0/en/main_classes/feature_extractor#transformers.ImageFeatureExtractionMixin" target="_blank" rel="noopener">ImageFeatureExtractionMixin</a></strong> class for processing image features or the <strong><a href="https://huggingface.co/docs/transformers/v4.18.0/en/main_classes/feature_extractor#transformers.SequenceFeatureExtractor" target="_blank" rel="noopener">SequenceFeatureExtractor</a></strong> class for processing audio inputs.</p>
<p>Depending on whether you are working on an audio or vision task, create a feature extractor associated with the model you’re using. For example, create a default <strong><a href="https://huggingface.co/docs/transformers/v4.18.0/en/model_doc/vit#transformers.ViTFeatureExtractor" target="_blank" rel="noopener">ViTFeatureExtractor</a></strong> if you are using <strong><a href="https://huggingface.co/docs/transformers/model_doc/vit" target="_blank" rel="noopener">ViT</a></strong> for image classification:</p>
<pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">from</span> transformers <span class="token keyword">import</span> ViTFeatureExtractor

vit_extractor <span class="token operator">=</span> ViTFeatureExtractor<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>vit_extractor<span class="token punctuation">)</span>
ViTFeatureExtractor <span class="token punctuation">{</span>
  <span class="token string">"do_normalize"</span><span class="token punctuation">:</span> true<span class="token punctuation">,</span>
  <span class="token string">"do_resize"</span><span class="token punctuation">:</span> true<span class="token punctuation">,</span>
  <span class="token string">"feature_extractor_type"</span><span class="token punctuation">:</span> <span class="token string">"ViTFeatureExtractor"</span><span class="token punctuation">,</span>
  <span class="token string">"image_mean"</span><span class="token punctuation">:</span> <span class="token punctuation">[</span>
    <span class="token number">0.5</span><span class="token punctuation">,</span>
    <span class="token number">0.5</span><span class="token punctuation">,</span>
    <span class="token number">0.5</span>
  <span class="token punctuation">]</span><span class="token punctuation">,</span>
  <span class="token string">"image_std"</span><span class="token punctuation">:</span> <span class="token punctuation">[</span>
    <span class="token number">0.5</span><span class="token punctuation">,</span>
    <span class="token number">0.5</span><span class="token punctuation">,</span>
    <span class="token number">0.5</span>
  <span class="token punctuation">]</span><span class="token punctuation">,</span>
  <span class="token string">"resample"</span><span class="token punctuation">:</span> <span class="token number">2</span><span class="token punctuation">,</span>
  <span class="token string">"size"</span><span class="token punctuation">:</span> <span class="token number">224</span>
<span class="token punctuation">}</span>
<span class="token keyword">from</span> transformers <span class="token keyword">import</span> ViTFeatureExtractor

my_vit_extractor <span class="token operator">=</span> ViTFeatureExtractor<span class="token punctuation">(</span>resample<span class="token operator">=</span><span class="token string">"PIL.Image.BOX"</span><span class="token punctuation">,</span> do_normalize<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span> image_mean<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">0.3</span><span class="token punctuation">,</span> <span class="token number">0.3</span><span class="token punctuation">,</span> <span class="token number">0.3</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>my_vit_extractor<span class="token punctuation">)</span>
ViTFeatureExtractor <span class="token punctuation">{</span>
  <span class="token string">"do_normalize"</span><span class="token punctuation">:</span> false<span class="token punctuation">,</span>
  <span class="token string">"do_resize"</span><span class="token punctuation">:</span> true<span class="token punctuation">,</span>
  <span class="token string">"feature_extractor_type"</span><span class="token punctuation">:</span> <span class="token string">"ViTFeatureExtractor"</span><span class="token punctuation">,</span>
  <span class="token string">"image_mean"</span><span class="token punctuation">:</span> <span class="token punctuation">[</span>
    <span class="token number">0.3</span><span class="token punctuation">,</span>
    <span class="token number">0.3</span><span class="token punctuation">,</span>
    <span class="token number">0.3</span>
  <span class="token punctuation">]</span><span class="token punctuation">,</span>
  <span class="token string">"image_std"</span><span class="token punctuation">:</span> <span class="token punctuation">[</span>
    <span class="token number">0.5</span><span class="token punctuation">,</span>
    <span class="token number">0.5</span><span class="token punctuation">,</span>
    <span class="token number">0.5</span>
  <span class="token punctuation">]</span><span class="token punctuation">,</span>
  <span class="token string">"resample"</span><span class="token punctuation">:</span> <span class="token string">"PIL.Image.BOX"</span><span class="token punctuation">,</span>
  <span class="token string">"size"</span><span class="token punctuation">:</span> <span class="token number">224</span>
<span class="token punctuation">}</span>
<span class="token keyword">from</span> transformers <span class="token keyword">import</span> Wav2Vec2FeatureExtractor

w2v2_extractor <span class="token operator">=</span> Wav2Vec2FeatureExtractor<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>w2v2_extractor<span class="token punctuation">)</span>
Wav2Vec2FeatureExtractor <span class="token punctuation">{</span>
  <span class="token string">"do_normalize"</span><span class="token punctuation">:</span> true<span class="token punctuation">,</span>
  <span class="token string">"feature_extractor_type"</span><span class="token punctuation">:</span> <span class="token string">"Wav2Vec2FeatureExtractor"</span><span class="token punctuation">,</span>
  <span class="token string">"feature_size"</span><span class="token punctuation">:</span> <span class="token number">1</span><span class="token punctuation">,</span>
  <span class="token string">"padding_side"</span><span class="token punctuation">:</span> <span class="token string">"right"</span><span class="token punctuation">,</span>
  <span class="token string">"padding_value"</span><span class="token punctuation">:</span> <span class="token number">0.0</span><span class="token punctuation">,</span>
  <span class="token string">"return_attention_mask"</span><span class="token punctuation">:</span> false<span class="token punctuation">,</span>
  <span class="token string">"sampling_rate"</span><span class="token punctuation">:</span> <span class="token number">16000</span>
<span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<h2 id="Processor-1"><a href="#Processor-1" class="headerlink" title="Processor"></a><strong>Processor</strong></h2><p>For models that support multimodal tasks, 🤗 Transformers offers a processor class that conveniently wraps a feature extractor and tokenizer into a single object. For example, let’s use the <strong><a href="https://huggingface.co/docs/transformers/v4.18.0/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor" target="_blank" rel="noopener">Wav2Vec2Processor</a></strong> for an automatic speech recognition task (ASR). ASR transcribes audio to text, so you will need a feature extractor and a tokenizer.</p>
<p>Create a feature extractor to handle the audio inputs:</p>
<pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">from</span> transformers <span class="token keyword">import</span> Wav2Vec2FeatureExtractor

feature_extractor <span class="token operator">=</span> Wav2Vec2FeatureExtractor<span class="token punctuation">(</span>padding_value<span class="token operator">=</span><span class="token number">1.0</span><span class="token punctuation">,</span> do_normalize<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
<span class="token keyword">from</span> transformers <span class="token keyword">import</span> Wav2Vec2CTCTokenizer

tokenizer <span class="token operator">=</span> Wav2Vec2CTCTokenizer<span class="token punctuation">(</span>vocab_file<span class="token operator">=</span><span class="token string">"my_vocab_file.txt"</span><span class="token punctuation">)</span>
<span class="token keyword">from</span> transformers <span class="token keyword">import</span> Wav2Vec2Processor

processor <span class="token operator">=</span> Wav2Vec2Processor<span class="token punctuation">(</span>feature_extractor<span class="token operator">=</span>feature_extractor<span class="token punctuation">,</span> tokenizer<span class="token operator">=</span>tokenizer<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<h1 id="Multilingual-models-for-inference"><a href="#Multilingual-models-for-inference" class="headerlink" title="Multilingual models for inference"></a>Multilingual models for inference</h1><p>🤗 Transformers 中有几种多语言模型，它们的推理用法与单语言模型不同。不过，并非<em>所有</em>多语言模型的使用都不同。一些模型，比如<strong><a href="https://huggingface.co/bert-base-multilingual-uncased" target="_blank" rel="noopener">bert-base-multilingual-uncased</a></strong>，可以像单语模型一样使用。</p>
<h2 id="XLM"><a href="#XLM" class="headerlink" title="XLM"></a><strong>XLM</strong></h2><p>XLM 有十个不同的检查点，其中只有一个是单语的。剩下的九个模型检查点可以分为两类：使用语言嵌入的检查点和不使用语言嵌入的检查点。</p>
<h3 id="带有语言嵌入的-XLM"><a href="#带有语言嵌入的-XLM" class="headerlink" title="带有语言嵌入的 XLM"></a><strong>带有语言嵌入的 XLM</strong></h3><p>以下 XLM 模型使用语言嵌入来指定推理时使用的语言：</p>
<ul>
<li><code>xlm-mlm-ende-1024</code>（蒙面语言建模，英语-德语）</li>
<li><code>xlm-mlm-enfr-1024</code>（蒙面语言建模，英法）</li>
<li><code>xlm-mlm-enro-1024</code>（蒙面语言建模，英语-罗马尼亚语）</li>
<li><code>xlm-mlm-xnli15-1024</code>（蒙面语言建模，XNLI 语言）</li>
<li><code>xlm-mlm-tlm-xnli15-1024</code>（蒙面语言建模+翻译，XNLI 语言）</li>
<li><code>xlm-clm-enfr-1024</code>（因果语言建模，英法）</li>
<li><code>xlm-clm-ende-1024</code>（因果语言建模，英语-德语）</li>
</ul>
<p><code>input_ids</code>语言嵌入表示为与传递给模型的形状相同的张量。这些张量中的值取决于所使用的语言，并由分词器<code>lang2id</code>和<code>id2lang</code>属性标识。</p>
<p>在此示例中，加载<code>xlm-clm-enfr-1024</code>检查点（因果语言建模，英语-法语）：</p>
<pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">import</span> torch
<span class="token keyword">from</span> transformers <span class="token keyword">import</span> XLMTokenizer<span class="token punctuation">,</span> XLMWithLMHeadModel

tokenizer <span class="token operator">=</span> XLMTokenizer<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span><span class="token string">"xlm-clm-enfr-1024"</span><span class="token punctuation">)</span>
model <span class="token operator">=</span> XLMWithLMHeadModel<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span><span class="token string">"xlm-clm-enfr-1024"</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>标记器的<code>lang2id</code>属性显示此模型的语言及其 ID：</p>
<pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">print</span><span class="token punctuation">(</span>tokenizer<span class="token punctuation">.</span>lang2id<span class="token punctuation">)</span>
<span class="token punctuation">{</span> <span class="token string">'en'</span> <span class="token punctuation">:</span> <span class="token number">0</span> <span class="token punctuation">,</span> <span class="token string">'fr'</span> <span class="token punctuation">:</span> <span class="token number">1</span> <span class="token punctuation">}</span>
input_ids <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span>tokenizer<span class="token punctuation">.</span>encode<span class="token punctuation">(</span><span class="token string">"Wikipedia was used to"</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># batch size of 1</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre>
<p>将语言 ID 设置为<code>"en"</code>并使用它来定义语言嵌入。语言嵌入是一个充满的张量，<code>0</code>因为它是英语的语言 ID。该张量的大小应与 相同<code>input_ids</code>。</p>
<pre class="line-numbers language-python"><code class="language-python">language_id <span class="token operator">=</span> tokenizer<span class="token punctuation">.</span>lang2id<span class="token punctuation">[</span><span class="token string">"en"</span><span class="token punctuation">]</span>  <span class="token comment" spellcheck="true"># 0</span>
langs <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span>language_id<span class="token punctuation">]</span> <span class="token operator">*</span> input_ids<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># torch.tensor([0, 0, 0, ..., 0])</span>

<span class="token comment" spellcheck="true"># We reshape it to be of size (batch_size, sequence_length)</span>
langs <span class="token operator">=</span> langs<span class="token punctuation">.</span>view<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># is now of shape [1, sequence_length] (we have a batch size of 1)</span>
outputs <span class="token operator">=</span> model<span class="token punctuation">(</span>input_ids<span class="token punctuation">,</span> langs<span class="token operator">=</span>langs<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p><strong><a href="https://github.com/huggingface/transformers/tree/main/examples/pytorch/text-generation/run_generation.py" target="_blank" rel="noopener">run_generation.py</a></strong>脚本可以使用检查点生成带有语言嵌入的文本<code>xlm-clm</code>。</p>
<h3 id="没有语言嵌入的-XLM"><a href="#没有语言嵌入的-XLM" class="headerlink" title="没有语言嵌入的 XLM"></a><strong>没有语言嵌入的 XLM</strong></h3><p>以下 XLM 模型在推理期间不需要语言嵌入：</p>
<ul>
<li><code>xlm-mlm-17-1280</code>（蒙面语言建模，17 种语言）</li>
<li><code>xlm-mlm-100-1280</code>（蒙面语言建模，100 种语言）</li>
</ul>
<p>与之前的 XLM 检查点不同，这些模型用于通用句子表示。</p>
<h2 id="BERT"><a href="#BERT" class="headerlink" title="BERT"></a><strong>BERT</strong></h2><p>以下 BERT 模型可用于多语言任务：</p>
<ul>
<li><code>bert-base-multilingual-uncased</code>（蒙面语言建模+下一句预测，102种语言）</li>
<li><code>bert-base-multilingual-cased</code>（蒙面语言建模+下一句预测，104种语言）</li>
</ul>
<p>这些模型在推理过程中不需要语言嵌入。他们应该从上下文中识别语言并做出相应的推断。</p>
<h2 id="XLM-RoBERTa"><a href="#XLM-RoBERTa" class="headerlink" title="XLM-RoBERTa"></a><strong>XLM-</strong>RoBERTa</h2><p>以下 XLM-RoBERTa 模型可用于多语言任务：</p>
<ul>
<li><code>xlm-roberta-base</code>（蒙面语言建模，100 种语言）</li>
<li><code>xlm-roberta-large</code>（蒙面语言建模，100 种语言）</li>
</ul>
<p>XLM-RoBERTa 接受了 100 种语言的 2.5TB 新创建和清理的 CommonCrawl 数据的培训。在分类、序列标记和问答等下游任务上，它比以前发布的多语言模型（如 mBERT 或 XLM）提供了强大的收益。</p>
<h2 id="M2M100"><a href="#M2M100" class="headerlink" title="M2M100"></a><strong>M2M100</strong></h2><p>以下 M2M100 型号可用于多语言翻译：</p>
<ul>
<li><code>facebook/m2m100_418M</code>（翻译）</li>
<li><code>facebook/m2m100_1.2B</code>（翻译）</li>
</ul>
<p>在本例中，加载<code>facebook/m2m100_418M</code>检查点以将中文翻译成英文。您可以在分词器中设置源语言：</p>
<pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">from</span> transformers <span class="token keyword">import</span> M2M100ForConditionalGeneration<span class="token punctuation">,</span> M2M100Tokenizer

en_text <span class="token operator">=</span> <span class="token string">"Do not meddle in the affairs of wizards, for they are subtle and quick to anger."</span>
chinese_text <span class="token operator">=</span> <span class="token string">"不要插手巫師的事務, 因為他們是微妙的, 很快就會發怒."</span>

tokenizer <span class="token operator">=</span> M2M100Tokenizer<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span><span class="token string">"facebook/m2m100_418M"</span><span class="token punctuation">,</span> src_lang<span class="token operator">=</span><span class="token string">"zh"</span><span class="token punctuation">)</span>
model <span class="token operator">=</span> M2M100ForConditionalGeneration<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span><span class="token string">"facebook/m2m100_418M"</span><span class="token punctuation">)</span>
encoded_zh <span class="token operator">=</span> tokenizer<span class="token punctuation">(</span>chinese_text<span class="token punctuation">,</span> return_tensors<span class="token operator">=</span><span class="token string">"pt"</span><span class="token punctuation">)</span>
generated_tokens <span class="token operator">=</span> model<span class="token punctuation">.</span>generate<span class="token punctuation">(</span><span class="token operator">**</span>encoded_zh<span class="token punctuation">,</span> forced_bos_token_id<span class="token operator">=</span>tokenizer<span class="token punctuation">.</span>get_lang_id<span class="token punctuation">(</span><span class="token string">"en"</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
tokenizer<span class="token punctuation">.</span>batch_decode<span class="token punctuation">(</span>generated_tokens<span class="token punctuation">,</span> skip_special_tokens<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<h2 id="MBart"><a href="#MBart" class="headerlink" title="MBart"></a>MBart</h2><p>以下 MBar 模型可用于多语言翻译：</p>
<ul>
<li><code>facebook/mbart-large-50-one-to-many-mmt</code>（一对多多语言机器翻译，50种语言）</li>
<li><code>facebook/mbart-large-50-many-to-many-mmt</code>（多对多多语言机器翻译，50种语言）</li>
<li><code>facebook/mbart-large-50-many-to-one-mmt</code>（多对一多语言机器翻译，50种语言）</li>
<li><code>facebook/mbart-large-50</code>（多语言翻译，50种语言）</li>
<li><code>facebook/mbart-large-cc25</code></li>
</ul>
<p>在此示例中，加载<code>facebook/mbart-large-50-many-to-many-mmt</code>检查点以将芬兰语翻译成英语。您可以在分词器中设置源语言：</p>
<pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">from</span> transformers <span class="token keyword">import</span> AutoTokenizer<span class="token punctuation">,</span> AutoModelForSeq2SeqLM

en_text <span class="token operator">=</span> <span class="token string">"Do not meddle in the affairs of wizards, for they are subtle and quick to anger."</span>
fi_text <span class="token operator">=</span> <span class="token string">"Älä sekaannu velhojen asioihin, sillä ne ovat hienovaraisia ja nopeasti vihaisia."</span>

tokenizer <span class="token operator">=</span> AutoTokenizer<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span><span class="token string">"facebook/mbart-large-50-many-to-many-mmt"</span><span class="token punctuation">,</span> src_lang<span class="token operator">=</span><span class="token string">"fi_FI"</span><span class="token punctuation">)</span>
model <span class="token operator">=</span> AutoModelForSeq2SeqLM<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span><span class="token string">"facebook/mbart-large-50-many-to-many-mmt"</span><span class="token punctuation">)</span>

encoded_en <span class="token operator">=</span> tokenizer<span class="token punctuation">(</span>en_text<span class="token punctuation">,</span> return_tensors<span class="token operator">=</span><span class="token string">"pt"</span><span class="token punctuation">)</span>

generated_tokens <span class="token operator">=</span> model<span class="token punctuation">.</span>generate<span class="token punctuation">(</span><span class="token operator">**</span>encoded_en<span class="token punctuation">,</span> forced_bos_token_id<span class="token operator">=</span>tokenizer<span class="token punctuation">.</span>lang_code_to_id<span class="token punctuation">(</span><span class="token string">"en_XX"</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
tokenizer<span class="token punctuation">.</span>batch_decode<span class="token punctuation">(</span>generated_tokens<span class="token punctuation">,</span> skip_special_tokens<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<h1 id="Datasets"><a href="#Datasets" class="headerlink" title="Datasets"></a>Datasets</h1><p>官方文档：<a href="https://huggingface.co/docs/datasets/index" target="_blank" rel="noopener">Datasets (huggingface.co)</a></p>
<blockquote>
<p>一般下载的Datasets数据集是一个DatasetsDict对象，里面会根据训练，验证和测试集分成三个DataSet对象。每个DataSet对象会有很多feature属性，这些属性组成该DataSet的字典。具体的DataSet类的构建与torch的Dataset构建类似，但是构建返回的<strong><code>__getitem__</code></strong>是个字典，里面包含了训练输入数据和label，通过字典的key调用。</p>
</blockquote>
<p>Datasets是一个库，用于轻松访问和共享数据集，以及自然语言处理 （NLP）、计算机视觉和音频任务的评估指标。</p>
<p>在一行代码中加载数据集，并使用我们强大的数据处理方法快速准备好您的数据集，以便在深度学习模型中进行训练。在 Apache Arrow 格式的支持下，通过零副本读取处理大型数据集，没有任何内存限制，以实现最佳速度和效率。我们还与<strong><a href="https://huggingface.co/datasets" target="_blank" rel="noopener">Hugging Face Hub</a></strong>进行了深度集成，使您可以轻松加载数据集并与更广泛的NLP社区共享。目前有超过 2658 个数据集，以及超过 34 个可用的指标。</p>
<h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="加载数据集和模型"><a href="#加载数据集和模型" class="headerlink" title="加载数据集和模型"></a><strong>加载数据集和模型</strong></h3><p>首先从<strong><a href="https://huggingface.co/datasets/glue" target="_blank" rel="noopener">一般语言理解评估 （GLUE） 基准</a></strong>测试加载 <strong><a href="https://huggingface.co/datasets/viewer/?dataset=glue&amp;config=mrpc" target="_blank" rel="noopener">Microsoft 研究院释义语料库 （MRPC</a></strong>） 训练数据集。MRPC 是人类注释的句子对的语料库，用于训练模型以确定句子对在语义上是否等效。</p>
<pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">from</span> datasets <span class="token keyword">import</span> load_dataset
dataset <span class="token operator">=</span> load_dataset<span class="token punctuation">(</span><span class="token string">'glue'</span><span class="token punctuation">,</span> <span class="token string">'mrpc'</span><span class="token punctuation">,</span> split<span class="token operator">=</span><span class="token string">'train'</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>
<p>导入分词器模型：</p>
<pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">from</span> transformers <span class="token keyword">import</span> AutoModelForSequenceClassification<span class="token punctuation">,</span> AutoTokenizer
model <span class="token operator">=</span> AutoModelForSequenceClassification<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span><span class="token string">'bert-base-cased'</span><span class="token punctuation">)</span>
tokenizer <span class="token operator">=</span> AutoTokenizer<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span><span class="token string">'bert-base-cased'</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre>
<h3 id="标记化数据集"><a href="#标记化数据集" class="headerlink" title="标记化数据集"></a><strong>标记化数据集</strong></h3><p>下一步是标记文本，以便构建模型可以理解的整数序列。使用 <strong><a href="https://huggingface.co/docs/datasets/v2.1.0/en/package_reference/main_classes#datasets.Dataset.map" target="_blank" rel="noopener">Dataset.map（）</a></strong> 对整个数据集进行编码，并将输入截断并填充到模型的最大长度。这确保了构建适当的张量批处理。</p>
<pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">encode</span><span class="token punctuation">(</span>examples<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">return</span> tokenizer<span class="token punctuation">(</span>examples<span class="token punctuation">[</span><span class="token string">'sentence1'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> examples<span class="token punctuation">[</span><span class="token string">'sentence2'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> truncation<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token string">'max_length'</span><span class="token punctuation">)</span>

dataset <span class="token operator">=</span> dataset<span class="token punctuation">.</span>map<span class="token punctuation">(</span>encode<span class="token punctuation">,</span> batched<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
dataset<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
<span class="token punctuation">{</span><span class="token string">'sentence1'</span><span class="token punctuation">:</span> <span class="token string">'Amrozi accused his brother , whom he called " the witness " , of deliberately distorting his evidence .'</span><span class="token punctuation">,</span>
<span class="token string">'sentence2'</span><span class="token punctuation">:</span> <span class="token string">'Referring to him as only " the witness " , Amrozi accused his brother of deliberately distorting his evidence .'</span><span class="token punctuation">,</span>
<span class="token string">'label'</span><span class="token punctuation">:</span> <span class="token number">1</span><span class="token punctuation">,</span>
<span class="token string">'idx'</span><span class="token punctuation">:</span> <span class="token number">0</span><span class="token punctuation">,</span>
<span class="token string">'input_ids'</span><span class="token punctuation">:</span> array<span class="token punctuation">(</span><span class="token punctuation">[</span>  <span class="token number">101</span><span class="token punctuation">,</span>  <span class="token number">7277</span><span class="token punctuation">,</span>  <span class="token number">2180</span><span class="token punctuation">,</span>  <span class="token number">5303</span><span class="token punctuation">,</span>  <span class="token number">4806</span><span class="token punctuation">,</span>  <span class="token number">1117</span><span class="token punctuation">,</span>  <span class="token number">1711</span><span class="token punctuation">,</span>   <span class="token number">117</span><span class="token punctuation">,</span>  <span class="token number">2292</span><span class="token punctuation">,</span> <span class="token number">1119</span><span class="token punctuation">,</span>  <span class="token number">1270</span><span class="token punctuation">,</span>   <span class="token number">107</span><span class="token punctuation">,</span>  <span class="token number">1103</span><span class="token punctuation">,</span>  <span class="token number">7737</span><span class="token punctuation">,</span>   <span class="token number">107</span><span class="token punctuation">,</span>   <span class="token number">117</span><span class="token punctuation">,</span>  <span class="token number">1104</span><span class="token punctuation">,</span>  <span class="token number">9938</span><span class="token punctuation">,</span> <span class="token number">4267</span><span class="token punctuation">,</span> <span class="token number">12223</span><span class="token punctuation">,</span> <span class="token number">21811</span><span class="token punctuation">,</span>  <span class="token number">1117</span><span class="token punctuation">,</span>  <span class="token number">2554</span><span class="token punctuation">,</span>   <span class="token number">119</span><span class="token punctuation">,</span>   <span class="token number">102</span><span class="token punctuation">,</span> <span class="token number">11336</span><span class="token punctuation">,</span>  <span class="token number">6732</span><span class="token punctuation">,</span> <span class="token number">3384</span><span class="token punctuation">,</span>  <span class="token number">1106</span><span class="token punctuation">,</span>  <span class="token number">1140</span><span class="token punctuation">,</span>  <span class="token number">1112</span><span class="token punctuation">,</span>  <span class="token number">1178</span><span class="token punctuation">,</span>   <span class="token number">107</span><span class="token punctuation">,</span>  <span class="token number">1103</span><span class="token punctuation">,</span>  <span class="token number">7737</span><span class="token punctuation">,</span>   <span class="token number">107</span><span class="token punctuation">,</span> <span class="token number">117</span><span class="token punctuation">,</span>  <span class="token number">7277</span><span class="token punctuation">,</span>  <span class="token number">2180</span><span class="token punctuation">,</span>  <span class="token number">5303</span><span class="token punctuation">,</span>  <span class="token number">4806</span><span class="token punctuation">,</span>  <span class="token number">1117</span><span class="token punctuation">,</span>  <span class="token number">1711</span><span class="token punctuation">,</span>  <span class="token number">1104</span><span class="token punctuation">,</span>  <span class="token number">9938</span><span class="token punctuation">,</span> <span class="token number">4267</span><span class="token punctuation">,</span> <span class="token number">12223</span><span class="token punctuation">,</span> <span class="token number">21811</span><span class="token punctuation">,</span>  <span class="token number">1117</span><span class="token punctuation">,</span>  <span class="token number">2554</span><span class="token punctuation">,</span>   <span class="token number">119</span><span class="token punctuation">,</span>   <span class="token number">102</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
<span class="token string">'token_type_ids'</span><span class="token punctuation">:</span> array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
<span class="token string">'attention_mask'</span><span class="token punctuation">:</span> array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>注意：数据集多了三个新的参数：<code>input_ids, token_type_ids, attention_mask</code></p>
<h3 id="设置数据集的格式"><a href="#设置数据集的格式" class="headerlink" title="设置数据集的格式"></a><strong>设置数据集的格式</strong></h3><p>需要相应地格式化数据集。需要对数据集进行三项更改：</p>
<ol>
<li>将列重命名为 <code>label</code>，这是 <strong><a href="https://huggingface.co/transformers/model_doc/bert#transformers.BertForSequenceClassification.forward" target="_blank" rel="noopener">BertForSequenceClassification</a></strong> 中预期的输入名称：<code>labels</code></li>
</ol>
<pre class="line-numbers language-python"><code class="language-python"><span class="token operator">>></span><span class="token operator">></span> dataset <span class="token operator">=</span> dataset<span class="token punctuation">.</span>map<span class="token punctuation">(</span><span class="token keyword">lambda</span> examples<span class="token punctuation">:</span> <span class="token punctuation">{</span><span class="token string">'labels'</span><span class="token punctuation">:</span> examples<span class="token punctuation">[</span><span class="token string">'label'</span><span class="token punctuation">]</span><span class="token punctuation">}</span><span class="token punctuation">,</span> batched<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<ol>
<li>从 Dataset 对象检索实际的张量，而不是使用当前的 Python 对象。</li>
<li>筛选数据集以仅返回模型输入：<code>input_ids</code>、<code>token_type_ids</code>和 <code>attention_mask</code></li>
</ol>
<p><strong><a href="https://huggingface.co/docs/datasets/v2.1.0/en/package_reference/main_classes#datasets.Dataset.set_format" target="_blank" rel="noopener">Dataset.set_format（）</a></strong> 动态完成最后两个步骤。设置格式后，将数据集包装在 ：<code>torch.utils.data.DataLoader</code></p>
<pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">import</span> torch
dataset<span class="token punctuation">.</span>set_format<span class="token punctuation">(</span>type<span class="token operator">=</span><span class="token string">'torch'</span><span class="token punctuation">,</span> columns<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">'input_ids'</span><span class="token punctuation">,</span> <span class="token string">'token_type_ids'</span><span class="token punctuation">,</span> <span class="token string">'attention_mask'</span><span class="token punctuation">,</span> <span class="token string">'labels'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
dataloader <span class="token operator">=</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data<span class="token punctuation">.</span>DataLoader<span class="token punctuation">(</span>dataset<span class="token punctuation">,</span> batch_size<span class="token operator">=</span><span class="token number">32</span><span class="token punctuation">)</span>
next<span class="token punctuation">(</span>iter<span class="token punctuation">(</span>dataloader<span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token punctuation">{</span><span class="token string">'attention_mask'</span><span class="token punctuation">:</span> tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span>  <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
                        <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span>  <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
                        <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span>  <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
                        <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">,</span>
                        <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span>  <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
                        <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span>  <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
                        <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span>  <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
<span class="token string">'input_ids'</span><span class="token punctuation">:</span> tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span>  <span class="token number">101</span><span class="token punctuation">,</span>  <span class="token number">7277</span><span class="token punctuation">,</span>  <span class="token number">2180</span><span class="token punctuation">,</span>  <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">,</span>     <span class="token number">0</span><span class="token punctuation">,</span>     <span class="token number">0</span><span class="token punctuation">,</span>     <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
                  <span class="token punctuation">[</span>  <span class="token number">101</span><span class="token punctuation">,</span> <span class="token number">10684</span><span class="token punctuation">,</span>  <span class="token number">2599</span><span class="token punctuation">,</span>  <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">,</span>     <span class="token number">0</span><span class="token punctuation">,</span>     <span class="token number">0</span><span class="token punctuation">,</span>     <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
                  <span class="token punctuation">[</span>  <span class="token number">101</span><span class="token punctuation">,</span>  <span class="token number">1220</span><span class="token punctuation">,</span>  <span class="token number">1125</span><span class="token punctuation">,</span>  <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">,</span>     <span class="token number">0</span><span class="token punctuation">,</span>     <span class="token number">0</span><span class="token punctuation">,</span>     <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
                  <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">,</span>
                  <span class="token punctuation">[</span>  <span class="token number">101</span><span class="token punctuation">,</span> <span class="token number">16944</span><span class="token punctuation">,</span>  <span class="token number">1107</span><span class="token punctuation">,</span>  <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">,</span>     <span class="token number">0</span><span class="token punctuation">,</span>     <span class="token number">0</span><span class="token punctuation">,</span>     <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
                  <span class="token punctuation">[</span>  <span class="token number">101</span><span class="token punctuation">,</span>  <span class="token number">1109</span><span class="token punctuation">,</span> <span class="token number">11896</span><span class="token punctuation">,</span>  <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">,</span>     <span class="token number">0</span><span class="token punctuation">,</span>     <span class="token number">0</span><span class="token punctuation">,</span>     <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
                  <span class="token punctuation">[</span>  <span class="token number">101</span><span class="token punctuation">,</span>  <span class="token number">1109</span><span class="token punctuation">,</span>  <span class="token number">4173</span><span class="token punctuation">,</span>  <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">,</span>     <span class="token number">0</span><span class="token punctuation">,</span>     <span class="token number">0</span><span class="token punctuation">,</span>     <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
<span class="token string">'label'</span><span class="token punctuation">:</span> tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
<span class="token string">'token_type_ids'</span><span class="token punctuation">:</span> tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span>  <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
                     <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span>  <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
                     <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span>  <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
                     <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">,</span>
                     <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span>  <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
                     <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span>  <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
                     <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span>  <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<h3 id="训练模型"><a href="#训练模型" class="headerlink" title="训练模型"></a>训练模型</h3><p>最后，创建一个简单的训练循环并开始训练：</p>
<pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">from</span> tqdm <span class="token keyword">import</span> tqdm
device <span class="token operator">=</span> <span class="token string">'cuda'</span> <span class="token keyword">if</span> torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>is_available<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">else</span> <span class="token string">'cpu'</span> 
model<span class="token punctuation">.</span>train<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>
optimizer <span class="token operator">=</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>AdamW<span class="token punctuation">(</span>params<span class="token operator">=</span>model<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> lr<span class="token operator">=</span><span class="token number">1e</span><span class="token operator">-</span><span class="token number">5</span><span class="token punctuation">)</span>
<span class="token keyword">for</span> epoch <span class="token keyword">in</span> range<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">for</span> i<span class="token punctuation">,</span> batch <span class="token keyword">in</span> enumerate<span class="token punctuation">(</span>tqdm<span class="token punctuation">(</span>dataloader<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        batch <span class="token operator">=</span> <span class="token punctuation">{</span>k<span class="token punctuation">:</span> v<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span> <span class="token keyword">for</span> k<span class="token punctuation">,</span> v <span class="token keyword">in</span> batch<span class="token punctuation">.</span>items<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">}</span>
        outputs <span class="token operator">=</span> model<span class="token punctuation">(</span><span class="token operator">**</span>batch<span class="token punctuation">)</span>
        loss <span class="token operator">=</span> outputs<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
        loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>
        optimizer<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>
        optimizer<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>
        <span class="token keyword">if</span> i <span class="token operator">%</span> <span class="token number">10</span> <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">:</span>
            <span class="token keyword">print</span><span class="token punctuation">(</span>f<span class="token string">"loss: {loss}"</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<h2 id="安装-1"><a href="#安装-1" class="headerlink" title="安装"></a>安装</h2><h3 id="pip"><a href="#pip" class="headerlink" title="pip"></a><strong>pip</strong></h3><p>The most straightforward way to install 🤗 Datasets is with pip:</p>
<pre><code>pip install datasets</code></pre><h3 id="conda"><a href="#conda" class="headerlink" title="conda"></a><strong>conda</strong></h3><p>🤗 Datasets can also be installed with conda, a package management system:</p>
<pre><code>conda install -c huggingface -c conda-forge datasets</code></pre><h2 id="Hugging-Face-Hub"><a href="#Hugging-Face-Hub" class="headerlink" title="Hugging Face Hub"></a>Hugging Face Hub</h2><h3 id="Load-a-dataset"><a href="#Load-a-dataset" class="headerlink" title="Load a dataset"></a>Load a dataset</h3><p>在花时间下载数据集之前，快速获取有关数据集的所有相关信息通常很有帮助。<strong><a href="https://huggingface.co/docs/datasets/v2.1.0/en/package_reference/loading_methods#datasets.load_dataset_builder" target="_blank" rel="noopener">load_dataset_builder（）</a></strong>方法允许您在不下载数据集的情况下检查数据集的属性。</p>
<pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">from</span> datasets <span class="token keyword">import</span> load_dataset_builder
dataset_builder <span class="token operator">=</span> load_dataset_builder<span class="token punctuation">(</span><span class="token string">'imdb'</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>dataset_builder<span class="token punctuation">.</span>cache_dir<span class="token punctuation">)</span>
<span class="token operator">/</span>Users<span class="token operator">/</span>thomwolf<span class="token operator">/</span><span class="token punctuation">.</span>cache<span class="token operator">/</span>huggingface<span class="token operator">/</span>datasets<span class="token operator">/</span>imdb<span class="token operator">/</span>plain_text<span class="token operator">/</span><span class="token number">1.0</span><span class="token punctuation">.</span><span class="token number">0</span><span class="token operator">/</span>fdc76b18d5506f14b0646729b8d371880ef1bc48a26d00835a7f3da44004b676
<span class="token keyword">print</span><span class="token punctuation">(</span>dataset_builder<span class="token punctuation">.</span>info<span class="token punctuation">.</span>features<span class="token punctuation">)</span>
<span class="token punctuation">{</span><span class="token string">'text'</span><span class="token punctuation">:</span> Value<span class="token punctuation">(</span>dtype<span class="token operator">=</span><span class="token string">'string'</span><span class="token punctuation">,</span> id<span class="token operator">=</span>None<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">'label'</span><span class="token punctuation">:</span> ClassLabel<span class="token punctuation">(</span>num_classes<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span> names<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">'neg'</span><span class="token punctuation">,</span> <span class="token string">'pos'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> names_file<span class="token operator">=</span>None<span class="token punctuation">,</span> id<span class="token operator">=</span>None<span class="token punctuation">)</span><span class="token punctuation">}</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>dataset_builder<span class="token punctuation">.</span>info<span class="token punctuation">.</span>splits<span class="token punctuation">)</span>
<span class="token punctuation">{</span><span class="token string">'train'</span><span class="token punctuation">:</span> SplitInfo<span class="token punctuation">(</span>name<span class="token operator">=</span><span class="token string">'train'</span><span class="token punctuation">,</span> num_bytes<span class="token operator">=</span><span class="token number">33432835</span><span class="token punctuation">,</span> num_examples<span class="token operator">=</span><span class="token number">25000</span><span class="token punctuation">,</span> dataset_name<span class="token operator">=</span><span class="token string">'imdb'</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">'test'</span><span class="token punctuation">:</span> SplitInfo<span class="token punctuation">(</span>name<span class="token operator">=</span><span class="token string">'test'</span><span class="token punctuation">,</span> num_bytes<span class="token operator">=</span><span class="token number">32650697</span><span class="token punctuation">,</span> num_examples<span class="token operator">=</span><span class="token number">25000</span><span class="token punctuation">,</span> dataset_name<span class="token operator">=</span><span class="token string">'imdb'</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">'unsupervised'</span><span class="token punctuation">:</span> SplitInfo<span class="token punctuation">(</span>name<span class="token operator">=</span><span class="token string">'unsupervised'</span><span class="token punctuation">,</span> num_bytes<span class="token operator">=</span><span class="token number">67106814</span><span class="token punctuation">,</span> num_examples<span class="token operator">=</span><span class="token number">50000</span><span class="token punctuation">,</span> dataset_name<span class="token operator">=</span><span class="token string">'imdb'</span><span class="token punctuation">)</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>对所需的数据集感到满意后，使用 <strong><a href="https://huggingface.co/docs/datasets/v2.1.0/en/package_reference/loading_methods#datasets.load_dataset" target="_blank" rel="noopener">load_dataset（）</a></strong>将其加载到一行中：</p>
<pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">from</span> datasets <span class="token keyword">import</span> load_dataset
dataset <span class="token operator">=</span> load_dataset<span class="token punctuation">(</span><span class="token string">'glue'</span><span class="token punctuation">,</span> <span class="token string">'mrpc'</span><span class="token punctuation">,</span> split<span class="token operator">=</span><span class="token string">'train'</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>
<h2 id="选择配置"><a href="#选择配置" class="headerlink" title="选择配置"></a><strong>选择配置</strong></h2><p>某些数据集（如<strong><a href="https://huggingface.co/datasets/glue" target="_blank" rel="noopener">通用语言理解评估 （GLUE）</a></strong> 基准测试）实际上由多个数据集组成。这些子数据集称为<strong>配置</strong>，您必须在加载数据集时显式选择一个。如果未提供配置名称，🤗则数据集将引发 a 并提醒您选择配置。<code>ValueError</code>使用 <strong><a href="https://huggingface.co/docs/datasets/v2.1.0/en/package_reference/loading_methods#datasets.get_dataset_config_names" target="_blank" rel="noopener">get_dataset_config_names（）</a></strong> 函数检索数据集可用的所有可能配置的列表：</p>
<pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">from</span> datasets <span class="token keyword">import</span> get_dataset_config_names

configs <span class="token operator">=</span> get_dataset_config_names<span class="token punctuation">(</span><span class="token string">"glue"</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>configs<span class="token punctuation">)</span>
<span class="token comment" spellcheck="true"># ['cola', 'sst2', 'mrpc', 'qqp', 'stsb', 'mnli', 'mnli_mismatched', 'mnli_matched', 'qnli', 'rte', 'wnli', 'ax']</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>加载配置的方式不正确：</p>
<pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">from</span> datasets <span class="token keyword">import</span> load_dataset
dataset <span class="token operator">=</span> load_dataset<span class="token punctuation">(</span><span class="token string">'glue'</span><span class="token punctuation">)</span>

ValueError<span class="token punctuation">:</span> Config name <span class="token keyword">is</span> missing<span class="token punctuation">.</span>
Please pick one among the available configs<span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token string">'cola'</span><span class="token punctuation">,</span> <span class="token string">'sst2'</span><span class="token punctuation">,</span> <span class="token string">'mrpc'</span><span class="token punctuation">,</span> <span class="token string">'qqp'</span><span class="token punctuation">,</span> <span class="token string">'stsb'</span><span class="token punctuation">,</span> <span class="token string">'mnli'</span><span class="token punctuation">,</span> <span class="token string">'mnli_mismatched'</span><span class="token punctuation">,</span> <span class="token string">'mnli_matched'</span><span class="token punctuation">,</span> <span class="token string">'qnli'</span><span class="token punctuation">,</span> <span class="token string">'rte'</span><span class="token punctuation">,</span> <span class="token string">'wnli'</span><span class="token punctuation">,</span> <span class="token string">'ax'</span><span class="token punctuation">]</span>
Example of usage<span class="token punctuation">:</span>
        <span class="token operator">*</span>load_dataset<span class="token punctuation">(</span><span class="token string">'glue'</span><span class="token punctuation">,</span> <span class="token string">'cola'</span><span class="token punctuation">)</span><span class="token operator">*</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>加载配置的正确方法：</p>
<pre class="line-numbers language-python"><code class="language-python">dataset <span class="token operator">=</span> load_dataset<span class="token punctuation">(</span><span class="token string">'glue'</span><span class="token punctuation">,</span> <span class="token string">'sst2'</span><span class="token punctuation">)</span>
Downloading <span class="token operator">and</span> preparing dataset glue<span class="token operator">/</span>sst2 <span class="token punctuation">(</span>download<span class="token punctuation">:</span> <span class="token number">7.09</span> MiB<span class="token punctuation">,</span> generated<span class="token punctuation">:</span> <span class="token number">4.81</span> MiB<span class="token punctuation">,</span> total<span class="token punctuation">:</span> <span class="token number">11.90</span> MiB<span class="token punctuation">)</span> to <span class="token operator">/</span>Users<span class="token operator">/</span>thomwolf<span class="token operator">/</span><span class="token punctuation">.</span>cache<span class="token operator">/</span>huggingface<span class="token operator">/</span>datasets<span class="token operator">/</span>glue<span class="token operator">/</span>sst2<span class="token operator">/</span><span class="token number">1.0</span><span class="token punctuation">.</span><span class="token number">0</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>
Downloading<span class="token punctuation">:</span> <span class="token number">100</span><span class="token operator">%</span><span class="token operator">|</span>██████████████████████████████████████████████████████████████<span class="token operator">|</span> <span class="token number">7.</span>44M<span class="token operator">/</span><span class="token number">7.</span>44M <span class="token punctuation">[</span><span class="token number">00</span><span class="token punctuation">:</span><span class="token number">01</span><span class="token operator">&lt;</span><span class="token number">00</span><span class="token punctuation">:</span><span class="token number">00</span><span class="token punctuation">,</span> <span class="token number">7.</span>03MB<span class="token operator">/</span>s<span class="token punctuation">]</span>
Dataset glue downloaded <span class="token operator">and</span> prepared to <span class="token operator">/</span>Users<span class="token operator">/</span>thomwolf<span class="token operator">/</span><span class="token punctuation">.</span>cache<span class="token operator">/</span>huggingface<span class="token operator">/</span>datasets<span class="token operator">/</span>glue<span class="token operator">/</span>sst2<span class="token operator">/</span><span class="token number">1.0</span><span class="token punctuation">.</span><span class="token number">0</span><span class="token punctuation">.</span> Subsequent calls will reuse this data<span class="token punctuation">.</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>dataset<span class="token punctuation">)</span>
<span class="token punctuation">{</span><span class="token string">'train'</span><span class="token punctuation">:</span> Dataset<span class="token punctuation">(</span>schema<span class="token punctuation">:</span> <span class="token punctuation">{</span><span class="token string">'sentence'</span><span class="token punctuation">:</span> <span class="token string">'string'</span><span class="token punctuation">,</span> <span class="token string">'label'</span><span class="token punctuation">:</span> <span class="token string">'int64'</span><span class="token punctuation">,</span> <span class="token string">'idx'</span><span class="token punctuation">:</span> <span class="token string">'int32'</span><span class="token punctuation">}</span><span class="token punctuation">,</span> num_rows<span class="token punctuation">:</span> <span class="token number">67349</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    <span class="token string">'validation'</span><span class="token punctuation">:</span> Dataset<span class="token punctuation">(</span>schema<span class="token punctuation">:</span> <span class="token punctuation">{</span><span class="token string">'sentence'</span><span class="token punctuation">:</span> <span class="token string">'string'</span><span class="token punctuation">,</span> <span class="token string">'label'</span><span class="token punctuation">:</span> <span class="token string">'int64'</span><span class="token punctuation">,</span> <span class="token string">'idx'</span><span class="token punctuation">:</span> <span class="token string">'int32'</span><span class="token punctuation">}</span><span class="token punctuation">,</span> num_rows<span class="token punctuation">:</span> <span class="token number">872</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    <span class="token string">'test'</span><span class="token punctuation">:</span> Dataset<span class="token punctuation">(</span>schema<span class="token punctuation">:</span> <span class="token punctuation">{</span><span class="token string">'sentence'</span><span class="token punctuation">:</span> <span class="token string">'string'</span><span class="token punctuation">,</span> <span class="token string">'label'</span><span class="token punctuation">:</span> <span class="token string">'int64'</span><span class="token punctuation">,</span> <span class="token string">'idx'</span><span class="token punctuation">:</span> <span class="token string">'int32'</span><span class="token punctuation">}</span><span class="token punctuation">,</span> num_rows<span class="token punctuation">:</span> <span class="token number">1821</span><span class="token punctuation">)</span>
<span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<h3 id="选择拆分"><a href="#选择拆分" class="headerlink" title="选择拆分"></a>选择拆分</h3><p>拆分是数据集的特定子集，如<code>train</code> 和<code>testsplit</code> 。请确保在加载数据集时选择拆分。如果未提供参数，🤗则数据集将仅返回包含数据集子集的字典。</p>
<pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">from</span> datasets <span class="token keyword">import</span> load_dataset
datasets <span class="token operator">=</span> load_dataset<span class="token punctuation">(</span><span class="token string">'glue'</span><span class="token punctuation">,</span> <span class="token string">'mrpc'</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>datasets<span class="token punctuation">)</span>
<span class="token punctuation">{</span>train<span class="token punctuation">:</span> Dataset<span class="token punctuation">(</span><span class="token punctuation">{</span>
    features<span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token string">'idx'</span><span class="token punctuation">,</span> <span class="token string">'label'</span><span class="token punctuation">,</span> <span class="token string">'sentence1'</span><span class="token punctuation">,</span> <span class="token string">'sentence2'</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
    num_rows<span class="token punctuation">:</span> <span class="token number">3668</span>
<span class="token punctuation">}</span><span class="token punctuation">)</span>
validation<span class="token punctuation">:</span> Dataset<span class="token punctuation">(</span><span class="token punctuation">{</span>
    features<span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token string">'idx'</span><span class="token punctuation">,</span> <span class="token string">'label'</span><span class="token punctuation">,</span> <span class="token string">'sentence1'</span><span class="token punctuation">,</span> <span class="token string">'sentence2'</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
    num_rows<span class="token punctuation">:</span> <span class="token number">408</span>
<span class="token punctuation">}</span><span class="token punctuation">)</span>
test<span class="token punctuation">:</span> Dataset<span class="token punctuation">(</span><span class="token punctuation">{</span>
    features<span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token string">'idx'</span><span class="token punctuation">,</span> <span class="token string">'label'</span><span class="token punctuation">,</span> <span class="token string">'sentence1'</span><span class="token punctuation">,</span> <span class="token string">'sentence2'</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
    num_rows<span class="token punctuation">:</span> <span class="token number">1725</span>
<span class="token punctuation">}</span><span class="token punctuation">)</span>
<span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>You can list the split names for a dataset, or a specific configuration, with the <strong><a href="https://huggingface.co/docs/datasets/v2.1.0/en/package_reference/loading_methods#datasets.get_dataset_split_names" target="_blank" rel="noopener">get_dataset_split_names()</a></strong> method:</p>
<pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">from</span> datasets <span class="token keyword">import</span> get_dataset_split_names
get_dataset_split_names<span class="token punctuation">(</span><span class="token string">'sent_comp'</span><span class="token punctuation">)</span>
<span class="token punctuation">[</span><span class="token string">'validation'</span><span class="token punctuation">,</span> <span class="token string">'train'</span><span class="token punctuation">]</span>
get_dataset_split_names<span class="token punctuation">(</span><span class="token string">'glue'</span><span class="token punctuation">,</span> <span class="token string">'cola'</span><span class="token punctuation">)</span>
<span class="token punctuation">[</span><span class="token string">'test'</span><span class="token punctuation">,</span> <span class="token string">'train'</span><span class="token punctuation">,</span> <span class="token string">'validation'</span><span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<h2 id="The-Dataset-object"><a href="#The-Dataset-object" class="headerlink" title="The Dataset object"></a>The Dataset object</h2><p>本部分熟悉<strong><a href="https://huggingface.co/docs/datasets/v2.1.0/en/package_reference/main_classes#datasets.Dataset" target="_blank" rel="noopener">数据集</a></strong>对象。了解存储在 Dataset 对象中的元数据，以及查询 Dataset 对象以返回行和列的基础知识。</p>
<p>加载<strong><a href="https://huggingface.co/docs/datasets/v2.1.0/en/package_reference/main_classes#datasets.Dataset" target="_blank" rel="noopener">数据集</a></strong>的实例时，将返回 Dataset 对象。此对象的行为类似于普通的 Python 容器。</p>
<pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">from</span> datasets <span class="token keyword">import</span> load_dataset
dataset <span class="token operator">=</span> load_dataset<span class="token punctuation">(</span><span class="token string">'glue'</span><span class="token punctuation">,</span> <span class="token string">'mrpc'</span><span class="token punctuation">,</span> split<span class="token operator">=</span><span class="token string">'train'</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>
<h3 id="元数据"><a href="#元数据" class="headerlink" title="元数据"></a><strong>元数据</strong></h3><p><strong><a href="https://huggingface.co/docs/datasets/v2.1.0/en/package_reference/main_classes#datasets.Dataset" target="_blank" rel="noopener">数据集</a></strong>对象包含有关数据集的大量有用信息。例如，访问 <strong><a href="https://huggingface.co/docs/datasets/v2.1.0/en/package_reference/main_classes#datasets.DatasetInfo" target="_blank" rel="noopener">DatasetInfo</a></strong> 以返回数据集、作者甚至数据集大小的简短说明。这将为您提供数据集最重要属性的快速快照。</p>
<pre class="line-numbers language-python"><code class="language-python">dataset<span class="token punctuation">.</span>info
DatasetInfo<span class="token punctuation">(</span>
    description<span class="token operator">=</span><span class="token string">'GLUE, the General Language Understanding Evaluation benchmark\\n(&lt;https://gluebenchmark.com/>) is a collection of resources for training,\\nevaluating, and analyzing natural language understanding systems.\\n\\n'</span><span class="token punctuation">,</span> 
    citation<span class="token operator">=</span><span class="token string">'@inproceedings{dolan2005automatically,\\n  title={Automatically constructing a corpus of sentential paraphrases},\\n  author={Dolan, William B and Brockett, Chris},\\n  booktitle={Proceedings of the Third International Workshop on Paraphrasing (IWP2005)},\\n  year={2005}\\n}\\n@inproceedings{wang2019glue,\\n  title={{GLUE}: A Multi-Task Benchmark and Analysis Platform for Natural Language Understanding},\\n  author={Wang, Alex and Singh, Amanpreet and Michael, Julian and Hill, Felix and Levy, Omer and Bowman, Samuel R.},\\n  note={In the Proceedings of ICLR.},\\n  year={2019}\\n}\\n'</span><span class="token punctuation">,</span> homepage<span class="token operator">=</span><span class="token string">'&lt;https: www.microsoft.com="" en-us="" download="" details.aspx?id="52398">'</span><span class="token punctuation">,</span> 
    license<span class="token operator">=</span><span class="token string">''</span><span class="token punctuation">,</span> 
    features<span class="token operator">=</span><span class="token punctuation">{</span><span class="token string">'sentence1'</span><span class="token punctuation">:</span> Value<span class="token punctuation">(</span>dtype<span class="token operator">=</span><span class="token string">'string'</span><span class="token punctuation">,</span> id<span class="token operator">=</span>None<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">'sentence2'</span><span class="token punctuation">:</span> Value<span class="token punctuation">(</span>dtype<span class="token operator">=</span><span class="token string">'string'</span><span class="token punctuation">,</span> id<span class="token operator">=</span>None<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">'label'</span><span class="token punctuation">:</span> ClassLabel<span class="token punctuation">(</span>num_classes<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span> names<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">'not_equivalent'</span><span class="token punctuation">,</span> <span class="token string">'equivalent'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> names_file<span class="token operator">=</span>None<span class="token punctuation">,</span> id<span class="token operator">=</span>None<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">'idx'</span><span class="token punctuation">:</span> Value<span class="token punctuation">(</span>dtype<span class="token operator">=</span><span class="token string">'int32'</span><span class="token punctuation">,</span> id<span class="token operator">=</span>None<span class="token punctuation">)</span><span class="token punctuation">}</span><span class="token punctuation">,</span> post_processed<span class="token operator">=</span>None<span class="token punctuation">,</span> supervised_keys<span class="token operator">=</span>None<span class="token punctuation">,</span> builder_name<span class="token operator">=</span><span class="token string">'glue'</span><span class="token punctuation">,</span> config_name<span class="token operator">=</span><span class="token string">'mrpc'</span><span class="token punctuation">,</span> version<span class="token operator">=</span><span class="token number">1.0</span><span class="token punctuation">.</span><span class="token number">0</span><span class="token punctuation">,</span> splits<span class="token operator">=</span><span class="token punctuation">{</span><span class="token string">'train'</span><span class="token punctuation">:</span> SplitInfo<span class="token punctuation">(</span>name<span class="token operator">=</span><span class="token string">'train'</span><span class="token punctuation">,</span> num_bytes<span class="token operator">=</span><span class="token number">943851</span><span class="token punctuation">,</span> num_examples<span class="token operator">=</span><span class="token number">3668</span><span class="token punctuation">,</span> dataset_name<span class="token operator">=</span><span class="token string">'glue'</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">'validation'</span><span class="token punctuation">:</span> SplitInfo<span class="token punctuation">(</span>name<span class="token operator">=</span><span class="token string">'validation'</span><span class="token punctuation">,</span> num_bytes<span class="token operator">=</span><span class="token number">105887</span><span class="token punctuation">,</span> num_examples<span class="token operator">=</span><span class="token number">408</span><span class="token punctuation">,</span> dataset_name<span class="token operator">=</span><span class="token string">'glue'</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">'test'</span><span class="token punctuation">:</span> SplitInfo<span class="token punctuation">(</span>name<span class="token operator">=</span><span class="token string">'test'</span><span class="token punctuation">,</span> num_bytes<span class="token operator">=</span><span class="token number">442418</span><span class="token punctuation">,</span> num_examples<span class="token operator">=</span><span class="token number">1725</span><span class="token punctuation">,</span> dataset_name<span class="token operator">=</span><span class="token string">'glue'</span><span class="token punctuation">)</span><span class="token punctuation">}</span><span class="token punctuation">,</span> 
    download_checksums<span class="token operator">=</span><span class="token punctuation">{</span><span class="token string">'&lt;https: dl.fbaipublicfiles.com="" glue="" data="" mrpc_dev_ids.tsv="">'</span><span class="token punctuation">:</span> <span class="token punctuation">{</span><span class="token string">'num_bytes'</span><span class="token punctuation">:</span> <span class="token number">6222</span><span class="token punctuation">,</span> <span class="token string">'checksum'</span><span class="token punctuation">:</span> <span class="token string">'971d7767d81b997fd9060ade0ec23c4fc31cbb226a55d1bd4a1bac474eb81dc7'</span><span class="token punctuation">}</span><span class="token punctuation">,</span> <span class="token string">'&lt;https: dl.fbaipublicfiles.com="" senteval="" senteval_data="" msr_paraphrase_train.txt="">'</span><span class="token punctuation">:</span> <span class="token punctuation">{</span><span class="token string">'num_bytes'</span><span class="token punctuation">:</span> <span class="token number">1047044</span><span class="token punctuation">,</span> <span class="token string">'checksum'</span><span class="token punctuation">:</span> <span class="token string">'60a9b09084528f0673eedee2b69cb941920f0b8cd0eeccefc464a98768457f89'</span><span class="token punctuation">}</span><span class="token punctuation">,</span> <span class="token string">'&lt;https: dl.fbaipublicfiles.com="" senteval="" senteval_data="" msr_paraphrase_test.txt="">'</span><span class="token punctuation">:</span> <span class="token punctuation">{</span><span class="token string">'num_bytes'</span><span class="token punctuation">:</span> <span class="token number">441275</span><span class="token punctuation">,</span> <span class="token string">'checksum'</span><span class="token punctuation">:</span> <span class="token string">'a04e271090879aaba6423d65b94950c089298587d9c084bf9cd7439bd785f784'</span><span class="token punctuation">}</span><span class="token punctuation">}</span><span class="token punctuation">,</span> 
    download_size<span class="token operator">=</span><span class="token number">1494541</span><span class="token punctuation">,</span> 
    post_processing_size<span class="token operator">=</span>None<span class="token punctuation">,</span> 
    dataset_size<span class="token operator">=</span><span class="token number">1492156</span><span class="token punctuation">,</span> 
    size_in_bytes<span class="token operator">=</span><span class="token number">2986697</span>
<span class="token punctuation">)</span><span class="token operator">&lt;</span><span class="token operator">/</span>https<span class="token punctuation">:</span><span class="token operator">></span><span class="token operator">&lt;</span><span class="token operator">/</span>https<span class="token punctuation">:</span><span class="token operator">></span><span class="token operator">&lt;</span><span class="token operator">/</span>https<span class="token punctuation">:</span><span class="token operator">></span><span class="token operator">&lt;</span><span class="token operator">/</span>https<span class="token punctuation">:</span><span class="token operator">></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>可以通过直接调用数据集的特定属性来请求它们</p>
<pre class="line-numbers language-python"><code class="language-python">dataset<span class="token punctuation">.</span>split
NamedSplit<span class="token punctuation">(</span><span class="token string">'train'</span><span class="token punctuation">)</span>
dataset<span class="token punctuation">.</span>description
<span class="token string">'GLUE, the General Language Understanding Evaluation benchmark\\n(&lt;https://gluebenchmark.com/>) is a collection of resources for training,\\nevaluating, and analyzing natural language understanding systems.\\n\\n'</span>
dataset<span class="token punctuation">.</span>citation
<span class="token string">'@inproceedings{dolan2005automatically,\\n  title={Automatically constructing a corpus of sentential paraphrases},\\n  author={Dolan, William B and Brockett, Chris},\\n  booktitle={Proceedings of the Third International Workshop on Paraphrasing (IWP2005)},\\n  year={2005}\\n}\\n@inproceedings{wang2019glue,\\n  title={{GLUE}: A Multi-Task Benchmark and Analysis Platform for Natural Language Understanding},\\n  author={Wang, Alex and Singh, Amanpreet and Michael, Julian and Hill, Felix and Levy, Omer and Bowman, Samuel R.},\\n  note={In the Proceedings of ICLR.},\\n  year={2019}\\n}\\n\\nNote that each GLUE dataset has its own citation. Please see the source to see\\nthe correct citation for each contained dataset.'</span>
dataset<span class="token punctuation">.</span>homepage
<span class="token string">'&lt;https://www.microsoft.com/en-us/download/details.aspx?id=52398>'</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<h3 id="功能和列"><a href="#功能和列" class="headerlink" title="功能和列"></a><strong>功能和列</strong></h3><p>数据集是行和类型化列的表。查询数据集将返回一个 Python 字典，其中键对应于列名，值对应于列值：</p>
<pre class="line-numbers language-python"><code class="language-python">dataset<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
<span class="token punctuation">{</span><span class="token string">'idx'</span><span class="token punctuation">:</span> <span class="token number">0</span><span class="token punctuation">,</span>
<span class="token string">'label'</span><span class="token punctuation">:</span> <span class="token number">1</span><span class="token punctuation">,</span>
<span class="token string">'sentence1'</span><span class="token punctuation">:</span> <span class="token string">'Amrozi accused his brother , whom he called " the witness " , of deliberately distorting his evidence .'</span><span class="token punctuation">,</span>
<span class="token string">'sentence2'</span><span class="token punctuation">:</span> <span class="token string">'Referring to him as only " the witness " , Amrozi accused his brother of deliberately distorting his evidence .'</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>返回具有以下标准属性的行数和列数：</p>
<pre class="line-numbers language-python"><code class="language-python">dataset<span class="token punctuation">.</span>shape
<span class="token punctuation">(</span><span class="token number">3668</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">)</span>
dataset<span class="token punctuation">.</span>num_columns
<span class="token number">4</span>
dataset<span class="token punctuation">.</span>num_rows
<span class="token number">3668</span>
len<span class="token punctuation">(</span>dataset<span class="token punctuation">)</span>
<span class="token number">3668</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>列出带有 <strong><a href="https://huggingface.co/docs/datasets/v2.1.0/en/package_reference/main_classes#datasets.Dataset.column_names" target="_blank" rel="noopener">Dataset.column_names（） 的</a></strong>列名称：</p>
<pre class="line-numbers language-python"><code class="language-python">dataset<span class="token punctuation">.</span>column_names
<span class="token punctuation">[</span><span class="token string">'idx'</span><span class="token punctuation">,</span> <span class="token string">'label'</span><span class="token punctuation">,</span> <span class="token string">'sentence1'</span><span class="token punctuation">,</span> <span class="token string">'sentence2'</span><span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>
<p>获取有关具有<strong><a href="https://huggingface.co/docs/datasets/v2.1.0/en/package_reference/main_classes#datasets.Features" target="_blank" rel="noopener">以下功能</a></strong>的列的详细信息：</p>
<pre class="line-numbers language-python"><code class="language-python">dataset<span class="token punctuation">.</span>features
<span class="token punctuation">{</span><span class="token string">'idx'</span><span class="token punctuation">:</span> Value<span class="token punctuation">(</span>dtype<span class="token operator">=</span><span class="token string">'int32'</span><span class="token punctuation">,</span> id<span class="token operator">=</span>None<span class="token punctuation">)</span><span class="token punctuation">,</span>
    <span class="token string">'label'</span><span class="token punctuation">:</span> ClassLabel<span class="token punctuation">(</span>num_classes<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span> names<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">'not_equivalent'</span><span class="token punctuation">,</span> <span class="token string">'equivalent'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> names_file<span class="token operator">=</span>None<span class="token punctuation">,</span> id<span class="token operator">=</span>None<span class="token punctuation">)</span><span class="token punctuation">,</span>
    <span class="token string">'sentence1'</span><span class="token punctuation">:</span> Value<span class="token punctuation">(</span>dtype<span class="token operator">=</span><span class="token string">'string'</span><span class="token punctuation">,</span> id<span class="token operator">=</span>None<span class="token punctuation">)</span><span class="token punctuation">,</span>
    <span class="token string">'sentence2'</span><span class="token punctuation">:</span> Value<span class="token punctuation">(</span>dtype<span class="token operator">=</span><span class="token string">'string'</span><span class="token punctuation">,</span> id<span class="token operator">=</span>None<span class="token punctuation">)</span><span class="token punctuation">,</span>
<span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>返回有关类<strong><a href="https://huggingface.co/docs/datasets/v2.1.0/en/package_reference/main_classes#datasets.ClassLabel" target="_blank" rel="noopener">标签</a></strong>等要素的更具体信息</p>
<pre class="line-numbers language-python"><code class="language-python">dataset<span class="token punctuation">.</span>features<span class="token punctuation">[</span><span class="token string">'label'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>num_classes
<span class="token number">2</span>
dataset<span class="token punctuation">.</span>features<span class="token punctuation">[</span><span class="token string">'label'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>names
<span class="token punctuation">[</span><span class="token string">'not_equivalent'</span><span class="token punctuation">,</span> <span class="token string">'equivalent'</span><span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre>
<h3 id="行、切片、批和列"><a href="#行、切片、批和列" class="headerlink" title="行、切片、批和列"></a><strong>行、切片、批和列</strong></h3><p>使用切片表示法或索引列表一次获取数据集的几行：</p>
<pre class="line-numbers language-python"><code class="language-python">dataset<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token number">3</span><span class="token punctuation">]</span>
<span class="token punctuation">{</span><span class="token string">'idx'</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
    <span class="token string">'label'</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
    <span class="token string">'sentence1'</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token string">'Amrozi accused his brother , whom he called " the witness " , of deliberately distorting his evidence .'</span><span class="token punctuation">,</span> <span class="token string">"Yucaipa owned Dominick 's before selling the chain to Safeway in 1998 for $ 2.5 billion ."</span><span class="token punctuation">,</span> <span class="token string">'They had published an advertisement on the Internet on June 10 , offering the cargo for sale , he added .'</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
    <span class="token string">'sentence2'</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token string">'Referring to him as only " the witness " , Amrozi accused his brother of deliberately distorting his evidence .'</span><span class="token punctuation">,</span> <span class="token string">"Yucaipa bought Dominick 's in 1995 for $ 693 million and sold it to Safeway for $ 1.8 billion in 1998 ."</span><span class="token punctuation">,</span> <span class="token string">"On June 10 , the ship 's owners had published an advertisement on the Internet , offering the explosives for sale ."</span><span class="token punctuation">]</span>
<span class="token punctuation">}</span>
dataset<span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">]</span><span class="token punctuation">]</span>
<span class="token punctuation">{</span><span class="token string">'idx'</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
    <span class="token string">'label'</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> 
    <span class="token string">'sentence1'</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token string">"Yucaipa owned Dominick 's before selling the chain to Safeway in 1998 for $ 2.5 billion ."</span><span class="token punctuation">,</span> <span class="token string">'Around 0335 GMT , Tab shares were up 19 cents , or 4.4 % , at A $ 4.56 , having earlier set a record high of A $ 4.57 .'</span><span class="token punctuation">,</span> <span class="token string">'Revenue in the first quarter of the year dropped 15 percent from the same period a year earlier .'</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
    <span class="token string">'sentence2'</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token string">"Yucaipa bought Dominick 's in 1995 for $ 693 million and sold it to Safeway for $ 1.8 billion in 1998 ."</span><span class="token punctuation">,</span> <span class="token string">'Tab shares jumped 20 cents , or 4.6 % , to set a record closing high at A $ 4.57 .'</span><span class="token punctuation">,</span> <span class="token string">"With the scandal hanging over Stewart 's company , revenue the first quarter of the year dropped 15 percent from the same period a year earlier ."</span><span class="token punctuation">]</span>
<span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>按列名查询将返回其值。例如，如果您只想返回前三个示例：</p>
<pre class="line-numbers language-python"><code class="language-python">dataset<span class="token punctuation">[</span><span class="token string">'sentence1'</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token number">3</span><span class="token punctuation">]</span>
<span class="token punctuation">[</span><span class="token string">'Amrozi accused his brother , whom he called " the witness " , of deliberately distorting his evidence .'</span><span class="token punctuation">,</span> <span class="token string">"Yucaipa owned Dominick 's before selling the chain to Safeway in 1998 for $ 2.5 billion ."</span><span class="token punctuation">,</span> <span class="token string">'They had published an advertisement on the Internet on June 10 , offering the cargo for sale , he added .'</span><span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>
<p>根据<strong><a href="https://huggingface.co/docs/datasets/v2.1.0/en/package_reference/main_classes#datasets.Dataset" target="_blank" rel="noopener">查询 Dataset</a></strong> 对象的方式，返回的格式将有所不同：</p>
<ul>
<li>像这样的单个行返回 Python 值字典。<code>dataset[0]</code></li>
<li>类似这样的批处理返回值列表的 Python 字典。<code>dataset[5:10]</code></li>
<li>类似这样的列返回 Python 值列表。<code>dataset['sentence1']</code></li>
</ul>
<h2 id="Train-with-🤗-Datasets"><a href="#Train-with-🤗-Datasets" class="headerlink" title="Train with 🤗 Datasets"></a>Train with 🤗 Datasets</h2><p>对数据集进行标记化，并将数据集与 PyTorch 或 TensorFlow 等框架配合使用。默认情况下，所有数据集列都作为 Python 对象返回。但是，您可以通过设置数据集的格式来弥合 Python 对象与机器学习框架之间的差距。格式化将列转换为兼容的 PyTorch 或 TensorFlow 类型。</p>
<p>通常，在使用数据集训练模型之前，您可能希望修改数据集的结构和内容。例如，您可能希望删除列或将其转换为其他类型。🤗 数据集提供了执行此操作所需的工具，但由于每个数据集都非常不同，因此处理方法将单独变化。</p>
<h3 id="标记化"><a href="#标记化" class="headerlink" title="标记化"></a><strong>标记化</strong></h3><p>标记化将文本划分为称为标记的单个单词。令牌被转换为数字，这是模型作为其输入接收的内容。</p>
<p>首先，安装Transformers</p>
<pre class="line-numbers language-python"><code class="language-python">pip install transformers<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<p>接下来，导入分词器。使用与您正在使用的模型关联的分词器非常重要，因此文本将以相同的方式拆分。在此示例中，加载 <strong><a href="https://huggingface.co/transformers/model_doc/bert#berttokenizerfast" target="_blank" rel="noopener">BERT 分词器，</a></strong>因为您使用的是 <strong><a href="https://huggingface.co/bert-base-cased" target="_blank" rel="noopener">BERT</a></strong>模型：</p>
<pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">from</span> transformers <span class="token keyword">import</span> BertTokenizerFast
tokenizer <span class="token operator">=</span> BertTokenizerFast<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span><span class="token string">'bert-base-cased'</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>
<p>现在，您可以对数据集的字段进行标记化：<code>sentence1</code></p>
<pre class="line-numbers language-python"><code class="language-python">encoded_dataset <span class="token operator">=</span> dataset<span class="token punctuation">.</span>map<span class="token punctuation">(</span><span class="token keyword">lambda</span> examples<span class="token punctuation">:</span> tokenizer<span class="token punctuation">(</span>examples<span class="token punctuation">[</span><span class="token string">'sentence1'</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span> batched<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
encoded_dataset<span class="token punctuation">.</span>column_names
<span class="token punctuation">[</span><span class="token string">'sentence1'</span><span class="token punctuation">,</span> <span class="token string">'sentence2'</span><span class="token punctuation">,</span> <span class="token string">'label'</span><span class="token punctuation">,</span> <span class="token string">'idx'</span><span class="token punctuation">,</span> <span class="token string">'input_ids'</span><span class="token punctuation">,</span> <span class="token string">'token_type_ids'</span><span class="token punctuation">,</span> <span class="token string">'attention_mask'</span><span class="token punctuation">]</span>
encoded_dataset<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
<span class="token punctuation">{</span><span class="token string">'sentence1'</span><span class="token punctuation">:</span> <span class="token string">'Amrozi accused his brother , whom he called " the witness " , of deliberately distorting his evidence .'</span><span class="token punctuation">,</span>
<span class="token string">'sentence2'</span><span class="token punctuation">:</span> <span class="token string">'Referring to him as only " the witness " , Amrozi accused his brother of deliberately distorting his evidence .'</span><span class="token punctuation">,</span>
<span class="token string">'label'</span><span class="token punctuation">:</span> <span class="token number">1</span><span class="token punctuation">,</span>
<span class="token string">'idx'</span><span class="token punctuation">:</span> <span class="token number">0</span><span class="token punctuation">,</span>
<span class="token string">'input_ids'</span><span class="token punctuation">:</span> <span class="token punctuation">[</span>  <span class="token number">101</span><span class="token punctuation">,</span>  <span class="token number">7277</span><span class="token punctuation">,</span>  <span class="token number">2180</span><span class="token punctuation">,</span>  <span class="token number">5303</span><span class="token punctuation">,</span>  <span class="token number">4806</span><span class="token punctuation">,</span>  <span class="token number">1117</span><span class="token punctuation">,</span>  <span class="token number">1711</span><span class="token punctuation">,</span>   <span class="token number">117</span><span class="token punctuation">,</span>  <span class="token number">2292</span><span class="token punctuation">,</span> <span class="token number">1119</span><span class="token punctuation">,</span>  <span class="token number">1270</span><span class="token punctuation">,</span>   <span class="token number">107</span><span class="token punctuation">,</span>  <span class="token number">1103</span><span class="token punctuation">,</span>  <span class="token number">7737</span><span class="token punctuation">,</span>   <span class="token number">107</span><span class="token punctuation">,</span>   <span class="token number">117</span><span class="token punctuation">,</span>  <span class="token number">1104</span><span class="token punctuation">,</span>  <span class="token number">9938</span><span class="token punctuation">,</span> <span class="token number">4267</span><span class="token punctuation">,</span> <span class="token number">12223</span><span class="token punctuation">,</span> <span class="token number">21811</span><span class="token punctuation">,</span>  <span class="token number">1117</span><span class="token punctuation">,</span>  <span class="token number">2554</span><span class="token punctuation">,</span>   <span class="token number">119</span><span class="token punctuation">,</span>   <span class="token number">102</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
<span class="token string">'token_type_ids'</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
<span class="token string">'attention_mask'</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span>
<span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>标记化过程将创建三个新列：<code>input_ids</code>、<code>token_type_ids</code>、<code>attention_mask</code> 。这些是模型的输入。</p>
<h3 id="PyTorch"><a href="#PyTorch" class="headerlink" title="PyTorch"></a><strong>PyTorch</strong></h3><p>如果使用的是 PyTorch，请使用 <strong><a href="https://huggingface.co/docs/datasets/v2.1.0/en/package_reference/main_classes#datasets.Dataset.set_format" target="_blank" rel="noopener">Dataset.set_format（）</a></strong> 设置格式，它接受两个主要参数：</p>
<ol>
<li><code>type</code>定义要强制转换为的列的类型。例如<code>torch</code>，返回 PyTorch 张量。</li>
<li><code>columns</code>指定应设置格式的列。</li>
</ol>
<p>设置格式后，使用 包装数据集。您的数据集现在已准备好在训练循环中使用！<code>torch.utils.data.DataLoader</code></p>
<pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">import</span> torch
<span class="token keyword">from</span> datasets <span class="token keyword">import</span> load_dataset
<span class="token keyword">from</span> transformers <span class="token keyword">import</span> AutoTokenizer
dataset <span class="token operator">=</span> load_dataset<span class="token punctuation">(</span><span class="token string">'glue'</span><span class="token punctuation">,</span> <span class="token string">'mrpc'</span><span class="token punctuation">,</span> split<span class="token operator">=</span><span class="token string">'train'</span><span class="token punctuation">)</span>
tokenizer <span class="token operator">=</span> AutoTokenizer<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span><span class="token string">'bert-base-cased'</span><span class="token punctuation">)</span>
dataset <span class="token operator">=</span> dataset<span class="token punctuation">.</span>map<span class="token punctuation">(</span><span class="token keyword">lambda</span> e<span class="token punctuation">:</span> tokenizer<span class="token punctuation">(</span>e<span class="token punctuation">[</span><span class="token string">'sentence1'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> truncation<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token string">'max_length'</span><span class="token punctuation">)</span><span class="token punctuation">,</span> batched<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
dataset<span class="token punctuation">.</span>set_format<span class="token punctuation">(</span>type<span class="token operator">=</span><span class="token string">'torch'</span><span class="token punctuation">,</span> columns<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">'input_ids'</span><span class="token punctuation">,</span> <span class="token string">'token_type_ids'</span><span class="token punctuation">,</span> <span class="token string">'attention_mask'</span><span class="token punctuation">,</span> <span class="token string">'label'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
dataloader <span class="token operator">=</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data<span class="token punctuation">.</span>DataLoader<span class="token punctuation">(</span>dataset<span class="token punctuation">,</span> batch_size<span class="token operator">=</span><span class="token number">32</span><span class="token punctuation">)</span>
next<span class="token punctuation">(</span>iter<span class="token punctuation">(</span>dataloader<span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token punctuation">{</span><span class="token string">'attention_mask'</span><span class="token punctuation">:</span> tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span>  <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
                         <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">,</span>
                         <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span>  <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
<span class="token string">'input_ids'</span><span class="token punctuation">:</span> tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span>  <span class="token number">101</span><span class="token punctuation">,</span>  <span class="token number">7277</span><span class="token punctuation">,</span>  <span class="token number">2180</span><span class="token punctuation">,</span>  <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">,</span>     <span class="token number">0</span><span class="token punctuation">,</span>     <span class="token number">0</span><span class="token punctuation">,</span>     <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
                    <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">,</span>
                    <span class="token punctuation">[</span>  <span class="token number">101</span><span class="token punctuation">,</span>  <span class="token number">1109</span><span class="token punctuation">,</span>  <span class="token number">4173</span><span class="token punctuation">,</span>  <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">,</span>     <span class="token number">0</span><span class="token punctuation">,</span>     <span class="token number">0</span><span class="token punctuation">,</span>     <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
<span class="token string">'label'</span><span class="token punctuation">:</span> tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
<span class="token string">'token_type_ids'</span><span class="token punctuation">:</span> tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span>  <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
                         <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">,</span>
                         <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span>  <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<h2 id="评估预测（Evaluate-predictions）"><a href="#评估预测（Evaluate-predictions）" class="headerlink" title="评估预测（Evaluate predictions）"></a>评估预测（Evaluate predictions）</h2><p>数据集提供了各种常见和特定于 NLP <strong><a href="https://huggingface.co/metrics" target="_blank" rel="noopener">的指标</a></strong>，供您衡量模型性能。在本教程的此部分中，您将加载一个指标，并使用它来评估模型预测。</p>
<p>您可以查看<strong><a href="https://huggingface.co/docs/datasets/v2.1.0/en/package_reference/loading_methods#datasets.list_metrics" target="_blank" rel="noopener">list_metrics（）</a></strong>提供了哪些指标：</p>
<pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">from</span> datasets <span class="token keyword">import</span> list_metrics
metrics_list <span class="token operator">=</span> list_metrics<span class="token punctuation">(</span><span class="token punctuation">)</span>
len<span class="token punctuation">(</span>metrics_list<span class="token punctuation">)</span>
<span class="token number">28</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>metrics_list<span class="token punctuation">)</span>
<span class="token punctuation">[</span><span class="token string">'accuracy'</span><span class="token punctuation">,</span> <span class="token string">'bertscore'</span><span class="token punctuation">,</span> <span class="token string">'bleu'</span><span class="token punctuation">,</span> <span class="token string">'bleurt'</span><span class="token punctuation">,</span> <span class="token string">'cer'</span><span class="token punctuation">,</span> <span class="token string">'comet'</span><span class="token punctuation">,</span> <span class="token string">'coval'</span><span class="token punctuation">,</span> <span class="token string">'cuad'</span><span class="token punctuation">,</span> <span class="token string">'f1'</span><span class="token punctuation">,</span> <span class="token string">'gleu'</span><span class="token punctuation">,</span> <span class="token string">'glue'</span><span class="token punctuation">,</span> <span class="token string">'indic_glue'</span><span class="token punctuation">,</span> <span class="token string">'matthews_correlation'</span><span class="token punctuation">,</span> <span class="token string">'meteor'</span><span class="token punctuation">,</span> <span class="token string">'pearsonr'</span><span class="token punctuation">,</span> <span class="token string">'precision'</span><span class="token punctuation">,</span> <span class="token string">'recall'</span><span class="token punctuation">,</span> <span class="token string">'rouge'</span><span class="token punctuation">,</span> <span class="token string">'sacrebleu'</span><span class="token punctuation">,</span> <span class="token string">'sari'</span><span class="token punctuation">,</span> <span class="token string">'seqeval'</span><span class="token punctuation">,</span> <span class="token string">'spearmanr'</span><span class="token punctuation">,</span> <span class="token string">'squad'</span><span class="token punctuation">,</span> <span class="token string">'squad_v2'</span><span class="token punctuation">,</span> <span class="token string">'super_glue'</span><span class="token punctuation">,</span> <span class="token string">'wer'</span><span class="token punctuation">,</span> <span class="token string">'wiki_split'</span><span class="token punctuation">,</span> <span class="token string">'xnli'</span><span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<h3 id="负载指标"><a href="#负载指标" class="headerlink" title="负载指标"></a><strong>负载指标</strong></h3><p>使用🤗数据集加载指标非常容易。实际上，您会注意到它与加载数据集非常相似！使用 <strong><a href="https://huggingface.co/docs/datasets/v2.1.0/en/package_reference/loading_methods#datasets.load_metric" target="_blank" rel="noopener">load_metric（）</a></strong>从中心加载指标：</p>
<pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">from</span> datasets <span class="token keyword">import</span> load_metric
metric <span class="token operator">=</span> load_metric<span class="token punctuation">(</span><span class="token string">'glue'</span><span class="token punctuation">,</span> <span class="token string">'mrpc'</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>
<p>这将从 GLUE 基准测试加载与 MRPC 数据集关联的指标。</p>
<h3 id="选择配置-1"><a href="#选择配置-1" class="headerlink" title="选择配置"></a><strong>选择配置</strong></h3><p>如果您使用的是基准数据集，则需要选择与所使用的配置关联的指标。通过提供配置名称来选择指标配置：</p>
<pre class="line-numbers language-python"><code class="language-python">metric <span class="token operator">=</span> load_metric<span class="token punctuation">(</span><span class="token string">'glue'</span><span class="token punctuation">,</span> <span class="token string">'mrpc'</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<h3 id="衡量指标对象"><a href="#衡量指标对象" class="headerlink" title="衡量指标对象"></a><strong>衡量指标对象</strong></h3><p>在开始使用<strong><a href="https://huggingface.co/docs/datasets/v2.1.0/en/package_reference/main_classes#datasets.Metric" target="_blank" rel="noopener">衡量指标</a></strong>对象之前，您应该更好地了解它。与数据集一样，您可以返回有关指标的一些基本信息。例如，访问数据集中的参数<strong><a href="https://huggingface.co/docs/datasets/v2.1.0/en/package_reference/main_classes#datasets.MetricInfo" target="_blank" rel="noopener">MetricInfo</a></strong></p>
<pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">print</span><span class="token punctuation">(</span>metric<span class="token punctuation">.</span>inputs_description<span class="token punctuation">)</span>
Compute GLUE evaluation metric associated to each GLUE dataset<span class="token punctuation">.</span>
Args<span class="token punctuation">:</span>
    predictions<span class="token punctuation">:</span> list of predictions to score<span class="token punctuation">.</span>
        Each translation should be tokenized into a list of tokens<span class="token punctuation">.</span>
    references<span class="token punctuation">:</span> list of lists of references <span class="token keyword">for</span> each translation<span class="token punctuation">.</span>
        Each reference should be tokenized into a list of tokens<span class="token punctuation">.</span>
Returns<span class="token punctuation">:</span> depending on the GLUE subset<span class="token punctuation">,</span> one <span class="token operator">or</span> several of<span class="token punctuation">:</span>
    <span class="token string">"accuracy"</span><span class="token punctuation">:</span> Accuracy
    <span class="token string">"f1"</span><span class="token punctuation">:</span> F1 score
    <span class="token string">"pearson"</span><span class="token punctuation">:</span> Pearson Correlation
    <span class="token string">"spearmanr"</span><span class="token punctuation">:</span> Spearman Correlation
    <span class="token string">"matthews_correlation"</span><span class="token punctuation">:</span> Matthew Correlation
Examples<span class="token punctuation">:</span>
    <span class="token operator">>></span><span class="token operator">></span> glue_metric <span class="token operator">=</span> datasets<span class="token punctuation">.</span>load_metric<span class="token punctuation">(</span><span class="token string">'glue'</span><span class="token punctuation">,</span> <span class="token string">'sst2'</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># 'sst2' or any of ["mnli", "mnli_mismatched", "mnli_matched", "qnli", "rte", "wnli", "hans"]</span>
    <span class="token operator">>></span><span class="token operator">></span> references <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span>
    <span class="token operator">>></span><span class="token operator">></span> predictions <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span>
    <span class="token operator">>></span><span class="token operator">></span> results <span class="token operator">=</span> glue_metric<span class="token punctuation">.</span>compute<span class="token punctuation">(</span>predictions<span class="token operator">=</span>predictions<span class="token punctuation">,</span> references<span class="token operator">=</span>references<span class="token punctuation">)</span>
    <span class="token operator">>></span><span class="token operator">></span> <span class="token keyword">print</span><span class="token punctuation">(</span>results<span class="token punctuation">)</span>
    <span class="token punctuation">{</span><span class="token string">'accuracy'</span><span class="token punctuation">:</span> <span class="token number">1.0</span><span class="token punctuation">}</span>
    <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>
    <span class="token operator">>></span><span class="token operator">></span> glue_metric <span class="token operator">=</span> datasets<span class="token punctuation">.</span>load_metric<span class="token punctuation">(</span><span class="token string">'glue'</span><span class="token punctuation">,</span> <span class="token string">'mrpc'</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># 'mrpc' or 'qqp'</span>
    <span class="token operator">>></span><span class="token operator">></span> references <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span>
    <span class="token operator">>></span><span class="token operator">></span> predictions <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span>
    <span class="token operator">>></span><span class="token operator">></span> results <span class="token operator">=</span> glue_metric<span class="token punctuation">.</span>compute<span class="token punctuation">(</span>predictions<span class="token operator">=</span>predictions<span class="token punctuation">,</span> references<span class="token operator">=</span>references<span class="token punctuation">)</span>
    <span class="token operator">>></span><span class="token operator">></span> <span class="token keyword">print</span><span class="token punctuation">(</span>results<span class="token punctuation">)</span>
    <span class="token punctuation">{</span><span class="token string">'accuracy'</span><span class="token punctuation">:</span> <span class="token number">1.0</span><span class="token punctuation">,</span> <span class="token string">'f1'</span><span class="token punctuation">:</span> <span class="token number">1.0</span><span class="token punctuation">}</span>
    <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>请注意，对于 MRPC 配置，指标期望输入格式为零或 1。有关可随指标一起返回的属性的完整列表，请查看 <strong><a href="https://huggingface.co/docs/datasets/v2.1.0/en/package_reference/main_classes#datasets.MetricInfo" target="_blank" rel="noopener">MetricInfo</a></strong>。</p>
<h3 id="计算指标"><a href="#计算指标" class="headerlink" title="计算指标"></a><strong>计算指标</strong></h3><p>加载指标后，即可使用它来评估模型预测。提供对 <strong><a href="https://huggingface.co/docs/datasets/v2.1.0/en/package_reference/main_classes#datasets.Metric.compute" target="_blank" rel="noopener">compute（）</a></strong> 的模型预测和引用：</p>
<pre class="line-numbers language-python"><code class="language-python">model_predictions <span class="token operator">=</span> model<span class="token punctuation">(</span>model_inputs<span class="token punctuation">)</span>
final_score <span class="token operator">=</span> metric<span class="token punctuation">.</span>compute<span class="token punctuation">(</span>predictions<span class="token operator">=</span>model_predictions<span class="token punctuation">,</span> references<span class="token operator">=</span>gold_references<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>
<h1 id="实践-FineTune-Practice"><a href="#实践-FineTune-Practice" class="headerlink" title="实践 FineTune Practice"></a>实践 FineTune Practice</h1><h2 id="NER"><a href="#NER" class="headerlink" title="NER"></a>NER</h2><ul>
<li>PKU中文分词数据集微调基本逻辑</li>
</ul>
<pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">import</span> torch
<span class="token keyword">from</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data <span class="token keyword">import</span> Dataset<span class="token punctuation">,</span> DataLoader<span class="token punctuation">,</span> random_split
<span class="token keyword">from</span> data_process <span class="token keyword">import</span> DataGenerator
<span class="token keyword">from</span> transformers <span class="token keyword">import</span> AutoTokenizer<span class="token punctuation">,</span> BertTokenizer<span class="token punctuation">,</span> BertModel<span class="token punctuation">,</span> AutoModelForTokenClassification<span class="token punctuation">,</span> DataCollatorForTokenClassification
<span class="token keyword">from</span> transformers <span class="token keyword">import</span> TrainingArguments<span class="token punctuation">,</span> Trainer

torch<span class="token punctuation">.</span>manual_seed<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span>

<span class="token comment" spellcheck="true"># 加载预训练模型和分词器</span>
tokenizer <span class="token operator">=</span> AutoTokenizer<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span><span class="token string">"/nfs/volume-1280-3/rushin/work/models/hfl/chinese-roberta-wwm-ext"</span><span class="token punctuation">)</span>
model <span class="token operator">=</span> AutoModelForTokenClassification<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span><span class="token string">"/nfs/volume-1280-3/rushin/work/models/hfl/chinese-roberta-wwm-ext"</span><span class="token punctuation">,</span> num_labels<span class="token operator">=</span><span class="token number">4</span><span class="token punctuation">)</span>
data_collator <span class="token operator">=</span> DataCollatorForTokenClassification<span class="token punctuation">(</span>tokenizer<span class="token operator">=</span>tokenizer<span class="token punctuation">)</span>

<span class="token comment" spellcheck="true"># Load Data，加载文本数据List(corpus)和标签数据List[list](labels)</span>
data_path <span class="token operator">=</span> <span class="token string">"../seg-data/training/pku_training.utf8"</span>
generator <span class="token operator">=</span> DataGenerator<span class="token punctuation">(</span>data_path<span class="token punctuation">)</span>
corpus<span class="token punctuation">,</span> labels <span class="token operator">=</span> generator<span class="token punctuation">.</span>generate_train_data<span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token comment" spellcheck="true"># 切分训练集和验证集</span>
l <span class="token operator">=</span> len<span class="token punctuation">(</span>corpus<span class="token punctuation">)</span>
train_size <span class="token operator">=</span> int<span class="token punctuation">(</span>l<span class="token operator">*</span><span class="token number">0.8</span><span class="token punctuation">)</span>

train_corpus <span class="token operator">=</span> corpus<span class="token punctuation">[</span><span class="token punctuation">:</span>train_size<span class="token punctuation">]</span>
valid_corpus <span class="token operator">=</span> corpus<span class="token punctuation">[</span>train_size<span class="token punctuation">:</span><span class="token punctuation">]</span>
train_labels <span class="token operator">=</span> labels<span class="token punctuation">[</span><span class="token punctuation">:</span>train_size<span class="token punctuation">]</span>
valid_labels <span class="token operator">=</span> labels<span class="token punctuation">[</span>train_size<span class="token punctuation">:</span><span class="token punctuation">]</span>

<span class="token comment" spellcheck="true"># 构造训练和验证数据字典，主要需要tokenizer返回的字典数据加上labels属性</span>
<span class="token keyword">def</span> <span class="token function">tokenize_and_align_labels</span><span class="token punctuation">(</span>corpus<span class="token punctuation">,</span> corpus_labels<span class="token punctuation">)</span><span class="token punctuation">:</span>
    tokenized_inputs <span class="token operator">=</span> tokenizer<span class="token punctuation">(</span>corpus<span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> truncation<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> max_length<span class="token operator">=</span><span class="token number">512</span><span class="token punctuation">)</span>
    labels <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
    <span class="token keyword">for</span> i<span class="token punctuation">,</span> label <span class="token keyword">in</span> enumerate<span class="token punctuation">(</span>corpus_labels<span class="token punctuation">)</span><span class="token punctuation">:</span>
        word_ids <span class="token operator">=</span> tokenized_inputs<span class="token punctuation">.</span>word_ids<span class="token punctuation">(</span>batch_index<span class="token operator">=</span>i<span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># Map tokens to their respective word.</span>
        label_ids <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
        <span class="token keyword">for</span> word_idx <span class="token keyword">in</span> word_ids<span class="token punctuation">:</span>  <span class="token comment" spellcheck="true"># Set the special tokens to -100.</span>
            <span class="token keyword">if</span> word_idx <span class="token keyword">is</span> None<span class="token punctuation">:</span>
                label_ids<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">100</span><span class="token punctuation">)</span>
            <span class="token keyword">else</span><span class="token punctuation">:</span>
                label_ids<span class="token punctuation">.</span>append<span class="token punctuation">(</span>label<span class="token punctuation">[</span>word_idx<span class="token punctuation">]</span><span class="token punctuation">)</span>
        labels<span class="token punctuation">.</span>append<span class="token punctuation">(</span>label_ids<span class="token punctuation">)</span>

    tokenized_inputs<span class="token punctuation">[</span><span class="token string">"labels"</span><span class="token punctuation">]</span> <span class="token operator">=</span> labels
    <span class="token keyword">return</span> tokenized_inputs

train_encoding <span class="token operator">=</span> tokenize_and_align_labels<span class="token punctuation">(</span>train_corpus<span class="token punctuation">,</span> train_labels<span class="token punctuation">)</span>
valid_encoding <span class="token operator">=</span> tokenize_and_align_labels<span class="token punctuation">(</span>valid_corpus<span class="token punctuation">,</span> valid_labels<span class="token punctuation">)</span>

<span class="token comment" spellcheck="true"># 构造Dataset类</span>
<span class="token keyword">class</span> <span class="token class-name">TokenDataset</span><span class="token punctuation">(</span>Dataset<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> encoding<span class="token punctuation">)</span><span class="token punctuation">:</span>
        super<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>encoding <span class="token operator">=</span> encoding

    <span class="token keyword">def</span> <span class="token function">__getitem__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> idx<span class="token punctuation">)</span><span class="token punctuation">:</span>
        item <span class="token operator">=</span> <span class="token punctuation">{</span>key<span class="token punctuation">:</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span>val<span class="token punctuation">[</span>idx<span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token keyword">for</span> key<span class="token punctuation">,</span> val <span class="token keyword">in</span> self<span class="token punctuation">.</span>encoding<span class="token punctuation">.</span>items<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">}</span>
        <span class="token keyword">return</span> item

    <span class="token keyword">def</span> <span class="token function">__len__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">return</span> len<span class="token punctuation">(</span>self<span class="token punctuation">.</span>encoding<span class="token punctuation">[</span><span class="token string">"labels"</span><span class="token punctuation">]</span><span class="token punctuation">)</span> 

<span class="token comment" spellcheck="true"># 生成训练和验证数据对象</span>
train_data <span class="token operator">=</span> TokenDataset<span class="token punctuation">(</span>train_encoding<span class="token punctuation">)</span>
valid_data <span class="token operator">=</span> TokenDataset<span class="token punctuation">(</span>valid_encoding<span class="token punctuation">)</span>

<span class="token comment" spellcheck="true"># 设置训练参数</span>
training_args <span class="token operator">=</span> TrainingArguments<span class="token punctuation">(</span>
    output_dir<span class="token operator">=</span><span class="token string">"./results/chinese-roberta-wwm-ext"</span><span class="token punctuation">,</span>
    evaluation_strategy<span class="token operator">=</span><span class="token string">"epoch"</span><span class="token punctuation">,</span>
    learning_rate<span class="token operator">=</span><span class="token number">2e</span><span class="token operator">-</span><span class="token number">5</span><span class="token punctuation">,</span>
    per_device_train_batch_size<span class="token operator">=</span><span class="token number">16</span><span class="token punctuation">,</span>
    per_device_eval_batch_size<span class="token operator">=</span><span class="token number">16</span><span class="token punctuation">,</span>
    num_train_epochs<span class="token operator">=</span><span class="token number">300</span><span class="token punctuation">,</span>
    weight_decay<span class="token operator">=</span><span class="token number">0.01</span><span class="token punctuation">,</span>
<span class="token punctuation">)</span>

trainer <span class="token operator">=</span> Trainer<span class="token punctuation">(</span>
    model<span class="token operator">=</span>model<span class="token punctuation">,</span>
    args<span class="token operator">=</span>training_args<span class="token punctuation">,</span>
    train_dataset<span class="token operator">=</span>train_data<span class="token punctuation">,</span>
    eval_dataset<span class="token operator">=</span>valid_data<span class="token punctuation">,</span>
    tokenizer<span class="token operator">=</span>tokenizer<span class="token punctuation">,</span>
    data_collator<span class="token operator">=</span>data_collator<span class="token punctuation">,</span>
<span class="token punctuation">)</span>

<span class="token comment" spellcheck="true"># 开始训练</span>
trainer<span class="token punctuation">.</span>train<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<ul>
<li>总结：对于预训练过程<ul>
<li>首先，需要根据任务确认数据集需要的属性字段信息，构造出针对该任务的数据集类，这一步也是关键的一步。<ul>
<li>分析数据集的属性，根据文本进行tokenize，将tokens变成input_ids，</li>
<li>labels根据原始数据生成模型需要的labels属性。</li>
</ul>
</li>
<li>构造出基本数据后，直接按照transformers训练模板设置参数训练即可</li>
</ul>
</li>
</ul>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        文章作者:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://jackhcc.github.io" rel="external nofollow noreferrer">杰克成</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        文章链接:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://jackhcc.github.io/posts/transformers-lib.html">https://jackhcc.github.io/posts/transformers-lib.html</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        版权声明:
                    </i>
                </span>
                <span class="reprint-info">
                    本博客所有文章除特別声明外，均采用
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    许可协议。转载请注明来源
                    <a href="https://jackhcc.github.io" target="_blank">杰克成</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>复制成功，请遵循本文的转载规则</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">查看</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/tags/Deep-Learning/">
                                    <span class="chip bg-color">Deep Learning</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/libs/share/css/share.min.css">

<div id="article-share">
    
    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>微信扫一扫即可分享！</p>"></div>
    <script src="https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
                <style>
    #reward {
        margin: 40px 0;
        text-align: center;
    }

    #reward .reward-link {
        font-size: 1.4rem;
        line-height: 38px;
    }

    #reward .btn-floating:hover {
        box-shadow: 0 6px 12px rgba(0, 0, 0, 0.2), 0 5px 15px rgba(0, 0, 0, 0.2);
    }

    #rewardModal {
        width: 320px;
        height: 350px;
    }

    #rewardModal .reward-title {
        margin: 15px auto;
        padding-bottom: 5px;
    }

    #rewardModal .modal-content {
        padding: 10px;
    }

    #rewardModal .close {
        position: absolute;
        right: 15px;
        top: 15px;
        color: rgba(0, 0, 0, 0.5);
        font-size: 1.3rem;
        line-height: 20px;
        cursor: pointer;
    }

    #rewardModal .close:hover {
        color: #ef5350;
        transform: scale(1.3);
        -moz-transform:scale(1.3);
        -webkit-transform:scale(1.3);
        -o-transform:scale(1.3);
    }

    #rewardModal .reward-tabs {
        margin: 0 auto;
        width: 210px;
    }

    .reward-tabs .tabs {
        height: 38px;
        margin: 10px auto;
        padding-left: 0;
    }

    .reward-content ul {
        padding-left: 0 !important;
    }

    .reward-tabs .tabs .tab {
        height: 38px;
        line-height: 38px;
    }

    .reward-tabs .tab a {
        color: #fff;
        background-color: #ccc;
    }

    .reward-tabs .tab a:hover {
        background-color: #ccc;
        color: #fff;
    }

    .reward-tabs .wechat-tab .active {
        color: #fff !important;
        background-color: #22AB38 !important;
    }

    .reward-tabs .alipay-tab .active {
        color: #fff !important;
        background-color: #019FE8 !important;
    }

    .reward-tabs .reward-img {
        width: 210px;
        height: 210px;
    }
</style>

<div id="reward">
    <a href="#rewardModal" class="reward-link modal-trigger btn-floating btn-medium waves-effect waves-light red">赏</a>

    <!-- Modal Structure -->
    <div id="rewardModal" class="modal">
        <div class="modal-content">
            <a class="close modal-close"><i class="fas fa-times"></i></a>
            <h4 class="reward-title">你的赏识是我前进的动力</h4>
            <div class="reward-content">
                <div class="reward-tabs">
                    <ul class="tabs row">
                        <li class="tab col s6 alipay-tab waves-effect waves-light"><a href="#alipay">支付宝</a></li>
                        <li class="tab col s6 wechat-tab waves-effect waves-light"><a href="#wechat">微 信</a></li>
                    </ul>
                    <div id="alipay">
                        <img src="/images/loading.gif" data-original="https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/medias/reward/aliqr.png" class="reward-img" alt="支付宝打赏二维码">
                    </div>
                    <div id="wechat">
                        <img src="/images/loading.gif" data-original="https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/medias/reward/wxqr.png" class="reward-img" alt="微信打赏二维码">
                    </div>
                </div>
            </div>
        </div>
    </div>
</div>

<script>
    $(function () {
        $('.tabs').tabs();
    });
</script>
            
        </div>
    </div>

    
        <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/libs/gitalk/gitalk.css">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/css/my-gitalk.css">

<div class="card gitalk-card" data-aos="fade-up">
    <div class="comment_headling" style="font-size: 20px; font-weight: 700; position: relative; left: 20px; top: 15px; padding-bottom: 5px;">
        <i class="fas fa-comments fa-fw" aria-hidden="true"></i>
        <span>评论</span>
    </div>
    <div id="gitalk-container" class="card-content"></div>
</div>

<script src="https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/libs/gitalk/gitalk.min.js"></script>
<script>
    let gitalk = new Gitalk({
        clientID: '3821a0bbb773038a51fc',
        clientSecret: '4b30b507d67ec5497ec0e77f43f80cb3e0d7dd3a',
        repo: 'JackHCC.github.io',
        owner: 'JackHCC',
        admin: "JackHCC",
        id: '2022-05-01T10-33-13',
        distractionFreeMode: false  // Facebook-like distraction free mode
    });

    gitalk.render('gitalk-container');
</script>
    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="far fa-dot-circle"></i>&nbsp;本篇
            </div>
            <div class="card">
                <a href="/posts/transformers-lib.html">
                    <div class="card-image">
                        
                        
                        <img src="/images/loading.gif" data-original="https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/medias/featureimages/0.jpg" class="responsive-img" alt="Transformers包详解">
                        
                        <span class="card-title">Transformers包详解</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            Transformers实践手册
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2022-05-01
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/categories/Transformers/" class="post-category">
                                    Transformers
                                </a>
                            
                            
                        </span>
                    </div>
                </div>

                
                <div class="card-action article-tags">
                    
                    <a href="/tags/Deep-Learning/">
                        <span class="chip bg-color">Deep Learning</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                下一篇&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/posts/neo4j.html">
                    <div class="card-image">
                        
                        
                        <img src="/images/loading.gif" data-original="https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/medias/featureimages/12.jpg" class="responsive-img" alt="neo4j基础">
                        
                        <span class="card-title">neo4j基础</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            neo4j学习笔记
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2022-04-30
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/categories/Database/" class="post-category">
                                    Database
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/tags/Neo4j/">
                        <span class="chip bg-color">Neo4j</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- 代码块功能依赖 -->
<script type="text/javascript" src="https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/libs/codeBlock/codeBlockFuction.js"></script>

<!-- 代码语言 -->

<script type="text/javascript" src="https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/libs/codeBlock/codeLang.js"></script>


<!-- 代码块复制 -->

<script type="text/javascript" src="https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/libs/codeBlock/codeCopy.js"></script>


<!-- 代码块收缩 -->

<script type="text/javascript" src="https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/libs/codeBlock/codeShrink.js"></script>


<!-- 代码块折行 -->

<style type="text/css">
code[class*="language-"], pre[class*="language-"] { white-space: pre !important; }
</style>


    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;目录</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC 悬浮按钮. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('4'),
            headingSelector: 'h1, h2, h3, h4'
        });

        // modify the toc link href to support Chinese.
        let i = 0;
        let tocHeading = 'toc-heading-';
        $('#toc-content a').each(function () {
            $(this).attr('href', '#' + tocHeading + (++i));
        });

        // modify the heading title id to support Chinese.
        i = 0;
        $('#articleContent').children('h1, h2, h3, h4').each(function () {
            $(this).attr('id', tocHeading + (++i));
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* 修复文章卡片 div 的宽度. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // 切换TOC目录展开收缩的相关操作.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>

    

</main>



    <footer class="page-footer bg-color">
    <div class="container row center-align" style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            <span id="year">2020</span>
            <a href="https://jackhcc.github.io" target="_blank">杰克成</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            <br>
            
            &nbsp;<i class="fas fa-chart-area"></i>&nbsp;站点总字数:&nbsp;<span
                class="white-color">3591.2k</span>&nbsp;字
            
            
            
            
            
            
            <span id="busuanzi_container_site_pv">
                |&nbsp;<i class="far fa-eye"></i>&nbsp;总访问量:&nbsp;<span id="busuanzi_value_site_pv"
                    class="white-color"></span>&nbsp;次
            </span>
            
            
            <span id="busuanzi_container_site_uv">
                |&nbsp;<i class="fas fa-users"></i>&nbsp;总访问人数:&nbsp;<span id="busuanzi_value_site_uv"
                    class="white-color"></span>&nbsp;人
            </span>
            
            <br>
            
            <span id="sitetime">载入运行时间...</span>
            <script>
                function siteTime() {
                    var seconds = 1000;
                    var minutes = seconds * 60;
                    var hours = minutes * 60;
                    var days = hours * 24;
                    var years = days * 365;
                    var today = new Date();
                    var startYear = "2020";
                    var startMonth = "2";
                    var startDate = "27";
                    var startHour = "6";
                    var startMinute = "30";
                    var startSecond = "0";
                    var todayYear = today.getFullYear();
                    var todayMonth = today.getMonth() + 1;
                    var todayDate = today.getDate();
                    var todayHour = today.getHours();
                    var todayMinute = today.getMinutes();
                    var todaySecond = today.getSeconds();
                    var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                    var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                    var diff = t2 - t1;
                    var diffYears = Math.floor(diff / years);
                    var diffDays = Math.floor((diff / days) - diffYears * 365);
                    var diffHours = Math.floor((diff - (diffYears * 365 + diffDays) * days) / hours);
                    var diffMinutes = Math.floor((diff - (diffYears * 365 + diffDays) * days - diffHours * hours) /
                        minutes);
                    var diffSeconds = Math.floor((diff - (diffYears * 365 + diffDays) * days - diffHours * hours -
                        diffMinutes * minutes) / seconds);
                    if (startYear == todayYear) {
                        document.getElementById("year").innerHTML = todayYear;
                        document.getElementById("sitetime").innerHTML = "本站已安全运行 " + diffDays + " 天 " + diffHours +
                            " 小时 " + diffMinutes + " 分钟 " + diffSeconds + " 秒";
                    } else {
                        document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                        document.getElementById("sitetime").innerHTML = "本站已安全运行 " + diffYears + " 年 " + diffDays +
                            " 天 " + diffHours + " 小时 " + diffMinutes + " 分钟 " + diffSeconds + " 秒";
                    }
                }
                setInterval(siteTime, 1000);
            </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/JackHCC" class="tooltipped" target="_blank" data-tooltip="访问我的GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:jackcc0701@163.com" class="tooltipped" target="_blank" data-tooltip="邮件联系我" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>



    <a href="https://www.facebook.com/profile.php?id=100046343443643" class="tooltipped" target="_blank" data-tooltip="关注我的Facebook: https://www.facebook.com/profile.php?id=100046343443643" data-position="top" data-delay="50">
        <i class="fab fa-facebook-f"></i>
    </a>



    <a href="https://twitter.com/JackChe66021834" class="tooltipped" target="_blank" data-tooltip="关注我的Twitter: https://twitter.com/JackChe66021834" data-position="top" data-delay="50">
        <i class="fab fa-twitter"></i>
    </a>



    <a href="tencent://AddContact/?fromId=50&fromSubId=1&subcmd=all&uin=2508074836" class="tooltipped" target="_blank" data-tooltip="QQ联系我: 2508074836" data-position="top" data-delay="50">
        <i class="fab fa-qq"></i>
    </a>



    <a href="https://weibo.com/u/6885584679" class="tooltipped" target="_blank" data-tooltip="关注我的微博: https://weibo.com/u/6885584679" data-position="top" data-delay="50">
        <i class="fab fa-weibo"></i>
    </a>



    <a href="https://www.zhihu.com/people/8f8482f01f0d6a04e844efe32e0f0710" class="tooltipped" target="_blank" data-tooltip="关注我的知乎: https://www.zhihu.com/people/8f8482f01f0d6a04e844efe32e0f0710" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">知</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- 搜索遮罩框 -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;搜索</span>
            <input type="search" id="searchInput" name="s" placeholder="请输入搜索的关键字"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script src="https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/js/search.js"></script>
<script type="text/javascript">
$(function () {
    searchFunc("https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/" + "search.xml", 'searchInput', 'searchResult');
});
</script>
    <!-- 回到顶部按钮 -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/libs/materialize/materialize.min.js"></script>
    <script src="https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/libs/aos/aos.js"></script>
    <script src="https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/js/matery.js"></script>

    <canvas class="fireworks" style="position: fixed;left: 0;top: 0;z-index: 1; pointer-events: none;" ></canvas>
    <script type="text/javascript" src="//cdn.bootcss.com/animejs/2.2.0/anime.min.js"></script>
    <script type="text/javascript" src="/js/fireworks.js"></script>

    <script type="text/javascript">
        //只在桌面版网页启用特效
        var windowWidth = $(window).width();
        if (windowWidth > 768) {
            document.write('<script type="text/javascript" src="/js/sakura.js"><\/script>'); }
    </script>

    <!-- weather -->
	<script type="text/javascript">
	WIDGET = {FID: 'TToslpmkVO'}
	</script>
	<script type="text/javascript" src="https://apip.weatherdt.com/float/static/js/r.js?v=1111"></script>


    <!-- Global site tag (gtag.js) - Google Analytics -->


    <!-- Baidu Analytics -->

<script>
    var _hmt = _hmt || [];
    (function () {
        var hm = document.createElement("script");
        hm.src = "https://hm.baidu.com/hm.js?";
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(hm, s);
    })();
</script>

    <!-- Baidu Push -->

    
    
    <script async src="https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/libs/others/busuanzi.pure.mini.js"></script>
    

    
        <script src="//code.tidio.co/kqhlkxviiccyoa0czpfpu4ijuey9hfre.js"></script>
        <script> 
            $(document).ready(function () {
                setInterval(change_Tidio, 50);  
                function change_Tidio() { 
                    var tidio=$("#tidio-chat iframe");
                    if(tidio.css("display")=="block"&& $(window).width()>977 ){
                        document.getElementById("tidio-chat-iframe").style.bottom= ($("div#backTop.top-scroll").css("display")=="none" &&$(window).width()>977)>0? "-40px" : ($("div.toc-title").length&&$(window).width()>977)>0?"85px":"20px";   
                        document.getElementById("tidio-chat-iframe").style.right="-15px";   
                        document.getElementById("tidio-chat-iframe").style.height=parseInt(tidio.css("height"))>=520?"520px":tidio.css("height");
                        document.getElementById("tidio-chat-iframe").style.zIndex="997";
                    } 
                    else if(tidio.css("display")=="block"&&$(window).width()>601 &&$(window).width()<992 ){
                        document.getElementById("tidio-chat-iframe").style.bottom= ($("div#backTop.top-scroll").css("display")=="none" && 601< $(window).width()<992)>0? "-40px":"20px" ;   
                        document.getElementById("tidio-chat-iframe").style.right="-15px"; 
                        document.getElementById("tidio-chat-iframe").style.zIndex="997";
                    }
                    else if(tidio.css("display")=="block"&&$(window).width()<601 && parseInt(tidio.css("height"))<230){
                        document.getElementById("tidio-chat-iframe").style.bottom= ($("div#backTop.top-scroll").css("display")=="none" && $(window).width()<601)>0? "-10px":"45px" ;   
                        document.getElementById("tidio-chat-iframe").style.zIndex="997";
                    }
                    if( tidio.css("display")=="block"&&$(window).width()<601 && parseInt(tidio.css("height"))>=230){
                        document.getElementById("tidio-chat-iframe").style.zIndex="998";
                    }
                } 
            }); 
        </script>
    

    

    
    <script type="text/javascript" color="0,0,255"
        pointColor="0,0,255" opacity='0.7'
        zIndex="-1" count="99"
        src="https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/libs/background/canvas-nest.js"></script>
    

    

    
    <script type="text/javascript" src="https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/libs/background/ribbon-dynamic.js" async="async"></script>
    
    
    
    <script src="https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/libs/instantpage/instantpage.js" type="module"></script>
    

        <script src="//cdn.jsdelivr.net/npm/js-base64/base64.min.js"></script>
        <script>
        $('a').each(function() {
          const $this = $(this);
          const href = $this.attr('href');
          if (href && href.match('^((http|https|thunder|qqdl|ed2k|Flashget|qbrowser|ftp|rtsp|mms)://)')) {
            const strs = href.split('/');
            if (strs.length >= 3) {
                const host = strs[2];
                if (host !== 'your_domain' || window.location.host) {
                    $this.attr('href', '/go.html?u='+Base64.encode(href)+'').attr('rel', 'external nofollow noopener noreferrer');
                    if (true) {
                        $this.attr('target', '_blank');
                    }
                }
            }
          }
        });
        </script><script>!function(e){var c=Array.prototype.slice.call(document.querySelectorAll("img[data-original]"));function i(){for(var r=0;r<c.length;r++)t=c[r],0<=(n=t.getBoundingClientRect()).bottom&&0<=n.left&&n.top<=(e.innerHeight||document.documentElement.clientHeight)&&function(){var t,n,e,i,o=c[r];t=o,n=function(){c=c.filter(function(t){return o!==t})},e=new Image,i=t.getAttribute("data-original"),e.onload=function(){t.src=i,n&&n()},e.src=i}();var t,n}i(),e.addEventListener("scroll",function(){var t,n;t=i,n=e,clearTimeout(t.tId),t.tId=setTimeout(function(){t.call(n)},500)})}(this);</script><script>window.addEventListener("load",function(){var t=/\.(gif|jpg|jpeg|tiff|png)$/i,r=/^data:image\/[a-z]+;base64,/;Array.prototype.slice.call(document.querySelectorAll("img[data-original]")).forEach(function(a){var e=a.parentNode;"A"===e.tagName&&(e.href.match(t)||e.href.match(r))&&(e.href=a.dataset.original)})});</script></body>

</html>

