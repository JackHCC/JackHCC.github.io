<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="GNN图神经网络详解, JackHCC">
    <meta name="description" content="GNN图神经网络学习实践记录">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <title>GNN图神经网络详解 | JackHCC</title>
    <link rel="icon" type="image/png" href="https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/medias/favicon.png">

    <link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/libs/awesome/css/all.css">
    <link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/libs/materialize/materialize.min.css">
    <link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/libs/aos/aos.css">
    <link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/libs/animate/animate.min.css">
    <link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/libs/lightGallery/css/lightgallery.min.css">
    <link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/css/matery.css">
    <link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/css/my.css">
    
    <script src="https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/libs/jquery/jquery.min.js"></script>
    
<meta name="generator" content="Hexo 4.2.0"><link rel="alternate" href="/atom.xml" title="JackHCC" type="application/atom+xml">
<link rel="stylesheet" href="/css/prism-hopscotch.css" type="text/css">
<link rel="stylesheet" href="/css/prism-line-numbers.css" type="text/css"></head>


<body>
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper head-container">
            <div class="brand-logo">
                <a href="/" class="waves-effect waves-light">
                    
                    <img src="/images/loading.gif" data-original="https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/medias/me.jpg" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">JackHCC</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>首页</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>标签</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>分类</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>归档</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="" class="waves-effect waves-light">

      
      <i class="fas fa-list" style="zoom: 0.6;"></i>
      
      <span>Tools</span>
      <i class="fas fa-chevron-down" aria-hidden="true" style="zoom: 0.6;"></i>
    </a>
    <ul class="sub-nav menus_item_child ">
      
      <li>
        <a href="https://creativecc.cn/" target="_blank" rel="noopener">
          
          <i class="fas fa-book" style="margin-top: -20px; zoom: 0.6;"></i>
          
          <span>Creative工具导航</span>
        </a>
      </li>
      
      <li>
        <a href="https://blog.creativecc.cn/Arxiv-NLP-Reporter/" target="_blank" rel="noopener">
          
          <i class="fas fa-film" style="margin-top: -20px; zoom: 0.6;"></i>
          
          <span>NLP每日论文</span>
        </a>
      </li>
      
      <li>
        <a href="http://chat.creativecc.cn/" target="_blank" rel="noopener">
          
          <i class="fas fa-music" style="margin-top: -20px; zoom: 0.6;"></i>
          
          <span>RocketChat聊天室</span>
        </a>
      </li>
      
      <li>
        <a href="/contact">
          
          <i class="fas fa-comments" style="margin-top: -20px; zoom: 0.6;"></i>
          
          <span>Contact留言板</span>
        </a>
      </li>
      
    </ul>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/friends" class="waves-effect waves-light">
      
      <i class="fas fa-address-book" style="zoom: 0.6;"></i>
      
      <span>友情链接</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/about" class="waves-effect waves-light">
      
      <i class="fas fa-user-circle" style="zoom: 0.6;"></i>
      
      <span>关于</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="搜索" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>

<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/images/loading.gif" data-original="https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/medias/me.jpg" class="logo-img circle responsive-img">
        
        <div class="logo-name">JackHCC</div>
        <div class="logo-desc">
            
            Make the world betterrrr!!!
            
        </div>
    </div>

    

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			首页
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			标签
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			分类
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			归档
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="javascript:;">
			
				<i class="fa-fw fas fa-list"></i>
			
			Tools
			<span class="m-icon"><i class="fas fa-chevron-right"></i></span>
		</a>
            <ul  style="background:  ;" >
              
                <li>   
				
                  <a href="https://creativecc.cn/ " target="_blank" rel="noopener" style="margin-left:75px";>
				  
				   <i class="fa fas fa-book" style="position: absolute;left:50px" ></i>
			      
		          <span>Creative工具导航</span>
                  </a>
                </li>
              
                <li>   
				
                  <a href="https://blog.creativecc.cn/Arxiv-NLP-Reporter/ " target="_blank" rel="noopener" style="margin-left:75px";>
				  
				   <i class="fa fas fa-film" style="position: absolute;left:50px" ></i>
			      
		          <span>NLP每日论文</span>
                  </a>
                </li>
              
                <li>   
				
                  <a href="http://chat.creativecc.cn/ " target="_blank" rel="noopener" style="margin-left:75px";>
				  
				   <i class="fa fas fa-music" style="position: absolute;left:50px" ></i>
			      
		          <span>RocketChat聊天室</span>
                  </a>
                </li>
              
                <li>   
				
                  <a href="/contact " style="margin-left:75px";>
				  
				   <i class="fa fas fa-comments" style="position: absolute;left:50px" ></i>
			      
		          <span>Contact留言板</span>
                  </a>
                </li>
               
            </ul>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/friends" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-address-book"></i>
			
			友情链接
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/about" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-user-circle"></i>
			
			关于
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/JackHCC/JackHCC.github.io" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>

        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/JackHCC/JackHCC.github.io" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    
<script src="https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/libs/cryptojs/crypto-js.min.js"></script>
<script>
    (function() {
        let pwd = '';
        if (pwd && pwd.length > 0) {
            if (pwd !== CryptoJS.SHA256(prompt('请输入访问本文章的密码')).toString(CryptoJS.enc.Hex)) {
                alert('密码错误，将返回主页！');
                location.href = '/';
            }
        }
    })();
</script>




<div class="bg-cover pd-header post-cover" style="background-image: url('https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/medias/featureimages/16.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">GNN图神经网络详解</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/libs/tocbot/tocbot.css">
<style>
    #articleContent h1::before,
    #articleContent h2::before,
    #articleContent h3::before,
    #articleContent h4::before,
    #articleContent h5::before,
    #articleContent h6::before {
        display: block;
        content: " ";
        height: 100px;
        margin-top: -100px;
        visibility: hidden;
    }

    #articleContent :focus {
        outline: none;
    }

    .toc-fixed {
        position: fixed;
        top: 64px;
    }

    .toc-widget {
        width: 345px;
        padding-left: 20px;
    }

    .toc-widget .toc-title {
        margin: 35px 0 15px 0;
        padding-left: 17px;
        font-size: 1.5rem;
        font-weight: bold;
        line-height: 1.5rem;
    }

    .toc-widget ol {
        padding: 0;
        list-style: none;
    }

    #toc-content {
        height: calc(100vh - 250px);
        overflow: auto;
    }

    #toc-content ol {
        padding-left: 10px;
    }

    #toc-content ol li {
        padding-left: 10px;
    }

    #toc-content .toc-link:hover {
        color: #42b983;
        font-weight: 700;
        text-decoration: underline;
    }

    #toc-content .toc-link::before {
        background-color: transparent;
        max-height: 25px;
    }

    #toc-content .is-active-link {
        color: #42b983;
    }

    #toc-content .is-active-link::before {
        background-color: #42b983;
    }

    #floating-toc-btn {
        position: fixed;
        right: 30px;
        bottom: 146px;
        padding-top: 15px;
        margin-bottom: 0;
        z-index: 998;
    }

    #floating-toc-btn .btn-floating {
        width: 48px;
        height: 48px;
    }

    #floating-toc-btn .btn-floating i {
        line-height: 48px;
        font-size: 1.4rem;
    }
</style>
<div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- 文章内容详情 -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/tags/GNN/">
                                <span class="chip bg-color">GNN</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/categories/Deep-Learning/" class="post-category">
                                Deep Learning
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>发布日期:&nbsp;&nbsp;
                    2021-08-24
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>更新日期:&nbsp;&nbsp;
                    2021-09-04
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>文章字数:&nbsp;&nbsp;
                    21k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>阅读时长:&nbsp;&nbsp;
                    90 分
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>阅读次数:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>

        </div>
        <hr class="clearfix">
        <div class="card-content article-card-content">
            <div id="articleContent">
                <h1 id="基本应用"><a href="#基本应用" class="headerlink" title="基本应用"></a>基本应用</h1><h2 id="图基础与中心指标"><a href="#图基础与中心指标" class="headerlink" title="图基础与中心指标"></a>图基础与中心指标</h2><h3 id="一-基础属性"><a href="#一-基础属性" class="headerlink" title="一.基础属性"></a>一.基础属性</h3><p><strong>基本定义</strong>：节点、边<br><strong>基本类型</strong>：有向图、无向图；加权图，非加权图；连通图，非连通图；连通分量，强连通分量，弱连通分量；二部图<br><strong>邻居，𝑘阶邻居，度</strong><br><strong>子图、𝑘阶子图、路径、图直径</strong><br><strong>表示方式</strong>: 邻接矩阵，关联矩阵<br><strong>遍历方式</strong>：深度优先，广度优先</p>
<pre><code>#构建图
%matplotlib inline
from matplotlib import pyplot as plt
import networkx as nx
G=nx.Graph()#无向图，有向图用DiGraph
G.add_nodes_from(["A","B","C","D","E","F","G","H"])
G.add_edges_from([("A","B"),("A","C"),("B","C"),("C","D"),("E","F"),("F","G"),("G","H")])
nx.draw_networkx(G)
plt.show()</code></pre><p><img src="/images/loading.gif" data-original="../images/ML/image-20210829195032100.png" alt=""></p>
<pre class="line-numbers language-python"><code class="language-python"><span class="token comment" spellcheck="true">#度</span>
nx<span class="token punctuation">.</span>degree<span class="token punctuation">(</span>G<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>
<p>&gt;&gt;&gt;</p>
<pre><code>DegreeView({'A': 2, 'B': 2, 'C': 3, 'D': 1, 'E': 1, 'F': 2, 'G': 2, 'H': 1})</code></pre><pre class="line-numbers language-python"><code class="language-python"><span class="token comment" spellcheck="true">#连通分量</span>
list<span class="token punctuation">(</span>nx<span class="token punctuation">.</span>connected_components<span class="token punctuation">(</span>G<span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>
<p>&gt;&gt;&gt;</p>
<pre><code>[{'A', 'B', 'C', 'D'}, {'E', 'F', 'G', 'H'}]</code></pre><pre class="line-numbers language-python"><code class="language-python"><span class="token comment" spellcheck="true">#图直径:所有两两节点直接最短路径的最大值</span>
subG<span class="token operator">=</span>nx<span class="token punctuation">.</span>subgraph<span class="token punctuation">(</span>G<span class="token punctuation">,</span><span class="token punctuation">[</span><span class="token string">"A"</span><span class="token punctuation">,</span><span class="token string">"B"</span><span class="token punctuation">,</span><span class="token string">"C"</span><span class="token punctuation">,</span><span class="token string">"D"</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
nx<span class="token punctuation">.</span>diameter<span class="token punctuation">(</span>subG<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre>
<p>&gt;&gt;&gt;</p>
<pre><code>2</code></pre><pre class="line-numbers language-python"><code class="language-python"><span class="token comment" spellcheck="true">#路径长度</span>
nx<span class="token punctuation">.</span>shortest_path_length<span class="token punctuation">(</span>G<span class="token punctuation">,</span>source<span class="token operator">=</span><span class="token string">"A"</span><span class="token punctuation">,</span>target<span class="token operator">=</span><span class="token string">"D"</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>
<p>&gt;&gt;&gt;</p>
<pre><code>2</code></pre><h3 id="二-中心性指标"><a href="#二-中心性指标" class="headerlink" title="二.中心性指标"></a>二.中心性指标</h3><p>中心性指标主要用于衡量节点在图中的重要性/影响力，我们对节点重要性的解释有很多，不同的解释下判定中心性的指标也有所不同，通常有这些：点度中心性，中介中心性，接近中心性，特征向量中心性，PageRank，hits</p>
<pre class="line-numbers language-python"><code class="language-python"><span class="token comment" spellcheck="true">#点度中心性</span>
<span class="token comment" spellcheck="true">#节点的邻居越多，它就越重要，定义为：度/(节点数-1)</span>
nx<span class="token punctuation">.</span>degree_centrality<span class="token punctuation">(</span>G<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre>
<p>&gt;&gt;&gt;</p>
<pre><code>{'A': 0.2857142857142857,
'B': 0.2857142857142857,
'C': 0.42857142857142855,
'D': 0.14285714285714285,
'E': 0.14285714285714285,
'F': 0.2857142857142857,
'G': 0.2857142857142857,
'H': 0.14285714285714285}</code></pre><pre class="line-numbers language-python"><code class="language-python"><span class="token comment" spellcheck="true">#中介中心性</span>
<span class="token comment" spellcheck="true">#如果该节点出现该其它两两节点路径上的次数越多，它就越重要</span>
nx<span class="token punctuation">.</span>betweenness_centrality<span class="token punctuation">(</span>G<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre>
<p>&gt;&gt;&gt;</p>
<pre><code>{'A': 0.0,
'B': 0.0,
'C': 0.09523809523809523,
'D': 0.0,
'E': 0.0,
'F': 0.09523809523809523,
'G': 0.09523809523809523,
'H': 0.0}</code></pre><pre class="line-numbers language-python"><code class="language-python"><span class="token comment" spellcheck="true">#接近中心性</span>
<span class="token comment" spellcheck="true">#如果该节点与其它节点之间的距离越近，它就越重要</span>
nx<span class="token punctuation">.</span>closeness_centrality<span class="token punctuation">(</span>G<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre>
<p>&gt;&gt;&gt;</p>
<pre><code>{'A': 0.3214285714285714,
'B': 0.3214285714285714,
'C': 0.42857142857142855,
'D': 0.2571428571428571,
'E': 0.21428571428571427,
'F': 0.3214285714285714,
'G': 0.3214285714285714,
'H': 0.21428571428571427}</code></pre><pre class="line-numbers language-python"><code class="language-python"><span class="token comment" spellcheck="true">#特征向量中心性</span>
<span class="token comment" spellcheck="true">#定义：取邻接矩阵特征分解后，最大特征值对应的特征向量</span>
<span class="token comment" spellcheck="true">#与某节点连接的节点的邻居越多，就越重要</span>
<span class="token comment" spellcheck="true">#新增加一个节点I来连接两块连通分量</span>
G<span class="token operator">=</span>nx<span class="token punctuation">.</span>Graph<span class="token punctuation">(</span><span class="token punctuation">)</span>
G<span class="token punctuation">.</span>add_nodes_from<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token string">"A"</span><span class="token punctuation">,</span><span class="token string">"B"</span><span class="token punctuation">,</span><span class="token string">"C"</span><span class="token punctuation">,</span><span class="token string">"D"</span><span class="token punctuation">,</span><span class="token string">"E"</span><span class="token punctuation">,</span><span class="token string">"F"</span><span class="token punctuation">,</span><span class="token string">"G"</span><span class="token punctuation">,</span><span class="token string">"H"</span><span class="token punctuation">,</span><span class="token string">"I"</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
G<span class="token punctuation">.</span>add_edges_from<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token string">"A"</span><span class="token punctuation">,</span><span class="token string">"B"</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token punctuation">(</span><span class="token string">"A"</span><span class="token punctuation">,</span><span class="token string">"C"</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token punctuation">(</span><span class="token string">"B"</span><span class="token punctuation">,</span><span class="token string">"C"</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token punctuation">(</span><span class="token string">"C"</span><span class="token punctuation">,</span><span class="token string">"D"</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token punctuation">(</span><span class="token string">"E"</span><span class="token punctuation">,</span><span class="token string">"F"</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token punctuation">(</span><span class="token string">"F"</span><span class="token punctuation">,</span><span class="token string">"G"</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token punctuation">(</span><span class="token string">"G"</span><span class="token punctuation">,</span><span class="token string">"H"</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token punctuation">(</span><span class="token string">"I"</span><span class="token punctuation">,</span><span class="token string">"B"</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token punctuation">(</span><span class="token string">"I"</span><span class="token punctuation">,</span><span class="token string">"F"</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
nx<span class="token punctuation">.</span>draw_networkx<span class="token punctuation">(</span>G<span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p> &gt;&gt;&gt;<br><img src="/images/loading.gif" data-original="../images/ML/output_10_0.png" alt=""></p>
<pre class="line-numbers language-python"><code class="language-python">nx<span class="token punctuation">.</span>eigenvector_centrality<span class="token punctuation">(</span>G<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<p>&gt;&gt;&gt;</p>
<pre><code>{'A': 0.44885390912200857,
'B': 0.5468450989996043,
'C': 0.5135021004101872,
'D': 0.21736961615213216,
'E': 0.09799461776528895,
'F': 0.2314938976977582,
'G': 0.11938887762076224,
'H': 0.0505393145300136,
'I': 0.3294789107351654}</code></pre><pre class="line-numbers language-python"><code class="language-python"><span class="token comment" spellcheck="true">#pagerank</span>
nx<span class="token punctuation">.</span>pagerank<span class="token punctuation">(</span>G<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>
<p>&gt;&gt;&gt;</p>
<pre><code>{'A': 0.10252135128679807,
'B': 0.14929077894067944,
'C': 0.153726203840718,
'D': 0.06022249294537078,
'E': 0.06475108608528522,
'F': 0.16971188372812845,
'G': 0.1235500933464885,
'H': 0.06917616539981883,
'I': 0.1070499444267125}</code></pre><pre class="line-numbers language-python"><code class="language-python"><span class="token comment" spellcheck="true">#hits</span>
nx<span class="token punctuation">.</span>hits<span class="token punctuation">(</span>G<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>
<p>&gt;&gt;&gt;</p>
<pre><code>({'A': 0.17564701604305502,
'B': 0.21399245433642766,
'C': 0.2009454874842481,
'D': 0.08506205753671801,
'E': 0.03834543957793587,
'F': 0.09058495722206274,
'G': 0.04671661924357704,
'H': 0.019775570471702603,
'I': 0.1289303980842729},
{'A': 0.1756470158158291,
'B': 0.21399245588711766,
'C': 0.2009454869245228,
'D': 0.085062057946483,
'E': 0.03834543855419052,
'F': 0.09058495938682286,
'G': 0.04671661787549817,
'H': 0.01977557118599924,
'I': 0.1289303964235366})</code></pre><h2 id="Graph-Embedding"><a href="#Graph-Embedding" class="headerlink" title="Graph Embedding"></a>Graph Embedding</h2><h3 id="一-DeepWalk原理"><a href="#一-DeepWalk原理" class="headerlink" title="一. DeepWalk原理"></a>一. DeepWalk原理</h3><p>其实就两个阶段：<br>1）对图随机游走得到一个序列；<br>2）将该序列进行word2vec训练得到embedding  </p>
<p>下面利用对word进行embbeding训练举例，我选择了当前的一条关于新冠的新闻，对其分词构建一个带权有向图，权重为其相邻两词的出现的次数</p>
<pre class="line-numbers language-python"><code class="language-python"><span class="token comment" spellcheck="true">#准备预料</span>
corpus<span class="token operator">=</span><span class="token triple-quoted-string string">"""新华社河内5月29日电（记者蒋声雄 黄硕）越南卫生部长阮青龙29日宣布该国发现新的新冠病毒变异毒株，它是此前在英国和印度发现的变异毒株的混合体。
阮青龙当天在越南全国新冠疫情防控视频会议上说，这种变异毒株混合体“非常危险”，传播性更强，能在空气中迅速传播。这一新发现的毒株混合体尚未命名。
据“越南快报网”报道，此前在越南已发现7种新冠病毒变异毒株，包括最早在印度和英国发现的变异毒株。
越南于今年4月底出现新一轮新冠疫情，首都河内、南部胡志明市、中部岘港市等主要城市出现多个本土病例，北部北江省某工业园内发生大规模感染新冠病毒事件。据越通社报道，截至当地时间29日12时，越南累计确诊新冠本土病例5213例，其中自4月27日以来新增确诊新冠本土病例3643例"""</span>\
<span class="token punctuation">.</span>replace<span class="token punctuation">(</span><span class="token string">"\n"</span><span class="token punctuation">,</span><span class="token string">""</span><span class="token punctuation">)</span><span class="token punctuation">.</span>replace<span class="token punctuation">(</span><span class="token string">"，"</span><span class="token punctuation">,</span><span class="token string">""</span><span class="token punctuation">)</span><span class="token punctuation">.</span>replace<span class="token punctuation">(</span><span class="token string">"、"</span><span class="token punctuation">,</span><span class="token string">""</span><span class="token punctuation">)</span><span class="token punctuation">.</span>replace<span class="token punctuation">(</span><span class="token string">"（"</span><span class="token punctuation">,</span><span class="token string">""</span><span class="token punctuation">)</span><span class="token punctuation">.</span>replace<span class="token punctuation">(</span><span class="token string">"）"</span><span class="token punctuation">,</span><span class="token string">""</span><span class="token punctuation">)</span><span class="token punctuation">.</span>replace<span class="token punctuation">(</span><span class="token string">" "</span><span class="token punctuation">,</span><span class="token string">""</span><span class="token punctuation">)</span><span class="token punctuation">.</span>replace<span class="token punctuation">(</span><span class="token string">"“"</span><span class="token punctuation">,</span><span class="token string">""</span><span class="token punctuation">)</span><span class="token punctuation">.</span>replace<span class="token punctuation">(</span><span class="token string">"”"</span><span class="token punctuation">,</span><span class="token string">""</span><span class="token punctuation">)</span><span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">"。"</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<pre class="line-numbers language-python"><code class="language-python">corpus<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<p>&gt;&gt;&gt;</p>
<pre><code>['新华社河内5月29日电记者蒋声雄黄硕越南卫生部长阮青龙29日宣布该国发现新的新冠病毒变异毒株它是此前在英国和印度发现的变异毒株的混合体',
'阮青龙当天在越南全国新冠疫情防控视频会议上说这种变异毒株混合体非常危险传播性更强能在空气中迅速传播',
'这一新发现的毒株混合体尚未命名',
'据越南快报网报道此前在越南已发现7种新冠病毒变异毒株包括最早在印度和英国发现的变异毒株',
'越南于今年4月底出现新一轮新冠疫情首都河内南部胡志明市中部岘港市等主要城市出现多个本土病例北部北江省某工业园内发生大规模感染新冠病毒事件',
'据越通社报道截至当地时间29日12时越南累计确诊新冠本土病例5213例其中自4月27日以来新增确诊新冠本土病例3643例']</code></pre><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">import</span> jieba
lines<span class="token operator">=</span><span class="token punctuation">[</span>list<span class="token punctuation">(</span>jieba<span class="token punctuation">.</span>cut<span class="token punctuation">(</span>line<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token keyword">for</span> line <span class="token keyword">in</span> corpus<span class="token punctuation">]</span><span class="token comment" spellcheck="true">#分词</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>
<p>Building prefix dict from the default dictionary …<br>Loading model from cache C:\Users\Alei\AppData\Local\Temp\jieba.cache<br>Loading model cost 0.619 seconds.<br>Prefix dict has been built successfully.</p>
<pre class="line-numbers language-python"><code class="language-python">word_cnt<span class="token operator">=</span><span class="token punctuation">{</span><span class="token punctuation">}</span>
word_set<span class="token operator">=</span>set<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token keyword">for</span> line <span class="token keyword">in</span> lines<span class="token punctuation">:</span>
    <span class="token keyword">for</span> i <span class="token keyword">in</span> range<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span>len<span class="token punctuation">(</span>line<span class="token punctuation">)</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        pre_cnt<span class="token operator">=</span>word_cnt<span class="token punctuation">.</span>get<span class="token punctuation">(</span><span class="token punctuation">(</span>line<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">,</span>line<span class="token punctuation">[</span>i<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">)</span>
        word_cnt<span class="token punctuation">[</span><span class="token punctuation">(</span>line<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">,</span>line<span class="token punctuation">[</span>i<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token operator">=</span><span class="token number">1</span><span class="token operator">+</span>pre_cnt
        word_set<span class="token punctuation">.</span>add<span class="token punctuation">(</span>line<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">)</span>
        word_set<span class="token punctuation">.</span>add<span class="token punctuation">(</span>line<span class="token punctuation">[</span>i<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<pre class="line-numbers language-python"><code class="language-python"><span class="token comment" spellcheck="true">#构建图</span>
<span class="token operator">%</span>matplotlib inline
<span class="token keyword">from</span> matplotlib <span class="token keyword">import</span> pyplot <span class="token keyword">as</span> plt
<span class="token keyword">import</span> networkx <span class="token keyword">as</span> nx
plt<span class="token punctuation">.</span>figure<span class="token punctuation">(</span>figsize<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">16</span><span class="token punctuation">,</span> <span class="token number">12</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>axis<span class="token punctuation">(</span><span class="token string">"off"</span><span class="token punctuation">)</span>
G<span class="token operator">=</span>nx<span class="token punctuation">.</span>DiGraph<span class="token punctuation">(</span><span class="token punctuation">)</span>
G<span class="token punctuation">.</span>add_edges_from<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">(</span>key<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span>key<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token keyword">for</span> key <span class="token keyword">in</span> word_cnt<span class="token punctuation">.</span>keys<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
nx<span class="token punctuation">.</span>draw_networkx<span class="token punctuation">(</span>G<span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p><img src="/images/loading.gif" data-original="../images/ML/output_5_0.png" alt=""></p>
<h3 id="二-随机游走实现"><a href="#二-随机游走实现" class="headerlink" title="二.随机游走实现"></a>二.随机游走实现</h3><p>随机游走的核心也很简单，大概流程如下：   </p>
<p>1）从图中随机选择一个起始node<br>2）从它的（箭头指向的）邻居中随机选择一个新node<br>3）重复第2）步，直到满足终止条件，上面的所有node组成的序列即是我们所需   </p>
<p>另外，上面的每一步都可以自定义自己的策略，比如第1）步初始点不从图中随机选择，而是从实际句子的初始词中选择，第2）步，随机选择下一个节点时，考虑边的权值，权值越大越容易被选择，第3）步，通常可以设置一个最大游走长度</p>
<pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">import</span> numpy <span class="token keyword">as</span> np
<span class="token keyword">def</span> <span class="token function">walk_one_time</span><span class="token punctuation">(</span>G<span class="token punctuation">,</span>start_node<span class="token punctuation">,</span>walk_len<span class="token punctuation">)</span><span class="token punctuation">:</span>
    seq<span class="token operator">=</span><span class="token punctuation">[</span>start_node<span class="token punctuation">]</span>
    <span class="token keyword">for</span> _ <span class="token keyword">in</span> range<span class="token punctuation">(</span>walk_len<span class="token number">-1</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        current_node<span class="token operator">=</span>seq<span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token comment" spellcheck="true">#获取seq的最有一个节点</span>
        next_nodes<span class="token operator">=</span>list<span class="token punctuation">(</span>G<span class="token punctuation">.</span>successors<span class="token punctuation">(</span>current_node<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true">#获取所有邻居节点</span>
        <span class="token keyword">if</span> len<span class="token punctuation">(</span>next_nodes<span class="token punctuation">)</span><span class="token operator">==</span><span class="token number">0</span><span class="token punctuation">:</span>
            <span class="token keyword">break</span>
        selected_next_node<span class="token operator">=</span>np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>choice<span class="token punctuation">(</span>next_nodes<span class="token punctuation">)</span><span class="token comment" spellcheck="true">#从所有邻居中随机选择一个</span>
        seq<span class="token punctuation">.</span>append<span class="token punctuation">(</span>selected_next_node<span class="token punctuation">)</span>
    <span class="token keyword">return</span> seq<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<pre class="line-numbers language-python"><code class="language-python"><span class="token comment" spellcheck="true">#test</span>
walk_one_time<span class="token punctuation">(</span>G<span class="token punctuation">,</span><span class="token string">"变异"</span><span class="token punctuation">,</span><span class="token number">5</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>
<p>&gt;&gt;&gt;</p>
<pre><code>['变异', '毒株', '它', '是', '此前']</code></pre><pre class="line-numbers language-python"><code class="language-python"><span class="token comment" spellcheck="true">#将上面的过程重复多次，即可得到一个新的corpus</span>
<span class="token keyword">def</span> <span class="token function">deep_walk</span><span class="token punctuation">(</span>G<span class="token punctuation">,</span>walk_len<span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">,</span>num_seqs<span class="token operator">=</span><span class="token number">100</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    corpus<span class="token operator">=</span><span class="token punctuation">[</span><span class="token punctuation">]</span>
    <span class="token keyword">for</span> _ <span class="token keyword">in</span> range<span class="token punctuation">(</span>num_seqs<span class="token punctuation">)</span><span class="token punctuation">:</span>
        start_node<span class="token operator">=</span>np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>choice<span class="token punctuation">(</span>G<span class="token punctuation">.</span>nodes<span class="token punctuation">)</span>
        corpus<span class="token punctuation">.</span>append<span class="token punctuation">(</span>walk_one_time<span class="token punctuation">(</span>G<span class="token punctuation">,</span>start_node<span class="token punctuation">,</span>walk_len<span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token keyword">return</span> corpus<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<pre class="line-numbers language-python"><code class="language-python">new_corpus<span class="token operator">=</span>deep_walk<span class="token punctuation">(</span>G<span class="token punctuation">)</span>
new_corpus<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>
<p>&gt;&gt;&gt;</p>
<pre><code>['包括', '最早', '在', '越南', '快报', '网', '报道', '截至', '当地', '时间']</code></pre><h3 id="三-Word2Vec的训练"><a href="#三-Word2Vec的训练" class="headerlink" title="三.Word2Vec的训练"></a>三.Word2Vec的训练</h3><p>word2vec的训练可以使用gensim工具包，word2vec的原理包括两点：    </p>
<p>1）基于语言模型的原理，语言模型的作用用于判断一个句子出现的概率，由于句子通常会被分词，所有语言模型可以看作判断一个词语序列的出现概率，好的语言模型应该能做到比如如下的判断：   </p>
<p>$$<br>Proba([[变异],[毒株],[混合体],[非常],[危险]])&gt;Proba([[变异],[危险],[混合体],[非常],[毒株]])<br>$$</p>
<p>显然，第一句是人话，第二句读不通  </p>
<p>2）而word2vec就是利用极大似然估计的方式让我们的人话出现的概率尽可能高，而鬼话的概率尽可能小，它采用三层的网络结构，  </p>
<blockquote>
<p>2.1）第一层是input层，它与我们的词典一一对应   </p>
</blockquote>
<blockquote>
<p>2.2）中间层是hidden层，它就是我们embedding的维度    </p>
</blockquote>
<blockquote>
<p>2.3）最后一层是output层，它同样与我们的词典一一对应  </p>
</blockquote>
<p>它的训练如下图，  </p>
<blockquote>
<p>1）我们对输入的文本截取一定的窗口，比如window_size=2，那么我们选取目标次前后的2X2+1=5个词语，比如[[变异],[毒株],[混合体],[非常],[危险]]这5个词语  </p>
</blockquote>
<blockquote>
<p>2）然后，我们构建([变异],[毒株],[非常],[危险])-&gt;([混合体])的映射，其中前半部分，我们称作[混合体]的上下文   </p>
</blockquote>
<blockquote>
<p>3）最后，我们利用极大似然估计估计上面的上下文和目标词的映射概率尽可能的大</p>
</blockquote>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20210829200204048.png" alt=""></p>
<pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">from</span> gensim<span class="token punctuation">.</span>models <span class="token keyword">import</span> word2vec
model <span class="token operator">=</span> word2vec<span class="token punctuation">.</span>Word2Vec<span class="token punctuation">(</span>new_corpus<span class="token punctuation">,</span>window<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span>vector_size<span class="token operator">=</span><span class="token number">5</span><span class="token punctuation">,</span>min_count<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>
<pre class="line-numbers language-python"><code class="language-python"><span class="token comment" spellcheck="true">#查看embedding</span>
model<span class="token punctuation">.</span>wv<span class="token punctuation">[</span><span class="token string">"变异"</span><span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>
<p>&gt;&gt;&gt;</p>
<pre><code>array([-0.19377613,  0.10809163, -0.16566691, -0.09616406,  0.00191299],
dtype=float32)</code></pre><pre class="line-numbers language-python"><code class="language-python">model<span class="token punctuation">.</span>wv<span class="token punctuation">[</span><span class="token string">"混合体"</span><span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<p>&gt;&gt;&gt;</p>
<pre><code>array([ 0.15368475, -0.18145339,  0.00444265,  0.05817473, -0.01261494],
dtype=float32)</code></pre><p>这样，我们就为图上的每个节点训练出了一个embedding，另外上面的训练过程实际是采用了CBOW的方式，即用上下文来预测某个词，而实际deepwalk更多是使用<strong>skip-gram</strong>的方式，即利用单个词去预测它的上下文（上面图中的箭头反向），这样训练的embedding效果通常会更好</p>
<h3 id="四-Node2Vec原理"><a href="#四-Node2Vec原理" class="headerlink" title="四.Node2Vec原理"></a>四.Node2Vec原理</h3><p>Node2vec其实是对于DeepWalk中第2)步，随机游走方式的调整，以学习到图结构的同质性和结构性信息。这里：  </p>
<p>1）同质性是指相邻两节点之间应该具有较高的相似度；    </p>
<p>2）结构性是指邻居结构相似的两节点之间应该具有较高的相似度，即使这两节点之间没有路径连接    </p>
<p>如下图，u与s1,s2,s3,s4之间在同质性上应该具有较高的相似度，而u与s6在结构性上应该具有较高相似度<br><img src="/images/loading.gif" data-original="../images/ML/image-20210829200439020.png" alt=""></p>
<p>那如何游走才能提现同质性和结构性呢，这其实可以利用我们常见的图搜索算法，深度优先搜索(DFS)和广度优先搜索(BFS):   </p>
<p>1)DFS:深度优先搜索，在相俩节点间游走，倾向于获取同质性信息；   </p>
<p>2)BFS:广度优先搜索，优先获取节点周围邻居序列，倾向于获取结构性信息；    </p>
<p>具体的游走方式如下<br><img src="/images/loading.gif" data-original="../images/ML/image-20210829200449990.png" alt=""></p>
<p>已知，当前序列的最后两节点为[t,v]，即最后一步游走为t-&gt;v，那么接下的游走方式满足如下公式：<br><img src="/images/loading.gif" data-original="../images/ML/image-20210829200501619.png" alt=""><br>下面直观解释一下这三种情况：   </p>
<blockquote>
<p>(1) $d_{tx}=0$，表示$t$节点与$x$节点距离为0，所以它们是同一节点，言外之意是说从$v$节点又跳回了前节点$t$，它的跳转概率定义为$\frac{1}{p}$<br>(2) $d_{tx}=1$，表示既与$t$相连，又与$v$相连的节点，如图中的$x_1$，它的跳转概率定义为1<br>(3) $d_{tx}=2$，即图中的$x_2,x_3$节点，它们的跳转概率被定义为$\frac{1}{q}$  </p>
</blockquote>
<p>注意，上面的“概率”都未归一化，最终需要进行归一化操作，另外node2vec还需要考虑边的权重$w_{vx}$，所以它实际是对$\pi_{vx}=\alpha_{pq}(t,x)\cdot w_{vx}$进行归一化，下面对超参数$p,q$进行讨论；   </p>
<blockquote>
<p>对于p：如果$p&gt;max(q,1)$,那么采样倾向于不会往回走，而如何$p&lt;min(q,1)$，采样倾向于返回上一个节点，在初始点周围游走  </p>
</blockquote>
<blockquote>
<p>对于q: 如果$q&gt;1$，采样点倾向于在起始点周围游走做BFS采样，而如果$q&lt;1$，倾向于远离起始点，做DFS采样   </p>
</blockquote>
<h3 id="五-实现"><a href="#五-实现" class="headerlink" title="五.实现"></a>五.实现</h3><pre class="line-numbers language-python"><code class="language-python"><span class="token comment" spellcheck="true">#构建图</span>
<span class="token operator">%</span>matplotlib inline
<span class="token keyword">from</span> matplotlib <span class="token keyword">import</span> pyplot <span class="token keyword">as</span> plt
<span class="token keyword">import</span> networkx <span class="token keyword">as</span> nx
plt<span class="token punctuation">.</span>axis<span class="token punctuation">(</span><span class="token string">"off"</span><span class="token punctuation">)</span>
G<span class="token operator">=</span>nx<span class="token punctuation">.</span>DiGraph<span class="token punctuation">(</span><span class="token punctuation">)</span>
edges<span class="token operator">=</span><span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token string">"u"</span><span class="token punctuation">,</span><span class="token string">"s1"</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token punctuation">(</span><span class="token string">"u"</span><span class="token punctuation">,</span><span class="token string">"s2"</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token punctuation">(</span><span class="token string">"u"</span><span class="token punctuation">,</span><span class="token string">"s3"</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token punctuation">(</span><span class="token string">"u"</span><span class="token punctuation">,</span><span class="token string">"s4"</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token punctuation">(</span><span class="token string">"s1"</span><span class="token punctuation">,</span><span class="token string">"s2"</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token punctuation">(</span><span class="token string">"s1"</span><span class="token punctuation">,</span><span class="token string">"s3"</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token punctuation">(</span><span class="token string">"s3"</span><span class="token punctuation">,</span><span class="token string">"s4"</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                  <span class="token punctuation">(</span><span class="token string">"s2"</span><span class="token punctuation">,</span><span class="token string">"s4"</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token punctuation">(</span><span class="token string">"s5"</span><span class="token punctuation">,</span><span class="token string">"s2"</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token punctuation">(</span><span class="token string">"s4"</span><span class="token punctuation">,</span><span class="token string">"s5"</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token punctuation">(</span><span class="token string">"s6"</span><span class="token punctuation">,</span><span class="token string">"s5"</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token punctuation">(</span><span class="token string">"s6"</span><span class="token punctuation">,</span><span class="token string">"s7"</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token punctuation">(</span><span class="token string">"s6"</span><span class="token punctuation">,</span><span class="token string">"s8"</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token punctuation">(</span><span class="token string">"s6"</span><span class="token punctuation">,</span><span class="token string">"s9"</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                  <span class="token punctuation">(</span><span class="token string">"s5"</span><span class="token punctuation">,</span><span class="token string">"s7"</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token punctuation">(</span><span class="token string">"s7"</span><span class="token punctuation">,</span><span class="token string">"s8"</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token punctuation">(</span><span class="token string">"s8"</span><span class="token punctuation">,</span><span class="token string">"s9"</span><span class="token punctuation">)</span><span class="token punctuation">]</span>
G<span class="token punctuation">.</span>add_edges_from<span class="token punctuation">(</span>edges<span class="token punctuation">)</span>
G<span class="token punctuation">.</span>add_edges_from<span class="token punctuation">(</span><span class="token punctuation">(</span>edge<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span>edge<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token keyword">for</span> edge <span class="token keyword">in</span> edges<span class="token punctuation">)</span>
nx<span class="token punctuation">.</span>draw_networkx<span class="token punctuation">(</span>G<span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p><img src="/images/loading.gif" data-original="../images/ML/output_1_0.png" alt=""></p>
<pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">import</span> numpy <span class="token keyword">as</span> np
<span class="token keyword">class</span> <span class="token class-name">Node2Vec</span><span class="token punctuation">(</span>object<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>walk_len<span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">,</span>num_seqs<span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">,</span>p<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span>q<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        self<span class="token punctuation">.</span>walk_len<span class="token operator">=</span>walk_len
        self<span class="token punctuation">.</span>num_seqs<span class="token operator">=</span>num_seqs
        self<span class="token punctuation">.</span>p<span class="token operator">=</span>p
        self<span class="token punctuation">.</span>q<span class="token operator">=</span>q
    <span class="token keyword">def</span> <span class="token function">walk_one_time</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>G<span class="token punctuation">,</span>start_node<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment" spellcheck="true">#添加第二个点</span>
        second_node<span class="token operator">=</span>np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>choice<span class="token punctuation">(</span>list<span class="token punctuation">(</span>G<span class="token punctuation">.</span>successors<span class="token punctuation">(</span>start_node<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        seq<span class="token operator">=</span><span class="token punctuation">[</span>start_node<span class="token punctuation">,</span>second_node<span class="token punctuation">]</span>
        <span class="token keyword">for</span> _ <span class="token keyword">in</span> range<span class="token punctuation">(</span>self<span class="token punctuation">.</span>walk_len<span class="token number">-2</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            t_node<span class="token operator">=</span>seq<span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">2</span><span class="token punctuation">]</span>
            v_node<span class="token operator">=</span>seq<span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span>
            next_nodes<span class="token operator">=</span>list<span class="token punctuation">(</span>G<span class="token punctuation">.</span>successors<span class="token punctuation">(</span>v_node<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true">#获取所有邻居节点</span>
            proba<span class="token operator">=</span><span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token comment" spellcheck="true">#记录概率</span>
            <span class="token keyword">for</span> next_node <span class="token keyword">in</span> next_nodes<span class="token punctuation">:</span>
                path_len<span class="token operator">=</span>nx<span class="token punctuation">.</span>shortest_path_length<span class="token punctuation">(</span>G<span class="token punctuation">,</span>source<span class="token operator">=</span>t_node<span class="token punctuation">,</span>target<span class="token operator">=</span>next_node<span class="token punctuation">)</span>
                <span class="token keyword">if</span> path_len<span class="token operator">==</span><span class="token number">0</span><span class="token punctuation">:</span>
                    proba<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token number">1</span><span class="token operator">/</span>self<span class="token punctuation">.</span>p<span class="token punctuation">)</span>
                <span class="token keyword">elif</span> path_len<span class="token operator">==</span><span class="token number">1</span><span class="token punctuation">:</span>
                    proba<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span>
                <span class="token keyword">else</span><span class="token punctuation">:</span>
                    proba<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token number">1</span><span class="token operator">/</span>self<span class="token punctuation">.</span>q<span class="token punctuation">)</span>
            proba<span class="token operator">=</span>np<span class="token punctuation">.</span>asarray<span class="token punctuation">(</span>proba<span class="token punctuation">)</span>
            proba<span class="token operator">=</span>proba<span class="token operator">/</span>np<span class="token punctuation">.</span>sum<span class="token punctuation">(</span>proba<span class="token punctuation">)</span><span class="token comment" spellcheck="true">#归一化</span>
            selected_next_node<span class="token operator">=</span>np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>choice<span class="token punctuation">(</span>next_nodes<span class="token punctuation">,</span>p<span class="token operator">=</span>proba<span class="token punctuation">)</span><span class="token comment" spellcheck="true">#从所有邻居中随机选择一个</span>
            seq<span class="token punctuation">.</span>append<span class="token punctuation">(</span>selected_next_node<span class="token punctuation">)</span>
        <span class="token keyword">return</span> seq
    <span class="token keyword">def</span> <span class="token function">deep_walk</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>G<span class="token punctuation">)</span><span class="token punctuation">:</span>
        corpus<span class="token operator">=</span><span class="token punctuation">[</span><span class="token punctuation">]</span>
        <span class="token keyword">for</span> _ <span class="token keyword">in</span> range<span class="token punctuation">(</span>self<span class="token punctuation">.</span>num_seqs<span class="token punctuation">)</span><span class="token punctuation">:</span>
            start_node<span class="token operator">=</span>np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>choice<span class="token punctuation">(</span>G<span class="token punctuation">.</span>nodes<span class="token punctuation">)</span>
            corpus<span class="token punctuation">.</span>append<span class="token punctuation">(</span>self<span class="token punctuation">.</span>walk_one_time<span class="token punctuation">(</span>G<span class="token punctuation">,</span>start_node<span class="token punctuation">)</span><span class="token punctuation">)</span>
        <span class="token keyword">return</span> corpus<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<pre class="line-numbers language-python"><code class="language-python">node2vec<span class="token operator">=</span>Node2Vec<span class="token punctuation">(</span>q<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span>
corpus<span class="token operator">=</span>node2vec<span class="token punctuation">.</span>deep_walk<span class="token punctuation">(</span>G<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>
<pre class="line-numbers language-python"><code class="language-python">corpus<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token number">1</span><span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<p>&gt;&gt;&gt;</p>
<pre><code>[['s1', 'u', 's3', 's4', 's2', 'u', 's1', 's3', 'u', 's1']]</code></pre><pre class="line-numbers language-python"><code class="language-python"><span class="token comment" spellcheck="true">#训练</span>
<span class="token keyword">from</span> gensim<span class="token punctuation">.</span>models <span class="token keyword">import</span> word2vec
model <span class="token operator">=</span> word2vec<span class="token punctuation">.</span>Word2Vec<span class="token punctuation">(</span>corpus<span class="token punctuation">,</span>window<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span>vector_size<span class="token operator">=</span><span class="token number">5</span><span class="token punctuation">,</span>min_count<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre>
<pre class="line-numbers language-python"><code class="language-python"><span class="token comment" spellcheck="true">#查看embedding</span>
model<span class="token punctuation">.</span>wv<span class="token punctuation">[</span><span class="token string">'u'</span><span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>
<p>&gt;&gt;&gt;</p>
<pre><code>array([-0.14191031,  0.13018166,  0.1809364 , -0.10049632, -0.07593277],
dtype=float32)</code></pre><pre class="line-numbers language-python"><code class="language-python"><span class="token comment" spellcheck="true">#计算相似度</span>
model<span class="token punctuation">.</span>wv<span class="token punctuation">.</span>similarity<span class="token punctuation">(</span><span class="token string">"u"</span><span class="token punctuation">,</span><span class="token string">"s5"</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>
<p>&gt;&gt;&gt;</p>
<pre><code>0.07862966</code></pre><pre class="line-numbers language-python"><code class="language-python">model<span class="token punctuation">.</span>wv<span class="token punctuation">.</span>similarity<span class="token punctuation">(</span><span class="token string">"u"</span><span class="token punctuation">,</span><span class="token string">"s6"</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<p>&gt;&gt;&gt;</p>
<pre><code>0.6219288</code></pre><h2 id="GCN"><a href="#GCN" class="headerlink" title="GCN"></a>GCN</h2><h3 id="GCN原理"><a href="#GCN原理" class="headerlink" title="GCN原理"></a>GCN原理</h3><p><strong>1.1  问题1：</strong> 先看一个例子，假如我们有如下的5个用户，他们编号为0~4，且知道他们的关系如下，假如我们现在面对的是车险反欺诈的预测场景，已知编号1，2的为欺诈客户（正样本），编号4的为正常客户（负样本），现在要我们预测剩下的编号0，3的客户是欺诈客户还是正常客户？该怎么办呢？<br><img src="/images/loading.gif" data-original="../images/ML/image-20210829200722942.png" alt=""></p>
<p>我想基于前三节的内容至少可以有两个思路：   </p>
<p>（1）基于度指标：计算当前节点的邻居节点中欺诈客户的占比，那么0号客户周围1/1的客户都是欺诈客户，所以他也是欺诈客户，而客户3周围有2/3的客户都是欺诈客户，所以他也是欺诈客户<br>（2）基于Graph Embedding：基于DeepWalk或者Node2Vec的方式为每个用户学习一个Embedding，然后计算它与邻居Embedding的相似度，然后统计累计相似度占比最高的标签为当前节点的标签，或者直接将这些Embedding送到一个分类器进行训练    </p>
<p><strong>1.2 问题2：</strong> 而我们在处理实际数据时，可能并不仅仅只有他们之间的关系数据，还会有他们各自的因子数据，比如年龄，最近半年的贷款额，最近一月的消费额度这三项，我们将其加到图中（已经归一化处理）   </p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20210829200734312.png" alt=""></p>
<p>那现在如何处理？以往我们可能会只利用他们的因子数据来构建分类模型，比如使用lgbm对这三维度的因子建模预测，但这样又少了结构信息；那如果只利用了上面的结构信息建模又少了因子数据（当然你也可以尝试将Embedding+因子结合起来），那有没有办法同时利用结构信息和因子信息呢？这可以从CNN的卷积操作进行借鉴   </p>
<p><strong>1.3 更一般的认识CNN:</strong> 让我们重新理解一下CNN中卷积操作，</p>
<blockquote>
<p>1) 卷积操作本质上是将某视野域内的像素点数据进行加权聚合，如下图左边将红色区块附近的8个绿块数据加权聚合到红块中（通常会包含红块自身的数据）；<br>2) 那如果我们将这些像素点强行拉开呢？这中间的图不就是一个图结构了吗？（而且现在的边时带权重的，它的权重就对应了卷积块上的数值）；<br>3) 那如果我们再将中图中的某些边切掉，那不就是更一般的图结构了</p>
</blockquote>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20210829200751451.png" alt=""></p>
<p>所以，我们完全可以利用CNN的方式来处理GNN：<strong>将周围邻居的信息加权聚合到中心节点</strong>，这便是GCN的基本思路了：   </p>
<p>1）节点上的信息就是我们的因子，比如上面的年龄，最近半年的贷款额，最近一月的消费额…<br>2）而对邻居的加权聚合便是对于结构信息的处理…   </p>
<p>如此这样，就能同时利用节点的因子信息和结构信息了，下面介绍GCN的详细推导   </p>
<p><strong>1.4 GCN推导</strong>   </p>
<p><strong>结构上</strong>：   </p>
<p>与CNN类似，当前节点的更新信息由当前节点的信息和周围邻居信息累加得到，对于图结构而言，我们需要为每个节点添加一个自连接<br><img src="/images/loading.gif" data-original="../images/ML/image-20210829200807156.png" alt=""></p>
<p>比如对于节点1，它的更新后的信息就是：   </p>
<p>$$<br>[0.4,0.2,0.7]+[0.2,0.3,0.5]+[0.3,0.3,0.5]+[0.4,0.2,0.3]=[1.3,1.0,2.0]<br>$$</p>
<p>再比如，对于节点4，它的更新后的信息就是：   </p>
<p>$$<br>[0.2,0.4,0.3]+[0.4,0.2,0.3]=[0.6,0.6,0.6]<br>$$</p>
<p>想必，你也发现问题了，对于邻居很多的节点，聚合后的数值会比其它邻居少的节点大很多，所以我们需要进行归一化，GCN是采用的归一化方式如下，对于节点$v_i,v_j$，它们的度为$d(v_i),d(v_j)$，聚合信息时，会在它们前面乘以一个权重，即度的乘积的平方根的倒数：    </p>
<p>$$<br>\frac{1}{\sqrt{d(v_i)}\cdot \sqrt{d(v_j)}}<br>$$</p>
<p>所以，这时对于节点1的更新就是：   </p>
<p>$$<br>\frac{1}{4}[0.4,0.2,0.7]+\frac{1}{2\sqrt{2}}[0.2,0.3,0.5]+\frac{1}{2\sqrt{3}}[0.3,0.3,0.5]+\frac{1}{2\sqrt{3}}[0.4,0.2,0.3]<br>$$</p>
<p>上面的更新操作，可以对$X$左乘一个矩阵来进行计算：   </p>
<p>$$<br>\tilde{L}_{sym}X<br>$$</p>
<p>这里的$X$就是我们的因子数据，第$i$行就是第$i$个因子的向量表示，比如$X_{0,:}=[0.2,0.3,0.5]$，而   </p>
<p>$$<br>\tilde{L}<em>{sym}=\tilde{D}^{-1/2}\tilde{A}\tilde{D}^{-1/2}, \tilde{A}=A+I, \tilde{D</em>{ii}}=\sum_j\tilde{A}_{ij}<br>$$</p>
<p>这里的$A$是连接矩阵，$I$是单位矩阵，所以$\tilde{A}X$，就是添加了自连接且没加权的聚合表示，即最上面的表示，如节点1的聚合   </p>
<p>$$<br>[0.4,0.2,0.7]+[0.2,0.3,0.5]+[0.3,0.3,0.5]+[0.4,0.2,0.3]=[1.3,1.0,2.0]<br>$$</p>
<p>而$\tilde{D}$是$\tilde{A}$的度矩阵，它只有对角线上有值，$\tilde{D}_{ii}$的值就是$\tilde{A}$的第$i$行求和，所以$\tilde{A}$矩阵前后分别乘一个$\tilde{D}^{-1/2}$相等于乘以了上文介绍的权重$\frac{1}{\sqrt{d(v_i)}\cdot \sqrt{d(v_j)}}$</p>
<p><strong>因子上：</strong>    </p>
<p>可以发现$ \tilde{L}<em>{sym}X $ 中的 $ \tilde{L}</em>{sym} $和$ X $都是已知的，GCN希望增强模型的表达能力，所以对于$ \tilde{L}_{sym}X $在特征上再做了一次线性变换，等价于右乘一个变量矩阵$ W $，为了进一步增强表达能力，通常还会对结果进行一个非线性变换$ \sigma $，所以最终的更新公式如下：   </p>
<p>$$<br>X’=\sigma(\tilde{L}_{sym}XW)<br>$$</p>
<p>需要注意的是，$W$是对每一层的所有节点共享的，这里可以将其类比为CNN中的卷积核系数   </p>
<p><strong>如何训练？</strong>  </p>
<p>这就和其它ML的任务一样的，构造一个损失函数$loss(X’,Y)$，然后基于梯度，更新参数$W$即可，比如($\eta$为学习率)：</p>
<p>$$<br>W\leftarrow W-\eta\frac{\partial loss(X’,Y)}{\partial W}<br>$$</p>
<h3 id="代码实践"><a href="#代码实践" class="headerlink" title="代码实践"></a>代码实践</h3><p>下面仅演示代码的核心部分   </p>
<p><strong>2.1 加载数据并构建$\tilde{L}_{sym}$</strong></p>
<pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">from</span> code<span class="token punctuation">.</span>gcn <span class="token keyword">import</span> <span class="token operator">*</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<pre class="line-numbers language-python"><code class="language-python"><span class="token comment" spellcheck="true">#加载数据</span>
dataset <span class="token operator">=</span> CoraData<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>data<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>
<p>Using Cached file: E:\datas\Algs\GNN\cora\processed_cora.pkl<br>Cached file: E:\datas\Algs\GNN\cora\processed_cora.pkl</p>
<p><strong>链接矩阵</strong>：表示文章之间的引用关系，这里是稀疏矩阵的格式</p>
<pre class="line-numbers language-python"><code class="language-python">dataset<span class="token punctuation">.</span>adjacency<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<p>&gt;&gt;&gt;</p>
<pre><code>&lt;2708x2708 sparse matrix of type '&lt;class 'numpy.float32'&gt;'
with 10556 stored elements in COOrdinate format&gt;</code></pre><p><strong>因子信息</strong>：2708X1433的矩阵，即2708篇文章的BOW表示</p>
<pre class="line-numbers language-python"><code class="language-python">dataset<span class="token punctuation">.</span>x<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<p>&gt;&gt;&gt;</p>
<pre><code>array([[0., 0., 0., ..., 0., 0., 0.],
[0., 0., 0., ..., 0., 0., 0.],
[0., 0., 0., ..., 0., 0., 0.],
...,
[0., 0., 0., ..., 0., 0., 0.],
[0., 0., 0., ..., 0., 0., 0.],
[0., 0., 0., ..., 0., 0., 0.]], dtype=float32)</code></pre><p><strong>标签信息</strong>：2708X1，分别标记了2708篇文章的7种类别</p>
<pre class="line-numbers language-python"><code class="language-python">dataset<span class="token punctuation">.</span>y<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<p>&gt;&gt;&gt;</p>
<pre><code>array([3, 4, 4, ..., 3, 3, 3], dtype=int64)</code></pre><p><strong>构建$\tilde{L}_{sym}$的代码</strong>：  </p>
<pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">normalization</span><span class="token punctuation">(</span>adjacency<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">"""计算 L=D^-0.5 * (A+I) * D^-0.5"""</span>
    adjacency <span class="token operator">+=</span> sp<span class="token punctuation">.</span>eye<span class="token punctuation">(</span>adjacency<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
    <span class="token comment" spellcheck="true"># 增加自连接</span>
    degree <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span>adjacency<span class="token punctuation">.</span>sum<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    d_hat <span class="token operator">=</span> sp<span class="token punctuation">.</span>diags<span class="token punctuation">(</span>np<span class="token punctuation">.</span>power<span class="token punctuation">(</span>degree<span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.5</span><span class="token punctuation">)</span><span class="token punctuation">.</span>flatten<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token keyword">return</span> d_hat<span class="token punctuation">.</span>dot<span class="token punctuation">(</span>adjacency<span class="token punctuation">)</span><span class="token punctuation">.</span>dot<span class="token punctuation">(</span>d_hat<span class="token punctuation">)</span><span class="token punctuation">.</span>tocoo<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<pre class="line-numbers language-python"><code class="language-python"><span class="token comment" spellcheck="true">#如果有GPU则使用GPU</span>
device <span class="token operator">=</span> <span class="token string">"cuda"</span> <span class="token keyword">if</span> torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>is_available<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">else</span> <span class="token string">"cpu"</span>
<span class="token comment" spellcheck="true">#接着预处理剩下的数据</span>
x <span class="token operator">=</span> dataset<span class="token punctuation">.</span>x <span class="token operator">/</span> dataset<span class="token punctuation">.</span>x<span class="token punctuation">.</span>sum<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> keepdims<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
<span class="token comment" spellcheck="true"># 归一化数据，使得每一行和为1</span>
tensor_x <span class="token operator">=</span> torch<span class="token punctuation">.</span>from_numpy<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>
tensor_y <span class="token operator">=</span> torch<span class="token punctuation">.</span>from_numpy<span class="token punctuation">(</span>dataset<span class="token punctuation">.</span>y<span class="token punctuation">)</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>
tensor_train_mask <span class="token operator">=</span> torch<span class="token punctuation">.</span>from_numpy<span class="token punctuation">(</span>dataset<span class="token punctuation">.</span>trn_mask<span class="token punctuation">)</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>
tensor_val_mask <span class="token operator">=</span> torch<span class="token punctuation">.</span>from_numpy<span class="token punctuation">(</span>dataset<span class="token punctuation">.</span>val_mask<span class="token punctuation">)</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>
tensor_test_mask <span class="token operator">=</span> torch<span class="token punctuation">.</span>from_numpy<span class="token punctuation">(</span>dataset<span class="token punctuation">.</span>test_mask<span class="token punctuation">)</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>
normalize_adjacency <span class="token operator">=</span> normalization<span class="token punctuation">(</span>dataset<span class="token punctuation">.</span>adjacency<span class="token punctuation">)</span>
<span class="token comment" spellcheck="true"># 规范化邻接矩阵</span>
indices <span class="token operator">=</span> torch<span class="token punctuation">.</span>from_numpy<span class="token punctuation">(</span>np<span class="token punctuation">.</span>asarray<span class="token punctuation">(</span><span class="token punctuation">[</span>normalize_adjacency<span class="token punctuation">.</span>row<span class="token punctuation">,</span> normalize_adjacency<span class="token punctuation">.</span>col<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>long<span class="token punctuation">(</span><span class="token punctuation">)</span>
values <span class="token operator">=</span> torch<span class="token punctuation">.</span>from_numpy<span class="token punctuation">(</span>normalize_adjacency<span class="token punctuation">.</span>data<span class="token punctuation">.</span>astype<span class="token punctuation">(</span>np<span class="token punctuation">.</span>float32<span class="token punctuation">)</span><span class="token punctuation">)</span>
tensor_adjacency <span class="token operator">=</span> torch<span class="token punctuation">.</span>sparse<span class="token punctuation">.</span>FloatTensor<span class="token punctuation">(</span>indices<span class="token punctuation">,</span> values<span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">2708</span><span class="token punctuation">,</span> <span class="token number">2708</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p><strong>2.2 构建模型</strong>  </p>
<p>这部分代码拆分为了两块，   </p>
<p>1）第一块是对单次图卷积的操作，对应上面的公式：$X’=\sigma(\tilde{L}_{sym}XW)$，代码如下(这里并没有实现激活函数的功能)：   </p>
<pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">GraphConvolution</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> input_dim<span class="token punctuation">,</span> output_dim<span class="token punctuation">,</span> use_bias<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token triple-quoted-string string">"""图卷积
        input_dim: 节点输入特征的维度
        output_dim: 输出特征维度 
        use_bias : bool, optional"""</span>
        super<span class="token punctuation">(</span>GraphConvolution<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>input_dim <span class="token operator">=</span> input_dim
        self<span class="token punctuation">.</span>output_dim <span class="token operator">=</span> output_dim
        self<span class="token punctuation">.</span>use_bias <span class="token operator">=</span> use_bias
        self<span class="token punctuation">.</span>weight <span class="token operator">=</span> nn<span class="token punctuation">.</span>Parameter<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>Tensor<span class="token punctuation">(</span>input_dim<span class="token punctuation">,</span> output_dim<span class="token punctuation">)</span><span class="token punctuation">)</span>
        <span class="token keyword">if</span> self<span class="token punctuation">.</span>use_bias<span class="token punctuation">:</span>
            self<span class="token punctuation">.</span>bias <span class="token operator">=</span> nn<span class="token punctuation">.</span>Parameter<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>Tensor<span class="token punctuation">(</span>output_dim<span class="token punctuation">)</span><span class="token punctuation">)</span>
        <span class="token keyword">else</span><span class="token punctuation">:</span>
            self<span class="token punctuation">.</span>register_parameter<span class="token punctuation">(</span><span class="token string">'bias'</span><span class="token punctuation">,</span> None<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>reset_parameters<span class="token punctuation">(</span><span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">reset_parameters</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        nn<span class="token punctuation">.</span>init<span class="token punctuation">.</span>kaiming_uniform_<span class="token punctuation">(</span>self<span class="token punctuation">.</span>weight<span class="token punctuation">)</span>
        <span class="token keyword">if</span> self<span class="token punctuation">.</span>use_bias<span class="token punctuation">:</span>
            nn<span class="token punctuation">.</span>init<span class="token punctuation">.</span>zeros_<span class="token punctuation">(</span>self<span class="token punctuation">.</span>bias<span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> adjacency<span class="token punctuation">,</span> input_feature<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token triple-quoted-string string">"""
        adjacency: 经过上面归一化后的链接矩阵，即\tilde{L}_{sym}
        input_feature:输入特征，即X """</span>
        support <span class="token operator">=</span> torch<span class="token punctuation">.</span>mm<span class="token punctuation">(</span>input_feature<span class="token punctuation">,</span> self<span class="token punctuation">.</span>weight<span class="token punctuation">)</span>
        output <span class="token operator">=</span> torch<span class="token punctuation">.</span>sparse<span class="token punctuation">.</span>mm<span class="token punctuation">(</span>adjacency<span class="token punctuation">,</span> support<span class="token punctuation">)</span>
        <span class="token keyword">if</span> self<span class="token punctuation">.</span>use_bias<span class="token punctuation">:</span>
            output <span class="token operator">+=</span> self<span class="token punctuation">.</span>bias
        <span class="token keyword">return</span> output<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>2）第二块代码叠加了两层图卷积，第一层将1433维的BOW降低到16维，第二层将16维降低到7维，对应到我们的类别数   </p>
<pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">GCNNet</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">""" 定义一个包含两层GraphConvolution的模型 """</span>

    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> input_dim<span class="token operator">=</span><span class="token number">1433</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        super<span class="token punctuation">(</span>GCNNet<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>gcn1 <span class="token operator">=</span> GraphConvolution<span class="token punctuation">(</span>input_dim<span class="token punctuation">,</span> <span class="token number">16</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>gcn2 <span class="token operator">=</span> GraphConvolution<span class="token punctuation">(</span><span class="token number">16</span><span class="token punctuation">,</span> <span class="token number">7</span><span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> adjacency<span class="token punctuation">,</span> feature<span class="token punctuation">)</span><span class="token punctuation">:</span>
        h <span class="token operator">=</span> F<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>self<span class="token punctuation">.</span>gcn1<span class="token punctuation">(</span>adjacency<span class="token punctuation">,</span> feature<span class="token punctuation">)</span><span class="token punctuation">)</span>
        logits <span class="token operator">=</span> self<span class="token punctuation">.</span>gcn2<span class="token punctuation">(</span>adjacency<span class="token punctuation">,</span> h<span class="token punctuation">)</span>
        <span class="token keyword">return</span> logits<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<pre class="line-numbers language-python"><code class="language-python"><span class="token comment" spellcheck="true">#构建模型</span>
model <span class="token operator">=</span> GCNNet<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>
<p><strong>2.3 训练模型</strong>  </p>
<p>主要包括：<br>1）损失函数定义<br>2）优化器定义<br>3）训练过程：  &lt;1&gt;前向得到loss ； &lt;2&gt;loss反向更新参数</p>
<pre class="line-numbers language-python"><code class="language-python"><span class="token comment" spellcheck="true"># 超参数定义</span>
learning_rate <span class="token operator">=</span> <span class="token number">0.1</span>
weight_decay <span class="token operator">=</span> <span class="token number">5e</span><span class="token operator">-</span><span class="token number">4</span>
epochs <span class="token operator">=</span> <span class="token number">200</span>
<span class="token comment" spellcheck="true"># 损失函数使用交叉熵</span>
criterion <span class="token operator">=</span> nn<span class="token punctuation">.</span>CrossEntropyLoss<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>
<span class="token comment" spellcheck="true"># 优化器使用Adam</span>
optimizer <span class="token operator">=</span> optim<span class="token punctuation">.</span>Adam<span class="token punctuation">(</span>model<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> lr<span class="token operator">=</span>learning_rate<span class="token punctuation">,</span> weight_decay<span class="token operator">=</span>weight_decay<span class="token punctuation">)</span>
<span class="token comment" spellcheck="true"># 训练</span>
loss_history <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
val_acc_history <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
model<span class="token punctuation">.</span>train<span class="token punctuation">(</span><span class="token punctuation">)</span>
train_y <span class="token operator">=</span> tensor_y<span class="token punctuation">[</span>tensor_train_mask<span class="token punctuation">]</span>
<span class="token keyword">for</span> epoch <span class="token keyword">in</span> range<span class="token punctuation">(</span>epochs<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token comment" spellcheck="true"># 前向传播</span>
    logits <span class="token operator">=</span> model<span class="token punctuation">(</span>tensor_adjacency<span class="token punctuation">,</span> tensor_x<span class="token punctuation">)</span>
    <span class="token comment" spellcheck="true"># 只选择训练节点进行监督</span>
    train_mask_logits <span class="token operator">=</span> logits<span class="token punctuation">[</span>tensor_train_mask<span class="token punctuation">]</span>
    <span class="token comment" spellcheck="true"># 计算损失值</span>
    loss <span class="token operator">=</span> criterion<span class="token punctuation">(</span>train_mask_logits<span class="token punctuation">,</span> train_y<span class="token punctuation">)</span>
    <span class="token comment" spellcheck="true"># 反向传播计算参数的梯度</span>
    optimizer<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>
    loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token comment" spellcheck="true"># 使用优化方法进行梯度更新</span>
    optimizer<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p><strong>2.4 预测并查看效果</strong></p>
<pre class="line-numbers language-python"><code class="language-python"><span class="token comment" spellcheck="true"># tsne降维，查看效果</span>
<span class="token keyword">import</span> warnings
warnings<span class="token punctuation">.</span>filterwarnings<span class="token punctuation">(</span><span class="token string">"ignore"</span><span class="token punctuation">,</span>category<span class="token operator">=</span>DeprecationWarning<span class="token punctuation">)</span>
<span class="token operator">%</span>matplotlib inline
<span class="token comment" spellcheck="true">#对X用tsne降维</span>
<span class="token keyword">from</span> sklearn <span class="token keyword">import</span> manifold
tsne <span class="token operator">=</span> manifold<span class="token punctuation">.</span>TSNE<span class="token punctuation">(</span>n_components<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span>init<span class="token operator">=</span><span class="token string">"pca"</span><span class="token punctuation">)</span>
X_tsne <span class="token operator">=</span> tsne<span class="token punctuation">.</span>fit_transform<span class="token punctuation">(</span>tensor_x<span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token comment" spellcheck="true">#预测</span>
pred <span class="token operator">=</span> model<span class="token punctuation">(</span>tensor_adjacency<span class="token punctuation">,</span> tensor_x<span class="token punctuation">)</span><span class="token punctuation">.</span>max<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token comment" spellcheck="true">#归一化显示</span>
x_min<span class="token punctuation">,</span> x_max <span class="token operator">=</span> X_tsne<span class="token punctuation">.</span>min<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">,</span> X_tsne<span class="token punctuation">.</span>max<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span>
X_norm <span class="token operator">=</span> <span class="token punctuation">(</span>X_tsne <span class="token operator">-</span> x_min<span class="token punctuation">)</span> <span class="token operator">/</span> <span class="token punctuation">(</span>x_max <span class="token operator">-</span> x_min<span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>figure<span class="token punctuation">(</span>figsize<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">12</span><span class="token punctuation">,</span> <span class="token number">9</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>scatter<span class="token punctuation">(</span>X_norm<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span>X_norm<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span>c<span class="token operator">=</span>pred<span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>yticks<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>xticks<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p><img src="/images/loading.gif" data-original="../images/ML/output_18_0.png" alt=""></p>
<h2 id="GraphSAGE"><a href="#GraphSAGE" class="headerlink" title="GraphSAGE"></a>GraphSAGE</h2><h3 id="GraphSAGE原理"><a href="#GraphSAGE原理" class="headerlink" title="GraphSAGE原理"></a>GraphSAGE原理</h3><p>GraphSAGE是对GCN的优化，其中SAGE是sample和aggreage的缩写，从名称我们也可以看出它主要优化的两个方向：即采样和聚合   </p>
<h4 id="采样"><a href="#采样" class="headerlink" title="采样"></a>采样</h4><p>GCN的训练需要图的全局信息（连接矩阵$\tilde{L}_{sym}$），对于太大的图，可能没有足够的内存或者显存进行训练，借鉴DNN中常用的批量训练方式，GCN也可以利用采样来进行训练，它的采样主要关注两方面：1）<strong>采样训练节点</strong>：由于GCN每增加一层，节点所利用到的邻居信息就要往外扩展一层，所以对于$k$层的GCN网络，我们需要每个训练节点的$k$阶子图样本；2）<strong>采样邻居节点</strong>：另外，由于某些超级节点（度特别大的节点，比如平均度为10的图，某些节点的度可能会有100W）存在，也有造成OOM的风险，对于$k$阶子图的规模也要进行控制，这可以通过限制每层邻居节点数量来控制，如下图第一层采样了3个节点，第二层采样了2个节点（有放回采样）<br><img src="/images/loading.gif" data-original="../images/ML/image-20210829201055183.png" alt=""></p>
<h4 id="聚合"><a href="#聚合" class="headerlink" title="聚合"></a>聚合</h4><p>这一部分其实都是借鉴的DNN中的常见操作，比如取平均/求和/池化等等，这里可以自己设计，需要满足两点：1）不对不同的邻居数量，需要有相同维度的输出，比如$|Agg(v_1,v_2,v_3)|=|Agg(v_1,v_2)|$（$|\cdot|$表示维度）；2）平移不变性，对于不同的输入顺序需要有相同的输出，比如$|Agg(v_1,v_2)=Agg(v_2,v_1)|$，接下来再利用上面的例子演示一下聚合过程：  </p>
<blockquote>
<p>（1）首先将训练节点周围的3个邻居信息聚合，得到图1；<br>（2）然后再将3个邻居的邻居信息聚合到邻居，得到图2，这时第一层GCN就结束了；<br>（3）最后，再次将3个邻居信息聚合到训练节点，得到图3，第二层GCN结束。   </p>
</blockquote>
<p>其中，淡蓝色的点，表示该次操作后不再被需要的点，粉红的点表示采样点，红色和橘黄色分别表示第一轮GCN和第二轮GCN聚合后的点，红色有向边表示第一层的GCN聚合，橘黄色有向边表示第二层的GCN聚合，无向边表示不操作<br><img src="/images/loading.gif" data-original="../images/ML/image-20210829201123170.png" alt=""></p>
<h3 id="实现"><a href="#实现" class="headerlink" title="实现"></a>实现</h3><pre class="line-numbers language-python"><code class="language-python"><span class="token comment" spellcheck="true">#1.准备数据</span>
<span class="token keyword">from</span> code<span class="token punctuation">.</span>graph_sage <span class="token keyword">import</span> <span class="token operator">*</span>
data <span class="token operator">=</span> CoraData<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>data
x <span class="token operator">=</span> data<span class="token punctuation">.</span>x <span class="token operator">/</span> data<span class="token punctuation">.</span>x<span class="token punctuation">.</span>sum<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> keepdims<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># 归一化数据，使得每一行和为1</span>
train_index <span class="token operator">=</span> np<span class="token punctuation">.</span>where<span class="token punctuation">(</span>data<span class="token punctuation">.</span>train_mask<span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
train_label <span class="token operator">=</span> data<span class="token punctuation">.</span>y
test_index <span class="token operator">=</span> np<span class="token punctuation">.</span>where<span class="token punctuation">(</span>data<span class="token punctuation">.</span>test_mask<span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>Using Cached file: E:\datas\Algs\GNN\cora\ch7_cached.pkl</p>
<pre class="line-numbers language-python"><code class="language-python"><span class="token comment" spellcheck="true">#2.训练模型</span>
INPUT_DIM <span class="token operator">=</span> <span class="token number">1433</span>  <span class="token comment" spellcheck="true"># 输入维度</span>
<span class="token comment" spellcheck="true"># Note: 采样的邻居阶数需要与GCN的层数保持一致</span>
HIDDEN_DIM <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">64</span><span class="token punctuation">,</span> <span class="token number">7</span><span class="token punctuation">]</span>  <span class="token comment" spellcheck="true"># 隐藏单元节点数</span>
NUM_NEIGHBORS_LIST <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">10</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">]</span>  <span class="token comment" spellcheck="true"># 每阶采样邻居的节点数</span>
BTACH_SIZE <span class="token operator">=</span> <span class="token number">16</span>  <span class="token comment" spellcheck="true"># 批处理大小</span>
EPOCHS <span class="token operator">=</span> <span class="token number">100</span>
NUM_BATCH_PER_EPOCH <span class="token operator">=</span> <span class="token number">20</span>  <span class="token comment" spellcheck="true"># 每个epoch循环的批次数</span>
LEARNING_RATE <span class="token operator">=</span> <span class="token number">0.01</span>  <span class="token comment" spellcheck="true"># 学习率</span>
DEVICE <span class="token operator">=</span> <span class="token string">"cuda"</span> <span class="token keyword">if</span> torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>is_available<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">else</span> <span class="token string">"cpu"</span>
model <span class="token operator">=</span> GraphSage<span class="token punctuation">(</span>input_dim<span class="token operator">=</span>INPUT_DIM<span class="token punctuation">,</span> hidden_dim<span class="token operator">=</span>HIDDEN_DIM<span class="token punctuation">,</span>
                      num_neighbors_list<span class="token operator">=</span>NUM_NEIGHBORS_LIST<span class="token punctuation">)</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span>DEVICE<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>model<span class="token punctuation">)</span>
criterion <span class="token operator">=</span> nn<span class="token punctuation">.</span>CrossEntropyLoss<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span>DEVICE<span class="token punctuation">)</span>
optimizer <span class="token operator">=</span> optim<span class="token punctuation">.</span>Adam<span class="token punctuation">(</span>model<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> lr<span class="token operator">=</span>LEARNING_RATE<span class="token punctuation">,</span> weight_decay<span class="token operator">=</span><span class="token number">5e</span><span class="token operator">-</span><span class="token number">4</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<pre><code>GraphSage(
    in_features=1433, num_neighbors_list=[10, 10]
    (gcn): ModuleList(
    (0): SageGCN(
        in_features=1433, out_features=64, aggr_hidden_method=sum
        (aggregator): NeighborAggregator(in_features=1433, out_features=64, aggr_method=mean)
    )
    (1): SageGCN(
        in_features=64, out_features=7, aggr_hidden_method=sum
        (aggregator): NeighborAggregator(in_features=64, out_features=7, aggr_method=mean)
    )
    )
)</code></pre><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">for</span> e <span class="token keyword">in</span> range<span class="token punctuation">(</span>EPOCHS<span class="token punctuation">)</span><span class="token punctuation">:</span>
    model<span class="token punctuation">.</span>train<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token keyword">for</span> batch <span class="token keyword">in</span> range<span class="token punctuation">(</span>NUM_BATCH_PER_EPOCH<span class="token punctuation">)</span><span class="token punctuation">:</span>
        batch_src_index <span class="token operator">=</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>choice<span class="token punctuation">(</span>train_index<span class="token punctuation">,</span> size<span class="token operator">=</span><span class="token punctuation">(</span>BTACH_SIZE<span class="token punctuation">,</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        batch_src_label <span class="token operator">=</span> torch<span class="token punctuation">.</span>from_numpy<span class="token punctuation">(</span>train_label<span class="token punctuation">[</span>batch_src_index<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">.</span>long<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span>DEVICE<span class="token punctuation">)</span>
        batch_sampling_result <span class="token operator">=</span> multihop_sampling<span class="token punctuation">(</span>batch_src_index<span class="token punctuation">,</span> NUM_NEIGHBORS_LIST<span class="token punctuation">,</span> data<span class="token punctuation">.</span>adjacency_dict<span class="token punctuation">)</span>
        batch_sampling_x <span class="token operator">=</span> <span class="token punctuation">[</span>torch<span class="token punctuation">.</span>from_numpy<span class="token punctuation">(</span>x<span class="token punctuation">[</span>idx<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">.</span>float<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span>DEVICE<span class="token punctuation">)</span> <span class="token keyword">for</span> idx <span class="token keyword">in</span> batch_sampling_result<span class="token punctuation">]</span>
        batch_train_logits <span class="token operator">=</span> model<span class="token punctuation">(</span>batch_sampling_x<span class="token punctuation">)</span>
        loss <span class="token operator">=</span> criterion<span class="token punctuation">(</span>batch_train_logits<span class="token punctuation">,</span> batch_src_label<span class="token punctuation">)</span>
        optimizer<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>
        loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># 反向传播计算参数的梯度</span>
        optimizer<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># 使用优化方法进行梯度更新</span>
<span class="token comment" spellcheck="true">#         print("Epoch {:03d} Batch {:03d} Loss: {:.4f}".format(e, batch, loss.item()))</span>
    <span class="token comment" spellcheck="true"># test</span>
    model<span class="token punctuation">.</span>eval<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token keyword">with</span> torch<span class="token punctuation">.</span>no_grad<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        test_sampling_result <span class="token operator">=</span> multihop_sampling<span class="token punctuation">(</span>test_index<span class="token punctuation">,</span> NUM_NEIGHBORS_LIST<span class="token punctuation">,</span> data<span class="token punctuation">.</span>adjacency_dict<span class="token punctuation">)</span>
        test_x <span class="token operator">=</span> <span class="token punctuation">[</span>torch<span class="token punctuation">.</span>from_numpy<span class="token punctuation">(</span>x<span class="token punctuation">[</span>idx<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">.</span>float<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span>DEVICE<span class="token punctuation">)</span> <span class="token keyword">for</span> idx <span class="token keyword">in</span> test_sampling_result<span class="token punctuation">]</span>
        test_logits <span class="token operator">=</span> model<span class="token punctuation">(</span>test_x<span class="token punctuation">)</span>
        test_label <span class="token operator">=</span> torch<span class="token punctuation">.</span>from_numpy<span class="token punctuation">(</span>data<span class="token punctuation">.</span>y<span class="token punctuation">[</span>test_index<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">.</span>long<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span>DEVICE<span class="token punctuation">)</span>
        predict_y <span class="token operator">=</span> test_logits<span class="token punctuation">.</span>max<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span>
        accuarcy <span class="token operator">=</span> torch<span class="token punctuation">.</span>eq<span class="token punctuation">(</span>predict_y<span class="token punctuation">,</span> test_label<span class="token punctuation">)</span><span class="token punctuation">.</span>float<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>mean<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token comment" spellcheck="true">#         print("Test Accuracy: ", accuarcy)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<pre class="line-numbers language-python"><code class="language-python"><span class="token comment" spellcheck="true">#3.查看效果</span>
<span class="token keyword">import</span> warnings
warnings<span class="token punctuation">.</span>filterwarnings<span class="token punctuation">(</span><span class="token string">"ignore"</span><span class="token punctuation">)</span>
<span class="token operator">%</span>matplotlib inline
<span class="token keyword">from</span> sklearn <span class="token keyword">import</span> manifold
tsne <span class="token operator">=</span> manifold<span class="token punctuation">.</span>TSNE<span class="token punctuation">(</span>n_components<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span>init<span class="token operator">=</span><span class="token string">"pca"</span><span class="token punctuation">)</span>
X_tsne <span class="token operator">=</span> tsne<span class="token punctuation">.</span>fit_transform<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
total_sampling_result <span class="token operator">=</span> multihop_sampling<span class="token punctuation">(</span>list<span class="token punctuation">(</span>range<span class="token punctuation">(</span>len<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span> NUM_NEIGHBORS_LIST<span class="token punctuation">,</span> data<span class="token punctuation">.</span>adjacency_dict<span class="token punctuation">)</span>
total_x <span class="token operator">=</span> <span class="token punctuation">[</span>torch<span class="token punctuation">.</span>from_numpy<span class="token punctuation">(</span>x<span class="token punctuation">[</span>idx<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">.</span>float<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span>DEVICE<span class="token punctuation">)</span> <span class="token keyword">for</span> idx <span class="token keyword">in</span> total_sampling_result<span class="token punctuation">]</span>
pred <span class="token operator">=</span> model<span class="token punctuation">(</span>total_x<span class="token punctuation">)</span><span class="token punctuation">.</span>max<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span>
x_min<span class="token punctuation">,</span> x_max <span class="token operator">=</span> X_tsne<span class="token punctuation">.</span>min<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">,</span> X_tsne<span class="token punctuation">.</span>max<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span>
X_norm <span class="token operator">=</span> <span class="token punctuation">(</span>X_tsne <span class="token operator">-</span> x_min<span class="token punctuation">)</span> <span class="token operator">/</span> <span class="token punctuation">(</span>x_max <span class="token operator">-</span> x_min<span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># 归一化</span>
plt<span class="token punctuation">.</span>figure<span class="token punctuation">(</span>figsize<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">12</span><span class="token punctuation">,</span> <span class="token number">9</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>scatter<span class="token punctuation">(</span>X_norm<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span>X_norm<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span>c<span class="token operator">=</span>pred<span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>yticks<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>xticks<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p><img src="/images/loading.gif" data-original="../images/ML/output_5_0-16302390215222.png" alt=""></p>
<h2 id="GAT"><a href="#GAT" class="headerlink" title="GAT"></a>GAT</h2><h3 id="GAT原理"><a href="#GAT原理" class="headerlink" title="GAT原理"></a>GAT原理</h3><p><strong>1.Attention是什么？</strong>   </p>
<p>GAT是Graph Attention Networks的简称，即图注意力网络，借鉴于DNN的发展，将Attention应用于图网络是很自然的想法，在原始的GCN中，我们对俩节点$v_i,v_j$聚合时，会设置它们的权重为：<br>$$<br>w_{ij}=\frac{1}{\sqrt{d(v_i)}\sqrt{d(v_j)}}<br>$$</p>
<p>而Attention机制认为，这个权重应该由算法自己去学习，而不是显示的指定，所以在Attention机制下，权重可以被定义为如下表达：   </p>
<p>$$<br>w_{i,j}=Attention(h_i,h_j,W)<br>$$</p>
<p>这里，$h_i,h_j$分别为$v_i,v_j$在当前层的向量表示，$W$是待学习参数，$Attention(h_i,h_j,W)$输出一个标量值，所以任意满足上面定义的表达式都可以看作是一种Attention，最简单的就是$h_i,h_j$向量做内积：$&lt;h_i,h_j&gt;$    </p>
<p><strong>2. GAT中的Attention</strong>  </p>
<p>它的定义可以表示如下：   </p>
<p>$$<br>e_{ij}=LeakyReLU(a^T[Wh_i||Wh_j])\<br>w_{ij}=\frac{exp(e_{ij})}{\sum_{k\in N(v_i)exp(e_{ik})}}<br>$$</p>
<p>首先，$h_i,h_j$通过矩阵$W$进行一次线性变换，然后通过$||$操作符将俩向量拼接成一个向量，接下来与一个同维度向量$a$做内积，最后通过非线性激活函数$LeakyReLU$得到一个标量$e_{ij}$，然后对其进行softmax归一化得到最终的权重值，按照加权求和的思路，节点$v_i$的新特征向量为：   </p>
<p>$$<br>h’<em>i=\sigma(\sum</em>{j\in N(v_i)}w_{ij} Wh_j)<br>$$</p>
<p>通常我们会将单个attention过程，独立做多次（不同的$W,a$），然后将最终得到的多个新特征向量拼接起来（多头注意力）作为最终的新特征向量</p>
<h3 id="实现-1"><a href="#实现-1" class="headerlink" title="实现"></a>实现</h3><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">from</span> code<span class="token punctuation">.</span>gat <span class="token keyword">import</span> <span class="token operator">*</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<pre class="line-numbers language-python"><code class="language-python"><span class="token comment" spellcheck="true">#1.加载数据</span>
dataset <span class="token operator">=</span> CoraData<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>data
<span class="token comment" spellcheck="true">#如果有GPU则使用GPU</span>
device <span class="token operator">=</span> <span class="token string">"cuda"</span> <span class="token keyword">if</span> torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>is_available<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">else</span> <span class="token string">"cpu"</span>
<span class="token comment" spellcheck="true">#接着预处理剩下的数据</span>
x <span class="token operator">=</span> dataset<span class="token punctuation">.</span>x <span class="token operator">/</span> dataset<span class="token punctuation">.</span>x<span class="token punctuation">.</span>sum<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> keepdims<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
<span class="token comment" spellcheck="true"># 归一化数据，使得每一行和为1</span>
tensor_x <span class="token operator">=</span> torch<span class="token punctuation">.</span>from_numpy<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>
tensor_y <span class="token operator">=</span> torch<span class="token punctuation">.</span>from_numpy<span class="token punctuation">(</span>dataset<span class="token punctuation">.</span>y<span class="token punctuation">)</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>
tensor_train_mask <span class="token operator">=</span> torch<span class="token punctuation">.</span>from_numpy<span class="token punctuation">(</span>dataset<span class="token punctuation">.</span>trn_mask<span class="token punctuation">)</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>
tensor_val_mask <span class="token operator">=</span> torch<span class="token punctuation">.</span>from_numpy<span class="token punctuation">(</span>dataset<span class="token punctuation">.</span>val_mask<span class="token punctuation">)</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>
tensor_test_mask <span class="token operator">=</span> torch<span class="token punctuation">.</span>from_numpy<span class="token punctuation">(</span>dataset<span class="token punctuation">.</span>test_mask<span class="token punctuation">)</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>
normalize_adjacency <span class="token operator">=</span> dataset<span class="token punctuation">.</span>adjacency
<span class="token comment" spellcheck="true"># 规范化邻接矩阵</span>
indices <span class="token operator">=</span> torch<span class="token punctuation">.</span>from_numpy<span class="token punctuation">(</span>np<span class="token punctuation">.</span>asarray<span class="token punctuation">(</span><span class="token punctuation">[</span>normalize_adjacency<span class="token punctuation">.</span>row<span class="token punctuation">,</span> normalize_adjacency<span class="token punctuation">.</span>col<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>long<span class="token punctuation">(</span><span class="token punctuation">)</span>
values <span class="token operator">=</span> torch<span class="token punctuation">.</span>from_numpy<span class="token punctuation">(</span>normalize_adjacency<span class="token punctuation">.</span>data<span class="token punctuation">.</span>astype<span class="token punctuation">(</span>np<span class="token punctuation">.</span>float32<span class="token punctuation">)</span><span class="token punctuation">)</span>
tensor_adjacency <span class="token operator">=</span> torch<span class="token punctuation">.</span>sparse<span class="token punctuation">.</span>FloatTensor<span class="token punctuation">(</span>indices<span class="token punctuation">,</span> values<span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">2708</span><span class="token punctuation">,</span> <span class="token number">2708</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>Using Cached file: E:\datas\Algs\GNN\cora\processed_cora.pkl<br>Cached file: E:\datas\Algs\GNN\cora\processed_cora.pkl</p>
<pre class="line-numbers language-python"><code class="language-python"><span class="token comment" spellcheck="true">#2.构建模型</span>
model <span class="token operator">=</span> GAT<span class="token punctuation">(</span><span class="token number">1433</span><span class="token punctuation">,</span> <span class="token number">16</span><span class="token punctuation">,</span> <span class="token number">7</span><span class="token punctuation">,</span> <span class="token number">0.2</span><span class="token punctuation">,</span> <span class="token number">0.2</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>
<pre class="line-numbers language-python"><code class="language-python"><span class="token comment" spellcheck="true">#3.训练模型</span>
learning_rate <span class="token operator">=</span> <span class="token number">0.1</span>
weight_decay <span class="token operator">=</span> <span class="token number">5e</span><span class="token operator">-</span><span class="token number">4</span>
epochs <span class="token operator">=</span> <span class="token number">5</span>
<span class="token comment" spellcheck="true"># 损失函数使用交叉熵</span>
criterion <span class="token operator">=</span> nn<span class="token punctuation">.</span>CrossEntropyLoss<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>
<span class="token comment" spellcheck="true"># 优化器使用Adam</span>
optimizer <span class="token operator">=</span> optim<span class="token punctuation">.</span>Adam<span class="token punctuation">(</span>model<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> lr<span class="token operator">=</span>learning_rate<span class="token punctuation">,</span> weight_decay<span class="token operator">=</span>weight_decay<span class="token punctuation">)</span>
<span class="token comment" spellcheck="true"># 训练</span>
loss_history <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
val_acc_history <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
model<span class="token punctuation">.</span>train<span class="token punctuation">(</span><span class="token punctuation">)</span>
train_y <span class="token operator">=</span> tensor_y<span class="token punctuation">[</span>tensor_train_mask<span class="token punctuation">]</span>
<span class="token keyword">for</span> epoch <span class="token keyword">in</span> range<span class="token punctuation">(</span>epochs<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token comment" spellcheck="true"># 前向传播</span>
    logits <span class="token operator">=</span> model<span class="token punctuation">(</span>tensor_x<span class="token punctuation">,</span>tensor_adjacency<span class="token punctuation">)</span>
    <span class="token comment" spellcheck="true"># 只选择训练节点进行监督</span>
    train_mask_logits <span class="token operator">=</span> logits<span class="token punctuation">[</span>tensor_train_mask<span class="token punctuation">]</span>
    <span class="token comment" spellcheck="true"># 计算损失值</span>
    loss <span class="token operator">=</span> criterion<span class="token punctuation">(</span>train_mask_logits<span class="token punctuation">,</span> train_y<span class="token punctuation">)</span>
    <span class="token comment" spellcheck="true"># 反向传播计算参数的梯度</span>
    optimizer<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>
    loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token comment" spellcheck="true"># 使用优化方法进行梯度更新</span>
    optimizer<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<pre class="line-numbers language-python"><code class="language-python"><span class="token comment" spellcheck="true">#4.查看效果</span>
<span class="token keyword">import</span> warnings
warnings<span class="token punctuation">.</span>filterwarnings<span class="token punctuation">(</span><span class="token string">"ignore"</span><span class="token punctuation">,</span>category<span class="token operator">=</span>DeprecationWarning<span class="token punctuation">)</span>
<span class="token operator">%</span>matplotlib inline
<span class="token comment" spellcheck="true">#对X用tsne降维</span>
<span class="token keyword">from</span> sklearn <span class="token keyword">import</span> manifold
tsne <span class="token operator">=</span> manifold<span class="token punctuation">.</span>TSNE<span class="token punctuation">(</span>n_components<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span>init<span class="token operator">=</span><span class="token string">"pca"</span><span class="token punctuation">)</span>
X_tsne <span class="token operator">=</span> tsne<span class="token punctuation">.</span>fit_transform<span class="token punctuation">(</span>tensor_x<span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token comment" spellcheck="true">#预测</span>
pred <span class="token operator">=</span> model<span class="token punctuation">(</span>tensor_x<span class="token punctuation">,</span>tensor_adjacency<span class="token punctuation">)</span><span class="token punctuation">.</span>max<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token comment" spellcheck="true">#归一化显示</span>
x_min<span class="token punctuation">,</span> x_max <span class="token operator">=</span> X_tsne<span class="token punctuation">.</span>min<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">,</span> X_tsne<span class="token punctuation">.</span>max<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span>
X_norm <span class="token operator">=</span> <span class="token punctuation">(</span>X_tsne <span class="token operator">-</span> x_min<span class="token punctuation">)</span> <span class="token operator">/</span> <span class="token punctuation">(</span>x_max <span class="token operator">-</span> x_min<span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>figure<span class="token punctuation">(</span>figsize<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">12</span><span class="token punctuation">,</span> <span class="token number">9</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>scatter<span class="token punctuation">(</span>X_norm<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span>X_norm<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span>c<span class="token operator">=</span>pred<span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>yticks<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>xticks<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p><img src="/images/loading.gif" data-original="../images/ML/output_6_0.png" alt=""></p>
<h2 id="DGL"><a href="#DGL" class="headerlink" title="DGL"></a>DGL</h2><h3 id="运行机制"><a href="#运行机制" class="headerlink" title="运行机制"></a>运行机制</h3><p>为了更加高效的运行GNN，我们可以利用一些高效的图计算框架帮助我们训练模型，DGL（Deep Graph Library）便是一种比较方便的框架，它将所有的图计算过程拆分为了三个基本部分，分别介绍如下：   </p>
<p><strong>1.1 消息传递函数</strong><br>该函数是将一条边以及与其关联的两个节点的信息进行聚合，然后将聚合后<strong>消息</strong>重新赋值到边上，可以用如下的表达式抽象表达：   </p>
<p>$$<br>m_{uv}^{(t+1)}=\phi(x_u^{(t)},x_v^{(t)},w_{uv}^{(t)})<br>$$</p>
<p>其中，$w_{uv}^{(t)}$表示边$(u,v)$上的特征，$x_u^{(t)}$表示节点$u$上的特征，$x_v^{(t)}$表示节点$v$上的特征  </p>
<p><strong>1.2 聚合函数</strong><br>聚合函数是将与训练节点关联的边上的消息，进行聚合：    </p>
<p>$$<br>\rho_u^{t+1}=\rho({m_{uk}^{(t+1)}\mid k\in N(u)})<br>$$</p>
<p>这里，$N(u)$表示与节点$u$相连的邻居节点   </p>
<p><strong>1.3 更新函数</strong><br>更新函数的作用是将聚合特征与节点的旧特征进行聚合，然后生成节点的新特征：   </p>
<p>$$<br>x_u^{(t+1)}=\varphi(x_u^{(t)},\rho_u^{t+1})<br>$$</p>
<p>我们之前介绍的GCN，GAT，GraphSAGE便可分解为这三个基本操作函数，接下来我利用DGL库演示一下这3个基本操作</p>
<h3 id="实践"><a href="#实践" class="headerlink" title="实践"></a>实践</h3><p><strong>2.1 构图</strong>：首先构建一张图，并为节点和边赋值</p>
<pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">import</span> dgl
<span class="token keyword">import</span> torch<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>
<p>Using backend: pytorch</p>
<pre class="line-numbers language-python"><code class="language-python">u<span class="token operator">=</span>torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">,</span><span class="token number">5</span><span class="token punctuation">,</span><span class="token number">5</span><span class="token punctuation">,</span><span class="token number">6</span><span class="token punctuation">,</span><span class="token number">6</span><span class="token punctuation">,</span><span class="token number">6</span><span class="token punctuation">,</span><span class="token number">7</span><span class="token punctuation">,</span><span class="token number">8</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
v<span class="token operator">=</span>torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">,</span><span class="token number">5</span><span class="token punctuation">,</span><span class="token number">5</span><span class="token punctuation">,</span><span class="token number">6</span><span class="token punctuation">,</span><span class="token number">7</span><span class="token punctuation">,</span><span class="token number">7</span><span class="token punctuation">,</span><span class="token number">8</span><span class="token punctuation">,</span><span class="token number">9</span><span class="token punctuation">,</span><span class="token number">8</span><span class="token punctuation">,</span><span class="token number">9</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
g<span class="token operator">=</span>dgl<span class="token punctuation">.</span>graph<span class="token punctuation">(</span><span class="token punctuation">(</span>u<span class="token punctuation">,</span>v<span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre>
<pre class="line-numbers language-python"><code class="language-python"><span class="token comment" spellcheck="true">#转换为networkx可视化</span>
<span class="token operator">%</span>matplotlib inline
<span class="token keyword">from</span> matplotlib <span class="token keyword">import</span> pyplot <span class="token keyword">as</span> plt
<span class="token keyword">import</span> networkx <span class="token keyword">as</span> nx
plt<span class="token punctuation">.</span>axis<span class="token punctuation">(</span><span class="token string">"off"</span><span class="token punctuation">)</span>
nx<span class="token punctuation">.</span>draw_networkx<span class="token punctuation">(</span>g<span class="token punctuation">.</span>to_networkx<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p><img src="/images/loading.gif" data-original="../images/ML/output_4_0.png" alt=""></p>
<pre class="line-numbers language-python"><code class="language-python"><span class="token comment" spellcheck="true">#分别为节点和边赋值一个三维的向量</span>
g<span class="token punctuation">.</span>ndata<span class="token punctuation">[</span><span class="token string">"nx"</span><span class="token punctuation">]</span><span class="token operator">=</span>torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span>g<span class="token punctuation">.</span>num_nodes<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">)</span>
g<span class="token punctuation">.</span>edata<span class="token punctuation">[</span><span class="token string">"ex"</span><span class="token punctuation">]</span><span class="token operator">=</span>torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span>g<span class="token punctuation">.</span>num_edges<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre>
<pre class="line-numbers language-python"><code class="language-python"><span class="token comment" spellcheck="true">#查看</span>
g<span class="token punctuation">.</span>ndata<span class="token punctuation">[</span><span class="token string">"nx"</span><span class="token punctuation">]</span><span class="token punctuation">,</span>g<span class="token punctuation">.</span>edata<span class="token punctuation">[</span><span class="token string">"ex"</span><span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>
<p>&gt;&gt;&gt;</p>
<pre><code>(tensor([[ 0.6239,  0.3987, -0.6238],
        [-0.7141, -1.0818, -1.0757],
        [-0.0540,  1.1078,  0.2700],
        [ 0.5681, -1.0023, -1.4963],
        [-1.3526, -0.5072,  0.3111],
        [ 0.4039,  0.1909,  2.4836],
        [ 0.2190,  0.9467, -0.6446],
        [-0.5860, -1.7527, -1.0872],
        [ 0.8450,  0.9458, -0.5495],
        [ 1.3140,  0.4514,  0.5442]]),
tensor([[-0.5180, -0.1497,  0.4278],
        [ 0.7970, -0.1222, -0.5810],
        [-0.9885,  0.7971, -1.0056],
        [-0.5377,  0.3229, -0.1410],
        [ 1.2062,  1.3272, -0.4768],
        [-0.6856,  0.9685, -1.3733],
        [ 1.0140, -0.1059,  1.4300],
        [-0.4088,  0.5824, -0.4151],
        [ 1.4490, -1.0892,  0.2116],
        [ 0.2986, -0.0652, -0.4363],
        [ 0.7020,  0.6645, -1.1004],
        [ 0.7326,  0.5491,  0.8222],
        [-0.5815, -1.3774,  0.7640],
        [ 1.1323, -1.4232,  0.2073],
        [-0.3632, -1.3108, -1.2507],
        [-0.7597, -1.1140,  0.2626],
        [-0.8476, -1.2887, -0.7922]]))</code></pre><p><strong>2.2 利用apply_edges进行消息传递</strong>  </p>
<p>apply_edges可以完成第一个函数的操作，即将两节点特征和边特征进行某种操作，然后将结果保存回边上，我们先用dgl自带的api，将$u,v$节点的特征相加然后赋值到边上</p>
<pre class="line-numbers language-python"><code class="language-python">g<span class="token punctuation">.</span>apply_edges<span class="token punctuation">(</span>dgl<span class="token punctuation">.</span>function<span class="token punctuation">.</span>u_add_v<span class="token punctuation">(</span><span class="token string">"nx"</span><span class="token punctuation">,</span><span class="token string">"nx"</span><span class="token punctuation">,</span><span class="token string">"add_x"</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true">#第一个nx表示u上的nx特征，第二个表示v上的nx特征，add_x表示赋值到边上的特征</span>
g<span class="token punctuation">.</span>edata<span class="token punctuation">[</span><span class="token string">"add_x"</span><span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>
<p>&gt;&gt;&gt;</p>
<pre><code>tensor([[-0.0902, -0.6831, -1.6995],        [ 0.5699,  1.5065, -0.3538],        [ 1.1919, -0.6036, -2.1202],        [-0.7288, -0.1085, -0.3128],        [-0.7681,  0.0260, -0.8057],        [-0.1461, -2.0841, -2.5721],        [-1.4066,  0.6007,  0.5811],        [-0.7846, -1.5095, -1.1853],        [ 0.3500,  1.2987,  2.7536],        [-0.9487, -0.3163,  2.7946],        [ 0.6229,  1.1375,  1.8389],        [-0.1821, -1.5618,  1.3964],        [-0.3670, -0.8060, -1.7318],        [ 1.0640,  1.8925, -1.1941],        [ 1.5330,  1.3981, -0.1005],        [ 0.2589, -0.8069, -1.6367],        [ 2.1590,  1.3972, -0.0053]])</code></pre><p>这个过程也可以写自定义函数进行操作</p>
<pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">message_func</span><span class="token punctuation">(</span>edges<span class="token punctuation">)</span><span class="token punctuation">:</span>     <span class="token keyword">return</span> <span class="token punctuation">{</span><span class="token string">'new_add_x'</span><span class="token punctuation">:</span> edges<span class="token punctuation">.</span>src<span class="token punctuation">[</span><span class="token string">'nx'</span><span class="token punctuation">]</span> <span class="token operator">+</span> edges<span class="token punctuation">.</span>dst<span class="token punctuation">[</span><span class="token string">'nx'</span><span class="token punctuation">]</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<pre class="line-numbers language-python"><code class="language-python">g<span class="token punctuation">.</span>apply_edges<span class="token punctuation">(</span>message_func<span class="token punctuation">)</span>g<span class="token punctuation">.</span>edata<span class="token punctuation">[</span><span class="token string">"new_add_x"</span><span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<p>&gt;&gt;&gt;</p>
<pre><code>tensor([[-0.0902, -0.6831, -1.6995],        [ 0.5699,  1.5065, -0.3538],        [ 1.1919, -0.6036, -2.1202],        [-0.7288, -0.1085, -0.3128],        [-0.7681,  0.0260, -0.8057],        [-0.1461, -2.0841, -2.5721],        [-1.4066,  0.6007,  0.5811],        [-0.7846, -1.5095, -1.1853],        [ 0.3500,  1.2987,  2.7536],        [-0.9487, -0.3163,  2.7946],        [ 0.6229,  1.1375,  1.8389],        [-0.1821, -1.5618,  1.3964],        [-0.3670, -0.8060, -1.7318],        [ 1.0640,  1.8925, -1.1941],        [ 1.5330,  1.3981, -0.1005],        [ 0.2589, -0.8069, -1.6367],        [ 2.1590,  1.3972, -0.0053]])</code></pre><p><strong>2.3 利用update_all组合消息传递函数与聚合函数</strong>  </p>
<p>update_all将消息传递和聚合函数一并进行操作，下面演示先将邻居节点特征加到边，然后再将边特征加到节点</p>
<pre class="line-numbers language-python"><code class="language-python">g<span class="token punctuation">.</span>update_all<span class="token punctuation">(</span>dgl<span class="token punctuation">.</span>function<span class="token punctuation">.</span>u_add_v<span class="token punctuation">(</span><span class="token string">"nx"</span><span class="token punctuation">,</span><span class="token string">"nx"</span><span class="token punctuation">,</span><span class="token string">"add_x"</span><span class="token punctuation">)</span><span class="token punctuation">,</span>             dgl<span class="token punctuation">.</span>function<span class="token punctuation">.</span>sum<span class="token punctuation">(</span><span class="token string">"add_x"</span><span class="token punctuation">,</span><span class="token string">"add_edge_x"</span><span class="token punctuation">)</span><span class="token punctuation">)</span>g<span class="token punctuation">.</span>ndata<span class="token punctuation">[</span><span class="token string">"add_edge_x"</span><span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<p>&gt;&gt;&gt;</p>
<pre><code>tensor([[ 0.0000,  0.0000,  0.0000],        [-0.0902, -0.6831, -1.6995],        [-0.1982,  1.5326, -1.1595],        [ 1.0459, -2.6876, -4.6922],        [-2.9200, -1.0173, -0.9170],        [-0.5987,  0.9824,  5.5482],        [ 0.6229,  1.1375,  1.8389],        [-0.5491, -2.3679, -0.3355],        [ 1.3229,  1.0856, -2.8309],        [ 3.6919,  2.7953, -0.1058]])</code></pre><p>当然，也可以自定义</p>
<pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">reduce_func</span><span class="token punctuation">(</span>nodes<span class="token punctuation">)</span><span class="token punctuation">:</span>     <span class="token keyword">return</span> <span class="token punctuation">{</span><span class="token string">'new_add_edge_x'</span><span class="token punctuation">:</span> torch<span class="token punctuation">.</span>sum<span class="token punctuation">(</span>nodes<span class="token punctuation">.</span>mailbox<span class="token punctuation">[</span><span class="token string">'add_x'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<pre class="line-numbers language-python"><code class="language-python">g<span class="token punctuation">.</span>update_all<span class="token punctuation">(</span>dgl<span class="token punctuation">.</span>function<span class="token punctuation">.</span>u_add_v<span class="token punctuation">(</span><span class="token string">"nx"</span><span class="token punctuation">,</span><span class="token string">"nx"</span><span class="token punctuation">,</span><span class="token string">"add_x"</span><span class="token punctuation">)</span><span class="token punctuation">,</span>             reduce_func<span class="token punctuation">)</span>g<span class="token punctuation">.</span>ndata<span class="token punctuation">[</span><span class="token string">"new_add_edge_x"</span><span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<p>&gt;&gt;&gt;</p>
<pre><code>tensor([[ 0.0000,  0.0000,  0.0000],        [-0.0902, -0.6831, -1.6995],        [-0.1982,  1.5326, -1.1595],        [ 1.0459, -2.6876, -4.6922],        [-2.9200, -1.0173, -0.9170],        [-0.5987,  0.9824,  5.5482],        [ 0.6229,  1.1375,  1.8389],        [-0.5491, -2.3679, -0.3355],        [ 1.3229,  1.0856, -2.8309],        [ 3.6919,  2.7953, -0.1058]])</code></pre><p><strong>2.3 更新函数：最后组合聚合特征和原特征</strong><br>这部分操作就很容易了，因为聚合特征和原特征都在节点上了，所以我们直接操作即可，比如相加</p>
<pre class="line-numbers language-python"><code class="language-python">g<span class="token punctuation">.</span>ndata<span class="token punctuation">[</span><span class="token string">"nx"</span><span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<p>&gt;&gt;&gt;</p>
<pre><code>tensor([[ 0.6239,  0.3987, -0.6238],
        [-0.7141, -1.0818, -1.0757],
        [-0.0540,  1.1078,  0.2700],
        [ 0.5681, -1.0023, -1.4963],
        [-1.3526, -0.5072,  0.3111],
        [ 0.4039,  0.1909,  2.4836],
        [ 0.2190,  0.9467, -0.6446],
        [-0.5860, -1.7527, -1.0872],
        [ 0.8450,  0.9458, -0.5495],
        [ 1.3140,  0.4514,  0.5442]])</code></pre><pre class="line-numbers language-python"><code class="language-python">g<span class="token punctuation">.</span>ndata<span class="token punctuation">[</span><span class="token string">"nx"</span><span class="token punctuation">]</span><span class="token operator">=</span>g<span class="token punctuation">.</span>ndata<span class="token punctuation">[</span><span class="token string">"nx"</span><span class="token punctuation">]</span><span class="token operator">+</span>g<span class="token punctuation">.</span>ndata<span class="token punctuation">[</span><span class="token string">"add_edge_x"</span><span class="token punctuation">]</span>
g<span class="token punctuation">.</span>ndata<span class="token punctuation">[</span><span class="token string">"nx"</span><span class="token punctuation">]</span><span class="token comment" spellcheck="true">#注意从第二行开始看</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>
<p>&gt;&gt;&gt;</p>
<pre><code>tensor([[ 0.6239,  0.3987, -0.6238],
        [-0.8044, -1.7649, -2.7753],
        [-0.2522,  2.6404, -0.8895],
        [ 1.6139, -3.6899, -6.1886],
        [-4.2726, -1.5244, -0.6059],
        [-0.1948,  1.1733,  8.0318],
        [ 0.8419,  2.0842,  1.1943],
        [-1.1352, -4.1206, -1.4227],
        [ 2.1679,  2.0314, -3.3804],
        [ 5.0059,  3.2467,  0.4384]])</code></pre><h3 id="PageRank算法"><a href="#PageRank算法" class="headerlink" title="PageRank算法"></a>PageRank算法</h3><p>关于PageRank的原理，大家可以参考<a href="https://nbviewer.jupyter.org/github/zhulei227/ML_Notes/blob/master/notebooks/12_07_PGM_%E9%A9%AC%E5%B0%94%E7%A7%91%E5%A4%AB%E9%93%BE_PageRank%E7%AE%97%E6%B3%95.ipynb" target="_blank" rel="noopener">&gt;&gt;note</a><br><img src="/images/loading.gif" data-original="../images/ML/image-20210829201724741.png" alt=""></p>
<p>如图，以节点A举例，他的PR更新公示可以表示为：   </p>
<p>$$<br>PR_A^{(t+1)}=w_{BA}PR_B^{(t)}+w_{CA}PR_C^{(t)}<br>$$</p>
<p>这里，$w_{BA}$表示边$(B,A)$上的权重，在默认情况下，我们可以设置为节点$B$的出度的倒数，而$PR_{*}$则表示某节点的PR值，下面利用DGL来计算PR，节点编号0 ~ 3分别对应上面的节点A ~ D</p>
<pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">import</span> dgl
<span class="token keyword">import</span> torch<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>
<p>Using backend: pytorch</p>
<p><strong>构建图</strong></p>
<pre class="line-numbers language-python"><code class="language-python">u<span class="token operator">=</span>torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
v<span class="token operator">=</span>torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
g<span class="token operator">=</span>dgl<span class="token punctuation">.</span>graph<span class="token punctuation">(</span><span class="token punctuation">(</span>u<span class="token punctuation">,</span>v<span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre>
<p><strong>计算边权重</strong></p>
<pre class="line-numbers language-python"><code class="language-python">g<span class="token punctuation">.</span>ndata<span class="token punctuation">[</span><span class="token string">"out_degrees"</span><span class="token punctuation">]</span><span class="token operator">=</span>g<span class="token punctuation">.</span>out_degrees<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">message_func</span><span class="token punctuation">(</span>edges<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">return</span> <span class="token punctuation">{</span><span class="token string">"weight"</span><span class="token punctuation">:</span><span class="token number">1.0</span><span class="token operator">/</span>edges<span class="token punctuation">.</span>src<span class="token punctuation">[</span><span class="token string">"out_degrees"</span><span class="token punctuation">]</span><span class="token punctuation">}</span>
g<span class="token punctuation">.</span>apply_edges<span class="token punctuation">(</span>message_func<span class="token punctuation">)</span>
g<span class="token punctuation">.</span>edata<span class="token punctuation">[</span><span class="token string">"weight"</span><span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre>
<p>&gt;&gt;&gt;</p>
<pre><code>tensor([0.3333, 0.3333, 0.3333, 0.5000, 0.5000, 1.0000, 0.5000, 0.5000])</code></pre><p><strong>计算PR</strong></p>
<pre class="line-numbers language-python"><code class="language-python"><span class="token comment" spellcheck="true">#随机初始化一组PR</span>
prs<span class="token operator">=</span>torch<span class="token punctuation">.</span>exp<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
prs<span class="token operator">=</span>prs<span class="token operator">/</span>torch<span class="token punctuation">.</span>sum<span class="token punctuation">(</span>prs<span class="token punctuation">)</span>
prs<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre>
<p>&gt;&gt;&gt;</p>
<pre><code>tensor([0.1702, 0.3912, 0.1391, 0.2994])</code></pre><pre class="line-numbers language-python"><code class="language-python">g<span class="token punctuation">.</span>ndata<span class="token punctuation">[</span><span class="token string">"pr"</span><span class="token punctuation">]</span><span class="token operator">=</span>prs<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">for</span> _ <span class="token keyword">in</span> range<span class="token punctuation">(</span><span class="token number">100</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    g<span class="token punctuation">.</span>update_all<span class="token punctuation">(</span>dgl<span class="token punctuation">.</span>function<span class="token punctuation">.</span>u_dot_e<span class="token punctuation">(</span><span class="token string">"pr"</span><span class="token punctuation">,</span><span class="token string">"weight"</span><span class="token punctuation">,</span><span class="token string">"weighted_pr"</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token comment" spellcheck="true">#将源节点上的pr与边上的weight相乘后放到边上的weighted_pr变量中</span>
                 dgl<span class="token punctuation">.</span>function<span class="token punctuation">.</span>sum<span class="token punctuation">(</span><span class="token string">"weighted_pr"</span><span class="token punctuation">,</span><span class="token string">"pr"</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true">#将所有入边上的weighted_pr求和后赋值到目标节点的pr变量中</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre>
<pre class="line-numbers language-python"><code class="language-python">g<span class="token punctuation">.</span>ndata<span class="token punctuation">[</span><span class="token string">"pr"</span><span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<p>&gt;&gt;&gt;</p>
<pre><code>tensor([0.3333, 0.2222, 0.2222, 0.2222])</code></pre><p>上面的实现不够严谨，为了防止没有出度或者没有入度的节点，其实需要在聚合的时候再添加一个平滑项（见上面链接中的note）</p>
<h3 id="GCN的DGL实现"><a href="#GCN的DGL实现" class="headerlink" title="GCN的DGL实现"></a>GCN的DGL实现</h3><p>我们先拎GCN出来看看，如何将其拆分为3个基本函数的形式，我们先回顾一下它的矩阵更新形式：   </p>
<p>$$<br>X^{(t+1)}=\sigma(\tilde{L}_{sym}X^{(t)}W^{(t)})<br>$$<br>我们可以如下拆解：   </p>
<p><strong>消息传递函数</strong>   </p>
<p>$$<br>m_{uv}^{(t+1)}=\frac{X_{v,:}^{(t)}W^{(t)}}{\sqrt{d_u}\cdot \sqrt{d_v}}<br>$$</p>
<p>这里，$d_u,d_v$分别表示节点$u,v$的度，$X_{v,:}^{(t)}$表示节点$v$的第$t$层的特征向量（这里是行向量表示），$W^{(t)}$是它在第$t$层的训练参数   </p>
<p><strong>聚合函数</strong><br>$$<br>\rho_u^{(t+1)}=\sum_{v\in N(u)}m_{uv}^{(t+1)}<br>$$</p>
<p>这里，只是简单将每条边上的消息相加  </p>
<p><strong>更新函数</strong><br>$$<br>X_{u,:}^{(t+1)}=\sigma(\rho_u^{(t+1)})<br>$$</p>
<p>就在聚合函数的基础上简单添加了一个激活函数即可</p>
<h4 id="代码"><a href="#代码" class="headerlink" title="代码"></a>代码</h4><p>只需要在之前gcn.py的基础上修改即可，下面说下主要修改的地方    </p>
<p><strong>1 将连接矩阵修改为DGLGraph</strong>    </p>
<pre class="line-numbers language-python"><code class="language-python">    @staticmethod
    <span class="token keyword">def</span> <span class="token function">build_dgl_graph</span><span class="token punctuation">(</span>adj_dict<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token triple-quoted-string string">"""根据邻接表创建邻接矩阵"""</span>
        edge_index <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
        <span class="token keyword">for</span> key <span class="token keyword">in</span> adj_dict<span class="token punctuation">.</span>keys<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            edge_index<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token punctuation">[</span>key<span class="token punctuation">,</span> key<span class="token punctuation">]</span><span class="token punctuation">)</span>
            <span class="token keyword">for</span> item <span class="token keyword">in</span> adj_dict<span class="token punctuation">[</span>key<span class="token punctuation">]</span><span class="token punctuation">:</span>
                edge_index<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token punctuation">[</span>key<span class="token punctuation">,</span> item<span class="token punctuation">]</span><span class="token punctuation">)</span>
                edge_index<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token punctuation">[</span>item<span class="token punctuation">,</span> key<span class="token punctuation">]</span><span class="token punctuation">)</span>
        u<span class="token punctuation">,</span> v <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span>item<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token keyword">for</span> item <span class="token keyword">in</span> edge_index<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span>item<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token keyword">for</span> item <span class="token keyword">in</span> edge_index<span class="token punctuation">]</span><span class="token punctuation">)</span>
        <span class="token keyword">return</span> dgl<span class="token punctuation">.</span>graph<span class="token punctuation">(</span><span class="token punctuation">(</span>u<span class="token punctuation">,</span> v<span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p><strong>2 GraphConvolution的Forward修改为DGL实现（核心）</strong></p>
<pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">GraphConvolution</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> input_dim<span class="token punctuation">,</span> output_dim<span class="token punctuation">,</span> use_bias<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        super<span class="token punctuation">(</span>GraphConvolution<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>input_dim <span class="token operator">=</span> input_dim
        self<span class="token punctuation">.</span>output_dim <span class="token operator">=</span> output_dim
        self<span class="token punctuation">.</span>use_bias <span class="token operator">=</span> use_bias
        self<span class="token punctuation">.</span>weight <span class="token operator">=</span> nn<span class="token punctuation">.</span>Parameter<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>Tensor<span class="token punctuation">(</span>input_dim<span class="token punctuation">,</span> output_dim<span class="token punctuation">)</span><span class="token punctuation">)</span>
        <span class="token keyword">if</span> self<span class="token punctuation">.</span>use_bias<span class="token punctuation">:</span>
            self<span class="token punctuation">.</span>bias <span class="token operator">=</span> nn<span class="token punctuation">.</span>Parameter<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>Tensor<span class="token punctuation">(</span>output_dim<span class="token punctuation">)</span><span class="token punctuation">)</span>
        <span class="token keyword">else</span><span class="token punctuation">:</span>
            self<span class="token punctuation">.</span>register_parameter<span class="token punctuation">(</span><span class="token string">'bias'</span><span class="token punctuation">,</span> None<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>reset_parameters<span class="token punctuation">(</span><span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">reset_parameters</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        nn<span class="token punctuation">.</span>init<span class="token punctuation">.</span>kaiming_uniform_<span class="token punctuation">(</span>self<span class="token punctuation">.</span>weight<span class="token punctuation">)</span>
        <span class="token keyword">if</span> self<span class="token punctuation">.</span>use_bias<span class="token punctuation">:</span>
            nn<span class="token punctuation">.</span>init<span class="token punctuation">.</span>zeros_<span class="token punctuation">(</span>self<span class="token punctuation">.</span>bias<span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">message_func</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> edges<span class="token punctuation">)</span><span class="token punctuation">:</span>
        message <span class="token operator">=</span> torch<span class="token punctuation">.</span>mm<span class="token punctuation">(</span>
            edges<span class="token punctuation">.</span>src<span class="token punctuation">[</span><span class="token string">"in_feature"</span><span class="token punctuation">]</span> <span class="token operator">/</span> torch<span class="token punctuation">.</span>sqrt<span class="token punctuation">(</span>edges<span class="token punctuation">.</span>src<span class="token punctuation">[</span><span class="token string">'degree'</span><span class="token punctuation">]</span> <span class="token operator">*</span> edges<span class="token punctuation">.</span>dst<span class="token punctuation">[</span><span class="token string">'degree'</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            self<span class="token punctuation">.</span>weight<span class="token punctuation">)</span>
        <span class="token keyword">if</span> self<span class="token punctuation">.</span>use_bias<span class="token punctuation">:</span>
            message <span class="token operator">+=</span> self<span class="token punctuation">.</span>bias
        <span class="token keyword">return</span> <span class="token punctuation">{</span><span class="token string">"m"</span><span class="token punctuation">:</span> message<span class="token punctuation">}</span>

    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> dgl_graph<span class="token punctuation">:</span> dgl<span class="token punctuation">.</span>graph<span class="token punctuation">,</span> input_feature<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">with</span> dgl_graph<span class="token punctuation">.</span>local_scope<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            dgl_graph<span class="token punctuation">.</span>ndata<span class="token punctuation">[</span><span class="token string">"in_feature"</span><span class="token punctuation">]</span> <span class="token operator">=</span> input_feature
            dgl_graph<span class="token punctuation">.</span>ndata<span class="token punctuation">[</span><span class="token string">"degree"</span><span class="token punctuation">]</span> <span class="token operator">=</span> dgl_graph<span class="token punctuation">.</span>in_degrees<span class="token punctuation">(</span><span class="token punctuation">)</span>
            dgl_graph<span class="token punctuation">.</span>update_all<span class="token punctuation">(</span>
                self<span class="token punctuation">.</span>message_func<span class="token punctuation">,</span>
                dgl<span class="token punctuation">.</span>function<span class="token punctuation">.</span>sum<span class="token punctuation">(</span><span class="token string">"m"</span><span class="token punctuation">,</span> <span class="token string">"neigh_sum"</span><span class="token punctuation">)</span>
            <span class="token punctuation">)</span>
            <span class="token keyword">return</span> dgl_graph<span class="token punctuation">.</span>ndata<span class="token punctuation">[</span><span class="token string">"neigh_sum"</span><span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">from</span> code<span class="token punctuation">.</span>gcn_dgl <span class="token keyword">import</span> <span class="token operator">*</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<p>Using backend: pytorch</p>
<pre class="line-numbers language-python"><code class="language-python"><span class="token comment" spellcheck="true">#1.加载数据</span>
dataset <span class="token operator">=</span> CoraData<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>data<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>
<p>Using Cached file: E:\datas\Algs\GNN\cora\processed_cora_dgl.pkl<br>Cached file: E:\datas\Algs\GNN\cora\processed_cora_dgl.pkl</p>
<pre class="line-numbers language-python"><code class="language-python">dataset<span class="token punctuation">.</span>dgl_graph<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<p>&gt;&gt;&gt;</p>
<pre><code>Graph(num_nodes=2708, num_edges=24424,
        ndata_schemes={}
        edata_schemes={})</code></pre><pre class="line-numbers language-python"><code class="language-python"><span class="token comment" spellcheck="true">#如果有GPU则使用GPUdevice = "cuda" if torch.cuda.is_available() else "cpu"#接着预处理剩下的数据x = dataset.x / dataset.x.sum(1, keepdims=True)# 归一化数据，使得每一行和为1tensor_x = torch.from_numpy(x).to(device)tensor_y = torch.from_numpy(dataset.y).to(device)tensor_train_mask = torch.from_numpy(dataset.trn_mask).to(device)tensor_val_mask = torch.from_numpy(dataset.val_mask).to(device)tensor_test_mask = torch.from_numpy(dataset.test_mask).to(device)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<pre class="line-numbers language-python"><code class="language-python"><span class="token comment" spellcheck="true">#2.构建模型model = GCNNet().to(device)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">accuracy</span><span class="token punctuation">(</span>mask<span class="token punctuation">)</span><span class="token punctuation">:</span>    model<span class="token punctuation">.</span>eval<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token keyword">with</span> torch<span class="token punctuation">.</span>no_grad<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        logits <span class="token operator">=</span> model<span class="token punctuation">(</span>dataset<span class="token punctuation">.</span>dgl_graph<span class="token punctuation">,</span> tensor_x<span class="token punctuation">)</span>        test_mask_logits <span class="token operator">=</span> logits<span class="token punctuation">[</span>mask<span class="token punctuation">]</span>        predict_y <span class="token operator">=</span> test_mask_logits<span class="token punctuation">.</span>max<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span>        accuracy <span class="token operator">=</span> torch<span class="token punctuation">.</span>eq<span class="token punctuation">(</span>predict_y<span class="token punctuation">,</span> tensor_y<span class="token punctuation">[</span>mask<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">.</span>float<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>mean<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token keyword">return</span> accuracy<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<pre class="line-numbers language-python"><code class="language-python"><span class="token comment" spellcheck="true">#3.训练模型</span>
<span class="token comment" spellcheck="true"># 超参数定义</span>
learning_rate <span class="token operator">=</span> <span class="token number">0.01</span>
weight_decay <span class="token operator">=</span> <span class="token number">5e</span><span class="token operator">-</span><span class="token number">4</span>
epochs <span class="token operator">=</span> <span class="token number">200</span>
<span class="token comment" spellcheck="true"># 损失函数使用交叉熵</span>
criterion <span class="token operator">=</span> nn<span class="token punctuation">.</span>CrossEntropyLoss<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>
<span class="token comment" spellcheck="true"># 优化器使用Adam</span>
optimizer <span class="token operator">=</span> optim<span class="token punctuation">.</span>Adam<span class="token punctuation">(</span>model<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> lr<span class="token operator">=</span>learning_rate<span class="token punctuation">,</span> weight_decay<span class="token operator">=</span>weight_decay<span class="token punctuation">)</span>
<span class="token comment" spellcheck="true"># 训练</span>
trn_acc_history <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
val_acc_history <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
model<span class="token punctuation">.</span>train<span class="token punctuation">(</span><span class="token punctuation">)</span>
train_y <span class="token operator">=</span> tensor_y<span class="token punctuation">[</span>tensor_train_mask<span class="token punctuation">]</span>
<span class="token keyword">for</span> epoch <span class="token keyword">in</span> range<span class="token punctuation">(</span>epochs<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token comment" spellcheck="true"># 前向传播</span>
    logits <span class="token operator">=</span> model<span class="token punctuation">(</span>dataset<span class="token punctuation">.</span>dgl_graph<span class="token punctuation">,</span> tensor_x<span class="token punctuation">)</span>
    <span class="token comment" spellcheck="true"># 只选择训练节点进行监督</span>
    train_mask_logits <span class="token operator">=</span> logits<span class="token punctuation">[</span>tensor_train_mask<span class="token punctuation">]</span>
    <span class="token comment" spellcheck="true"># 计算损失值</span>
    loss <span class="token operator">=</span> criterion<span class="token punctuation">(</span>train_mask_logits<span class="token punctuation">,</span> train_y<span class="token punctuation">)</span>
    <span class="token comment" spellcheck="true"># 反向传播计算参数的梯度</span>
    optimizer<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>
    loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token comment" spellcheck="true"># 使用优化方法进行梯度更新</span>
    optimizer<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token comment" spellcheck="true"># 计算当前模型在训练集上的准确率</span>
    train_acc <span class="token operator">=</span> accuracy<span class="token punctuation">(</span>tensor_train_mask<span class="token punctuation">)</span>
    trn_acc_history<span class="token punctuation">.</span>append<span class="token punctuation">(</span>train_acc<span class="token punctuation">)</span>
    <span class="token comment" spellcheck="true"># 计算当前模型在验证集上的准确率</span>
    val_acc <span class="token operator">=</span> accuracy<span class="token punctuation">(</span>tensor_val_mask<span class="token punctuation">)</span>
    val_acc_history<span class="token punctuation">.</span>append<span class="token punctuation">(</span>val_acc<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> plt
<span class="token operator">%</span>matplotlib inline
plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>val_acc_history<span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>trn_acc_history<span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>legend<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token string">'val acc'</span><span class="token punctuation">,</span><span class="token string">'trn acc'</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>&gt;&gt;&gt;</p>
<pre><code>&lt;matplotlib.legend.Legend at 0x1a3b8099f60&gt;</code></pre><p>​<br><img src="/images/loading.gif" data-original="../images/ML/output_9_1.png" alt=""><br>​    </p>
<h3 id="异质图RGCN-节点预测"><a href="#异质图RGCN-节点预测" class="headerlink" title="异质图RGCN_节点预测"></a>异质图RGCN_节点预测</h3><h4 id="原理"><a href="#原理" class="headerlink" title="原理"></a>原理</h4><p>我们通常处理的更多的还是异构图，异构图包含了多种类型的节点以及多种类型的边，我们之前介绍的GCN/GAT/SAGE目前都只能应用于同质图（只有一种节点类型，一种边类型），那如何将同质图的算法扩展到异构图呢？一种通常的做法是：  </p>
<blockquote>
<p>（1）将异构图按照边的类别将切分为多个子图；<br>（2）然后分别在这些子图上运行图算法；<br>（3）最后将各子图的结果再进行一次聚合  </p>
</blockquote>
<p>相较于之前，我们就再多一次对关系的聚合即可：   </p>
<p>$$<br>h_{i}^{(t+1)}=AGG({GNN_r(h_i^{(t)})\mid r\in R})<br>$$</p>
<p>这里，$GNN_r(h_i^{(t)})$表达在关系$r$上对节点$h_i^{(t)}$运行算法$GNN$后的结果，$R$表示所有关系，$AGG(\cdot)$表示对所有结果进行某种聚合，比如max,mean,sum等</p>
<h4 id="实现-2"><a href="#实现-2" class="headerlink" title="实现"></a>实现</h4><p>下面利用官方的示例以及API演示如何构造异构图，如何构造RGCN，并完成节点分类的任务  </p>
<p><strong>1 构造异构图</strong>  </p>
<p>随机构造了1000个用户，500个商品，以及用户与用户之间的follow关系，用户与商品之间的click和dislike关系</p>
<pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">import</span> numpy <span class="token keyword">as</span> np
<span class="token keyword">import</span> torch
<span class="token keyword">import</span> dgl

n_users <span class="token operator">=</span> <span class="token number">1000</span>
n_items <span class="token operator">=</span> <span class="token number">500</span>
n_follows <span class="token operator">=</span> <span class="token number">3000</span>
n_clicks <span class="token operator">=</span> <span class="token number">5000</span>
n_dislikes <span class="token operator">=</span> <span class="token number">500</span>
n_hetero_features <span class="token operator">=</span> <span class="token number">10</span>
n_user_classes <span class="token operator">=</span> <span class="token number">5</span>
n_max_clicks <span class="token operator">=</span> <span class="token number">10</span>

follow_src <span class="token operator">=</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>randint<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> n_users<span class="token punctuation">,</span> n_follows<span class="token punctuation">)</span>
follow_dst <span class="token operator">=</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>randint<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> n_users<span class="token punctuation">,</span> n_follows<span class="token punctuation">)</span>
click_src <span class="token operator">=</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>randint<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> n_users<span class="token punctuation">,</span> n_clicks<span class="token punctuation">)</span>
click_dst <span class="token operator">=</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>randint<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> n_items<span class="token punctuation">,</span> n_clicks<span class="token punctuation">)</span>
dislike_src <span class="token operator">=</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>randint<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> n_users<span class="token punctuation">,</span> n_dislikes<span class="token punctuation">)</span>
dislike_dst <span class="token operator">=</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>randint<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> n_items<span class="token punctuation">,</span> n_dislikes<span class="token punctuation">)</span>

hetero_graph <span class="token operator">=</span> dgl<span class="token punctuation">.</span>heterograph<span class="token punctuation">(</span><span class="token punctuation">{</span>
    <span class="token punctuation">(</span><span class="token string">'user'</span><span class="token punctuation">,</span> <span class="token string">'follow'</span><span class="token punctuation">,</span> <span class="token string">'user'</span><span class="token punctuation">)</span><span class="token punctuation">:</span> <span class="token punctuation">(</span>follow_src<span class="token punctuation">,</span> follow_dst<span class="token punctuation">)</span><span class="token punctuation">,</span>
    <span class="token punctuation">(</span><span class="token string">'user'</span><span class="token punctuation">,</span> <span class="token string">'followed-by'</span><span class="token punctuation">,</span> <span class="token string">'user'</span><span class="token punctuation">)</span><span class="token punctuation">:</span> <span class="token punctuation">(</span>follow_dst<span class="token punctuation">,</span> follow_src<span class="token punctuation">)</span><span class="token punctuation">,</span>
    <span class="token punctuation">(</span><span class="token string">'user'</span><span class="token punctuation">,</span> <span class="token string">'click'</span><span class="token punctuation">,</span> <span class="token string">'item'</span><span class="token punctuation">)</span><span class="token punctuation">:</span> <span class="token punctuation">(</span>click_src<span class="token punctuation">,</span> click_dst<span class="token punctuation">)</span><span class="token punctuation">,</span>
    <span class="token punctuation">(</span><span class="token string">'item'</span><span class="token punctuation">,</span> <span class="token string">'clicked-by'</span><span class="token punctuation">,</span> <span class="token string">'user'</span><span class="token punctuation">)</span><span class="token punctuation">:</span> <span class="token punctuation">(</span>click_dst<span class="token punctuation">,</span> click_src<span class="token punctuation">)</span><span class="token punctuation">,</span>
    <span class="token punctuation">(</span><span class="token string">'user'</span><span class="token punctuation">,</span> <span class="token string">'dislike'</span><span class="token punctuation">,</span> <span class="token string">'item'</span><span class="token punctuation">)</span><span class="token punctuation">:</span> <span class="token punctuation">(</span>dislike_src<span class="token punctuation">,</span> dislike_dst<span class="token punctuation">)</span><span class="token punctuation">,</span>
    <span class="token punctuation">(</span><span class="token string">'item'</span><span class="token punctuation">,</span> <span class="token string">'disliked-by'</span><span class="token punctuation">,</span> <span class="token string">'user'</span><span class="token punctuation">)</span><span class="token punctuation">:</span> <span class="token punctuation">(</span>dislike_dst<span class="token punctuation">,</span> dislike_src<span class="token punctuation">)</span><span class="token punctuation">}</span><span class="token punctuation">)</span>

hetero_graph<span class="token punctuation">.</span>nodes<span class="token punctuation">[</span><span class="token string">'user'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>data<span class="token punctuation">[</span><span class="token string">'feature'</span><span class="token punctuation">]</span> <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span>n_users<span class="token punctuation">,</span> n_hetero_features<span class="token punctuation">)</span>
hetero_graph<span class="token punctuation">.</span>nodes<span class="token punctuation">[</span><span class="token string">'item'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>data<span class="token punctuation">[</span><span class="token string">'feature'</span><span class="token punctuation">]</span> <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span>n_items<span class="token punctuation">,</span> n_hetero_features<span class="token punctuation">)</span>
hetero_graph<span class="token punctuation">.</span>nodes<span class="token punctuation">[</span><span class="token string">'user'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>data<span class="token punctuation">[</span><span class="token string">'label'</span><span class="token punctuation">]</span> <span class="token operator">=</span> torch<span class="token punctuation">.</span>randint<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> n_user_classes<span class="token punctuation">,</span> <span class="token punctuation">(</span>n_users<span class="token punctuation">,</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
hetero_graph<span class="token punctuation">.</span>edges<span class="token punctuation">[</span><span class="token string">'click'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>data<span class="token punctuation">[</span><span class="token string">'label'</span><span class="token punctuation">]</span> <span class="token operator">=</span> torch<span class="token punctuation">.</span>randint<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> n_max_clicks<span class="token punctuation">,</span> <span class="token punctuation">(</span>n_clicks<span class="token punctuation">,</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>float<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token comment" spellcheck="true"># 在user类型的节点和click类型的边上随机生成训练集的掩码</span>
hetero_graph<span class="token punctuation">.</span>nodes<span class="token punctuation">[</span><span class="token string">'user'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>data<span class="token punctuation">[</span><span class="token string">'train_mask'</span><span class="token punctuation">]</span> <span class="token operator">=</span> torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span>n_users<span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>bool<span class="token punctuation">)</span><span class="token punctuation">.</span>bernoulli<span class="token punctuation">(</span><span class="token number">0.6</span><span class="token punctuation">)</span>
hetero_graph<span class="token punctuation">.</span>edges<span class="token punctuation">[</span><span class="token string">'click'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>data<span class="token punctuation">[</span><span class="token string">'train_mask'</span><span class="token punctuation">]</span> <span class="token operator">=</span> torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span>n_clicks<span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>bool<span class="token punctuation">)</span><span class="token punctuation">.</span>bernoulli<span class="token punctuation">(</span><span class="token number">0.6</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>Using backend: pytorch</p>
<p><strong>2 构造模型</strong>  </p>
<p>这里对每种关系都训练的GCN模型，然后每种关系的结果采用sum进行聚合</p>
<pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">import</span> dgl<span class="token punctuation">.</span>nn <span class="token keyword">as</span> dglnn
<span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn <span class="token keyword">as</span> nn
<span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>functional <span class="token keyword">as</span> F

<span class="token keyword">class</span> <span class="token class-name">RGCN</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> in_feats<span class="token punctuation">,</span> hid_feats<span class="token punctuation">,</span> out_feats<span class="token punctuation">,</span> rel_names<span class="token punctuation">)</span><span class="token punctuation">:</span>
        super<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        <span class="token comment" spellcheck="true"># 实例化HeteroGraphConv，in_feats是输入特征的维度，out_feats是输出特征的维度，aggregate是聚合函数的类型</span>
        self<span class="token punctuation">.</span>conv1 <span class="token operator">=</span> dglnn<span class="token punctuation">.</span>HeteroGraphConv<span class="token punctuation">(</span><span class="token punctuation">{</span>
            rel<span class="token punctuation">:</span> dglnn<span class="token punctuation">.</span>GraphConv<span class="token punctuation">(</span>in_feats<span class="token punctuation">,</span> hid_feats<span class="token punctuation">)</span>
            <span class="token keyword">for</span> rel <span class="token keyword">in</span> rel_names<span class="token punctuation">}</span><span class="token punctuation">,</span> aggregate<span class="token operator">=</span><span class="token string">'sum'</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>conv2 <span class="token operator">=</span> dglnn<span class="token punctuation">.</span>HeteroGraphConv<span class="token punctuation">(</span><span class="token punctuation">{</span>
            rel<span class="token punctuation">:</span> dglnn<span class="token punctuation">.</span>GraphConv<span class="token punctuation">(</span>hid_feats<span class="token punctuation">,</span> out_feats<span class="token punctuation">)</span>
            <span class="token keyword">for</span> rel <span class="token keyword">in</span> rel_names<span class="token punctuation">}</span><span class="token punctuation">,</span> aggregate<span class="token operator">=</span><span class="token string">'sum'</span><span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> graph<span class="token punctuation">,</span> inputs<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment" spellcheck="true"># 输入是节点的特征字典</span>
        h <span class="token operator">=</span> self<span class="token punctuation">.</span>conv1<span class="token punctuation">(</span>graph<span class="token punctuation">,</span> inputs<span class="token punctuation">)</span>
        h <span class="token operator">=</span> <span class="token punctuation">{</span>k<span class="token punctuation">:</span> F<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>v<span class="token punctuation">)</span> <span class="token keyword">for</span> k<span class="token punctuation">,</span> v <span class="token keyword">in</span> h<span class="token punctuation">.</span>items<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">}</span>
        h <span class="token operator">=</span> self<span class="token punctuation">.</span>conv2<span class="token punctuation">(</span>graph<span class="token punctuation">,</span> h<span class="token punctuation">)</span>
        <span class="token keyword">return</span> h<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p><strong>3 训练模型</strong></p>
<pre class="line-numbers language-python"><code class="language-python">model <span class="token operator">=</span> RGCN<span class="token punctuation">(</span>n_hetero_features<span class="token punctuation">,</span> <span class="token number">20</span><span class="token punctuation">,</span> n_user_classes<span class="token punctuation">,</span> hetero_graph<span class="token punctuation">.</span>etypes<span class="token punctuation">)</span>
user_feats <span class="token operator">=</span> hetero_graph<span class="token punctuation">.</span>nodes<span class="token punctuation">[</span><span class="token string">'user'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>data<span class="token punctuation">[</span><span class="token string">'feature'</span><span class="token punctuation">]</span>
item_feats <span class="token operator">=</span> hetero_graph<span class="token punctuation">.</span>nodes<span class="token punctuation">[</span><span class="token string">'item'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>data<span class="token punctuation">[</span><span class="token string">'feature'</span><span class="token punctuation">]</span>
labels <span class="token operator">=</span> hetero_graph<span class="token punctuation">.</span>nodes<span class="token punctuation">[</span><span class="token string">'user'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>data<span class="token punctuation">[</span><span class="token string">'label'</span><span class="token punctuation">]</span>
train_mask <span class="token operator">=</span> hetero_graph<span class="token punctuation">.</span>nodes<span class="token punctuation">[</span><span class="token string">'user'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>data<span class="token punctuation">[</span><span class="token string">'train_mask'</span><span class="token punctuation">]</span>

node_features <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token string">'user'</span><span class="token punctuation">:</span> user_feats<span class="token punctuation">,</span> <span class="token string">'item'</span><span class="token punctuation">:</span> item_feats<span class="token punctuation">}</span>

opt <span class="token operator">=</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>Adam<span class="token punctuation">(</span>model<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

<span class="token keyword">for</span> epoch <span class="token keyword">in</span> range<span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    model<span class="token punctuation">.</span>train<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token comment" spellcheck="true"># 使用所有节点的特征进行前向传播计算，并提取输出的user节点嵌入</span>
    logits <span class="token operator">=</span> model<span class="token punctuation">(</span>hetero_graph<span class="token punctuation">,</span> node_features<span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token string">'user'</span><span class="token punctuation">]</span>
    <span class="token comment" spellcheck="true"># 计算损失值</span>
    loss <span class="token operator">=</span> F<span class="token punctuation">.</span>cross_entropy<span class="token punctuation">(</span>logits<span class="token punctuation">[</span>train_mask<span class="token punctuation">]</span><span class="token punctuation">,</span> labels<span class="token punctuation">[</span>train_mask<span class="token punctuation">]</span><span class="token punctuation">)</span>
    <span class="token comment" spellcheck="true"># 进行反向传播计算</span>
    opt<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>
    loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>
    opt<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span>loss<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>&gt;&gt;&gt;</p>
<pre><code>1.8662775754928589
1.851954698562622
1.8382809162139893
1.8252463340759277
1.812849998474121</code></pre><h3 id="异质图RGCN-边预测"><a href="#异质图RGCN-边预测" class="headerlink" title="异质图RGCN_边预测"></a>异质图RGCN_边预测</h3><h4 id="原理-1"><a href="#原理-1" class="headerlink" title="原理"></a>原理</h4><p>边的预测我们可以基于它所关联的俩节点来计算，对于单个输出预测，等价于我们需要定义如下的一个函数：   </p>
<p>$$<br>score_{(i,j)}=g(h_i,h_j)<br>$$</p>
<p>即构造一个函数，输入俩向量$h_i,h_j$（分别表示俩节点特征），然后输出一个标量（表示边的输出），最简单的我们可以使用内积$&lt;h_i,h_j&gt;$，或者将$h_i,h_j$拼接后再进行一次线性变换$w^T(h_i||h_j)$，或者将$h_i,h_j$相加后再进行一次线性变换$w^T(h_i+h_j)$，这里可以是任意你能想到的方式（不过要可导），而这个操作我们可以利用dgl的<strong>apply_edges</strong>这个api来实现，比如下面分别实现内积和线性变换的操作</p>
<pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">import</span> dgl<span class="token punctuation">.</span>function <span class="token keyword">as</span> fn
<span class="token keyword">from</span> torch <span class="token keyword">import</span> nn
<span class="token keyword">class</span> <span class="token class-name">HeteroDotProductPredictor</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> graph<span class="token punctuation">,</span> h<span class="token punctuation">,</span> etype<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">with</span> graph<span class="token punctuation">.</span>local_scope<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            graph<span class="token punctuation">.</span>ndata<span class="token punctuation">[</span><span class="token string">'h'</span><span class="token punctuation">]</span> <span class="token operator">=</span> h   <span class="token comment" spellcheck="true">#一次性为所有节点类型的 'h'赋值</span>
            graph<span class="token punctuation">.</span>apply_edges<span class="token punctuation">(</span>fn<span class="token punctuation">.</span>u_dot_v<span class="token punctuation">(</span><span class="token string">'h'</span><span class="token punctuation">,</span> <span class="token string">'h'</span><span class="token punctuation">,</span> <span class="token string">'score'</span><span class="token punctuation">)</span><span class="token punctuation">,</span> etype<span class="token operator">=</span>etype<span class="token punctuation">)</span>
            <span class="token keyword">return</span> graph<span class="token punctuation">.</span>edges<span class="token punctuation">[</span>etype<span class="token punctuation">]</span><span class="token punctuation">.</span>data<span class="token punctuation">[</span><span class="token string">'score'</span><span class="token punctuation">]</span>
<span class="token keyword">class</span> <span class="token class-name">MLPPredictor</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> in_features<span class="token punctuation">,</span> out_classes<span class="token punctuation">)</span><span class="token punctuation">:</span>
        super<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>W <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>in_features <span class="token operator">*</span> <span class="token number">2</span><span class="token punctuation">,</span> out_classes<span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">apply_edges</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> edges<span class="token punctuation">)</span><span class="token punctuation">:</span>
        h_u <span class="token operator">=</span> edges<span class="token punctuation">.</span>src<span class="token punctuation">[</span><span class="token string">'h'</span><span class="token punctuation">]</span>
        h_v <span class="token operator">=</span> edges<span class="token punctuation">.</span>dst<span class="token punctuation">[</span><span class="token string">'h'</span><span class="token punctuation">]</span>
        score <span class="token operator">=</span> self<span class="token punctuation">.</span>W<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>cat<span class="token punctuation">(</span><span class="token punctuation">[</span>h_u<span class="token punctuation">,</span> h_v<span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        <span class="token keyword">return</span> <span class="token punctuation">{</span><span class="token string">'score'</span><span class="token punctuation">:</span> score<span class="token punctuation">}</span>

    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> graph<span class="token punctuation">,</span> h<span class="token punctuation">,</span> etype<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">with</span> graph<span class="token punctuation">.</span>local_scope<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            graph<span class="token punctuation">.</span>ndata<span class="token punctuation">[</span><span class="token string">'h'</span><span class="token punctuation">]</span> <span class="token operator">=</span> h   <span class="token comment" spellcheck="true">#一次性为所有节点类型的 'h'赋值</span>
            graph<span class="token punctuation">.</span>apply_edges<span class="token punctuation">(</span>self<span class="token punctuation">.</span>apply_edges<span class="token punctuation">,</span> etype<span class="token operator">=</span>etype<span class="token punctuation">)</span>
            <span class="token keyword">return</span> graph<span class="token punctuation">.</span>edges<span class="token punctuation">[</span>etype<span class="token punctuation">]</span><span class="token punctuation">.</span>data<span class="token punctuation">[</span><span class="token string">'score'</span><span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<pre><code>Using backend: pytorch</code></pre><h4 id="实现-3"><a href="#实现-3" class="headerlink" title="实现"></a>实现</h4><p>下面与前一节的实现一样的内容就直接贴进来了</p>
<pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">import</span> numpy <span class="token keyword">as</span> np
<span class="token keyword">import</span> torch
<span class="token keyword">import</span> dgl

n_users <span class="token operator">=</span> <span class="token number">1000</span>
n_items <span class="token operator">=</span> <span class="token number">500</span>
n_follows <span class="token operator">=</span> <span class="token number">3000</span>
n_clicks <span class="token operator">=</span> <span class="token number">5000</span>
n_dislikes <span class="token operator">=</span> <span class="token number">500</span>
n_hetero_features <span class="token operator">=</span> <span class="token number">10</span>
n_user_classes <span class="token operator">=</span> <span class="token number">5</span>
n_max_clicks <span class="token operator">=</span> <span class="token number">10</span>

follow_src <span class="token operator">=</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>randint<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> n_users<span class="token punctuation">,</span> n_follows<span class="token punctuation">)</span>
follow_dst <span class="token operator">=</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>randint<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> n_users<span class="token punctuation">,</span> n_follows<span class="token punctuation">)</span>
click_src <span class="token operator">=</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>randint<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> n_users<span class="token punctuation">,</span> n_clicks<span class="token punctuation">)</span>
click_dst <span class="token operator">=</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>randint<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> n_items<span class="token punctuation">,</span> n_clicks<span class="token punctuation">)</span>
dislike_src <span class="token operator">=</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>randint<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> n_users<span class="token punctuation">,</span> n_dislikes<span class="token punctuation">)</span>
dislike_dst <span class="token operator">=</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>randint<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> n_items<span class="token punctuation">,</span> n_dislikes<span class="token punctuation">)</span>

hetero_graph <span class="token operator">=</span> dgl<span class="token punctuation">.</span>heterograph<span class="token punctuation">(</span><span class="token punctuation">{</span>
    <span class="token punctuation">(</span><span class="token string">'user'</span><span class="token punctuation">,</span> <span class="token string">'follow'</span><span class="token punctuation">,</span> <span class="token string">'user'</span><span class="token punctuation">)</span><span class="token punctuation">:</span> <span class="token punctuation">(</span>follow_src<span class="token punctuation">,</span> follow_dst<span class="token punctuation">)</span><span class="token punctuation">,</span>
    <span class="token punctuation">(</span><span class="token string">'user'</span><span class="token punctuation">,</span> <span class="token string">'followed-by'</span><span class="token punctuation">,</span> <span class="token string">'user'</span><span class="token punctuation">)</span><span class="token punctuation">:</span> <span class="token punctuation">(</span>follow_dst<span class="token punctuation">,</span> follow_src<span class="token punctuation">)</span><span class="token punctuation">,</span>
    <span class="token punctuation">(</span><span class="token string">'user'</span><span class="token punctuation">,</span> <span class="token string">'click'</span><span class="token punctuation">,</span> <span class="token string">'item'</span><span class="token punctuation">)</span><span class="token punctuation">:</span> <span class="token punctuation">(</span>click_src<span class="token punctuation">,</span> click_dst<span class="token punctuation">)</span><span class="token punctuation">,</span>
    <span class="token punctuation">(</span><span class="token string">'item'</span><span class="token punctuation">,</span> <span class="token string">'clicked-by'</span><span class="token punctuation">,</span> <span class="token string">'user'</span><span class="token punctuation">)</span><span class="token punctuation">:</span> <span class="token punctuation">(</span>click_dst<span class="token punctuation">,</span> click_src<span class="token punctuation">)</span><span class="token punctuation">,</span>
    <span class="token punctuation">(</span><span class="token string">'user'</span><span class="token punctuation">,</span> <span class="token string">'dislike'</span><span class="token punctuation">,</span> <span class="token string">'item'</span><span class="token punctuation">)</span><span class="token punctuation">:</span> <span class="token punctuation">(</span>dislike_src<span class="token punctuation">,</span> dislike_dst<span class="token punctuation">)</span><span class="token punctuation">,</span>
    <span class="token punctuation">(</span><span class="token string">'item'</span><span class="token punctuation">,</span> <span class="token string">'disliked-by'</span><span class="token punctuation">,</span> <span class="token string">'user'</span><span class="token punctuation">)</span><span class="token punctuation">:</span> <span class="token punctuation">(</span>dislike_dst<span class="token punctuation">,</span> dislike_src<span class="token punctuation">)</span><span class="token punctuation">}</span><span class="token punctuation">)</span>

hetero_graph<span class="token punctuation">.</span>nodes<span class="token punctuation">[</span><span class="token string">'user'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>data<span class="token punctuation">[</span><span class="token string">'feature'</span><span class="token punctuation">]</span> <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span>n_users<span class="token punctuation">,</span> n_hetero_features<span class="token punctuation">)</span>
hetero_graph<span class="token punctuation">.</span>nodes<span class="token punctuation">[</span><span class="token string">'item'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>data<span class="token punctuation">[</span><span class="token string">'feature'</span><span class="token punctuation">]</span> <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span>n_items<span class="token punctuation">,</span> n_hetero_features<span class="token punctuation">)</span>
hetero_graph<span class="token punctuation">.</span>nodes<span class="token punctuation">[</span><span class="token string">'user'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>data<span class="token punctuation">[</span><span class="token string">'label'</span><span class="token punctuation">]</span> <span class="token operator">=</span> torch<span class="token punctuation">.</span>randint<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> n_user_classes<span class="token punctuation">,</span> <span class="token punctuation">(</span>n_users<span class="token punctuation">,</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
hetero_graph<span class="token punctuation">.</span>edges<span class="token punctuation">[</span><span class="token string">'click'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>data<span class="token punctuation">[</span><span class="token string">'label'</span><span class="token punctuation">]</span> <span class="token operator">=</span> torch<span class="token punctuation">.</span>randint<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> n_max_clicks<span class="token punctuation">,</span> <span class="token punctuation">(</span>n_clicks<span class="token punctuation">,</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>float<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token comment" spellcheck="true"># 在user类型的节点和click类型的边上随机生成训练集的掩码</span>
hetero_graph<span class="token punctuation">.</span>nodes<span class="token punctuation">[</span><span class="token string">'user'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>data<span class="token punctuation">[</span><span class="token string">'train_mask'</span><span class="token punctuation">]</span> <span class="token operator">=</span> torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span>n_users<span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>bool<span class="token punctuation">)</span><span class="token punctuation">.</span>bernoulli<span class="token punctuation">(</span><span class="token number">0.6</span><span class="token punctuation">)</span>
hetero_graph<span class="token punctuation">.</span>edges<span class="token punctuation">[</span><span class="token string">'click'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>data<span class="token punctuation">[</span><span class="token string">'train_mask'</span><span class="token punctuation">]</span> <span class="token operator">=</span> torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span>n_clicks<span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>bool<span class="token punctuation">)</span><span class="token punctuation">.</span>bernoulli<span class="token punctuation">(</span><span class="token number">0.6</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">import</span> dgl<span class="token punctuation">.</span>nn <span class="token keyword">as</span> dglnn
<span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>functional <span class="token keyword">as</span> F

<span class="token keyword">class</span> <span class="token class-name">RGCN</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> in_feats<span class="token punctuation">,</span> hid_feats<span class="token punctuation">,</span> out_feats<span class="token punctuation">,</span> rel_names<span class="token punctuation">)</span><span class="token punctuation">:</span>
        super<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        <span class="token comment" spellcheck="true"># 实例化HeteroGraphConv，in_feats是输入特征的维度，out_feats是输出特征的维度，aggregate是聚合函数的类型</span>
        self<span class="token punctuation">.</span>conv1 <span class="token operator">=</span> dglnn<span class="token punctuation">.</span>HeteroGraphConv<span class="token punctuation">(</span><span class="token punctuation">{</span>
            rel<span class="token punctuation">:</span> dglnn<span class="token punctuation">.</span>GraphConv<span class="token punctuation">(</span>in_feats<span class="token punctuation">,</span> hid_feats<span class="token punctuation">)</span>
            <span class="token keyword">for</span> rel <span class="token keyword">in</span> rel_names<span class="token punctuation">}</span><span class="token punctuation">,</span> aggregate<span class="token operator">=</span><span class="token string">'sum'</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>conv2 <span class="token operator">=</span> dglnn<span class="token punctuation">.</span>HeteroGraphConv<span class="token punctuation">(</span><span class="token punctuation">{</span>
            rel<span class="token punctuation">:</span> dglnn<span class="token punctuation">.</span>GraphConv<span class="token punctuation">(</span>hid_feats<span class="token punctuation">,</span> out_feats<span class="token punctuation">)</span>
            <span class="token keyword">for</span> rel <span class="token keyword">in</span> rel_names<span class="token punctuation">}</span><span class="token punctuation">,</span> aggregate<span class="token operator">=</span><span class="token string">'sum'</span><span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> graph<span class="token punctuation">,</span> inputs<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment" spellcheck="true"># 输入是节点的特征字典</span>
        h <span class="token operator">=</span> self<span class="token punctuation">.</span>conv1<span class="token punctuation">(</span>graph<span class="token punctuation">,</span> inputs<span class="token punctuation">)</span>
        h <span class="token operator">=</span> <span class="token punctuation">{</span>k<span class="token punctuation">:</span> F<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>v<span class="token punctuation">)</span> <span class="token keyword">for</span> k<span class="token punctuation">,</span> v <span class="token keyword">in</span> h<span class="token punctuation">.</span>items<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">}</span>
        h <span class="token operator">=</span> self<span class="token punctuation">.</span>conv2<span class="token punctuation">(</span>graph<span class="token punctuation">,</span> h<span class="token punctuation">)</span>
        <span class="token keyword">return</span> h<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>在RGCN的基础上，我们可以继续构建对边的预测任务</p>
<pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">Model</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> in_features<span class="token punctuation">,</span> hidden_features<span class="token punctuation">,</span> out_features<span class="token punctuation">,</span> rel_names<span class="token punctuation">)</span><span class="token punctuation">:</span>
        super<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>rgcn <span class="token operator">=</span> RGCN<span class="token punctuation">(</span>in_features<span class="token punctuation">,</span> hidden_features<span class="token punctuation">,</span> out_features<span class="token punctuation">,</span> rel_names<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>pred <span class="token operator">=</span> HeteroDotProductPredictor<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> g<span class="token punctuation">,</span> x<span class="token punctuation">,</span> etype<span class="token punctuation">)</span><span class="token punctuation">:</span>
        h <span class="token operator">=</span> self<span class="token punctuation">.</span>rgcn<span class="token punctuation">(</span>g<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token comment" spellcheck="true">#这里得到RGCN后各节点的特征</span>
        <span class="token keyword">return</span> self<span class="token punctuation">.</span>pred<span class="token punctuation">(</span>g<span class="token punctuation">,</span> h<span class="token punctuation">,</span> etype<span class="token punctuation">)</span><span class="token comment" spellcheck="true">#然后求得边的score</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>模型训练</p>
<pre class="line-numbers language-python"><code class="language-python">model <span class="token operator">=</span> Model<span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">,</span> <span class="token number">20</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">,</span> hetero_graph<span class="token punctuation">.</span>etypes<span class="token punctuation">)</span>
user_feats <span class="token operator">=</span> hetero_graph<span class="token punctuation">.</span>nodes<span class="token punctuation">[</span><span class="token string">'user'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>data<span class="token punctuation">[</span><span class="token string">'feature'</span><span class="token punctuation">]</span>
item_feats <span class="token operator">=</span> hetero_graph<span class="token punctuation">.</span>nodes<span class="token punctuation">[</span><span class="token string">'item'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>data<span class="token punctuation">[</span><span class="token string">'feature'</span><span class="token punctuation">]</span>
label <span class="token operator">=</span> hetero_graph<span class="token punctuation">.</span>edges<span class="token punctuation">[</span><span class="token string">'click'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>data<span class="token punctuation">[</span><span class="token string">'label'</span><span class="token punctuation">]</span>
train_mask <span class="token operator">=</span> hetero_graph<span class="token punctuation">.</span>edges<span class="token punctuation">[</span><span class="token string">'click'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>data<span class="token punctuation">[</span><span class="token string">'train_mask'</span><span class="token punctuation">]</span>
node_features <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token string">'user'</span><span class="token punctuation">:</span> user_feats<span class="token punctuation">,</span> <span class="token string">'item'</span><span class="token punctuation">:</span> item_feats<span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<pre class="line-numbers language-python"><code class="language-python">opt <span class="token operator">=</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>Adam<span class="token punctuation">(</span>model<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">for</span> epoch <span class="token keyword">in</span> range<span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    pred <span class="token operator">=</span> model<span class="token punctuation">(</span>hetero_graph<span class="token punctuation">,</span> node_features<span class="token punctuation">,</span> <span class="token string">'click'</span><span class="token punctuation">)</span>
    loss <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token punctuation">(</span>pred<span class="token punctuation">[</span>train_mask<span class="token punctuation">]</span> <span class="token operator">-</span> label<span class="token punctuation">[</span>train_mask<span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token operator">**</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">.</span>mean<span class="token punctuation">(</span><span class="token punctuation">)</span>
    opt<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>
    loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>
    opt<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span>loss<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>39.65708541870117<br>37.67030715942383<br>35.77607727050781<br>33.9720344543457<br>32.25625228881836</p>
<h3 id="链接预测"><a href="#链接预测" class="headerlink" title="链接预测"></a>链接预测</h3><h4 id="原理-2"><a href="#原理-2" class="headerlink" title="原理"></a>原理</h4><p>链接预测是预测边的存在性，注意它与边预测任务很不同，边预测是去预测已存在的边的属性。但通过<strong>负采样</strong>的技巧，我们可以将链接预测的问题转换为边预测的问题，可以看作：   </p>
<p>$$<br>链接预测=负采样+边预测<br>$$</p>
<p>我们可以这样理解，如果两节点间存在边，那么我们定义该边上的属性为1，如果不存在边那么我们定义该边上的属性为0，所以我们将链接预测问题就转换为了边上的1/0预测问题，如果俩节点上的预测值靠近1，我们就可以认为它们之间存在一条边，如果预测值靠近0，就认为它们之间不存在边。但是“不存在的边”的量往往很大，这需要考虑任意两两之间的连接，所以我们采用负采样，从所有不存在的边中随机采样部分出来训练，如下示例图：   </p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20210829203046513.png" alt=""></p>
<p>对于上面的假设，我们可以类似于logistic任务，使用交叉熵损失函数：<br>$$<br>L=-log\sigma(y_{u,v})-\sum{[1-log(y_{u,k})]\mid k\in P(u)}<br>$$</p>
<p>这里，$u,v$是存在连接的点，$P(u)$是对$u$的负采样点的集合，$y_{u,v}$类似于上一节输入两向量，输出一个标量的函数，比如做内积，而$\sigma(\cdot)$是sigmoid函数，将输出约束在(0,1)之间，除了交叉熵，我们还可以选择其他函数，<a href="https://docs.dgl.ai/guide_cn/training-link.html" target="_blank" rel="noopener">参考&gt;&gt;</a></p>
<h4 id="实现-4"><a href="#实现-4" class="headerlink" title="实现"></a>实现</h4><p>这里需要实现的内容其实相比上一节主要多了两部分内容：<br>（1）第一部分是多了负采样；<br>（2）另一部分是需要修改损失函数的定义</p>
<pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">import</span> numpy <span class="token keyword">as</span> np
<span class="token keyword">import</span> torch
<span class="token keyword">import</span> dgl
<span class="token keyword">import</span> dgl<span class="token punctuation">.</span>nn <span class="token keyword">as</span> dglnn
<span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn <span class="token keyword">as</span> nn
<span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>functional <span class="token keyword">as</span> F
<span class="token keyword">import</span> dgl<span class="token punctuation">.</span>function <span class="token keyword">as</span> fn<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>Using backend: pytorch</p>
<pre class="line-numbers language-python"><code class="language-python"><span class="token comment" spellcheck="true">#1.生成异构图</span>
n_users <span class="token operator">=</span> <span class="token number">1000</span>
n_items <span class="token operator">=</span> <span class="token number">500</span>
n_follows <span class="token operator">=</span> <span class="token number">3000</span>
n_clicks <span class="token operator">=</span> <span class="token number">5000</span>
n_dislikes <span class="token operator">=</span> <span class="token number">500</span>
n_hetero_features <span class="token operator">=</span> <span class="token number">10</span>
n_user_classes <span class="token operator">=</span> <span class="token number">5</span>
n_max_clicks <span class="token operator">=</span> <span class="token number">10</span>

follow_src <span class="token operator">=</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>randint<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> n_users<span class="token punctuation">,</span> n_follows<span class="token punctuation">)</span>
follow_dst <span class="token operator">=</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>randint<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> n_users<span class="token punctuation">,</span> n_follows<span class="token punctuation">)</span>
click_src <span class="token operator">=</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>randint<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> n_users<span class="token punctuation">,</span> n_clicks<span class="token punctuation">)</span>
click_dst <span class="token operator">=</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>randint<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> n_items<span class="token punctuation">,</span> n_clicks<span class="token punctuation">)</span>
dislike_src <span class="token operator">=</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>randint<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> n_users<span class="token punctuation">,</span> n_dislikes<span class="token punctuation">)</span>
dislike_dst <span class="token operator">=</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>randint<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> n_items<span class="token punctuation">,</span> n_dislikes<span class="token punctuation">)</span>

hetero_graph <span class="token operator">=</span> dgl<span class="token punctuation">.</span>heterograph<span class="token punctuation">(</span><span class="token punctuation">{</span>
    <span class="token punctuation">(</span><span class="token string">'user'</span><span class="token punctuation">,</span> <span class="token string">'follow'</span><span class="token punctuation">,</span> <span class="token string">'user'</span><span class="token punctuation">)</span><span class="token punctuation">:</span> <span class="token punctuation">(</span>follow_src<span class="token punctuation">,</span> follow_dst<span class="token punctuation">)</span><span class="token punctuation">,</span>
    <span class="token punctuation">(</span><span class="token string">'user'</span><span class="token punctuation">,</span> <span class="token string">'followed-by'</span><span class="token punctuation">,</span> <span class="token string">'user'</span><span class="token punctuation">)</span><span class="token punctuation">:</span> <span class="token punctuation">(</span>follow_dst<span class="token punctuation">,</span> follow_src<span class="token punctuation">)</span><span class="token punctuation">,</span>
    <span class="token punctuation">(</span><span class="token string">'user'</span><span class="token punctuation">,</span> <span class="token string">'click'</span><span class="token punctuation">,</span> <span class="token string">'item'</span><span class="token punctuation">)</span><span class="token punctuation">:</span> <span class="token punctuation">(</span>click_src<span class="token punctuation">,</span> click_dst<span class="token punctuation">)</span><span class="token punctuation">,</span>
    <span class="token punctuation">(</span><span class="token string">'item'</span><span class="token punctuation">,</span> <span class="token string">'clicked-by'</span><span class="token punctuation">,</span> <span class="token string">'user'</span><span class="token punctuation">)</span><span class="token punctuation">:</span> <span class="token punctuation">(</span>click_dst<span class="token punctuation">,</span> click_src<span class="token punctuation">)</span><span class="token punctuation">,</span>
    <span class="token punctuation">(</span><span class="token string">'user'</span><span class="token punctuation">,</span> <span class="token string">'dislike'</span><span class="token punctuation">,</span> <span class="token string">'item'</span><span class="token punctuation">)</span><span class="token punctuation">:</span> <span class="token punctuation">(</span>dislike_src<span class="token punctuation">,</span> dislike_dst<span class="token punctuation">)</span><span class="token punctuation">,</span>
    <span class="token punctuation">(</span><span class="token string">'item'</span><span class="token punctuation">,</span> <span class="token string">'disliked-by'</span><span class="token punctuation">,</span> <span class="token string">'user'</span><span class="token punctuation">)</span><span class="token punctuation">:</span> <span class="token punctuation">(</span>dislike_dst<span class="token punctuation">,</span> dislike_src<span class="token punctuation">)</span><span class="token punctuation">}</span><span class="token punctuation">)</span>

hetero_graph<span class="token punctuation">.</span>nodes<span class="token punctuation">[</span><span class="token string">'user'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>data<span class="token punctuation">[</span><span class="token string">'feature'</span><span class="token punctuation">]</span> <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span>n_users<span class="token punctuation">,</span> n_hetero_features<span class="token punctuation">)</span>
hetero_graph<span class="token punctuation">.</span>nodes<span class="token punctuation">[</span><span class="token string">'item'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>data<span class="token punctuation">[</span><span class="token string">'feature'</span><span class="token punctuation">]</span> <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span>n_items<span class="token punctuation">,</span> n_hetero_features<span class="token punctuation">)</span>
hetero_graph<span class="token punctuation">.</span>nodes<span class="token punctuation">[</span><span class="token string">'user'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>data<span class="token punctuation">[</span><span class="token string">'label'</span><span class="token punctuation">]</span> <span class="token operator">=</span> torch<span class="token punctuation">.</span>randint<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> n_user_classes<span class="token punctuation">,</span> <span class="token punctuation">(</span>n_users<span class="token punctuation">,</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
hetero_graph<span class="token punctuation">.</span>edges<span class="token punctuation">[</span><span class="token string">'click'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>data<span class="token punctuation">[</span><span class="token string">'label'</span><span class="token punctuation">]</span> <span class="token operator">=</span> torch<span class="token punctuation">.</span>randint<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> n_max_clicks<span class="token punctuation">,</span> <span class="token punctuation">(</span>n_clicks<span class="token punctuation">,</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>float<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token comment" spellcheck="true"># 在user类型的节点和click类型的边上随机生成训练集的掩码</span>
hetero_graph<span class="token punctuation">.</span>nodes<span class="token punctuation">[</span><span class="token string">'user'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>data<span class="token punctuation">[</span><span class="token string">'train_mask'</span><span class="token punctuation">]</span> <span class="token operator">=</span> torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span>n_users<span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>bool<span class="token punctuation">)</span><span class="token punctuation">.</span>bernoulli<span class="token punctuation">(</span><span class="token number">0.6</span><span class="token punctuation">)</span>
hetero_graph<span class="token punctuation">.</span>edges<span class="token punctuation">[</span><span class="token string">'click'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>data<span class="token punctuation">[</span><span class="token string">'train_mask'</span><span class="token punctuation">]</span> <span class="token operator">=</span> torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span>n_clicks<span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>bool<span class="token punctuation">)</span><span class="token punctuation">.</span>bernoulli<span class="token punctuation">(</span><span class="token number">0.6</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<pre class="line-numbers language-python"><code class="language-python"><span class="token comment" spellcheck="true">#2.定义模型</span>
<span class="token keyword">class</span> <span class="token class-name">RGCN</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> in_feats<span class="token punctuation">,</span> hid_feats<span class="token punctuation">,</span> out_feats<span class="token punctuation">,</span> rel_names<span class="token punctuation">)</span><span class="token punctuation">:</span>
        super<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        <span class="token comment" spellcheck="true"># 实例化HeteroGraphConv，in_feats是输入特征的维度，out_feats是输出特征的维度，aggregate是聚合函数的类型</span>
        self<span class="token punctuation">.</span>conv1 <span class="token operator">=</span> dglnn<span class="token punctuation">.</span>HeteroGraphConv<span class="token punctuation">(</span><span class="token punctuation">{</span>
            rel<span class="token punctuation">:</span> dglnn<span class="token punctuation">.</span>GraphConv<span class="token punctuation">(</span>in_feats<span class="token punctuation">,</span> hid_feats<span class="token punctuation">)</span>
            <span class="token keyword">for</span> rel <span class="token keyword">in</span> rel_names<span class="token punctuation">}</span><span class="token punctuation">,</span> aggregate<span class="token operator">=</span><span class="token string">'sum'</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>conv2 <span class="token operator">=</span> dglnn<span class="token punctuation">.</span>HeteroGraphConv<span class="token punctuation">(</span><span class="token punctuation">{</span>
            rel<span class="token punctuation">:</span> dglnn<span class="token punctuation">.</span>GraphConv<span class="token punctuation">(</span>hid_feats<span class="token punctuation">,</span> out_feats<span class="token punctuation">)</span>
            <span class="token keyword">for</span> rel <span class="token keyword">in</span> rel_names<span class="token punctuation">}</span><span class="token punctuation">,</span> aggregate<span class="token operator">=</span><span class="token string">'sum'</span><span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> graph<span class="token punctuation">,</span> inputs<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment" spellcheck="true"># 输入是节点的特征字典</span>
        h <span class="token operator">=</span> self<span class="token punctuation">.</span>conv1<span class="token punctuation">(</span>graph<span class="token punctuation">,</span> inputs<span class="token punctuation">)</span>
        h <span class="token operator">=</span> <span class="token punctuation">{</span>k<span class="token punctuation">:</span> F<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>v<span class="token punctuation">)</span> <span class="token keyword">for</span> k<span class="token punctuation">,</span> v <span class="token keyword">in</span> h<span class="token punctuation">.</span>items<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">}</span>
        h <span class="token operator">=</span> self<span class="token punctuation">.</span>conv2<span class="token punctuation">(</span>graph<span class="token punctuation">,</span> h<span class="token punctuation">)</span>
        <span class="token keyword">return</span> h


<span class="token keyword">class</span> <span class="token class-name">HeteroDotProductPredictor</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> graph<span class="token punctuation">,</span> h<span class="token punctuation">,</span> etype<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment" spellcheck="true"># h是从5.1节中对异构图的每种类型的边所计算的节点表示</span>
        <span class="token keyword">with</span> graph<span class="token punctuation">.</span>local_scope<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            graph<span class="token punctuation">.</span>ndata<span class="token punctuation">[</span><span class="token string">'h'</span><span class="token punctuation">]</span> <span class="token operator">=</span> h
            graph<span class="token punctuation">.</span>apply_edges<span class="token punctuation">(</span>fn<span class="token punctuation">.</span>u_dot_v<span class="token punctuation">(</span><span class="token string">'h'</span><span class="token punctuation">,</span> <span class="token string">'h'</span><span class="token punctuation">,</span> <span class="token string">'score'</span><span class="token punctuation">)</span><span class="token punctuation">,</span> etype<span class="token operator">=</span>etype<span class="token punctuation">)</span>
            <span class="token keyword">return</span> graph<span class="token punctuation">.</span>edges<span class="token punctuation">[</span>etype<span class="token punctuation">]</span><span class="token punctuation">.</span>data<span class="token punctuation">[</span><span class="token string">'score'</span><span class="token punctuation">]</span>

<span class="token keyword">class</span> <span class="token class-name">Model</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> in_features<span class="token punctuation">,</span> hidden_features<span class="token punctuation">,</span> out_features<span class="token punctuation">,</span> rel_names<span class="token punctuation">)</span><span class="token punctuation">:</span>
        super<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>sage <span class="token operator">=</span> RGCN<span class="token punctuation">(</span>in_features<span class="token punctuation">,</span> hidden_features<span class="token punctuation">,</span> out_features<span class="token punctuation">,</span> rel_names<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>pred <span class="token operator">=</span> HeteroDotProductPredictor<span class="token punctuation">(</span><span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> g<span class="token punctuation">,</span> neg_g<span class="token punctuation">,</span> x<span class="token punctuation">,</span> etype<span class="token punctuation">)</span><span class="token punctuation">:</span>
        h <span class="token operator">=</span> self<span class="token punctuation">.</span>sage<span class="token punctuation">(</span>g<span class="token punctuation">,</span> x<span class="token punctuation">)</span>
        <span class="token keyword">return</span> self<span class="token punctuation">.</span>pred<span class="token punctuation">(</span>g<span class="token punctuation">,</span> h<span class="token punctuation">,</span> etype<span class="token punctuation">)</span><span class="token punctuation">,</span> self<span class="token punctuation">.</span>pred<span class="token punctuation">(</span>neg_g<span class="token punctuation">,</span> h<span class="token punctuation">,</span> etype<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<pre class="line-numbers language-python"><code class="language-python"><span class="token comment" spellcheck="true">#3.定义负采样函数，将负样本采样为另外一张图</span>
<span class="token keyword">def</span> <span class="token function">construct_negative_graph</span><span class="token punctuation">(</span>graph<span class="token punctuation">,</span> k<span class="token punctuation">,</span> etype<span class="token punctuation">)</span><span class="token punctuation">:</span>
    utype<span class="token punctuation">,</span> _<span class="token punctuation">,</span> vtype <span class="token operator">=</span> etype
    src<span class="token punctuation">,</span> dst <span class="token operator">=</span> graph<span class="token punctuation">.</span>edges<span class="token punctuation">(</span>etype<span class="token operator">=</span>etype<span class="token punctuation">)</span>
    neg_src <span class="token operator">=</span> src<span class="token punctuation">.</span>repeat_interleave<span class="token punctuation">(</span>k<span class="token punctuation">)</span>
    neg_dst <span class="token operator">=</span> torch<span class="token punctuation">.</span>randint<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> graph<span class="token punctuation">.</span>num_nodes<span class="token punctuation">(</span>vtype<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span>len<span class="token punctuation">(</span>src<span class="token punctuation">)</span> <span class="token operator">*</span> k<span class="token punctuation">,</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token keyword">return</span> dgl<span class="token punctuation">.</span>heterograph<span class="token punctuation">(</span>
        <span class="token punctuation">{</span>etype<span class="token punctuation">:</span> <span class="token punctuation">(</span>neg_src<span class="token punctuation">,</span> neg_dst<span class="token punctuation">)</span><span class="token punctuation">}</span><span class="token punctuation">,</span>
        num_nodes_dict<span class="token operator">=</span><span class="token punctuation">{</span>ntype<span class="token punctuation">:</span> graph<span class="token punctuation">.</span>num_nodes<span class="token punctuation">(</span>ntype<span class="token punctuation">)</span> <span class="token keyword">for</span> ntype <span class="token keyword">in</span> graph<span class="token punctuation">.</span>ntypes<span class="token punctuation">}</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<pre class="line-numbers language-python"><code class="language-python"><span class="token comment" spellcheck="true">#4.定义损失函数</span>
<span class="token keyword">def</span> <span class="token function">compute_loss</span><span class="token punctuation">(</span>pos_score<span class="token punctuation">,</span> neg_score<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token comment" spellcheck="true"># 间隔损失</span>
    n_edges <span class="token operator">=</span> pos_score<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
    <span class="token keyword">return</span> <span class="token punctuation">(</span><span class="token number">1</span> <span class="token operator">-</span> pos_score<span class="token punctuation">.</span>unsqueeze<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span> <span class="token operator">+</span> neg_score<span class="token punctuation">.</span>view<span class="token punctuation">(</span>n_edges<span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>clamp<span class="token punctuation">(</span>min<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">.</span>mean<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<pre class="line-numbers language-python"><code class="language-python"><span class="token comment" spellcheck="true">#5.训练模型</span>
k <span class="token operator">=</span> <span class="token number">5</span>
model <span class="token operator">=</span> Model<span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">,</span> <span class="token number">20</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">,</span> hetero_graph<span class="token punctuation">.</span>etypes<span class="token punctuation">)</span>
user_feats <span class="token operator">=</span> hetero_graph<span class="token punctuation">.</span>nodes<span class="token punctuation">[</span><span class="token string">'user'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>data<span class="token punctuation">[</span><span class="token string">'feature'</span><span class="token punctuation">]</span>
item_feats <span class="token operator">=</span> hetero_graph<span class="token punctuation">.</span>nodes<span class="token punctuation">[</span><span class="token string">'item'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>data<span class="token punctuation">[</span><span class="token string">'feature'</span><span class="token punctuation">]</span>
node_features <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token string">'user'</span><span class="token punctuation">:</span> user_feats<span class="token punctuation">,</span> <span class="token string">'item'</span><span class="token punctuation">:</span> item_feats<span class="token punctuation">}</span>
opt <span class="token operator">=</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>Adam<span class="token punctuation">(</span>model<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">for</span> epoch <span class="token keyword">in</span> range<span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    negative_graph <span class="token operator">=</span> construct_negative_graph<span class="token punctuation">(</span>hetero_graph<span class="token punctuation">,</span> k<span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token string">'user'</span><span class="token punctuation">,</span> <span class="token string">'click'</span><span class="token punctuation">,</span> <span class="token string">'item'</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true">#这里只对"click"关系进行预测</span>
    pos_score<span class="token punctuation">,</span> neg_score <span class="token operator">=</span> model<span class="token punctuation">(</span>hetero_graph<span class="token punctuation">,</span> negative_graph<span class="token punctuation">,</span> node_features<span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token string">'user'</span><span class="token punctuation">,</span> <span class="token string">'click'</span><span class="token punctuation">,</span> <span class="token string">'item'</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    loss <span class="token operator">=</span> compute_loss<span class="token punctuation">(</span>pos_score<span class="token punctuation">,</span> neg_score<span class="token punctuation">)</span>
    opt<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>
    loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>
    opt<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span>loss<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>&gt;&gt;&gt;</p>
<pre><code>1.327864170074463
1.3069148063659668
1.277003288269043
1.2585861682891846
1.246128797531128</code></pre><h3 id="整图预测"><a href="#整图预测" class="headerlink" title="整图预测"></a>整图预测</h3><h4 id="原理-3"><a href="#原理-3" class="headerlink" title="原理"></a>原理</h4><p>整图预测是针对图层面的学习任务，比如判断某药物分子是否具有某种理化性质，再比如判断某社团是否具有欺诈可能，这需要我们对整个图提取它的特征表示，然后再基于此构建我们的学习任务，图的整体特征无外乎来源于三部分：1）节点特征；2）边特征；3）结构信息，基于这些信息，我们可以通过许多方式来构建图特征，DGL提供了一些简单的API，比如对各节点特征求和/求平均/pooling等，这可以方便我们构建一些基准图预测模型，下面我们利用对节点特征求平均的方式构建图特征，这可以通过<code>dgl.mean_nodes</code>这个API很方便的实现，它相当于做了如下计算：    </p>
<p>$$<br>h_g=\frac{1}{|V|}\sum_{v\in V }h_v<br>$$</p>
<p>$h_v$表示节点$v$的特征，然后基于$h_g$特征向量，构建我们预测模型</p>
<h4 id="实现-5"><a href="#实现-5" class="headerlink" title="实现"></a>实现</h4><p>利用dgl自带的MiniGCDataset数据集，它包括如下的8种类别的图结构<br><img src="/images/loading.gif" data-original="../images/ML/image-20210829203210021.png" alt=""></p>
<pre class="line-numbers language-python"><code class="language-python"><span class="token comment" spellcheck="true">#1.导入数据</span>
<span class="token keyword">import</span> dgl
<span class="token keyword">import</span> torch
<span class="token keyword">from</span> dgl<span class="token punctuation">.</span>data <span class="token keyword">import</span> MiniGCDataset
<span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> plt
<span class="token keyword">import</span> networkx <span class="token keyword">as</span> nx
<span class="token comment" spellcheck="true">#这里，随机构造了80个图，每个图是少10条边，最多30条边</span>
dataset <span class="token operator">=</span> MiniGCDataset<span class="token punctuation">(</span><span class="token number">80</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">,</span> <span class="token number">20</span><span class="token punctuation">)</span>
graph<span class="token punctuation">,</span> label <span class="token operator">=</span> dataset<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>

<span class="token comment" spellcheck="true">#绘制图像</span>
<span class="token operator">%</span>matplotlib inline
fig<span class="token punctuation">,</span> ax <span class="token operator">=</span> plt<span class="token punctuation">.</span>subplots<span class="token punctuation">(</span><span class="token punctuation">)</span>
nx<span class="token punctuation">.</span>draw<span class="token punctuation">(</span>graph<span class="token punctuation">.</span>to_networkx<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> ax<span class="token operator">=</span>ax<span class="token punctuation">)</span>
ax<span class="token punctuation">.</span>set_title<span class="token punctuation">(</span><span class="token string">'Class: {:d}'</span><span class="token punctuation">.</span>format<span class="token punctuation">(</span>label<span class="token punctuation">)</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>Using backend: pytorch</p>
<p><img src="/images/loading.gif" data-original="../images/ML/output_2_1.png" alt=""></p>
<pre class="line-numbers language-python"><code class="language-python"><span class="token comment" spellcheck="true">#2.定义模型</span>
<span class="token keyword">from</span> dgl<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>pytorch <span class="token keyword">import</span> GraphConv
<span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>functional <span class="token keyword">as</span> F
<span class="token keyword">from</span> torch <span class="token keyword">import</span> nn
<span class="token keyword">class</span> <span class="token class-name">Classifier</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> in_dim<span class="token punctuation">,</span> hidden_dim<span class="token punctuation">,</span> n_classes<span class="token punctuation">)</span><span class="token punctuation">:</span>
        super<span class="token punctuation">(</span>Classifier<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>conv1 <span class="token operator">=</span> GraphConv<span class="token punctuation">(</span>in_dim<span class="token punctuation">,</span> hidden_dim<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>conv2 <span class="token operator">=</span> GraphConv<span class="token punctuation">(</span>hidden_dim<span class="token punctuation">,</span> hidden_dim<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>classify <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>hidden_dim<span class="token punctuation">,</span> n_classes<span class="token punctuation">)</span><span class="token comment" spellcheck="true">#线性分类器</span>

    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> g<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment" spellcheck="true"># 以节点度作为初始节点特征。对于无向图，入度与外度相同。</span>
        h <span class="token operator">=</span> g<span class="token punctuation">.</span>in_degrees<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>view<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">.</span>float<span class="token punctuation">(</span><span class="token punctuation">)</span>
        <span class="token comment" spellcheck="true"># 执行图形卷积和激活函数</span>
        h <span class="token operator">=</span> F<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>self<span class="token punctuation">.</span>conv1<span class="token punctuation">(</span>g<span class="token punctuation">,</span>h<span class="token punctuation">)</span><span class="token punctuation">)</span>
        h <span class="token operator">=</span> F<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>self<span class="token punctuation">.</span>conv2<span class="token punctuation">(</span>g<span class="token punctuation">,</span>h<span class="token punctuation">)</span><span class="token punctuation">)</span>
        g<span class="token punctuation">.</span>ndata<span class="token punctuation">[</span><span class="token string">'h'</span><span class="token punctuation">]</span> <span class="token operator">=</span> h

        <span class="token comment" spellcheck="true"># 通过对所有节点表示求平均来计算图形表示。</span>
        hg <span class="token operator">=</span> dgl<span class="token punctuation">.</span>mean_nodes<span class="token punctuation">(</span>g<span class="token punctuation">,</span> <span class="token string">'h'</span><span class="token punctuation">)</span>
        <span class="token keyword">return</span> self<span class="token punctuation">.</span>classify<span class="token punctuation">(</span>hg<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<pre class="line-numbers language-python"><code class="language-python"><span class="token comment" spellcheck="true">#3.训练</span>
<span class="token keyword">import</span> torch<span class="token punctuation">.</span>optim <span class="token keyword">as</span> optim
<span class="token keyword">from</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data <span class="token keyword">import</span> DataLoader

<span class="token comment" spellcheck="true"># 将多张图合并为一张图</span>
<span class="token keyword">def</span> <span class="token function">collate</span><span class="token punctuation">(</span>samples<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token comment" spellcheck="true"># The input `samples` is a list of pairs (graph, label).</span>
    graphs<span class="token punctuation">,</span> labels <span class="token operator">=</span> map<span class="token punctuation">(</span>list<span class="token punctuation">,</span> zip<span class="token punctuation">(</span><span class="token operator">*</span>samples<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token comment" spellcheck="true">#把一批图 zip成 列表对象</span>
    batched_graph <span class="token operator">=</span> dgl<span class="token punctuation">.</span>batch<span class="token punctuation">(</span>graphs<span class="token punctuation">)</span><span class="token comment" spellcheck="true">#合并为一张图</span>
    <span class="token keyword">return</span> batched_graph<span class="token punctuation">,</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span>labels<span class="token punctuation">)</span>


<span class="token comment" spellcheck="true"># 训练集/测试集</span>
trainset <span class="token operator">=</span> MiniGCDataset<span class="token punctuation">(</span><span class="token number">320</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">,</span> <span class="token number">20</span><span class="token punctuation">)</span>
testset <span class="token operator">=</span> MiniGCDataset<span class="token punctuation">(</span><span class="token number">80</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">,</span> <span class="token number">20</span><span class="token punctuation">)</span>

<span class="token comment" spellcheck="true">#batch训练</span>
data_loader <span class="token operator">=</span> DataLoader<span class="token punctuation">(</span>trainset<span class="token punctuation">,</span> batch_size<span class="token operator">=</span><span class="token number">32</span><span class="token punctuation">,</span> shuffle<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>
                         collate_fn<span class="token operator">=</span>collate<span class="token punctuation">)</span>

<span class="token comment" spellcheck="true"># 构建模型</span>
model <span class="token operator">=</span> Classifier<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">256</span><span class="token punctuation">,</span> trainset<span class="token punctuation">.</span>num_classes<span class="token punctuation">)</span>

loss_func <span class="token operator">=</span> nn<span class="token punctuation">.</span>CrossEntropyLoss<span class="token punctuation">(</span><span class="token punctuation">)</span>

optimizer <span class="token operator">=</span> optim<span class="token punctuation">.</span>Adam<span class="token punctuation">(</span>model<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> lr<span class="token operator">=</span><span class="token number">0.001</span><span class="token punctuation">)</span>

model<span class="token punctuation">.</span>train<span class="token punctuation">(</span><span class="token punctuation">)</span>
epoch_losses <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>

<span class="token keyword">for</span> epoch <span class="token keyword">in</span> range<span class="token punctuation">(</span><span class="token number">100</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    epoch_loss <span class="token operator">=</span> <span class="token number">0</span>
    <span class="token keyword">for</span> i<span class="token punctuation">,</span> <span class="token punctuation">(</span>bg<span class="token punctuation">,</span> label<span class="token punctuation">)</span> <span class="token keyword">in</span> enumerate<span class="token punctuation">(</span>data_loader<span class="token punctuation">)</span><span class="token punctuation">:</span>
        prediction <span class="token operator">=</span> model<span class="token punctuation">(</span>bg<span class="token punctuation">)</span>
        loss <span class="token operator">=</span> loss_func<span class="token punctuation">(</span>prediction<span class="token punctuation">,</span> label<span class="token punctuation">.</span>long<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        optimizer<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>
        loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>
        optimizer<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>
        epoch_loss <span class="token operator">+=</span> loss<span class="token punctuation">.</span>detach<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span>
    epoch_loss <span class="token operator">/=</span> <span class="token punctuation">(</span>i <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">)</span>
<span class="token comment" spellcheck="true">#     print('Epoch {}, loss {:.4f}'.format(epoch, epoch_loss))</span>
    epoch_losses<span class="token punctuation">.</span>append<span class="token punctuation">(</span>epoch_loss<span class="token punctuation">)</span>

plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>epoch_losses<span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>legend<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token string">"loss"</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>&gt;&gt;&gt;</p>
<pre><code>&lt;matplotlib.legend.Legend at 0x2658c2b9dd8&gt;</code></pre><p><img src="/images/loading.gif" data-original="../images/ML/output_4_1.png" alt=""></p>
<pre class="line-numbers language-python"><code class="language-python"><span class="token comment" spellcheck="true">#4.测试</span>
model<span class="token punctuation">.</span>eval<span class="token punctuation">(</span><span class="token punctuation">)</span>
test_X<span class="token punctuation">,</span> test_Y <span class="token operator">=</span> map<span class="token punctuation">(</span>list<span class="token punctuation">,</span> zip<span class="token punctuation">(</span><span class="token operator">*</span>testset<span class="token punctuation">)</span><span class="token punctuation">)</span>

test_bg <span class="token operator">=</span> dgl<span class="token punctuation">.</span>batch<span class="token punctuation">(</span>test_X<span class="token punctuation">)</span>
test_Y <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span>test_Y<span class="token punctuation">)</span><span class="token punctuation">.</span>float<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>view<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>

pred_Y <span class="token operator">=</span> torch<span class="token punctuation">.</span>max<span class="token punctuation">(</span>model<span class="token punctuation">(</span>test_bg<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">.</span>view<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>

<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Accuracy of argmax predictions on the test set: {:4f}%'</span><span class="token punctuation">.</span>format<span class="token punctuation">(</span>
    <span class="token punctuation">(</span>test_Y <span class="token operator">==</span> pred_Y<span class="token punctuation">.</span>float<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>sum<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">/</span> len<span class="token punctuation">(</span>test_Y<span class="token punctuation">)</span> <span class="token operator">*</span> <span class="token number">100</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>Accuracy of argmax predictions on the test set: 72.500000%</p>
<pre class="line-numbers language-python"><code class="language-python"><span class="token comment" spellcheck="true">#5.查看混淆矩阵</span>
<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>metrics <span class="token keyword">import</span> confusion_matrix
confusion_matrix<span class="token punctuation">(</span>test_Y<span class="token punctuation">,</span> pred_Y<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre>
<p>&gt;&gt;&gt;</p>
<pre><code>array([[10,  0,  0,  0,  0,  0,  0,  0],
    [ 0,  5,  0,  0,  3,  2,  0,  0],
    [ 0,  0, 10,  0,  0,  0,  0,  0],
    [ 0,  0,  0,  7,  0,  0,  3,  0],
    [ 0,  0,  3,  0,  0,  0,  0,  7],
    [ 0,  0,  0,  0,  2,  6,  0,  2],
    [ 0,  0,  0,  0,  0,  0, 10,  0],
    [ 0,  0,  0,  0,  0,  0,  0, 10]], dtype=int64)</code></pre><h3 id="批量采样训练"><a href="#批量采样训练" class="headerlink" title="批量采样训练"></a>批量采样训练</h3><p>实际业务中，我们需要处理的图往往很大，可能会有上亿的节点和边，如果把这些数据进行全量训练，GPU显存很难放的下，所以我们需要使用类似于DNN中那样的随机批量学习的方式进行训练，与DNN中的批量学习不同，GNN对单个训练样本的训练还需要利用到它的邻居节点，而且每多增加一层网络，所需的邻居样本还要往外扩展一层，所以对于$k$层的GNN网络，我们需要对训练样本进行$k$阶的子图采样操作（回想一下之前GraphSAGE代码中采样…），借助于DGL的api，我们只需要多添加2行代码就可以了…</p>
<pre class="line-numbers language-python"><code class="language-python"><span class="token comment" spellcheck="true">#1.准备数据</span>
<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np
<span class="token keyword">import</span> torch
<span class="token keyword">import</span> dgl
<span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn <span class="token keyword">as</span> nn
<span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>functional <span class="token keyword">as</span> F
<span class="token keyword">from</span> dgl<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>pytorch <span class="token keyword">import</span> HeteroGraphConv<span class="token punctuation">,</span> GraphConv

n_users <span class="token operator">=</span> <span class="token number">1000</span>
n_items <span class="token operator">=</span> <span class="token number">500</span>
n_follows <span class="token operator">=</span> <span class="token number">3000</span>
n_clicks <span class="token operator">=</span> <span class="token number">5000</span>
n_dislikes <span class="token operator">=</span> <span class="token number">500</span>
n_hetero_features <span class="token operator">=</span> <span class="token number">10</span>
n_user_classes <span class="token operator">=</span> <span class="token number">5</span>
n_max_clicks <span class="token operator">=</span> <span class="token number">10</span>

follow_src <span class="token operator">=</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>randint<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> n_users<span class="token punctuation">,</span> n_follows<span class="token punctuation">)</span>
follow_dst <span class="token operator">=</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>randint<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> n_users<span class="token punctuation">,</span> n_follows<span class="token punctuation">)</span>
click_src <span class="token operator">=</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>randint<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> n_users<span class="token punctuation">,</span> n_clicks<span class="token punctuation">)</span>
click_dst <span class="token operator">=</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>randint<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> n_items<span class="token punctuation">,</span> n_clicks<span class="token punctuation">)</span>
dislike_src <span class="token operator">=</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>randint<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> n_users<span class="token punctuation">,</span> n_dislikes<span class="token punctuation">)</span>
dislike_dst <span class="token operator">=</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>randint<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> n_items<span class="token punctuation">,</span> n_dislikes<span class="token punctuation">)</span>

hetero_graph <span class="token operator">=</span> dgl<span class="token punctuation">.</span>heterograph<span class="token punctuation">(</span><span class="token punctuation">{</span>
    <span class="token punctuation">(</span><span class="token string">'user'</span><span class="token punctuation">,</span> <span class="token string">'follow'</span><span class="token punctuation">,</span> <span class="token string">'user'</span><span class="token punctuation">)</span><span class="token punctuation">:</span> <span class="token punctuation">(</span>follow_src<span class="token punctuation">,</span> follow_dst<span class="token punctuation">)</span><span class="token punctuation">,</span>
    <span class="token punctuation">(</span><span class="token string">'user'</span><span class="token punctuation">,</span> <span class="token string">'followed-by'</span><span class="token punctuation">,</span> <span class="token string">'user'</span><span class="token punctuation">)</span><span class="token punctuation">:</span> <span class="token punctuation">(</span>follow_dst<span class="token punctuation">,</span> follow_src<span class="token punctuation">)</span><span class="token punctuation">,</span>
    <span class="token punctuation">(</span><span class="token string">'user'</span><span class="token punctuation">,</span> <span class="token string">'click'</span><span class="token punctuation">,</span> <span class="token string">'item'</span><span class="token punctuation">)</span><span class="token punctuation">:</span> <span class="token punctuation">(</span>click_src<span class="token punctuation">,</span> click_dst<span class="token punctuation">)</span><span class="token punctuation">,</span>
    <span class="token punctuation">(</span><span class="token string">'item'</span><span class="token punctuation">,</span> <span class="token string">'clicked-by'</span><span class="token punctuation">,</span> <span class="token string">'user'</span><span class="token punctuation">)</span><span class="token punctuation">:</span> <span class="token punctuation">(</span>click_dst<span class="token punctuation">,</span> click_src<span class="token punctuation">)</span><span class="token punctuation">,</span>
    <span class="token punctuation">(</span><span class="token string">'user'</span><span class="token punctuation">,</span> <span class="token string">'dislike'</span><span class="token punctuation">,</span> <span class="token string">'item'</span><span class="token punctuation">)</span><span class="token punctuation">:</span> <span class="token punctuation">(</span>dislike_src<span class="token punctuation">,</span> dislike_dst<span class="token punctuation">)</span><span class="token punctuation">,</span>
    <span class="token punctuation">(</span><span class="token string">'item'</span><span class="token punctuation">,</span> <span class="token string">'disliked-by'</span><span class="token punctuation">,</span> <span class="token string">'user'</span><span class="token punctuation">)</span><span class="token punctuation">:</span> <span class="token punctuation">(</span>dislike_dst<span class="token punctuation">,</span> dislike_src<span class="token punctuation">)</span><span class="token punctuation">}</span><span class="token punctuation">)</span>

hetero_graph<span class="token punctuation">.</span>nodes<span class="token punctuation">[</span><span class="token string">'user'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>data<span class="token punctuation">[</span><span class="token string">'feature'</span><span class="token punctuation">]</span> <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span>n_users<span class="token punctuation">,</span> n_hetero_features<span class="token punctuation">)</span>
hetero_graph<span class="token punctuation">.</span>nodes<span class="token punctuation">[</span><span class="token string">'item'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>data<span class="token punctuation">[</span><span class="token string">'feature'</span><span class="token punctuation">]</span> <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span>n_items<span class="token punctuation">,</span> n_hetero_features<span class="token punctuation">)</span>
hetero_graph<span class="token punctuation">.</span>nodes<span class="token punctuation">[</span><span class="token string">'user'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>data<span class="token punctuation">[</span><span class="token string">'label'</span><span class="token punctuation">]</span> <span class="token operator">=</span> torch<span class="token punctuation">.</span>randint<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> n_user_classes<span class="token punctuation">,</span> <span class="token punctuation">(</span>n_users<span class="token punctuation">,</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
hetero_graph<span class="token punctuation">.</span>edges<span class="token punctuation">[</span><span class="token string">'click'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>data<span class="token punctuation">[</span><span class="token string">'label'</span><span class="token punctuation">]</span> <span class="token operator">=</span> torch<span class="token punctuation">.</span>randint<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> n_max_clicks<span class="token punctuation">,</span> <span class="token punctuation">(</span>n_clicks<span class="token punctuation">,</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>float<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token comment" spellcheck="true"># 在user类型的节点和click类型的边上随机生成训练集的掩码</span>
hetero_graph<span class="token punctuation">.</span>nodes<span class="token punctuation">[</span><span class="token string">'user'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>data<span class="token punctuation">[</span><span class="token string">'train_mask'</span><span class="token punctuation">]</span> <span class="token operator">=</span> torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span>n_users<span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>bool<span class="token punctuation">)</span><span class="token punctuation">.</span>bernoulli<span class="token punctuation">(</span><span class="token number">0.6</span><span class="token punctuation">)</span>
hetero_graph<span class="token punctuation">.</span>edges<span class="token punctuation">[</span><span class="token string">'click'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>data<span class="token punctuation">[</span><span class="token string">'train_mask'</span><span class="token punctuation">]</span> <span class="token operator">=</span> torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span>n_clicks<span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>bool<span class="token punctuation">)</span><span class="token punctuation">.</span>bernoulli<span class="token punctuation">(</span><span class="token number">0.6</span><span class="token punctuation">)</span>

user_feats <span class="token operator">=</span> hetero_graph<span class="token punctuation">.</span>nodes<span class="token punctuation">[</span><span class="token string">'user'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>data<span class="token punctuation">[</span><span class="token string">'feature'</span><span class="token punctuation">]</span>
item_feats <span class="token operator">=</span> hetero_graph<span class="token punctuation">.</span>nodes<span class="token punctuation">[</span><span class="token string">'item'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>data<span class="token punctuation">[</span><span class="token string">'feature'</span><span class="token punctuation">]</span>
labels <span class="token operator">=</span> hetero_graph<span class="token punctuation">.</span>nodes<span class="token punctuation">[</span><span class="token string">'user'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>data<span class="token punctuation">[</span><span class="token string">'label'</span><span class="token punctuation">]</span>
train_mask <span class="token operator">=</span> hetero_graph<span class="token punctuation">.</span>nodes<span class="token punctuation">[</span><span class="token string">'user'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>data<span class="token punctuation">[</span><span class="token string">'train_mask'</span><span class="token punctuation">]</span>
train_idx <span class="token operator">=</span> torch<span class="token punctuation">.</span>nonzero<span class="token punctuation">(</span>train_mask<span class="token punctuation">,</span> as_tuple<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span><span class="token punctuation">.</span>squeeze<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>Using backend: pytorch</p>
<p>我们使用<code>MultiLayerFullNeighborSampler</code>进行采样，它会采样当前节点的所有邻居节点，利用<code>NodeDataLoader</code>进行数据的批量读取</p>
<pre class="line-numbers language-python"><code class="language-python"><span class="token comment" spellcheck="true">#2.定义采样器</span>
sampler <span class="token operator">=</span> dgl<span class="token punctuation">.</span>dataloading<span class="token punctuation">.</span>MultiLayerFullNeighborSampler<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true">#采样2阶子图，对应了GNN中2层网络</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>
<pre class="line-numbers language-python"><code class="language-python">dataloader <span class="token operator">=</span> dgl<span class="token punctuation">.</span>dataloading<span class="token punctuation">.</span>NodeDataLoader<span class="token punctuation">(</span>hetero_graph<span class="token punctuation">,</span> <span class="token punctuation">{</span><span class="token string">"user"</span><span class="token punctuation">:</span> train_idx<span class="token punctuation">}</span><span class="token punctuation">,</span> sampler<span class="token punctuation">,</span> batch_size<span class="token operator">=</span><span class="token number">128</span><span class="token punctuation">,</span> shuffle<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>num_workers<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<p>通过对dataloader迭代，我们每次可以取出input_nodes, output_nodes, blocks这三个变量，其中：<br><strong>input_nodes</strong>：包括训练所需的所有节点ID<br><strong>output_nodes</strong>：包括训练目标的节点，对应上面128个随机的user节点<br><strong>blocks</strong>：是个list,从blocks[0],blocks[1]….分别对应了节点的$k$阶子图，$k-1$阶子图…..直到这128个user节点自身的$0$阶子图</p>
<pre class="line-numbers language-python"><code class="language-python">input_nodes<span class="token punctuation">,</span> output_nodes<span class="token punctuation">,</span> blocks <span class="token operator">=</span> next<span class="token punctuation">(</span>iter<span class="token punctuation">(</span>dataloader<span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<p>由于将原始的大图切分为了一个一个的block，所以对于模型定义中的<code>forward</code>阶段需要做一点修改，改动也很简单，将原始的全图变量，依层替换为对应的block即可</p>
<pre class="line-numbers language-python"><code class="language-python"><span class="token comment" spellcheck="true">#3.定义模型</span>
<span class="token keyword">class</span> <span class="token class-name">RGCN</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> in_feats<span class="token punctuation">,</span> hid_feats<span class="token punctuation">,</span> out_feats<span class="token punctuation">,</span> rel_names<span class="token punctuation">)</span><span class="token punctuation">:</span>
        super<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        <span class="token comment" spellcheck="true"># 实例化HeteroGraphConv，in_feats是输入特征的维度，out_feats是输出特征的维度，aggregate是聚合函数的类型</span>
        self<span class="token punctuation">.</span>conv1 <span class="token operator">=</span> HeteroGraphConv<span class="token punctuation">(</span><span class="token punctuation">{</span>
            rel<span class="token punctuation">:</span> GraphConv<span class="token punctuation">(</span>in_feats<span class="token punctuation">,</span> hid_feats<span class="token punctuation">)</span>
            <span class="token keyword">for</span> rel <span class="token keyword">in</span> rel_names<span class="token punctuation">}</span><span class="token punctuation">,</span> aggregate<span class="token operator">=</span><span class="token string">'sum'</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>conv2 <span class="token operator">=</span> HeteroGraphConv<span class="token punctuation">(</span><span class="token punctuation">{</span>
            rel<span class="token punctuation">:</span> GraphConv<span class="token punctuation">(</span>hid_feats<span class="token punctuation">,</span> out_feats<span class="token punctuation">)</span>
            <span class="token keyword">for</span> rel <span class="token keyword">in</span> rel_names<span class="token punctuation">}</span><span class="token punctuation">,</span> aggregate<span class="token operator">=</span><span class="token string">'sum'</span><span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> blocks<span class="token punctuation">,</span> inputs<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment" spellcheck="true"># 输入是节点的特征字典</span>
        h <span class="token operator">=</span> self<span class="token punctuation">.</span>conv1<span class="token punctuation">(</span>blocks<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> inputs<span class="token punctuation">)</span><span class="token comment" spellcheck="true">#2阶子图</span>
        h <span class="token operator">=</span> <span class="token punctuation">{</span>k<span class="token punctuation">:</span> F<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>v<span class="token punctuation">)</span> <span class="token keyword">for</span> k<span class="token punctuation">,</span> v <span class="token keyword">in</span> h<span class="token punctuation">.</span>items<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">}</span>
        h <span class="token operator">=</span> self<span class="token punctuation">.</span>conv2<span class="token punctuation">(</span>blocks<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> h<span class="token punctuation">)</span><span class="token comment" spellcheck="true">#1阶子图</span>
        <span class="token keyword">return</span> h<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<pre class="line-numbers language-python"><code class="language-python"><span class="token comment" spellcheck="true">#4.训练模型</span>
<span class="token comment" spellcheck="true">#训练阶段没太大差异，注意输入、输出的具体格式</span>
losses<span class="token operator">=</span><span class="token punctuation">[</span><span class="token punctuation">]</span>
model <span class="token operator">=</span> RGCN<span class="token punctuation">(</span>n_hetero_features<span class="token punctuation">,</span> <span class="token number">20</span><span class="token punctuation">,</span> n_user_classes<span class="token punctuation">,</span> hetero_graph<span class="token punctuation">.</span>etypes<span class="token punctuation">)</span>
opt <span class="token operator">=</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>Adam<span class="token punctuation">(</span>model<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>lr<span class="token operator">=</span><span class="token number">1e</span><span class="token operator">-</span><span class="token number">2</span><span class="token punctuation">)</span>
<span class="token keyword">if</span> __name__ <span class="token operator">==</span> <span class="token string">'__main__'</span><span class="token punctuation">:</span>
    model<span class="token punctuation">.</span>train<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token keyword">for</span> _ <span class="token keyword">in</span> range<span class="token punctuation">(</span><span class="token number">20</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">for</span> input_nodes<span class="token punctuation">,</span> output_nodes<span class="token punctuation">,</span> blocks <span class="token keyword">in</span> dataloader<span class="token punctuation">:</span>
            <span class="token comment" spellcheck="true"># blocks = [b.to(torch.device('cuda')) for b in blocks]</span>
            input_features <span class="token operator">=</span> blocks<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>srcdata<span class="token punctuation">[</span><span class="token string">'feature'</span><span class="token punctuation">]</span>  <span class="token comment" spellcheck="true"># returns a dict</span>
            output_labels <span class="token operator">=</span> blocks<span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">.</span>dstdata<span class="token punctuation">[</span><span class="token string">'label'</span><span class="token punctuation">]</span>  <span class="token comment" spellcheck="true"># returns a dict</span>
            output_predictions <span class="token operator">=</span> model<span class="token punctuation">(</span>blocks<span class="token punctuation">,</span> input_features<span class="token punctuation">)</span>
            loss <span class="token operator">=</span> F<span class="token punctuation">.</span>cross_entropy<span class="token punctuation">(</span>output_predictions<span class="token punctuation">[</span><span class="token string">'user'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> output_labels<span class="token punctuation">[</span><span class="token string">'user'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
            opt<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>
            loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>
            opt<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>
            losses<span class="token punctuation">.</span>append<span class="token punctuation">(</span>loss<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> plt
<span class="token operator">%</span>matplotlib inline
plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>losses<span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>legend<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token string">"loss"</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre>
<p>&gt;&gt;&gt;</p>
<pre><code>&lt;matplotlib.legend.Legend at 0x281a2e53fd0&gt;</code></pre><p>​<br><img src="/images/loading.gif" data-original="../images/ML/output_10_1.png" alt=""><br>​    </p>
<h1 id="图网络解释"><a href="#图网络解释" class="headerlink" title="图网络解释"></a>图网络解释</h1><p>原论文：<a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=4700287" target="_blank" rel="noopener">The graph neural network model</a></p>
<h2 id="GNN"><a href="#GNN" class="headerlink" title="GNN"></a>GNN</h2><ol>
<li><p>很多领域的数据的底层关系可以表示为图结构，如计算机视觉、分子化学、分子生物学、模式识别、数据挖掘等领域。</p>
<p>最简单的图结构为单节点图，以及作为节点序列的图，更复杂的图结构包括树、无环图、带环图等。</p>
</li>
<li><p>关于图的任务可以分为两类：</p>
<ul>
<li><p>基于图的任务<code>graph-focused</code>：以图为单位，直接在图结构的数据上实现分类或者回归。</p>
<p>如：图表示化学化合物，每个顶点表示一个原子或者化学基团、边表示化学键。模型可以用于评估被检测的化合物的类别。</p>
<p><img src="/images/loading.gif" data-original="../images/ML/adc557597d3c3ecfb0c351e61b5bdbb2.png" alt=""></p>
</li>
<li><p>基于节点的任务 <code>node-focused</code>：以节点为单位，在每个结点上实现分类或者回归。如：</p>
<ul>
<li><p>目标检测任务中需要检测图像是否包含特定的目标并进行目标定位。该问题可以通过一个映射函数来解决，该映射函数根据相应区域是否属于目标对象从而对邻接的顶点进行分类。</p>
<p>如下图所示，对应于城堡的黑色顶点的输出为<code>1</code>，其它顶点输出为 <code>0</code> 。</p>
<p><img src="/images/loading.gif" data-original="../images/ML/2af9fa9e9f42cbcb89ae2a1f204485a3.png" alt=""></p>
</li>
<li><p>网页分类任务中需要判断每个网页的类别。我们将所有的网页视作一个大图，每个网页代表一个顶点、网页之间的超链接代表边。可以利用网页的内容和图结构来进行建模。</p>
<p><img src="/images/loading.gif" data-original="../images/ML/3253eb9068afcecb35c09221a503d05e.png" alt=""></p>
</li>
</ul>
</li>
</ul>
</li>
<li><p>传统的机器学习算法通过使用预处理阶段来处理图结构的数据。在这一阶段，算法将图结构数据映射到一个更简单的表达<code>representation</code>，如一个实值向量。即：预处理阶段首先将图结构的数据“压缩” 为实值向量，然后使用 <code>list-based</code> 数据处理技术来处理。</p>
<p>在数据压缩过程中，一些重要的信息（如：每个顶点的拓扑依赖性）可能会被丢失。最终的效果严重依赖于数据预处理算法。</p>
<p>最近有很多算法尝试在预处理阶段保留数据的图结构性质，其基本思路是：利用图的结点之间的拓扑关系对图结构的数据进行编码，从而在数据预处理过程中融合图的结构信息。递归神经网络<code>RNN</code>、马尔科夫链都是这类技术。</p>
<p>论文 <code>《The graph neural network model》</code> 提出了 <code>GNN</code> 模型，该模型扩展了<code>RNN</code> 和马尔科夫链技术，适合处理图结构的数据。</p>
<ul>
<li><code>GNN</code> 既适用于 <code>graph-focused</code> 任务，又适用于 <code>node-focused</code> 任务。</li>
<li><code>GNN</code> 扩展了<code>RNN</code>，它可以处理更广泛的图任务，包括无环图、带环图、有向图、无向图等。</li>
<li><code>GNN</code> 扩展了马尔科夫链，它通过引入学习算法并扩大了可建模的随机过程的类型从而扩展了随机游走理论。</li>
</ul>
</li>
<li><p><code>GNN</code> 是基于消息扩散机制 <code>information diffusion mechanism</code> 。图由一组处理单元来处理，每个处理单元对应于图的一个顶点。</p>
<ul>
<li>处理单元之间根据图的连接性来链接。</li>
<li>处理单元之间交换信息并更新单元状态，直到达到稳定的平衡为止。</li>
<li>通过每个处理单元的稳定状态可以得到对应顶点的输出。</li>
<li>为确保始终存在唯一的稳定状态，消息扩散机制存在约束。</li>
</ul>
</li>
</ol>
<h3 id="模型"><a href="#模型" class="headerlink" title="模型"></a>模型</h3><p><img src="/images/loading.gif" data-original="../images/ML/image-20210903094959341.png" alt=""></p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20210903095022946.png" alt=""></p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20210903095051917.png" alt=""></p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20210903095117747.png" alt=""></p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20210903095224632.png" alt=""></p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20210903095241775.png" alt=""></p>
<h4 id="方程求解算法"><a href="#方程求解算法" class="headerlink" title="方程求解算法"></a>方程求解算法</h4><p><img src="/images/loading.gif" data-original="../images/ML/image-20210903095335459.png" alt=""></p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20210903095358128.png" alt=""></p>
<p><img src="/images/loading.gif" data-original="../images/ML/e7b64cb02cdf984b592f9cbdaae378e0.png" alt=""></p>
<h4 id="参数学习算法"><a href="#参数学习算法" class="headerlink" title="参数学习算法"></a>参数学习算法</h4><p><img src="/images/loading.gif" data-original="../images/ML/image-20210903095453658.png" alt=""></p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20210903095522966.png" alt=""></p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20210903095552140.png" alt=""></p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20210903095614573.png" alt=""></p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20210903095730419.png" alt=""></p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20210903095746578.png" alt=""></p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20210903095807563.png" alt=""></p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20210903095832380.png" alt=""></p>
<p>8.实际上编码网络仅仅类似于静态的前馈神经网络，但是编码网络的<code>layer</code> 层数是动态确定的，并且网络权重根据输入图的拓扑结构来共享。因此为静态网络设计的二阶学习算法、剪枝算法、以及逐层学习算法无法直接应用于 <code>GNN</code> 。</p>
<h4 id="转移函数和输出函数"><a href="#转移函数和输出函数" class="headerlink" title="转移函数和输出函数"></a>转移函数和输出函数</h4><p><img src="/images/loading.gif" data-original="../images/ML/image-20210903095925053.png" alt=""></p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20210903095956742.png" alt=""></p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20210903100014627.png" alt=""></p>
<h3 id="模型分析"><a href="#模型分析" class="headerlink" title="模型分析"></a>模型分析</h3><h4 id="RNN"><a href="#RNN" class="headerlink" title="RNN"></a>RNN</h4><p><img src="/images/loading.gif" data-original="../images/ML/image-20210903100055121.png" alt=""></p>
<h4 id="随机游走"><a href="#随机游走" class="headerlink" title="随机游走"></a>随机游走</h4><p><img src="/images/loading.gif" data-original="../images/ML/image-20210903100430936.png" alt=""></p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20210903100449376.png" alt=""></p>
<h4 id="计算复杂度"><a href="#计算复杂度" class="headerlink" title="计算复杂度"></a>计算复杂度</h4><p><img src="/images/loading.gif" data-original="../images/ML/image-20210903100524586.png" alt=""></p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20210903100607915.png" alt=""></p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20210903100631909.png" alt=""></p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20210903100647155.png" alt=""></p>
<h4 id="不动点"><a href="#不动点" class="headerlink" title="不动点"></a>不动点</h4><p><code>GNN</code> 的核心是不动点理论，通过顶点的消息传播使得整张图的每个顶点的状态收敛，然后在收敛的状态基础上预测。</p>
<p>这里存在两个局限：</p>
<ul>
<li><p><code>GNN</code> 将顶点之间的边仅仅视为一种消息传播手段，并未区分边的功能。</p>
</li>
<li><p>基于不动点的收敛会导致顶点之间的状态存在较多的消息共享，从而导致顶点状态之间过于光滑 <code>over smooth</code> ，这将使得顶点之间缺少区分度。</p>
<p>如下图所示，每个像素点和它的上下左右、以及斜上下左右八个像素点相邻。初始时刻蓝色没有信息量，绿色、黄色、红色各有一部分信息。</p>
<p>开始时刻，不同像素点的区分非常明显；在不动点的收敛过程中，所有像素点都趋向于一致，最终整个系统的信息分布比较均匀。最终，虽然每个像素点都感知到了全局信息，但是我们已经无法根据每个像素点的最终状态来区分它们。</p>
</li>
</ul>
<p><img src="/images/loading.gif" data-original="../images/ML/e67a79049891e9b69335cb4527c0c47b.gif" alt=""></p>
<h2 id="GCN-1"><a href="#GCN-1" class="headerlink" title="GCN"></a>GCN</h2><p>原论文：Spectral Networks and Deep Locally Connected Networks on Graphs</p>
<ol>
<li><p>卷积神经网络 <code>CNN</code> 要求输入数据为网格结构，并且要求数据在网格中具有平移不变性，如一维语音、二维图像、三维视频都是这类数据的典型代表。<code>CNN</code> 充分利用了以下几个特点来大幅度降低模型的参数数量：</p>
<ul>
<li>权重共享：同一个卷积核可以应用于不同的位置。</li>
<li>空间局部性：卷积核的大小通常都远远小于输入信号的尺寸。</li>
<li>多尺度：通过步长大于一的卷积或者池化操作来减少参数，并获得更大的感受野 <code>receptive field</code> 。</li>
</ul>
<p>在网格数据结构中，顶点的邻居数量都是固定的。但是在很多任务中，数据并不是网格结构，如社交网络数据。在这些图数据结构中，顶点的邻居数量是不固定的。</p>
<p>图结构是一种比网格结构更通用的结构，论文 <code>《Spectral Networks and Deep Locally Connected Networks on Graphs》</code> 在图结构上扩展了卷积的概念，并提出了两种构建方式：</p>
<ul>
<li>基于空域的卷积构建<code>Spatial Construction</code> ：直接在原始图结构上执行卷积。</li>
<li>基于谱域的卷积构建<code>Spectral Construction</code> ：对图结构进行傅里叶变换之后，在谱域进行卷积。</li>
</ul>
</li>
<li><p>在网格数据中的卷积可以采用固定大小的卷积核来抽取特征；但是在图数据中，传统的卷积核无能为力。图卷积的本质是找到适合于图结构的可学习的卷积核。</p>
</li>
</ol>
<h3 id="空域构建"><a href="#空域构建" class="headerlink" title="空域构建"></a>空域构建</h3><p><img src="/images/loading.gif" data-original="../images/ML/image-20210903101049350.png" alt=""></p>
<p><img src="/images/loading.gif" data-original="../images/ML/1ac74457e5080fdbff591c9ff2b485cc.png" alt=""></p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20210903101125182.png" alt=""></p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20210903101145142.png" alt=""></p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20210903101209271.png" alt=""></p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20210903101237066.png" alt=""></p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20210903101254895.png" alt=""></p>
<h3 id="图卷积"><a href="#图卷积" class="headerlink" title="图卷积"></a>图卷积</h3><h4 id="拉普拉斯算子"><a href="#拉普拉斯算子" class="headerlink" title="拉普拉斯算子"></a>拉普拉斯算子</h4><p><img src="/images/loading.gif" data-original="../images/ML/image-20210903101327520.png" alt=""></p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20210903101349178.png" alt=""></p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20210903101408237.png" alt=""></p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20210903101427245.png" alt=""></p>
<h4 id="卷积"><a href="#卷积" class="headerlink" title="卷积"></a>卷积</h4><p><img src="/images/loading.gif" data-original="../images/ML/image-20210903101501142.png" alt=""></p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20210903101531862.png" alt=""></p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20210903101550937.png" alt=""></p>
<h3 id="频域构建"><a href="#频域构建" class="headerlink" title="频域构建"></a>频域构建</h3><p><img src="/images/loading.gif" data-original="../images/ML/image-20210903101613969.png" alt=""></p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20210903101635435.png" alt=""></p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20210903101654905.png" alt=""></p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20210903101726283.png" alt=""></p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20210903101753772.png" alt=""></p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20210903101821939.png" alt=""></p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20210903101847390.png" alt=""></p>
<h2 id="Fast-GCN"><a href="#Fast-GCN" class="headerlink" title="Fast GCN"></a>Fast GCN</h2><p>原论文：<a href="https://proceedings.neurips.cc/paper/2016/file/04df4d434d481c5bb723be1b6df1ee65-Paper.pdf" target="_blank" rel="noopener">Convolutional Neural Networks on Graphs with Fast Localized Spectral Filtering</a></p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20210903101930702.png" alt=""></p>
<h3 id="模型-1"><a href="#模型-1" class="headerlink" title="模型"></a>模型</h3><p><img src="/images/loading.gif" data-original="../images/ML/image-20210903102114370.png" alt=""></p>
<h4 id="卷积核"><a href="#卷积核" class="headerlink" title="卷积核"></a>卷积核</h4><p><img src="/images/loading.gif" data-original="../images/ML/image-20210903102217719.png" alt=""></p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20210903102313023.png" alt=""></p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20210903102333120.png" alt=""></p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20210903102356106.png" alt=""></p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20210903102420802.png" alt=""></p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20210903102439023.png" alt=""></p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20210903102457809.png" alt=""></p>
<h4 id="图粗化"><a href="#图粗化" class="headerlink" title="图粗化"></a>图粗化</h4><p><img src="/images/loading.gif" data-original="../images/ML/image-20210903102522322.png" alt=""></p>
<h4 id="池化"><a href="#池化" class="headerlink" title="池化"></a>池化</h4><p><img src="/images/loading.gif" data-original="../images/ML/image-20210903102553485.png" alt=""></p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20210903102621045.png" alt=""></p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20210903102649676.png" alt=""></p>
<h2 id="Semi-Supervised-GCN"><a href="#Semi-Supervised-GCN" class="headerlink" title="Semi-Supervised GCN"></a>Semi-Supervised GCN</h2><p>原论文：<a href="https://arxiv.org/pdf/1609.02907.pdf?fbclid=IwAR0BgJeoKHIAvPuSE9fJ0_IQOEu5l75yxyNo7PUC08RTOFlm_IIo5YmcnQM" target="_blank" rel="noopener">SEMI-SUPERVISED CLASSIFICATION WITH GRAPH CONVOLUTIONAL NETWORKS</a></p>
<p>图的半监督学习方法大致分为两大类：</p>
<ul>
<li><p>基于图的拉普拉斯矩阵正则化的方法， 包括标签传播算法<code>label propagation</code>、流行正则化算法<code>manifold regularization</code> 。</p>
</li>
<li><p>基于图嵌入的方法，包括 <code>DeepWalk、LINE</code> 等。</p>
<p>但是基于图嵌入的方法需要一个<code>pipeline</code>，其中包括生成随机游走序列、执行半监督训练等多个步骤，而每个步骤都需要分别进行优化。</p>
</li>
</ul>
<p>论文<code>《 SEMI-SUPERVISED CLASSIFICATION WITH GRAPH CONVOLUTIONAL NETWORKS》</code> 提出了一种可扩展的、基于<code>Graph</code> 的半监督学习方法，该方法基于一个有效的、能直接对<code>Graph</code> 进行操作的卷积神经网络变种。</p>
<p>该模型基于频域卷积的局部一阶近似来选择卷积网络结构，其计算复杂度为 <img src="/images/loading.gif" data-original="https://static.sitestack.cn/projects/huaxiaozhuan-ai/72fefaa1d0ea1670a551ea3407087d62.svg" alt="四、Semi-Supervised GCN - 图1"> ，其中 <img src="/images/loading.gif" data-original="https://static.sitestack.cn/projects/huaxiaozhuan-ai/4365d8a30ced9f1330d84230f785e7cd.svg" alt="四、Semi-Supervised GCN - 图2"> 为边的数量。</p>
<p>该模型学到的隐层<code>representation</code> 既能够编码图的局部结构，又能够编码顶点的特征。</p>
<h2 id="分子指纹GCN"><a href="#分子指纹GCN" class="headerlink" title="分子指纹GCN"></a>分子指纹GCN</h2><p>原论文：<a href="https://arxiv.org/pdf/1509.09292.pdf" target="_blank" rel="noopener">Convolutional Networks on Graphs for Learning Molecular Fingerprints</a></p>
<p>在材料设计领域的最新工作已经将神经网络用于材料筛选，其任务是通过学习样本来预测新型分子的特性。预测分子特性通常需要将分子图作为输入，然后构建模型来预测。在分子图中顶点表示原子，边表示化学键。</p>
<p>这个任务的一个难点在于：输入的分子图可以具有任意大小和任意形状，而大多数机器学习模型只能够处理固定大小、固定形状的输入。</p>
<p>目前主流的方法是通过<code>hash</code> 函数对分子图进行预处理从而生成固定大小的指纹向量<code>fingerprint vector</code>，该指纹向量作为分子的特征灌入后续的模型中。</p>
<p>论文<code>《Convolutional Networks on Graphs for Learning Molecular Fingerprints》</code> 提出了分子指纹<code>GCN</code> 模型，该模型用一个可微的神经网络代替了分子指纹部分。</p>
<p>神经网络以原始的分子图作为输入，采用卷积层来抽取特征，然后通过全局池化来结合所有原子的特征。这种方式使得我们可以端到端的进行分子预测。</p>
<p>相比较传统的指纹向量的方式，我们的方法具有以下优势：</p>
<ul>
<li><p>预测能力强：通过实验比较可以发现，我们的模型比传统的指纹向量能够提供更好的预测能力。</p>
</li>
<li><p>模型简洁：为了对所有可能的子结构进行编码，传统的指纹向量必须维度非常高。而我们的模型只需要对相关特征进行编码，模型的维度相对而言低得多，这降低了下游的计算量。</p>
</li>
<li><p>可解释性：传统的指纹向量对每个片段<code>fragment</code> 进行不同的编码，片段之间没有相似的概念。即：相似的片段不一定有相似的编码；相似的编码也不一定代表了相似的片段。</p>
<p>我们的模型中，每个特征都可以由相似但是不同的分子片段激活，因此相似的片段具有相似的特征，相似的特征也代表了相似的片段。这使得特征的<code>representation</code> 更具有意义。</p>
</li>
</ul>
<h2 id="GGS-NN"><a href="#GGS-NN" class="headerlink" title="GGS-NN"></a>GGS-NN</h2><p>原论文：<a href="https://arxiv.org/pdf/1511.05493.pdf" target="_blank" rel="noopener">GATED GRAPH SEQUENCE NEURAL NETWORKS</a></p>
<ol>
<li><p>目前关于图神经网络模型的工作主要集中在单输出模型上，如<code>graph-level</code> 的分类。实际上有一些图任务需要输出序列，如：输出一条包含特定属性的顶点组成的路径。</p>
<p>论文<code>《GATED GRAPH SEQUENCE NEURAL NETWORKS》</code> 基于 <code>GNN</code> 模型进行修改，它使用门控循环单元 <code>gated recurrent units</code> 以及现代的优化技术，并扩展到序列输出的形式。这种模型被称作门控图序列神经网络<code>Gated Graph Sequence Neural Networks:GGS-NNs</code> 。</p>
<p>在<code>Graph</code> 数据结构上，<code>GGS-NNs</code> 相比于单纯的基于序列的模型（如<code>LSTM</code>）具有有利的归纳偏置<code>inductive biases</code> 。</p>
<blockquote>
<p>归纳偏置：算法对于学习的问题做的一些假设，这些假设就称作归纳偏置。它可以理解为贝叶斯学习中的“先验<code>prior</code>”，即对模型的偏好。</p>
<ul>
<li><code>CNN</code> 的归纳偏置为：局部性<code>locality</code>和平移不变性<code>spatial invariance</code>。即：空间相近的元素之间联系较紧、空间较远的元素之间没有联系；卷积核权重共享。</li>
<li><code>RNN</code> 的归纳偏置为：序列性<code>sequentiality</code> 和时间不变性 <code>time invariance</code>。即：序列顺序上的 <code>timestep</code> 之间有联系；<code>RNN</code> 权重共享。</li>
</ul>
</blockquote>
</li>
<li><p>在图上学习<code>representation</code> 有两种方式：</p>
<ul>
<li>学习输入图的 <code>representation</code> 。这也是目前大多数模型的处理方式。</li>
<li>在生成一系列输出的过程中学习内部状态的 <code>representation</code>，其中的挑战在于：如何学习 <code>representation</code>，它既能对已经生成的部分输出序列进行编码（如路径输出任务中，已经产生的路径），又能对后续待生成的部分输出序列进行编码（如路径输出任务中，剩余路径）。</li>
</ul>
</li>
</ol>
<h2 id="PATCHY-SAN"><a href="#PATCHY-SAN" class="headerlink" title="PATCHY-SAN"></a>PATCHY-SAN</h2><p>原论文：<a href="http://proceedings.mlr.press/v48/niepert16.pdf" target="_blank" rel="noopener">Learning Convolutional Neural Networks for Graphs</a></p>
<ol>
<li><p>很多重要问题都可以视为图数据得学习问题。考虑以下两个问题：</p>
<ul>
<li>给定一组图作为训练数据，学习一个用于对未见过的图（即测试图）进行分类或者回归的函数。其中训练集中任意两个图的结构不一定是相同的。例如：给定一组化合物以及它们对于癌细胞活性抑制效果，用于预测新的化合物对于癌细胞活性抑制的结果。</li>
<li>给定一张大图，学习该图的<code>representation</code> 从而可以推断未见过的图属性，如顶点类型（即顶点分类）、缺失边（即链接预测）。</li>
</ul>
</li>
<li><p>卷积神经网络<code>CNN</code> 在图像领域中大获成功。图像<code>image</code> 也是一种图<code>graph</code> ，但是它是一种特殊的正方形的网格图，其中顶点表示像素。如下图所示，黑色/白色顶点表示像素的不同取值（黑色取值为<code>1</code>、白色取值为<code>0</code> ），红色顶点表示当前卷积核的中心位置。<code>(a)</code> 图给出了一个 <code>3x3</code> 卷积核在一个 <code>4x4</code> 图像上的卷积过程，其中步幅为<code>1</code>、采用非零填充。</p>
<p>我们可以将 <code>CNN</code> 视为遍历一个顶点序列（即图<code>(a)</code> 中的红色顶点 <code>1,2,3,4</code> ）、然后为该序列中的每个顶点生成固定大小的邻域子图（即图<code>(b)</code> 中的 <code>3x3</code> 网格） 的过程。其中邻域子图作为感受野<code>receptive field</code>，用于特征抽取（抽取感受野中顶点的特征）。</p>
<p><img src="/images/loading.gif" data-original="../images/ML/760e39197c2dd0004b571d76b2d285df.png" alt=""></p>
<p>由于像素点的隐式空间顺序，从左到右以及从上到下唯一确定了这个顶点序列。在<code>NLP</code> 问题中，句子也隐式的从左到右确定了单词的顺序。但是对于图<code>graph</code> 问题，难以针对不同的问题给予一个合适的顶点顺序。同时数据集中不同图的结构不同，不同图的顶点之间都无法对应。</p>
<p>因此如果希望将卷积神经网络应用到图结构上，必须解决两个问题：</p>
<ul>
<li>为图确定一个顶点序列，其中我们为序列中的每个顶点创建邻域子图。</li>
<li>邻域图的归一化，即将邻域子图映射到向量空间，从而方便后续的卷积运算（因为卷积核无法作用于子图上）。</li>
</ul>
<p>论文<code>《Learning Convolutional Neural Networks for Graphs》</code> 提出了一种学习任意图的卷积神经网络框架 <code>PATCHY-SAN</code> ，该框架解决了这两个问题。<code>PATCHY-SAN</code> 适用于无向图/有向图，可以处理连续/离散的顶点和边的属性，也支持多种类型的边。</p>
<p>对于每个输入的<code>graph</code>，<code>PATCHY-SAN</code> 方法首先确定了一个顶点序列；然后，对序列中每个顶点提取一个正好由 <img src="/images/loading.gif" data-original="https://static.sitestack.cn/projects/huaxiaozhuan-ai/cc2f295f0763f0ecede26c79e869fe9a.svg" alt="七、PATCHY-SAN - 图2"> 个顶点组成的邻域并归一化邻域，归一化的邻域将作为当前顶点的感受野；最后，就像 <code>CNN</code> 的感受野一样，可以将一些特征学习组件（如卷积层、<code>dense</code> 层)作用到归一化邻域上。其整体架构如下图所示，其中红色顶点表示顶点序列中的顶点。</p>
<p><img src="/images/loading.gif" data-original="../images/ML/074c89685c6e42200fc84ba04d19cc73.png" alt=""></p>
</li>
<li><p><code>PATCHY-SAN</code> 方法具有以下优势：</p>
<ul>
<li>计算高效，原生支持并行计算，并且可用于大型图。</li>
<li>支持特征可视化，可以深入了解图的结构属性。</li>
<li>相比较与 <code>graph kernel</code> 方法，<code>PATCHY-SAN</code> 无需依赖任何特征工程就可以学到具体任务的特征。</li>
</ul>
</li>
</ol>
<h2 id="GraphSage"><a href="#GraphSage" class="headerlink" title="GraphSage"></a>GraphSage</h2><p>原论文：<a href="https://proceedings.neurips.cc/paper/2017/file/5dd9db5e033da9c6fb5ba83c7a7ebea9-Paper.pdf" target="_blank" rel="noopener">Inductive Representation Learning on Large Graphs</a></p>
<ol>
<li><p>在大型<code>Graph</code> 中，顶点的低维<code>embedding</code> 在从内容推荐到蛋白质功能识别等各项任务中都非常有效。</p>
<p>之前的工作都集中在从单个指定的图来学习顶点 <code>embedding</code>，这些方法都是 <code>transductive</code> 的。但是，很多实际应用需要为从未见过的顶点或者全新的图来快速生成 <code>embedding</code> ，即需要 <code>inductive</code> 能力。这种 <code>inductive</code> 能力对于生产中的机器学习系统至关重要，这些机器学习系统需要在不断变化的图上运行，并不断遇到从未见过的顶点（如 <code>Youtube</code> 上的新用户、新视频）。 另外这种 <code>inductive</code> 能力还可以促进图的泛化，例如我们在已知的分子结构图上训练模型，然后该模型可以为新的分子图产生顶点 <code>embedding</code> 。</p>
<ul>
<li><p>与 <code>transductiv</code> 相比，<code>inductive</code> 的顶点 <code>embedding</code> 更为困难，因为这需要泛化到从未就按过的顶点。而这需要将新观察到的子图 “对齐” 到模型已经训练过的旧的子图。<code>inductive</code> 框架必须学会识别顶点邻域的结构属性，从而识别每个顶点（包括新发现的顶点）在图的局部角色以及全局位置。</p>
</li>
<li><p>大多数现有的顶点<code>embedding</code> 方法本质都是 <code>transductive</code> 的。这些方法都使用基于矩阵分解来直接优化每个顶点的 <code>embedding</code> 。因为它们是在单个固定的图上对顶点进行训练和预测，因此天然地无法推广到未见过的顶点。</p>
<p>也可以修改这些方法来满足<code>inductinve</code> 的要求， 如针对新的未见过的顶点进行若干轮额外的梯度下降。但是这种方式的计算代价较高，也容易导致顶点 <code>embedding</code> 在重新训练期间发生漂移。</p>
</li>
</ul>
<p>最近也有通过图卷积（如<code>Semi-Supervised GCN</code> ）来学习图结构的方法，但是这些方法也是以 <code>transductive</code> 的方式在使用。论文<code>《Inductive Representation Learning on Large Graphs》</code> 提出了一个通用的、称作 <code>Graph Sample and Aggregage:GraphSAGE</code> 的学习框架，该框架将图卷积推广到 <code>inductinve</code> 无监督学习。</p>
</li>
<li><p><code>GraphSage</code> 是一种<code>inductive</code> 的顶点 <code>embedding</code> 方法。与基于矩阵分解的<code>embedding</code> 方法不同，<code>GraphSage</code> 利用顶点特征（如文本属性、顶点画像信息、顶点的<code>degree</code> 等）来学习，并泛化到从未见过的顶点。</p>
<ul>
<li>通过将顶点特征融合到学习算法中，<code>GraphSage</code> 可以同时学习每个顶点的邻域拓扑结构，以及顶点特征在邻域中的分布。<code>GraphSage</code> 不仅可以应用于顶点特征丰富的图（如引文网络、生物分子网络），还可以应用到没有任何顶点特征的简单的图，此时可以采用顶点的结构属性来作为顶点特征（如顶点<code>degree</code> ）。</li>
<li><code>GraphSage</code> 并没有为每个顶点训练一个 <code>embedding</code>，而是训练了一组聚合函数，这些聚合函数用于从顶点的局部邻域中聚合信息特征。在测试期间，我们使用训练好的模型的聚合函数来为从未见过的顶点生成 <code>embedding</code> 。</li>
</ul>
<p><img src="/images/loading.gif" data-original="../images/ML/d7b0083456e9d0a24f6fa2460514e6dd.png" alt=""></p>
</li>
<li><p>和之前的 <code>embedding</code> 方法类似，<code>GraphSage</code> 设计了一个无监督损失函数。该损失函数允许对<code>GraphSage</code> 进行无监督训练，而无需任何特定于具体任务监督信息。论文还展示了以监督方式来训练 <code>GraphSage</code> 。</p>
<p>论文在三个顶点分类 <code>benchmark</code> 上评估了<code>GraphSave</code> 方法，从而验证了<code>GraphSage</code> 在从未见过的数据上具有优秀的顶点 <code>embedding</code> 能力。</p>
<p>最后论文研究了 <code>GraphSave</code> 的表达能力，并通过理论分析证明了：虽然<code>GraphSage</code> 是基于顶点特征的，但是它能够学得顶点在图中角色的结构信息。</p>
</li>
<li><p><code>GraphSave</code> 方法和 <code>Semi-Supervised GCN</code> 密切相关。原始的 <code>Semi-Supervised GCN</code> 以 <code>transductive</code> 的方式进行半监督学习，这要求在训练过程中已知完整的图拉普拉斯算子。<code>GraphSage</code> 的一个简单变种可以视为 <code>Semi-Supervised GCN</code> 框架以 <code>inductive</code> 方式的扩展。</p>
</li>
</ol>
<h2 id="GAT-1"><a href="#GAT-1" class="headerlink" title="GAT"></a>GAT</h2><p>原论文：<a href="https://arxiv.org/pdf/1710.10903.pdf" target="_blank" rel="noopener">GRAPH ATTENTION NETWORKS</a></p>
<ol>
<li><p>卷积神经网络<code>CNN</code> 已经成功应用于图像分类、语义分割以及机器翻译之类的问题，其底层数据结构为网格状结构<code>grid-like structure</code> 。但很多任务涉及到无法以网状结构表示的数据，如：社交网络、电信网络等，而这些数据通常可以用图的方式来组织。</p>
<ul>
<li><p>早期图领域任务通常作为有向无环图，采用循环神经网络<code>RNN</code> 来处理。后来发展出图神经网络<code>GNN</code> 作为 <code>RNN</code> 的泛化来直接处理更通用的图，如循环图、有向图、无环图。</p>
<p><code>GNN</code> 包含一个迭代过程来传播顶点状态直至达到状态平衡，即不动点；然后再根据顶点状态为每个顶点生成输出。<code>GG-NN</code> 通过在顶点状态传播过程中使用门控循环单元来改进这一方法。</p>
</li>
<li><p>另一个方向是将卷积推广到图领域，有两种推广思路：谱方法<code>spectral approach</code> 、非谱方法<code>non-spectral approach</code> 。</p>
<ul>
<li><p>谱方法通常和图的谱表达<code>spectral representation</code> 配合使用，并已成功应用于顶点分类。</p>
<p>但是这些谱方法中，学习的<code>filter</code> 都依赖于拉普拉斯矩阵分解后的特征向量。这种分解依赖于具体的图结构，因此在一种图结构上训练的模型无法直接应用到具有不同结构的图上。</p>
<p>另外，该方法无法应用于 <code>graph-level</code> 任务，因为不同图的结构通常不同，因此拉普拉斯矩阵也不同。</p>
</li>
<li><p>非谱方法可以直接在图上定义卷积，从而对空间相邻的邻域顶点进行运算。</p>
<p>但是如何定义一种可以处理不同数量邻居顶点、且能保持 <code>CNN</code> 权重共享的卷积操作是一个挑战。<code>PATCHY-SAN</code> 通过归一化邻域得到固定大小的邻域。</p>
</li>
</ul>
</li>
<li><p><code>attention</code> 机制在很多基于序列的任务中已经称为标配。注意力机制的一个好处是可以处理变长输入，并聚焦于输入中最相关的部分来做决策。当注意力机制作用于单个序列的<code>representation</code> 时，通常称作<code>self-attention</code> 或者 <code>intra-attention</code> 。</p>
<p>受此启发，论文 <code>《GRAPH ATTENTION NETWORKS》</code> 提出了一种基于注意力的架构 <code>Graph attention network:GAT</code> 来对图结构数据进行顶点分类。其基本思想是：通过<code>self-attention</code> 策略来“注意”邻居顶点，从而计算每个顶点的 <code>representation</code> 。</p>
<p><code>GAT</code> 堆叠了一些 <code>masked self-attention layer</code> ，这些层中的顶点能够注意到邻居顶点的特征，并给邻域中不同的顶点赋予不同权重。在这个过程中不需要进行任何复杂的矩阵操作（如矩阵求逆或者矩阵分解），也不需要任何依赖于图结构的先验知识。</p>
<p><code>GAT</code> 模型具有以下优势：</p>
<ul>
<li>计算高效，因为<code>GAT</code> 可以在顶点邻居<code>pair</code> 对之间并行执行。</li>
<li>通过对邻居顶点赋予任意权重，它可以应用到任意<code>degree</code> 的顶点，对网络结构的普适性更强。</li>
<li>该模型可以直接应用于归纳学习<code>inductive learning</code> 问题，包括将模型推广到从未见过的图。</li>
</ul>
</li>
</ul>
</li>
<li><p><code>inductive learning</code> 和 <code>transductive learning</code>的区别：</p>
<ul>
<li><p><code>inductive learning</code> 是从具体样本中总结普适性规律，然后泛化到训练中从未见过的样本。</p>
</li>
<li><p><code>transductive learning</code> 是从具体样本中总结具体性规律，它用于预测训练集中已经出现过的<code>unlabelled</code> 样本，常用于半监督学习。</p>
<blockquote>
<p>半监督学习不一定是 <code>transductive</code>，它也可能是 <code>inductive</code> 。如：训练时仅考虑 <code>labelled</code> 样本，不使用任何 <code>unlabelled</code> 样本的信息。</p>
</blockquote>
</li>
</ul>
</li>
</ol>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        文章作者:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://jackhcc.github.io" rel="external nofollow noreferrer">杰克成</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        文章链接:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://jackhcc.github.io/posts/gnn.html">https://jackhcc.github.io/posts/gnn.html</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        版权声明:
                    </i>
                </span>
                <span class="reprint-info">
                    本博客所有文章除特別声明外，均采用
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    许可协议。转载请注明来源
                    <a href="https://jackhcc.github.io" target="_blank">杰克成</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>复制成功，请遵循本文的转载规则</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">查看</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/tags/GNN/">
                                    <span class="chip bg-color">GNN</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/libs/share/css/share.min.css">

<div id="article-share">
    
    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>微信扫一扫即可分享！</p>"></div>
    <script src="https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
                <style>
    #reward {
        margin: 40px 0;
        text-align: center;
    }

    #reward .reward-link {
        font-size: 1.4rem;
        line-height: 38px;
    }

    #reward .btn-floating:hover {
        box-shadow: 0 6px 12px rgba(0, 0, 0, 0.2), 0 5px 15px rgba(0, 0, 0, 0.2);
    }

    #rewardModal {
        width: 320px;
        height: 350px;
    }

    #rewardModal .reward-title {
        margin: 15px auto;
        padding-bottom: 5px;
    }

    #rewardModal .modal-content {
        padding: 10px;
    }

    #rewardModal .close {
        position: absolute;
        right: 15px;
        top: 15px;
        color: rgba(0, 0, 0, 0.5);
        font-size: 1.3rem;
        line-height: 20px;
        cursor: pointer;
    }

    #rewardModal .close:hover {
        color: #ef5350;
        transform: scale(1.3);
        -moz-transform:scale(1.3);
        -webkit-transform:scale(1.3);
        -o-transform:scale(1.3);
    }

    #rewardModal .reward-tabs {
        margin: 0 auto;
        width: 210px;
    }

    .reward-tabs .tabs {
        height: 38px;
        margin: 10px auto;
        padding-left: 0;
    }

    .reward-content ul {
        padding-left: 0 !important;
    }

    .reward-tabs .tabs .tab {
        height: 38px;
        line-height: 38px;
    }

    .reward-tabs .tab a {
        color: #fff;
        background-color: #ccc;
    }

    .reward-tabs .tab a:hover {
        background-color: #ccc;
        color: #fff;
    }

    .reward-tabs .wechat-tab .active {
        color: #fff !important;
        background-color: #22AB38 !important;
    }

    .reward-tabs .alipay-tab .active {
        color: #fff !important;
        background-color: #019FE8 !important;
    }

    .reward-tabs .reward-img {
        width: 210px;
        height: 210px;
    }
</style>

<div id="reward">
    <a href="#rewardModal" class="reward-link modal-trigger btn-floating btn-medium waves-effect waves-light red">赏</a>

    <!-- Modal Structure -->
    <div id="rewardModal" class="modal">
        <div class="modal-content">
            <a class="close modal-close"><i class="fas fa-times"></i></a>
            <h4 class="reward-title">你的赏识是我前进的动力</h4>
            <div class="reward-content">
                <div class="reward-tabs">
                    <ul class="tabs row">
                        <li class="tab col s6 alipay-tab waves-effect waves-light"><a href="#alipay">支付宝</a></li>
                        <li class="tab col s6 wechat-tab waves-effect waves-light"><a href="#wechat">微 信</a></li>
                    </ul>
                    <div id="alipay">
                        <img src="/images/loading.gif" data-original="https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/medias/reward/aliqr.png" class="reward-img" alt="支付宝打赏二维码">
                    </div>
                    <div id="wechat">
                        <img src="/images/loading.gif" data-original="https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/medias/reward/wxqr.png" class="reward-img" alt="微信打赏二维码">
                    </div>
                </div>
            </div>
        </div>
    </div>
</div>

<script>
    $(function () {
        $('.tabs').tabs();
    });
</script>
            
        </div>
    </div>

    
        <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/libs/gitalk/gitalk.css">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/css/my-gitalk.css">

<div class="card gitalk-card" data-aos="fade-up">
    <div class="comment_headling" style="font-size: 20px; font-weight: 700; position: relative; left: 20px; top: 15px; padding-bottom: 5px;">
        <i class="fas fa-comments fa-fw" aria-hidden="true"></i>
        <span>评论</span>
    </div>
    <div id="gitalk-container" class="card-content"></div>
</div>

<script src="https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/libs/gitalk/gitalk.min.js"></script>
<script>
    let gitalk = new Gitalk({
        clientID: '3821a0bbb773038a51fc',
        clientSecret: '4b30b507d67ec5497ec0e77f43f80cb3e0d7dd3a',
        repo: 'JackHCC.github.io',
        owner: 'JackHCC',
        admin: "JackHCC",
        id: '2021-08-24T21-32-27',
        distractionFreeMode: false  // Facebook-like distraction free mode
    });

    gitalk.render('gitalk-container');
</script>
    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;上一篇</div>
            <div class="card">
                <a href="/posts/Database-Sqlite.html">
                    <div class="card-image">
                        
                        
                        <img src="/images/loading.gif" data-original="https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/medias/featureimages/7.jpg" class="responsive-img" alt="SQLite详解">
                        
                        <span class="card-title">SQLite详解</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            SQLite数据库详解
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2021-08-25
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/categories/Database/" class="post-category">
                                    Database
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/tags/SQLite/">
                        <span class="chip bg-color">SQLite</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                下一篇&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/posts/gan.html">
                    <div class="card-image">
                        
                        
                        <img src="/images/loading.gif" data-original="https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/medias/featureimages/17.jpg" class="responsive-img" alt="GAN详解">
                        
                        <span class="card-title">GAN详解</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            GAN 学习纪录
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2021-08-23
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/categories/Deep-Learning/" class="post-category">
                                    Deep Learning
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/tags/GAN/">
                        <span class="chip bg-color">GAN</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- 代码块功能依赖 -->
<script type="text/javascript" src="https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/libs/codeBlock/codeBlockFuction.js"></script>

<!-- 代码语言 -->

<script type="text/javascript" src="https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/libs/codeBlock/codeLang.js"></script>


<!-- 代码块复制 -->

<script type="text/javascript" src="https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/libs/codeBlock/codeCopy.js"></script>


<!-- 代码块收缩 -->

<script type="text/javascript" src="https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/libs/codeBlock/codeShrink.js"></script>


<!-- 代码块折行 -->

<style type="text/css">
code[class*="language-"], pre[class*="language-"] { white-space: pre !important; }
</style>


    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;目录</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC 悬浮按钮. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('4'),
            headingSelector: 'h1, h2, h3, h4'
        });

        // modify the toc link href to support Chinese.
        let i = 0;
        let tocHeading = 'toc-heading-';
        $('#toc-content a').each(function () {
            $(this).attr('href', '#' + tocHeading + (++i));
        });

        // modify the heading title id to support Chinese.
        i = 0;
        $('#articleContent').children('h1, h2, h3, h4').each(function () {
            $(this).attr('id', tocHeading + (++i));
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* 修复文章卡片 div 的宽度. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // 切换TOC目录展开收缩的相关操作.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>

    

</main>


<script src="https://cdn.bootcss.com/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
<script>
    MathJax.Hub.Config({
        tex2jax: {inlineMath: [['$', '$'], ['\(', '\)']]}
    });
</script>


    <footer class="page-footer bg-color">
    <div class="container row center-align" style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            <span id="year">2020</span>
            <a href="https://jackhcc.github.io" target="_blank">杰克成</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            <br>
            
            &nbsp;<i class="fas fa-chart-area"></i>&nbsp;站点总字数:&nbsp;<span
                class="white-color">3591.2k</span>&nbsp;字
            
            
            
            
            
            
            <span id="busuanzi_container_site_pv">
                |&nbsp;<i class="far fa-eye"></i>&nbsp;总访问量:&nbsp;<span id="busuanzi_value_site_pv"
                    class="white-color"></span>&nbsp;次
            </span>
            
            
            <span id="busuanzi_container_site_uv">
                |&nbsp;<i class="fas fa-users"></i>&nbsp;总访问人数:&nbsp;<span id="busuanzi_value_site_uv"
                    class="white-color"></span>&nbsp;人
            </span>
            
            <br>
            
            <span id="sitetime">载入运行时间...</span>
            <script>
                function siteTime() {
                    var seconds = 1000;
                    var minutes = seconds * 60;
                    var hours = minutes * 60;
                    var days = hours * 24;
                    var years = days * 365;
                    var today = new Date();
                    var startYear = "2020";
                    var startMonth = "2";
                    var startDate = "27";
                    var startHour = "6";
                    var startMinute = "30";
                    var startSecond = "0";
                    var todayYear = today.getFullYear();
                    var todayMonth = today.getMonth() + 1;
                    var todayDate = today.getDate();
                    var todayHour = today.getHours();
                    var todayMinute = today.getMinutes();
                    var todaySecond = today.getSeconds();
                    var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                    var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                    var diff = t2 - t1;
                    var diffYears = Math.floor(diff / years);
                    var diffDays = Math.floor((diff / days) - diffYears * 365);
                    var diffHours = Math.floor((diff - (diffYears * 365 + diffDays) * days) / hours);
                    var diffMinutes = Math.floor((diff - (diffYears * 365 + diffDays) * days - diffHours * hours) /
                        minutes);
                    var diffSeconds = Math.floor((diff - (diffYears * 365 + diffDays) * days - diffHours * hours -
                        diffMinutes * minutes) / seconds);
                    if (startYear == todayYear) {
                        document.getElementById("year").innerHTML = todayYear;
                        document.getElementById("sitetime").innerHTML = "本站已安全运行 " + diffDays + " 天 " + diffHours +
                            " 小时 " + diffMinutes + " 分钟 " + diffSeconds + " 秒";
                    } else {
                        document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                        document.getElementById("sitetime").innerHTML = "本站已安全运行 " + diffYears + " 年 " + diffDays +
                            " 天 " + diffHours + " 小时 " + diffMinutes + " 分钟 " + diffSeconds + " 秒";
                    }
                }
                setInterval(siteTime, 1000);
            </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/JackHCC" class="tooltipped" target="_blank" data-tooltip="访问我的GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:jackcc0701@163.com" class="tooltipped" target="_blank" data-tooltip="邮件联系我" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>



    <a href="https://www.facebook.com/profile.php?id=100046343443643" class="tooltipped" target="_blank" data-tooltip="关注我的Facebook: https://www.facebook.com/profile.php?id=100046343443643" data-position="top" data-delay="50">
        <i class="fab fa-facebook-f"></i>
    </a>



    <a href="https://twitter.com/JackChe66021834" class="tooltipped" target="_blank" data-tooltip="关注我的Twitter: https://twitter.com/JackChe66021834" data-position="top" data-delay="50">
        <i class="fab fa-twitter"></i>
    </a>



    <a href="tencent://AddContact/?fromId=50&fromSubId=1&subcmd=all&uin=2508074836" class="tooltipped" target="_blank" data-tooltip="QQ联系我: 2508074836" data-position="top" data-delay="50">
        <i class="fab fa-qq"></i>
    </a>



    <a href="https://weibo.com/u/6885584679" class="tooltipped" target="_blank" data-tooltip="关注我的微博: https://weibo.com/u/6885584679" data-position="top" data-delay="50">
        <i class="fab fa-weibo"></i>
    </a>



    <a href="https://www.zhihu.com/people/8f8482f01f0d6a04e844efe32e0f0710" class="tooltipped" target="_blank" data-tooltip="关注我的知乎: https://www.zhihu.com/people/8f8482f01f0d6a04e844efe32e0f0710" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">知</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- 搜索遮罩框 -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;搜索</span>
            <input type="search" id="searchInput" name="s" placeholder="请输入搜索的关键字"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script src="https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/js/search.js"></script>
<script type="text/javascript">
$(function () {
    searchFunc("https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/" + "search.xml", 'searchInput', 'searchResult');
});
</script>
    <!-- 回到顶部按钮 -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/libs/materialize/materialize.min.js"></script>
    <script src="https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/libs/aos/aos.js"></script>
    <script src="https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/js/matery.js"></script>

    <canvas class="fireworks" style="position: fixed;left: 0;top: 0;z-index: 1; pointer-events: none;" ></canvas>
    <script type="text/javascript" src="//cdn.bootcss.com/animejs/2.2.0/anime.min.js"></script>
    <script type="text/javascript" src="/js/fireworks.js"></script>

    <script type="text/javascript">
        //只在桌面版网页启用特效
        var windowWidth = $(window).width();
        if (windowWidth > 768) {
            document.write('<script type="text/javascript" src="/js/sakura.js"><\/script>'); }
    </script>

    <!-- weather -->
	<script type="text/javascript">
	WIDGET = {FID: 'TToslpmkVO'}
	</script>
	<script type="text/javascript" src="https://apip.weatherdt.com/float/static/js/r.js?v=1111"></script>


    <!-- Global site tag (gtag.js) - Google Analytics -->


    <!-- Baidu Analytics -->

<script>
    var _hmt = _hmt || [];
    (function () {
        var hm = document.createElement("script");
        hm.src = "https://hm.baidu.com/hm.js?";
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(hm, s);
    })();
</script>

    <!-- Baidu Push -->

    
    
    <script async src="https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/libs/others/busuanzi.pure.mini.js"></script>
    

    
        <script src="//code.tidio.co/kqhlkxviiccyoa0czpfpu4ijuey9hfre.js"></script>
        <script> 
            $(document).ready(function () {
                setInterval(change_Tidio, 50);  
                function change_Tidio() { 
                    var tidio=$("#tidio-chat iframe");
                    if(tidio.css("display")=="block"&& $(window).width()>977 ){
                        document.getElementById("tidio-chat-iframe").style.bottom= ($("div#backTop.top-scroll").css("display")=="none" &&$(window).width()>977)>0? "-40px" : ($("div.toc-title").length&&$(window).width()>977)>0?"85px":"20px";   
                        document.getElementById("tidio-chat-iframe").style.right="-15px";   
                        document.getElementById("tidio-chat-iframe").style.height=parseInt(tidio.css("height"))>=520?"520px":tidio.css("height");
                        document.getElementById("tidio-chat-iframe").style.zIndex="997";
                    } 
                    else if(tidio.css("display")=="block"&&$(window).width()>601 &&$(window).width()<992 ){
                        document.getElementById("tidio-chat-iframe").style.bottom= ($("div#backTop.top-scroll").css("display")=="none" && 601< $(window).width()<992)>0? "-40px":"20px" ;   
                        document.getElementById("tidio-chat-iframe").style.right="-15px"; 
                        document.getElementById("tidio-chat-iframe").style.zIndex="997";
                    }
                    else if(tidio.css("display")=="block"&&$(window).width()<601 && parseInt(tidio.css("height"))<230){
                        document.getElementById("tidio-chat-iframe").style.bottom= ($("div#backTop.top-scroll").css("display")=="none" && $(window).width()<601)>0? "-10px":"45px" ;   
                        document.getElementById("tidio-chat-iframe").style.zIndex="997";
                    }
                    if( tidio.css("display")=="block"&&$(window).width()<601 && parseInt(tidio.css("height"))>=230){
                        document.getElementById("tidio-chat-iframe").style.zIndex="998";
                    }
                } 
            }); 
        </script>
    

    

    
    <script type="text/javascript" color="0,0,255"
        pointColor="0,0,255" opacity='0.7'
        zIndex="-1" count="99"
        src="https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/libs/background/canvas-nest.js"></script>
    

    

    
    <script type="text/javascript" src="https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/libs/background/ribbon-dynamic.js" async="async"></script>
    
    
    
    <script src="https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/libs/instantpage/instantpage.js" type="module"></script>
    

        <script src="//cdn.jsdelivr.net/npm/js-base64/base64.min.js"></script>
        <script>
        $('a').each(function() {
          const $this = $(this);
          const href = $this.attr('href');
          if (href && href.match('^((http|https|thunder|qqdl|ed2k|Flashget|qbrowser|ftp|rtsp|mms)://)')) {
            const strs = href.split('/');
            if (strs.length >= 3) {
                const host = strs[2];
                if (host !== 'your_domain' || window.location.host) {
                    $this.attr('href', '/go.html?u='+Base64.encode(href)+'').attr('rel', 'external nofollow noopener noreferrer');
                    if (true) {
                        $this.attr('target', '_blank');
                    }
                }
            }
          }
        });
        </script><script>!function(e){var c=Array.prototype.slice.call(document.querySelectorAll("img[data-original]"));function i(){for(var r=0;r<c.length;r++)t=c[r],0<=(n=t.getBoundingClientRect()).bottom&&0<=n.left&&n.top<=(e.innerHeight||document.documentElement.clientHeight)&&function(){var t,n,e,i,o=c[r];t=o,n=function(){c=c.filter(function(t){return o!==t})},e=new Image,i=t.getAttribute("data-original"),e.onload=function(){t.src=i,n&&n()},e.src=i}();var t,n}i(),e.addEventListener("scroll",function(){var t,n;t=i,n=e,clearTimeout(t.tId),t.tId=setTimeout(function(){t.call(n)},500)})}(this);</script><script>window.addEventListener("load",function(){var t=/\.(gif|jpg|jpeg|tiff|png)$/i,r=/^data:image\/[a-z]+;base64,/;Array.prototype.slice.call(document.querySelectorAll("img[data-original]")).forEach(function(a){var e=a.parentNode;"A"===e.tagName&&(e.href.match(t)||e.href.match(r))&&(e.href=a.dataset.original)})});</script></body>

</html>

