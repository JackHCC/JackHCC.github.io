<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="Adversarial-Attack与Explainable-AI, JackHCC">
    <meta name="description" content="Adversarial-Attack与Explainable-AI学习记录">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <title>Adversarial-Attack与Explainable-AI | JackHCC</title>
    <link rel="icon" type="image/png" href="https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/medias/favicon.png">

    <link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/libs/awesome/css/all.css">
    <link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/libs/materialize/materialize.min.css">
    <link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/libs/aos/aos.css">
    <link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/libs/animate/animate.min.css">
    <link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/libs/lightGallery/css/lightgallery.min.css">
    <link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/css/matery.css">
    <link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/css/my.css">
    
    <script src="https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/libs/jquery/jquery.min.js"></script>
    
<meta name="generator" content="Hexo 4.2.0"><link rel="alternate" href="/atom.xml" title="JackHCC" type="application/atom+xml">
<link rel="stylesheet" href="/css/prism-hopscotch.css" type="text/css">
<link rel="stylesheet" href="/css/prism-line-numbers.css" type="text/css"></head>


<body>
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper head-container">
            <div class="brand-logo">
                <a href="/" class="waves-effect waves-light">
                    
                    <img src="/images/loading.gif" data-original="https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/medias/me.jpg" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">JackHCC</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>首页</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>标签</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>分类</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>归档</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="" class="waves-effect waves-light">

      
      <i class="fas fa-list" style="zoom: 0.6;"></i>
      
      <span>Tools</span>
      <i class="fas fa-chevron-down" aria-hidden="true" style="zoom: 0.6;"></i>
    </a>
    <ul class="sub-nav menus_item_child ">
      
      <li>
        <a href="https://creativecc.cn/" target="_blank" rel="noopener">
          
          <i class="fas fa-book" style="margin-top: -20px; zoom: 0.6;"></i>
          
          <span>Creative工具导航</span>
        </a>
      </li>
      
      <li>
        <a href="https://blog.creativecc.cn/Arxiv-NLP-Reporter/" target="_blank" rel="noopener">
          
          <i class="fas fa-film" style="margin-top: -20px; zoom: 0.6;"></i>
          
          <span>NLP每日论文</span>
        </a>
      </li>
      
      <li>
        <a href="http://chat.creativecc.cn/" target="_blank" rel="noopener">
          
          <i class="fas fa-music" style="margin-top: -20px; zoom: 0.6;"></i>
          
          <span>RocketChat聊天室</span>
        </a>
      </li>
      
      <li>
        <a href="/contact">
          
          <i class="fas fa-comments" style="margin-top: -20px; zoom: 0.6;"></i>
          
          <span>Contact留言板</span>
        </a>
      </li>
      
    </ul>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/friends" class="waves-effect waves-light">
      
      <i class="fas fa-address-book" style="zoom: 0.6;"></i>
      
      <span>友情链接</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/about" class="waves-effect waves-light">
      
      <i class="fas fa-user-circle" style="zoom: 0.6;"></i>
      
      <span>关于</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="搜索" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>

<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/images/loading.gif" data-original="https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/medias/me.jpg" class="logo-img circle responsive-img">
        
        <div class="logo-name">JackHCC</div>
        <div class="logo-desc">
            
            Make the world betterrrr!!!
            
        </div>
    </div>

    

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			首页
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			标签
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			分类
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			归档
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="javascript:;">
			
				<i class="fa-fw fas fa-list"></i>
			
			Tools
			<span class="m-icon"><i class="fas fa-chevron-right"></i></span>
		</a>
            <ul  style="background:  ;" >
              
                <li>   
				
                  <a href="https://creativecc.cn/ " target="_blank" rel="noopener" style="margin-left:75px";>
				  
				   <i class="fa fas fa-book" style="position: absolute;left:50px" ></i>
			      
		          <span>Creative工具导航</span>
                  </a>
                </li>
              
                <li>   
				
                  <a href="https://blog.creativecc.cn/Arxiv-NLP-Reporter/ " target="_blank" rel="noopener" style="margin-left:75px";>
				  
				   <i class="fa fas fa-film" style="position: absolute;left:50px" ></i>
			      
		          <span>NLP每日论文</span>
                  </a>
                </li>
              
                <li>   
				
                  <a href="http://chat.creativecc.cn/ " target="_blank" rel="noopener" style="margin-left:75px";>
				  
				   <i class="fa fas fa-music" style="position: absolute;left:50px" ></i>
			      
		          <span>RocketChat聊天室</span>
                  </a>
                </li>
              
                <li>   
				
                  <a href="/contact " style="margin-left:75px";>
				  
				   <i class="fa fas fa-comments" style="position: absolute;left:50px" ></i>
			      
		          <span>Contact留言板</span>
                  </a>
                </li>
               
            </ul>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/friends" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-address-book"></i>
			
			友情链接
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/about" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-user-circle"></i>
			
			关于
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/JackHCC/JackHCC.github.io" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>

        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/JackHCC/JackHCC.github.io" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    
<script src="https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/libs/cryptojs/crypto-js.min.js"></script>
<script>
    (function() {
        let pwd = '';
        if (pwd && pwd.length > 0) {
            if (pwd !== CryptoJS.SHA256(prompt('请输入访问本文章的密码')).toString(CryptoJS.enc.Hex)) {
                alert('密码错误，将返回主页！');
                location.href = '/';
            }
        }
    })();
</script>




<div class="bg-cover pd-header post-cover" style="background-image: url('https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/medias/featureimages/5.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">Adversarial-Attack与Explainable-AI</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/libs/tocbot/tocbot.css">
<style>
    #articleContent h1::before,
    #articleContent h2::before,
    #articleContent h3::before,
    #articleContent h4::before,
    #articleContent h5::before,
    #articleContent h6::before {
        display: block;
        content: " ";
        height: 100px;
        margin-top: -100px;
        visibility: hidden;
    }

    #articleContent :focus {
        outline: none;
    }

    .toc-fixed {
        position: fixed;
        top: 64px;
    }

    .toc-widget {
        width: 345px;
        padding-left: 20px;
    }

    .toc-widget .toc-title {
        margin: 35px 0 15px 0;
        padding-left: 17px;
        font-size: 1.5rem;
        font-weight: bold;
        line-height: 1.5rem;
    }

    .toc-widget ol {
        padding: 0;
        list-style: none;
    }

    #toc-content {
        height: calc(100vh - 250px);
        overflow: auto;
    }

    #toc-content ol {
        padding-left: 10px;
    }

    #toc-content ol li {
        padding-left: 10px;
    }

    #toc-content .toc-link:hover {
        color: #42b983;
        font-weight: 700;
        text-decoration: underline;
    }

    #toc-content .toc-link::before {
        background-color: transparent;
        max-height: 25px;
    }

    #toc-content .is-active-link {
        color: #42b983;
    }

    #toc-content .is-active-link::before {
        background-color: #42b983;
    }

    #floating-toc-btn {
        position: fixed;
        right: 30px;
        bottom: 146px;
        padding-top: 15px;
        margin-bottom: 0;
        z-index: 998;
    }

    #floating-toc-btn .btn-floating {
        width: 48px;
        height: 48px;
    }

    #floating-toc-btn .btn-floating i {
        line-height: 48px;
        font-size: 1.4rem;
    }
</style>
<div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- 文章内容详情 -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/tags/Adversarial-Attack/">
                                <span class="chip bg-color">Adversarial Attack</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/categories/Deep-Learning/" class="post-category">
                                Deep Learning
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>发布日期:&nbsp;&nbsp;
                    2021-08-27
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>更新日期:&nbsp;&nbsp;
                    2021-09-04
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>文章字数:&nbsp;&nbsp;
                    35.7k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>阅读时长:&nbsp;&nbsp;
                    125 分
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>阅读次数:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>

        </div>
        <hr class="clearfix">
        <div class="card-content article-card-content">
            <div id="articleContent">
                <h1 id="Adversarial-Attack"><a href="#Adversarial-Attack" class="headerlink" title="Adversarial Attack"></a>Adversarial Attack</h1><p>Adversarial Attack 要讲这个主题,我们这边要讲的是,我们在作业裡面,我们已经训练了非常多,各式各样的类神经网路,那我们当然期待说,我们可以把这些技术用在真正的应用上</p>
<img src="/images/loading.gif" data-original="../images/ML/image-20210810180148893.png">

<p>但是光是把这些 Network 用在真正的应用上,要把这些 Network 用在真正应用上,光是它们正确率高是不够的,它们还需要什麼能力呢</p>
<p>他们需要能够<strong>应付来自人类的恶意</strong>,有时候你的 Network,它的工作是為了要侦测一些有恶意的行為,如果今天它的工作是要侦测有恶意的行為,这些它要侦测的对象,会去想办法骗过 Network,Network 在一般的情况下,都可以得到高的正确率是不够的,它要<strong>在有人试图想要欺骗它的情况下,也得到高的正确率</strong></p>
<p>举例来说 我们今天都会用 Network,来做 E-Mail 的 Filtering,你会用 Network 来做侦测一封邮件,它是不是垃圾邮件,那今天对於一个垃圾邮件的发信者而言,他也会想尽办法避免,他的邮件被分类為垃圾邮件,如果今天有人他想办法去更改邮件的内容,想要去欺骗过 Network 的话,那 Network 到底能不能不要被欺骗呢</p>
<p>所以今天我们希望我们的类神经网路,它光是正确率高还不够,我们希望它可以应付来自人类的恶意</p>
<p>举例来说 这个是蚁王</p>
<img src="/images/loading.gif" data-original="../images/ML/image-20210810180325834.png">

<p>牠叫做梅路艾姆,牠是站在生物顶点,牠是生物顶点的一个存在,牠非常地强,人类没有办法打赢牠,那牠会消灭掉所有的人类,但是人类并没有跟牠打,<strong>人类是不讲武德的</strong>,人类就直接放一个核弹就把牠炸死,然后故事就结束了 就这样</p>
<h2 id="Example-of-Attack"><a href="#Example-of-Attack" class="headerlink" title="Example of Attack"></a>Example of Attack</h2><p>我们先来看一个真正的例子,我们今天在好多个作业裡面,我们都已经训练了影像辨识的模型,也就是说你有一个影像辨识的系统,给它一张照片,它可以告诉我们说,这张照片属於什麼样的类别</p>
<img src="/images/loading.gif" data-original="../images/ML/image-20210810181138333.png">

<p>那今天我们要做的事情是,在这张<strong>照片上面加入一个非常小的杂讯</strong>,一张照片可以被看作是一个非常长的向量,我们在这个非常长的向量上加入,每一个维度都加入一个小小的杂讯,把这个有加入杂讯以后的照片丢到 Network,看看会发生什麼样的事情</p>
<p>那一般这个<strong>杂讯都非常非常地小</strong>,小到什麼地步呢,最好小到人肉眼没有办法看出来,所以这个例子裡面加的杂讯其实太大了,一般这个杂讯是小到人肉眼看不出来的</p>
<p>有被加杂讯的照片叫做 <strong>Attacked Image</strong>,有被攻击的照片,那还没有被加杂讯的照片呢,我们一般就叫做 <strong>Benign Image</strong>,它是好的 Image,它是还没有被攻击的图片</p>
<p>Benign Image 丢到 Network 裡面,它的输出是猫,那我们期待说 Attacked Image,就我们现在是攻击方 我们是坏人,我们希望 Attacked Image 丢到 Network 裡面,它的输出不可以是猫,要变成其他的东西</p>
<p>那攻击呢 大致上可以分成<strong>两种类型</strong>,一种是<strong>没有目标的攻击</strong>,没有目标的攻击是,原来的答案是猫,只要你能够让 Network 的输出不是猫,你就算是成功了</p>
<p>但是还有另外一种更困难的攻击,是<strong>有目标的攻击</strong>,也就是说我们希望 Network,不止它输出不能是猫,还要输出别的东西,比如说 我们希望加了一个杂讯以后,Network 输出呢 是海星,它把猫错误判断成一隻海星,才算是攻击成功,好 那这样子的攻击真的有可能做到吗,我们真的可以加入一个人肉眼看不到的杂讯,去改变 Network 的输出吗</p>
<p>实际上是可以的,这边用的 Network 并不是一个很弱的 Network,它是 50 层的 ResNet</p>
<img src="/images/loading.gif" data-original="../images/ML/image-20210810181503642.png">

<p>当我们把一个 Benign Image 没有被攻击的图片,丢到 50 层的 ResNet 的时候,它的输出是 Tiger Cat</p>
<p>你知道今天这种影像辨识的系统,它的输出都不只会告诉你它是什麼动物,还会告诉你它是哪一个品种的动物,所以它给它这隻猫,它不只说它是 Cat,还说它是 Tiger Cat,不过据说这个答案其实是错的,据说这个猫不是 Tiger Cat,不过没有关係,反正它都认得出这个是一隻猫就对了,至少知道是一个猫科的动物</p>
<p>那它还有一个信心的分数,<strong>信心的分数(置信度)是 0.64</strong>,这个信心的分数是什麼呢,这个信心的分数就是,做完那个 Soft Mask 以后,得到的那个分数,就假设你的影像分类的类别有 2000 类,2000 个类别都会有一个分数,那这个分数呢 一定介於 0 到 1 之间,而且 2000 个类别的分数合起来,会刚刚好是 1</p>
<p>那既然有 2000 个类别那麼多,Tiger Cat 可以拿到 0.64 的分数,那其实算是挺高的</p>
<p>接下来呢 我们在这个 Benign Image 上面,加入一些杂讯,我们现在希望成功攻击的目标,是把 Tiger Cat 变成海星,而被攻击以后的图片长的是这个样子的,你可能问说 杂讯加在哪裡呢,杂讯已经加进去了,但它非常非常地小,<strong>小到人的肉眼根本没有办法看出来</strong></p>
<p>把这张图片丢到 ResNet 以后,会发生什麼事呢,<strong>ResNet 的 Output 变成 Star Fish,而且它的信心分数是 100 %</strong> 啊,本来它还没有那麼确定这是不是一隻猫,现在它百分之百确定,它就是海星</p>
<p>那為了要证明说,这两张照片还是有一些不一样的,我们把它做一下<strong>相减</strong></p>
<img src="/images/loading.gif" data-original="../images/ML/image-20210810181737766.png">

<p>光做相减是不够的,做完相减以后,还要把它们的差距放大 50 倍,你会得到这样子的结论,所以这两张照片确实有些不一样,我并不是把同一张照片复製两次来骗你,它们是有一点不一样的,但是人根本看不出,这点不一样会造成什麼样的影响,但是对 ResNet 而言,它却有了天差地远的输出</p>
<p>那也许有人会觉得说,啊 也许是因為猫跟海星有什麼特别的关係</p>
<img src="/images/loading.gif" data-original="../images/ML/image-20210810181846165.png">

<p>我们可以把猫变成海星只是一个特例,这不是一个特例,你可以<strong>把这隻猫轻易地变成任何的东西</strong>,我完全可以加上另外一个杂讯,就让这隻猫变成一个键盘,它一样信心分数高达 0.98,本来不太确定它是不是猫,现在加入另外一个杂讯以后,Network 98% 确定它就是一个键盘</p>
<p>那有人可能会觉得说,欸 怎麼会发生这麼离谱的行為,会不会是<strong>这个 Network 太烂了？</strong>,我要告诉你 它可是有 50 层的喔,它可不是一个非常烂的 Network</p>
<p>如果你加入的只是<strong>一般的杂讯,它并不一定会犯错</strong>,这个是原来的图片,我们现在加入一个杂讯,这个杂讯是你肉眼可见的</p>
<img src="/images/loading.gif" data-original="../images/ML/image-20210810182027298.png">

<ul>
<li><p>你可以很明显地看到,这张图片裡面被加入了杂讯,这个时候 ResNet 觉得,它看到的是 Tabby Cat,这可能才是正确答案,但无论如何 它都知道是猫科动物</p>
</li>
<li><p>把杂讯加得更大一点,它说这是 Persian Cat 这是波斯猫,可能杂讯加得大一点,这个猫看起来毛茸茸的,所以 ResNet 觉得它看到了波斯猫</p>
</li>
<li><p>把杂讯再加更大一点,你可能已经不知道这是什麼东西了,这个时候 ResNet 说,它看到了 Fire Screen,Fire Screen 是什麼呢,我 Google 了一下发现,Fire Screen 长这个样子,这裡完全可以理解机器為什麼会犯错,它觉得前面的杂讯是这个屏风,而后面这个橙色的猫就是火焰</p>
</li>
</ul>
<p>它虽然犯错 它错的是有尊严的,它错的是有道理的,但不知道為什麼,加入一个人肉眼看不到的杂讯的时候,它却產生了天差地远的结果</p>
<h2 id="How-to-Attack"><a href="#How-to-Attack" class="headerlink" title="How to Attack"></a>How to Attack</h2><p>那接下来我们在讲為什麼这件事会发生之前,我们来看看刚才所说的攻击,究竟是如何做到的,我们到底是<strong>怎麼加入了一个非常微小的杂讯,可以让 Network 產生非常错误的结果</strong>呢</p>
<img src="/images/loading.gif" data-original="../images/ML/image-20210810224455361.png">

<p>而这个是我们的 Network,它是一个 Function 我们叫它 f,这个 Function 输入是一张图片,我们叫它 $x^0$,它的输出是一个 Distribution,这个是这个分类的结果,那我们叫它 $y^0$</p>
<p>那我们这边假设 <strong>Network 的参数就是固定的</strong>,我们不讨论 Network 的参数的部分,Network 的参数不是我们今天的重点,所以它是固定的</p>
<ul>
<li><p>如果是 Non-Targeted Attack 的话,我们要怎麼找出 Non-Targeted Attack 的杂讯呢</p>
<p>我们现在要做的目标就是,我们要<strong>找到一张新的图片</strong></p>
<img src="/images/loading.gif" data-original="../images/ML/image-20210810225816985.png">

<p>这张新的图片呢 我们用 x 来表示,当我们把 x 丢到这个 Network f 的时候,它的输出是 y,我们正确的答案叫做 ŷ,我们<strong>希望 y 跟 ŷ 它的差距越大越好</strong></p>
<p>那怎麼做到这件事呢,怎麼找到这个 x,丢到一个 Network 裡以后,它產生的 y 跟 ŷ 差距越大越好呢？</p>
<p>我们一样要<strong>解一个 Optimization 的问题</strong>,这个跟我们训练的 Network,其实是非常类似的</p>
<p>我们先定一个 Loss Function,这个 Loss Function 呢,叫做 L,这个 L 呢 是 y 跟 ŷ 之间的差距,<strong>取一个负号</strong>,举例来说,我们一般在做这个 Classification 的时候,我们训练的目标 y 跟 ŷ,都是看它的 Cross Entropy,那我们这个 -e(y, ŷ),这一项代表的就是 y 跟 ŷ 之间的 Cross Entropy</p>
<p>但是我们希望这个 <strong>Cross Entropy 越大越好</strong>,所以我们今天在 Cross Entropy 前面加一个负号,那这个负的 Cross Entropy 就是我们的 Loss,而我们期望这个 Loss 越小越好,我们希望找到一个 x,x 可以让 L(x) 越小越好,L(x) 越小 就代表说 y 跟 ŷ,它们的 Cross Entropy 越大,也就是 y 跟 ŷ 它们的距离越大,这个是没有目标的攻击</p>
</li>
<li><p>如果是有目标的攻击的话</p>
<img src="/images/loading.gif" data-original="../images/ML/image-20210810230324810.png">

<p>那我们会先设定好我们的目标,我们用 $y^{target}$ 来代表我们的目标,那 ŷ 其实是一个 One-Hot Vector,$y^{target}$ 也是一个 One-Hot Vector,那我们现在希望这个 <strong>y 不止跟 ŷ 越远越好,我们还要跟 $y^{target}$ 越近越好</strong></p>
<p>所以假设你的 $y^{target}$​ 是一个 Fish,那你希望你输出的这个 y 啊,它不止 Cat 的机率越低越好,Fish 的机率还要越高越好,那你的 Loss Function 就写成这样<br>$$<br>𝐿(𝒙)=−𝑒(𝒚,𝒚 ̂ )+𝑒(𝒚,𝒚^{𝒕𝒂𝒓𝒈𝒆𝒕} )<br>$$<br>我们的 Loss Function</p>
<ul>
<li>是负的 y 跟 ŷ 之间的 Cross Entropy,希望这一项越大越好</li>
<li>同时你又希望 y 跟 $y^{target}$,它们越小越好</li>
<li>你把这两项加起来就是你的 Loss,你希望找一个 x,去 Minimize 这个 Loss</li>
</ul>
<p>但光是找一个 x,去 Minimize Loss 是不够的,因為我们其实还期待说,我们加入的杂讯越小越好,也就是我们新找到的图片,可以欺骗过 Network 的图片,跟原来的图片要越相近越好,<strong>x 跟 $x^0$ 要越近越好</strong></p>
<p>所以我们在解这个,Optimization 的 Problem 的时候,我们还会<strong>多加入一个限制</strong>,这个限制是<br>$$<br>d(x^0,x)≤ε<br>$$<br>它的意思就是,我们希望 x 跟 $x^0$ 之间的差距,小於某一个 Threshold,小於某一个閾值,那这个閾值是根据什麼东西来决定的呢,通常就是<strong>根据人类的感知能力来决定</strong></p>
<p><strong>如果 $x^0$ 跟 x 之间的差距大於 Σ,我们假设人就会看到这个杂讯</strong>,人就会发现有一个杂讯存在,所以我们要让 $x^0$ 跟 x 它的差距,小於等於 Σ,小於等於人类可以感知的极限,那我们就可以產生一张图片,人类看起来 x 跟 $x^0$ 是一模一样的,但產生的结果对 Network 来说,是非常不一样的</p>
</li>
</ul>
<p>好 那怎麼计算 x 跟 $x^0$​ 之间的差距,它们之间的距离呢?d($x^0$​,x) 就代表它们之间的距离</p>
<p>有各式各样不同的算法,那為了等一下符号的方便起见呢,我们假设 <strong>x 是一个向量</strong>,因為它是个图片 所以它是个向量嘛,<strong>$x^0$​​ 是另外一张图片,它也是一个向量</strong>,这两个向量<strong>相减 我们叫它 Δx</strong></p>
<img src="/images/loading.gif" data-original="../images/ML/image-20210810231653104.png">

<p>那这个距离啊</p>
<ul>
<li>你可以定 L2-Norm 当做它们的距离,也就是说你可以计算 Δx 的 L2-Norm,Δx 的 L2-Norm 就是把这个 Δx 的第一位,拿出来取平方,第二位拿出来取平方,第三位拿出来取平方,在这边你其实要开根号也可以啦,就看你的 L2-Norm 的定义是怎样,你要开根号也是可以的</li>
<li>另外还有一个定义呢 是 L-Infinity,L-Infinity 是怎麼看的呢,它就是把这个 Δx 拿来,然后看裡面哪一个维度它的绝对值最大,那这一个就是L-Infinity,就把 Δx1 Δx2 Δx3,也就是 Δx 的每一维都拿出来取绝对值,看谁最大,最大的那一个就代表 x 跟 $x^0$​​ 之间的距离</li>
</ul>
<p>那有各种不同的方法,可以计算两张图片之间的距离,但是我们在决定要使用哪一种方法,来计算图片的距离的时候,其实我们应该<strong>把人类的感知把它考虑进来</strong></p>
<p>那 L2 跟 L-Infinity 到底哪一个,在 Attack 的时候是比较好的距离呢,以下我举一个例子来跟大家说明</p>
<p>这是一张图片,假设这个图片只有四个 Pixel 而已,现在啊,我们把这张图片做两种不同的变化</p>
<p>第一个变化是这四个 Pixel 的顏色,都做了非常小的改变</p>
<img src="/images/loading.gif" data-original="../images/ML/image-20210810232148760.png" style="zoom:67%;">

<p>第二种变化是只有右下角这个 Pixel,它的顏色被改了,而且改的是比较大的</p>
<img src="/images/loading.gif" data-original="../images/ML/image-20210810232209129.png" style="zoom:67%;">

<p>如果我们今天在计算 L2 的 Norm 的时候,<strong>上面这两张图片的 L2-Norm,和下面这两张图片的 L2-Norm 是一样的</strong></p>
<img src="/images/loading.gif" data-original="../images/ML/image-20210810232311223.png" style="zoom:50%;">

<p>这两个变化他们的 L2 的 Norm 是一样的</p>
<p>而但是如果你看 <strong>L-Infinity 的话,它们是不一样的</strong>,因為 L-Infinity 只在意最大的变化量,那<strong>对於 L-Infinity 而言,下面这个改变它最大的变化量是比较大的,上面这个改变最大的变化量是比较小</strong></p>
<p>那如果从这个例子来看 L-Infinity 跟 L2,哪一个比较<strong>接近人类的感知能力呢,也许应该是 L-Infinity</strong> 吧</p>
<p>因為对你来说,其实这两张图片,我相信多数人你可能都看不出,它们之间有什麼差别,那我跟你保证它们两个之间是有差别的,就它们是有非常非常微小的差别,只是它的差别是分布在每一个 Pixel 上面</p>
<p>而这下面这两个改变呢,你会很明显的看到右下角这个绿色,它的顏色变深了,虽然这另外这三个 Pixel 的顏色是固定的,右下角的顏色一变深,你就发现有图片有变化,就发现这个图片有做到,有做了某种修改,所以看起来 L-Infinity 也许更符合实际的需求,我们要避免被人类,我们要避免被人类发现</p>
<p><strong>光是 L2 小是不够的,我们要让 L-Infinity 小才是最好的,才是比较不会被发现</strong>,所以在作业裡面我们是用 L-Infinity,来当做我们的限制,来当做攻击,那我们作业就是要去攻击一个,JudgeBoi 上面的那个,像辨识系统產生出来的图片,我们会有所限制说,新的图片跟旧的图片,跟原来 Benign 图片的差距,要小於某一个 Threshold,那我们在定这个差距的时候,我们就是选择 L-Infinity,那实际上这个差距要怎麼定才是比较好,这个也要凭 Domain Knowledge</p>
<p>我们刚才举的例子是影像上的例子,如果我们今天要攻击的对象,其实是一个跟语音相关的系统,我们的 x 跟 $x^0$​​ 其实都是声音讯号,那什麼样的声音讯号,对人类来说听起来有差距,那就不见得是 L2 跟 L-Infinity 了,你就要去研究人类的听觉系统,看看人类对什麼频态的变化特别敏感,那根据人类的听觉系统来制定,比较适合的 x 跟 $x^0$​​ 之间距离的衡量方式,那这个部分就是需要用到 <strong>Domain Knowledge</strong></p>
<h2 id="Attack-Approach"><a href="#Attack-Approach" class="headerlink" title="Attack Approach"></a>Attack Approach</h2><p>好 那我们现在已经有了,我们的 Optimization 的问题,我们要做的事情就是,我们要去 Minimize 是一个 Loss,那现在我们要找一个 x 去 Minimize 这个 Loss,但是这个 x 我们是有限制的</p>
<img src="/images/loading.gif" data-original="../images/ML/image-20210810232828937.png" style="zoom:67%;">

<p>x 跟 $x^0$​​ 它们的 Distance 要小於等於 x,那这个问题到底要怎麼解呢,我们<strong>先把这个限制拿掉</strong></p>
<p>如果把这个限制拿掉,你会不会解这个问题呢,你其实会解这个问题,因為这跟我们 <strong>Train 一个模型其实没有什麼差别</strong>啊,我们在第一堂课的时候,就列过这个 Optimization 的问题给你看,告诉你说你可以调你的 Network 的参数,去让一个 Loss 最小</p>
<p>我们今天只是<strong>把参数改成Network 的 Input 而已</strong></p>
<img src="/images/loading.gif" data-original="../images/ML/image-20210810233009320.png" style="zoom:50%;">

<p>你就<strong>把 Input 那一张 Image,看作是 Network 参数的一部分</strong>,然后 <strong>Minimize 你的 Loss Function</strong> 就结束了</p>
<p>现在 <strong>Network 的参数是固定的</strong>,我们只去<strong>调 Input</strong> 部分,让 Input 的部分去改变,去 Minimum 一个 Loss 就结束了,用的一样是 Gradient Descent,怎麼做呢</p>
<p>你就这样做啦,就是你要先有个 Initialization 嘛,我们现在找的对象不是 Network 参数,是 x,是你 Input 的 Image,但是它还是需要一个初始化的值 对不对</p>
<p>你还是需要一个,做 <strong>Gradient Descent 的时候初始化的值</strong>,那初始化的值设什麼样的数值比较好呢</p>
<ul>
<li>你可能不会从随机的 Image 开始,你可能会<strong>从 $x^0$​​ 开始</strong>,因為我们本来就希望说,我们新找到的 x 应该跟 $x^0$​​ 越接近越好嘛,那你何不就从 $x^0$​​ 开始找呢,你从 $x^0$​​ 开始找</li>
<li>你接下来找出来的 x 可能就会跟 $x^0$​​ 比较接近,所以你初始化的 x,你会初始化的这个 $x^0$​​ 就直接设 $x^0$​​,然后接下来就跟,一般的 Gradient Descent 是一模一样的,我们就是 <strong>Iterative 去 Update 你的参数</strong>,你就设一个 Iteration,t 等於 1 到 T,然后在每一个 Iteration 裡面,你都会计算 Gradient,只是这个 Gradient 不是 Network 参数,对 Loss 的 Gradient,我们现在已经不管 Network 参数了,而是 Input 那一张 Image x,对於 Loss 的 Gradient,那 Input 这个 x,它也是一个很长的向量嘛,它裡面就是有 x1 x2 x3 嘛,你就去计算这个 Input Image 裡面,每一个数值对 L 的偏微分,就 x1 对 L 的偏微分,x2 对 L 的偏微分,算出来,算出一个 Gradient,用这个 Gradient,去 Update 你的 Image 就结束了</li>
<li>所以你本来的 Image $x^0$​​​​,它就减掉这个 Gradient,那前面你也会<strong>乘上一个 Learning Rate</strong>,就跟一般 Gradient Descent 是一模一样的,只是要做 Gradient Descent 的对象,从参数换成 Input 而已,其他都是一样的,也有 Learning Rate 那些什麼东西统统都有,乘上一个 Gradient,乘上 Learning Rate,减掉原来的 Image,然后就得到新的 Image,你可以 Iteration 地跑,就跟一般的 Gradient Descent 是一模一样</li>
</ul>
<p>但是这个是在没有 Constraint 的前提,接下来我们得把 Constraint 加进去</p>
<p>因為一般我们在做 Gradient Descent 的时候,我们并没有把那个,Gradient Descent 的对象做什麼限制,我们并没有设限说,我们的参数一定要长什麼样子</p>
<p>那现在我们是有限制的,我们限制说 x 跟 $x^0$​​,他们的差距一定要小於等於 $x^0$​​,那要怎麼处理这个问题呢</p>
<p>你就在你的 Gradient Descent 裡面,再加一个 Module</p>
<img src="/images/loading.gif" data-original="../images/ML/image-20210810234123458.png" style="zoom:50%;">

<p>这个我们要跑 Gradient Descent 这个演算法,但是我们要同时考虑 $x^0$​​ 跟 x 之间的差距,怎麼考虑这件事情呢,这边呢,这个方法说穿了不值钱,非常地简单</p>
<p>你 Update 完你的参数以后发现,你的 <strong>$x^t$ 跟 $x^0$​​ 的差距大於 ε</strong> 以后,你就做一个修改,<strong>把 $x^t$​ 做个修改,把它改回符合限制就结束</strong>了</p>
<p>举例来说,假设我们现在用的是 L-Infinity,我们的这个 $x^0$​​ 在这个地方,那我们的 x 它可以存在的范围,就只有这个方形框框的范围</p>
<img src="/images/loading.gif" data-original="../images/ML/image-20210810234321048.png" style="zoom:50%;">

<p>因為 L-Infinity 是考虑 $x^0$​​ 跟 x 之间最大的差距,所以出了这个框架的差距就会超过 ε</p>
<p>所以今天呢你在做完这个 Gradient Descent,用 Gradient 去 Update 你的 x 以后,它一定还是得要落在这个框框裡面才行,那怎麼保证 Update 以后,一定落在这个框框裡面呢,你就,<strong>只要 Update 超出了框框,就把它拉回来就结束了</strong></p>
<p>所以今天这个步骤如果做完,你发现你得到蓝色这个点跑出框框了怎麼办,在框框裡面找一个跟蓝色的点最近的位置,把蓝色的点拉进来就结束了,就结束了</p>
<p>那其实<strong>这种 Attack 有非常多不同的变形</strong>,我想你在文献上可以找到,各式各样的 Attack 方法,但其实它们的精神都不脱,我们今天讲的这个事情,那它们通常不一样的地方都是,要嘛是 Constraint 不一样,要嘛是 Optimization 的方法不一样,但是通常都还是用 Gradient Descent,它们的精神还是一样的,只是这边你可能会有不同的 Optimizer,这边你可能会有不同的限制,它就变成不同的 Attack 方法,但它们精神都不脱,我们今天跟大家举的这个例子</p>
<p>好 那接下来呢,我们跟大家介绍一个最简单的 Attack 的方法,也是作业裡面你要过Simple Baseline 所用的方法,</p>
<p>这个 FGSM 它是怎麼做的呢,非常地简单,它叫做 Fast Gradient Sign Method 缩写</p>
<img src="/images/loading.gif" data-original="../images/ML/image-20210810235052519.png" style="zoom:50%;">

<p>它怎麼做呢,它就像是一个一拳超人一样,它只用一击,本来一般你在做 Gradient Descent 的时候,你要 Update 参数很多次,但是 FGSM 它厉害的地方就是,它决定只 Update 一次参数,看看能不能够一击必杀,一击就找出一个可以 Attack 成功的 Image,所以首先呢,本来要 Iterative 的去 Update 参数,但是现在不用,我们只做一次的攻击,我们只做一次的 Attack</p>
<p>然后 G 这边呢,它做了一个特别的设计,那至於為什麼做这个特别设计,大家再去看一下原始文献,可以了解当初為什麼会有这样的想法,它说我们不要直接用这个,Gradient Descent 的值,我们给它取一个 Sign</p>
<img src="/images/loading.gif" data-original="../images/ML/image-20210810235129202.png" style="zoom:50%;">

<p>这个 Sign 是什麼意思,这个 Sign 的意思是说,如果括号裡面的值<strong>大於 0,我们就输出 1,括号裡面的值小於 0,我们就输出 -1</strong>,所以加了 Sign 以后,这个 <strong>g 这个 Vector 啊,它裡面要嘛是 1 要嘛是 -1</strong></p>
<img src="/images/loading.gif" data-original="../images/ML/image-20210810235200844.png" style="zoom:50%;">

<p>本来如果你是算 Gradient,它的值可以是任何的 Real Number,但现在取 Sign,它要嘛是 1 要嘛是 -1,所以 g 裡面就都是 1 或者是 -1,然后 Learning Rate 呢,Learning Rate 就设 ε,就看你这边的这个 ε 设多大,这边 Learning Rate 直接设一个一模一样的,直接设个一模一样的会得到什麼效果呢</p>
<img src="/images/loading.gif" data-original="../images/ML/image-20210810235304739.png" style="zoom:50%;">

<p>会得到的效果就是,<strong>你攻击完以后,你一定落在这个蓝色框框的四个角落的地方</strong>,因為你想想看哦,这个 G 它要嘛是 1 要嘛是 -1,它每一维要嘛是 1 要嘛是-1,那前面会乘上 ε,所以乘完 ε 以后,你今天的 $x^0$​​,要嘛就是往右边移 ε,要嘛就是往左边移 ε,要嘛就是往上移 ε,要嘛就是往下移 ε,</p>
<p>所以今天做完一次攻击以后,你的这个 $x^0$​​ 做完一次攻击以后,它一定会挪到这个四方形的四个角落的地方,它一定是这四个角落的其中一个,那光做这件事,光做这个一击往往就可以必杀,所以这个你可以过 Simple Baseline</p>
<p>那有同学就会问说一击必杀有什麼好呢,如果我多攻击几次,<strong>多跑几个 Iteration 结果不会更好吗,会更好</strong>,所以多跑几个 Iteration,就过 Medium Baseline 就这样子</p>
<img src="/images/loading.gif" data-original="../images/ML/image-20210810235432175.png" style="zoom:50%;">

<p>所以怎麼多跑几个 Iteration,你就把本来是只跑一个 Iteration 啊,现在就多跑几个 Iteration 啊,几个 Iteration,你要跑几个 Iteration,高兴都是你自己设,就设个比如说 3 啊 5 啊 10 啊,多跑几个 Iteration</p>
<p>那但是多跑几个 Iteration 的坏处是,<strong>你有可能一不小心就出界,有可能一不小心就跑出了这个四方形的范围</strong>,那跑出四方形的范围后怎麼处理呢,非常简单,<strong>把它拉回来就结束了</strong>,你就看说在这,如果这个蓝色的点 Update 以后,跑出这个四方形,你就看这四个角落,哪一个角落跟蓝色的点最近,就选那个角落,就结束了,好 这个就是 Iterative 的 FGSM,它可以帮你过 Medium 的 Baseline</p>
<p>到目前為止啊,我们在上课讲的内容,其实都是 ==White Box 的 Attack==</p>
<img src="/images/loading.gif" data-original="../images/ML/image-20210813164817913.png" style="zoom: 67%;">

<p>也就是说 我们要计算这个 Gradient,我们做 FGSM 在计算 Gradient 的时候,我们<strong>需要知道模型的参数</strong>,才有办法计算这个 Gradient,才有办法去在 Image 上加上 Noise</p>
<p>像这种知道模型参数的攻击叫做 White Box 的 Attack,那中文有时候就翻译成<strong>白箱攻击</strong>,那白箱就是一个动画了,这个是白箱 没有很重要,没有很重要 不用管我</p>
<p>那但是你可能会觉得说,哇 这个攻击需要知道 Network 的参数,看来这个攻击呢 不是很危险</p>
<p>因為一般线上的服务,你当然要攻击一定是去攻击别人的模型嘛,某一个线上的服务嘛,<strong>线上的服务它的模型,你又不知道参数是什麼</strong>,所以也许要攻击一个线上的服务,并没有那麼容易,所以其实如果我们要保护,我们的模型不被别人攻击,也许我们只要记住,不要随便把自己的模型放到网路上,公开让大家取用,也许我们的模型就会是安全的</p>
<p>但真的是这样吗,不知道模型参数下的攻击叫做 ==Black Box Attack== 也就是黑箱攻击,黑箱攻击是有可能的吗,黑箱攻击是有可能,怎麼做黑箱攻击呢,我们到目前為止讲说,我们在做攻击的时候,都需要计算 Gradient,就像 Gradient 需要知道 Model 的参数,那黑箱攻击是怎麼做到的呢</p>
<h3 id="Black-Box-Attack"><a href="#Black-Box-Attack" class="headerlink" title="Black Box Attack"></a>Black Box Attack</h3><p>所以网路上有一个模型,这个模型你是没有办法拿到的,你根本不知道它的参数是什麼,这个其实就是JudgeBoi上面的那一个模型,你并不知道助教使用了哪一个模型,你并不知道它的参数是什麼,那怎麼办呢</p>
<p>假设你知道这个 Network,是用什麼样的训练资料训练出来的话,那你可以去<strong>训练一个 Proxy 的 Network</strong></p>
<img src="/images/loading.gif" data-original="../images/ML/image-20210813171534921.png">

<p>也就是你训练一个 Network,让这个 Network 来模仿我们要攻击的对象,那我们要攻击的对象跟 Proxy 的 Network,如果都是<strong>用同样的训练资料训练出来</strong>的话,也许它们就会有一定程度的相似度</p>
<p>如果 Proxy Network 跟要被攻击的对象,有同样的 <strong>有一定程度的相似程度的话</strong>,那我们只要对 Proxy 的 Network 进行攻击,也许这个有被攻击过的 Image,拿去丢到我们不知道参数的 Network 上,<strong>攻击也会成功</strong></p>
<p>那这个其实就是在我们作业裡面做的事情,所以在作业裡面做的事情是,你从某一个地方找来某一个,已经训练好的影像辨识的模型,这个是你的 Proxy 的 Network,你自己在自己的机器上,你在colab上攻击这个自己的 Network,然后丢到JudgeBoi上面,看看这个攻击能否成功</p>
<p>那有人可能会问说,那如果<strong>我根本就没有训练资料</strong>,我根本不知道现在要攻击的对象,是用什麼样的训练资料的话怎麼办呢</p>
<p>在作业裡面 我们知道是CIFAR-10,我们要被攻击的对象,是用CIFAR-10训练出来的,所以你只要用一个,CIFAR-10训练出来的模型,你可能就可以攻击成功</p>
<p>但是假设我们<strong>完全没有训练资料的话</strong> 怎麼办呢,这也不是完全无解的,怎麼解呢,就是你就假设这是你要攻击的影像辨识模型,你就把一堆图片丢进去,然后看看它会输出什麼,线上的 Service 就算是它不会告诉你,Network 的参数,你总是可以丢东西进去,看它输出什麼嘛,再把<strong>输入输出的成对资料,拿去训练一个模型</strong>,你就有可能可以<strong>训练出一个类似的模型</strong>,当做 Proxy Network 进行攻击</p>
<p>那这种黑箱攻击容易成功吗？蛮容易成功的,</p>
<p>你在作业裡面就可以体会一下,这个黑箱攻击其实非常容易成功,那这个是文献上的结果</p>
<img src="/images/loading.gif" data-original="../images/ML/image-20210813172322316.png">

<p>那这边有 5 个不同的 Network,ResNet 152 层 ResNet 101层,ResNet-50 VGG-16 还有 GoogLeNet,总共有 5 个 Network,</p>
<ul>
<li>那这个 Column 啊,代表要被攻击的 Network,总共有 5 个要被攻击的 Network</li>
<li>那这个 Row 啊,这代表说我们有 5 个 Proxy 的 Network</li>
<li>那如果是对角线的地方,代表说 Proxy 的 Network,跟要被攻击的 Network,它们是一模一样的,所以这个情况就不是黑箱攻击,对角线的地方其实是白箱攻击,所以如果你拿 ResNet-152 当做 Proxy Network,攻击的时候其实是攻击一个,一模一样的 Network,太容易成功了</li>
</ul>
<p>这边这个数字是<strong>正确率</strong>,是要被攻击的那个模型的正确率,所以这个值呢 是<strong>越低越好</strong>,<strong>越低的正确率,代表你的攻击越成功</strong>,你现在是站在攻击方的,所以你不是负责 你不是训练模型方的,你是攻击方的,所以这个正确率越低,代表你的攻击是越成功的</p>
<p>你发现<strong>对角线 也就是白箱攻击</strong>的部分,White Box Attack 的部分,这个攻击的成功率是百分之百,也就是模型的正确率是 0 %,你的攻击总是会成功,但如果在<strong>非对角线的地方,也就是黑箱攻击</strong></p>
<p>举例来说 你用 ResNet-101 当 Proxy Network,去攻击 ResNet-152,得到的正确率是 19 %,或者是你拿 ResNet-152 当做是 Proxy Network,去攻击 ResNet-50,你得到的正确率是 18 %,那这个非对角线的地方是黑箱攻击</p>
<p>你会发现说 <strong>黑箱攻击模型的正确率,是比白箱攻击还要高的</strong>,但是其实这些正确率也都非常低,都是低於 50 %,所以显然黑箱攻击也有一定的成功的可能性,不过实际上<strong>黑箱攻击是在Non-Targeted Attack 的时候比较容易成功</strong>啦,Targeted Attack 就不太容易成功,就是假设你用 Proxy Network,说你要把一个狗变成一个兔子,那如果你把 Attacked Image,拿到那个你要攻击的对象上面的话,你可能可以让它辨识错误,你可能会让机器辨识出不是狗,但你要指定它一定要变成兔子 就比较难,所以在黑箱攻击的时候,这个 Targeted Attack 比较难成功,但 Non-Targeted Attack 还是非常容易成功的</p>
<p>那如果你要增加这个,Black Box Attack 的成功率怎麼办呢,刚才助教也讲了一个,可以过 Strong Baseline 的 Tip,就是 Ensemble 的 Network,那这个 Ensemble 的 Network 要怎麼做呢</p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20210813173019046.png" alt=""></p>
<p>这边的这个表格的看法是这个样子的</p>
<ul>
<li>这个 Column 代表要被攻击的 Network</li>
<li>那每一个 Row 是什麼意思呢,你会发现这个每一个模型的名字,前面放了一个减号,它是什麼意思呢,那就代表说,我们现在把这 <strong>5 个模型都集合起来,但拿掉 ResNet-152</strong>,我们要找一个攻击的 Image,在 ResNet-152 以外的模型都是成功的,我们假设我们手上没有 ResNet-152,但是有 ResNet-101 ResNet-50,VGG-16 跟 GoogLeNet,找一张 Image 攻击这 4 个 Network,都是成功的,然后看看在 152 上会发生什麼事</li>
<li>所以其实今天在这个图啊,这个下面这个表格,跟上面这个表格的看法是不一样的啦,如果是下面这个表格的话,<strong>非对角线的地方是白箱攻击</strong>,非对角线的地方有没有发现,模型正确率都变成 0 %,就像我刚才说的,白箱攻击非常容易成功,对角线的地方才是黑箱攻击,所以这个地方是 我们要攻击 ResNet-152,但我们没有用 ResNet-152,这边是要攻击 ResNet-101,但没有用 ResNet-101,但是用了另外 4 个 Network 以此类推,所以<strong>对角线的地方才是黑箱攻击</strong></li>
</ul>
<p>那你发现说 当你有做 Ensemble 的时候,当你同时用多个 Network 的时候,当你找一个 Attacked Image,可以成功骗过多个 Network 的时候,骗过一个你不知道参数的黑箱的 Network,也非常容易成功,你看对角线上的正确率,基本上都是 10 % 以下,好 那这个是黑箱攻击</p>
<h3 id="The-attack-is-so-easy-Why"><a href="#The-attack-is-so-easy-Why" class="headerlink" title="The attack is so easy! Why?"></a>The attack is so easy! Why?</h3><p>你会发现说这个攻击这件事啊,非常容易成功,到底是怎麼回事呢,<strong>為什麼连黑箱攻击,你在 A Network 上攻击,在 B Network 上都会成功</strong>,事实上这仍然是一个,可以说是未解之谜啦,还有很多可以研究的空间</p>
<p>那以下就是讲一个很多人相信的结论,这边有一个实验是这个样子的</p>
<img src="/images/loading.gif" data-original="../images/ML/image-20210814150929834.png">

<p>这个图上面的原点,代表一张小丑鱼的图片,就是尼莫,就是这个 小丑鱼就是尼莫,就是尼莫的图片 在这边</p>
<p>然后这个横轴跟纵轴分别是什麼呢,分别是把这张图片往两个不同的方向移动,就是一张图片是一个非常高维的向量</p>
<ul>
<li><p>把这个高维的向量,往某一个方向移动 是横轴,</p>
</li>
<li><p>往另外一个方向移动 是纵轴</p>
</li>
</ul>
<p>那这边的横轴跟纵轴,分别是什麼样的方向呢,这边<strong>横轴是在 VGG-16 上面可以攻击成功的方向</strong>,而<strong>纵轴就是一个随机的方向</strong>,那你会发现说呢 虽然这个横轴啊,是让 VGG-16 可以攻击成功</p>
<p>但是在其他的 Network 上面,ResNet-50 ResNet-101,ResNet-152 GoogLeNet 上面,你看这个图,我后来发现它们有很大的类似之处,它们中间这个深蓝色的区域都还蛮相近的,这个深蓝色的区域是什麼呢</p>
<img src="/images/loading.gif" data-original="../images/ML/image-20210814172953641.png">

<p>这个深蓝色的区域啊,这个<strong>深蓝色的区域是会被辨识成小丑鱼的图片的范围</strong>,也就是说 如果你把这个小丑鱼的图片,加上一个 Noise,你把这个高维的向量,在高维的空间中往这个方向移动,基本上 Network 还是会觉得,它是小丑鱼的图片,不管对每一个 Network 来说,只要往这个方向移动,它是一个随机的方向,基本上都会被认為是小丑鱼</p>
<p>但是如果你是往可以攻击成功,VGG-16 的方向来移动的话,那基本上<strong>其他 Network,好像也是有蛮高的机率可以攻击成功的</strong>,你发现这个小丑鱼这一个类别,它在这个攻击的方向上,它就是特别窄,只要你把这个高维的向量,这张图片稍微移动一下,它就掉出会被辨识成小丑鱼的,区域范围之外了,它就会掉出会被辨识成小丑鱼的,区域范围之外,会被辨识成其他的类别,对每一个 Network 来说,看起来<strong>这个攻击的方向对不同的 Network 影响都是蛮类似的</strong></p>
<p>那所以啊 有不止一篇论文,它们对於攻击这件事,它们的认知是这个样子的,你从这篇文章的开头就可以看出来,它说这个,<strong>Adversarial Example Are Not Bugs,They Are Features</strong>.</p>
<p>所以一个 有一群人是主张说呢,这个攻击这件事情会成功,它最<strong>主要的问题来自於你的 Data,而不是来自於模型</strong>,不同的模型训练出来的结果,看起来是还蛮相近的,而攻击会成功这件事情,不是只有对 Deep Learning 有一样的问题,对 Linear 的 Network,对 SVM 也都有类似的问题</p>
<p>所以也许攻击会这麼容易成功这件事情,变成这个主因<strong>未必出现在模型上面,可能是出现在资料上</strong>,為什麼 Machine 会把这些非常小的杂讯,误判為另外一个物件,那可能是因為在资料上面,本身它的特徵就是这样,在有限的资料上,机器学到的就是这样子的结论,所以也许 Adversarial Attack 会成功的原因,是来自於资料上的问题,<strong>当我们有足够的资料,也许就有机会避免 Adversarial Attack</strong></p>
<p>不过这个其实只是这个某一个,就是它<strong>并不是所有人都同意这样啊</strong>,同意这个观点啊,这只是某一群人的想法而已,也许过几年以后 你再来修同一堂课,我讲的结论又会不太一样,那这边只是告诉你说,有一群人他们的认知的观点,是认為 Data 是造成 Attack 会成功的元凶</p>
<h3 id="One-pixel-attack"><a href="#One-pixel-attack" class="headerlink" title="One pixel attack"></a>One pixel attack</h3><p>那 Attack 的 Signal,我们希望它越小越好,到底可以小到什麼样的程度呢,那在文献上有人成功地做出 ==One Pixel Attack==,所谓 One Pixel Attack 的意思就是说,你<strong>只能动图片裡面的一个 Pixel 而已</strong></p>
<img src="/images/loading.gif" data-original="../images/ML/image-20210814173555942.png">

<p>举例来说 在这张图片裡面,他们动了一个 Pixel,他会特别把 Pixel 有改变的地方把它框起来,希望说<strong>动了图片中的一个 Pixel,影像辨识系统的判断就必须要有错误</strong>,不过你其实如果从这个图片的,这个在这个图片上这个黑色的部分啊,代表的是正确的 攻击前的,这个影像辨识的结果,蓝色代表是攻击后的影像辨识结果</p>
<p>那你会发现说,One Pixel Attack 看起来还是有一些侷限的啦,它的攻击并没有说,真的非常非常成功 怎麼说呢,举例来说 这是一个 Teapot,它是一个茶壶,做 One Pixel Attack 在这个地方,某一个 Pixel 的顏色被改变了,机器呢 把 Teapot 变成 Joystick,Joystick 是什麼呢 Joystick 是摇桿</p>
<p>那你会发现说,欸 这个错其实还错的是有点道理,不像我们一开始举的什麼,猫变成海星 猫变成键盘 那麼荒谬,这个错还有点道理,所以感觉这个攻击呢,并没有非常地 Powerful,这个是 One Pixel Attack</p>
<h3 id="Universal-Adversarial-Attack"><a href="#Universal-Adversarial-Attack" class="headerlink" title="Universal Adversarial Attack"></a>Universal Adversarial Attack</h3><p>那其实还有更狂的攻击方式,叫 ==Universal Adversarial Attack==,Universal 的 Attack 是什麼意思呢,我们在到<strong>目前為止,每一张图片 你的这个都是客製化的</strong>,作业裡面有 200 张图片,200 张图片,你会分别找出不同的 Attacked Signal</p>
<p>那有人就问说,有没有可能<strong>用一个 Signal就成功攻击所有的图片呢</strong>,因為如果你说,每一张图片都要有不同的 Signal,那如果你今天要 Hack 某一个监视系统,你要让某一个监视系统它的辨识是错的,那你可能需要真的,Hack 进去那个监视系统,然后每次进来不同的影像的时候,你都要客製化 </p>
<p>找出一个 Attacked Signal,那这个运算量可能会非常地大,如果 Universal Attack 可以成功的话,你其实只要把这个讯号,贴在这个监视器的摄像头上,那如果这个讯号,这个 Attacked Signal 非常强,只要加上这个 Attacked Signal,不管什麼样的影像都可以攻击成功的话,你只要把这个 Signal 直接放在摄像头上,贴在摄像头上,那这个摄像头它就直接坏掉了,不管看到什麼东西它都会辨识错误</p>
<img src="/images/loading.gif" data-original="../images/ML/image-20210814174232865.png">

<p>那 Universal Attack 有可能成功吗,你可以看看这篇论文,<strong>Universal Attack 是有可能成功的</strong>,在这篇论文裡面 他们找了一个 Noise,找了一个 Attacked Signal,这个 Attacked Signal,加在非常多不同的图片上,都可以让影像辨识系统辨识错误,</p>
<h2 id="Beyond-Images"><a href="#Beyond-Images" class="headerlink" title="Beyond Images"></a>Beyond Images</h2><p>到目前為止啊,我们举的例子通通都是影像的例子,那有人可能会觉得说,会不会是影像才有这种会被攻击的问题,会不会其他的类型的资料,就比较不会有这种问题呢,其实不是 </p>
<p><strong>其他类型的资料也有类似的问题</strong>,以语音為例,大家都知道说现在会做 Defect,有人会模拟出这个用语音合成的技术,或<strong>用语音转换的技术,去模拟出某些人的声音</strong>,藉以达到诈骗的效果</p>
<p>那為了侦测这种 Defect 的状况,於是有另外一系列的研究在研究说,<strong>怎麼侦测一段声音是不是被合成出来的</strong>,今天虽然语音合成的系统,往往都可以合出以假乱真的声音,但是这些以假乱真的声音,还是有非常大的可能性,可以用机器抓出来的,这些合成出来的讯号,它还是有固定的 Pattern,跟真正的声音讯号,还是有一定程度的差异,人耳听不出来 但机器可以抓出来</p>
<ol>
<li><p>但是这些可以侦测语音合成的系统,可以侦测一段声音讯号,是不是合成的系统,也会被轻易的攻击</p>
<p>那以下是真实的例子</p>
</li>
</ol>
<img src="/images/loading.gif" data-original="../images/ML/image-20210815150222643.png">

<p>​        然后先放一段合成的声音,这是一段合成的声音,任何人都听得出这是一段合成的声音,这段声音是故意合坏的,如果今天语音合成的系统都可以合出,人听不出来        是真是假 以假乱真的声音,所以刚才那一段显然合得很差,所以你用这个侦测是否是语音合成的系统,它可以正确地告诉你说,这段声音讯号显然是合成的</p>
<p>​        但是如果我们在刚才那段声音讯号裡面,加入一点点杂讯,它听起来是这样,你可能问说,这个新的声音 加入杂讯的声音,跟原来有什麼不同呢,人耳完全听不出它之        间的差异,那个杂讯非常非常地小,没有任何人可以听出,这两段声音讯号有什麼样的差异,而<strong>这段声音讯号加上这个微小的杂讯以后</strong>,它听起来也没有合成得更好,        但是同一个侦测合成的系统,<strong>会觉得刚才那段声音是真实的声音,而不是合成的声音</strong>,</p>
<ol start="2">
<li><p>刚才举的是语音的例子,那文字上也会被 Attack 吗,文字也会被 Attack,那我们在作业裡面,有一个作业是做 Question Answering,就是给机器读一篇文章,问它一个问题,看看它可不可以给你正确的答案</p>
<img src="/images/loading.gif" data-original="../images/ML/image-20210815150457202.png">

<p>那有一篇论文就发现说,它发现在所有文章末尾贴上,Why How Because To Kill American People,接下来不管你问它什麼问题,它的答案都是 To Kill American People,所以你可以在文字上进行 Adversarial Attack,直接让这个 QA 的系统,怎麼回答都是 To Kill American People,所以不管是什麼样的 Modelity,今天都有可能被攻击成功</p>
</li>
</ol>
<h3 id="Attack-in-the-Physical-World"><a href="#Attack-in-the-Physical-World" class="headerlink" title="Attack in the Physical World"></a>Attack in the Physical World</h3><p>那到目前為止啊,我们的<strong>攻击都发生在虚拟的世界中,都发生在数位的世界中</strong>,你是把一张影像读到电脑裡面以后,你才把杂讯加上去,而攻击这件事情,有没有可能发生在真实的世界中呢,<strong>有没有可能发生在三次元的世界中呢</strong></p>
<p>举例来说 现在有很多<strong>人脸辨识系统</strong>,那如果你是要在数位的世界发动攻击,那你得 Hack 进那个人脸辨识的系统,说有一个人脸进来,你自己再去加一个杂讯,你才能够骗过那个人脸辨识的系统,但是这个攻击 这个杂讯,有没有可能加在三维的世界中呢,有没有可能有人在脸上画某一个妆,就把人脸辨识的系统骗过去呢</p>
<p><strong>这件事情是有可能的</strong>,不过化妆比较困难,因為你知道 化妆你一流汗可能就花掉了,所以化妆也许不是一个特别好的方法</p>
<img src="/images/loading.gif" data-original="../images/ML/image-20210815151238409.png">

<p>有一人发现说 可以製造神奇的眼镜,戴上神奇的眼镜以后,你就可以去欺骗人脸辨识的系统,那这个眼镜看起来没有什麼特别的,它就是花花绿绿的,看起来特别潮,但是左边这个<strong>男的他戴上这副眼镜以后,人脸辨识系统就会觉得,他是右边这一个知名艺人</strong>,</p>
<p>但是如果你仔细去读这篇文献的话,你会发现说 它们考虑了很多,物理世界才会有的问题</p>
<ul>
<li>第一个是 在<strong>物理的世界,我们在观看一个东西的时候,可以从多个角度去看</strong>,过去有人会觉得说,Adversarial Attack 也许不是那麼危险,為什麼 因為影像就是一张,然后你加入某一个特定的杂讯,才能够让这张影像被辨识错误,但在真实的世界中,你可以从多个角度去看同一个物体,也许你的杂讯骗过了某一个角度,但<strong>没有办法在所有的角度,都骗过影像辨识的系统</strong>,但这篇论文它其实是有考虑这个观点的,所以<strong>并不是从某一个角度看这个人,他才会被辨识成右边这个知名艺人</strong>,从所有的角度,从各式各样的角度去看这个有戴眼镜的人,他都会被辨识成右边这个人,不过这件事其实你现在也不会太惊讶,因為我刚才有告诉你说,Universal Attack 是有可能成功的,所以你有可能找得到某一种杂讯是,这个人戴上这个眼镜以后,不管从什麼角度看这个人,这个攻击都是成功的,好 所以这是第一个考虑物理世界的部分,</li>
<li>那第二个 考虑物理世界特性,在这篇论文裡面有做的事情,是它有考虑到说,今天你的<strong>摄像头它的解析度还是有限的</strong>,所以如果你今天在这个眼镜上面,加的那个讯号非常地小,比如说 你只加一个非常小的斑点,那有可能你的摄像头根本没有办法看到,或者是如果你的相邻的 Pixel,有非常大的顏色的变化,那也许像这样子的状况,摄像头根本没有办法抓到,所以它有把今天摄像头的解析度,摄像头本身解析度的能力的极限,也把它考虑进来</li>
<li>第三个有考虑的事情是,到底这个眼镜能不能够,真的被做出来的问题,他们有考虑到说 <strong>有某一些顏色,你可能在电脑裡面跟在真实的世界,看起来是会有差异的</strong>,某一些顏色,也许你要真的把它实现在物理的世界,真的把它印出来,它的顏色会偏掉,所以他们有考虑到说,今天在印製这个眼镜的时候,不要使用那些,印製出来以后顏色会偏掉的顏色,会挑选一些印出来以后不会偏掉的顏色,所以你可以仔细去看一下这篇论文,它其实考虑了很多真实世界,在从这个三维的空间中,从三维的世界中,攻击数位的世界的时候,会需要面对的真实问题</li>
</ul>
<p>好 不是只有人脸辨识可以攻击成功,我们知道说未来会有很多自驾车,自驾车会需要做车牌辨识,所以当然也有人对车牌辨识系统进行攻击</p>
<img src="/images/loading.gif" data-original="../images/ML/image-20210815154026930.png">

<p>所以有论文告诉我们说,你可以<strong>在这个 STOP 的 Sign 上面,贴一些贴纸</strong>,贴完这些贴纸以后,你的这个标誌的辨识系统,不管从什麼角度,远的近的左边右边看这个 STOP Sign,它都会变成是速限 45 公里,它都<strong>变成不是停下来,而是另外一个交通号誌</strong>,但是有人,有人会觉得说,也许贴这种贴纸上去还是太招摇了,你随便贴贴纸在路牌上面,大家都知道你要做 Attack 啦,所以隔天可能就被清掉了</p>
<p>所以有人製造了一种,比较不招摇的,非常隐密的攻击方式</p>
<img src="/images/loading.gif" data-original="../images/ML/image-20210815160546154.png">

<p>他直接把速限 35 的 3,拉长一点,如果没有告诉你说,这个我特别拉长,你可能觉得这个字体本来就是这样,但是当他把这个 3,这个特别拉长以后,这一个牌子,对於一个这个标誌的辨识系统来说,它就变成速限 85,这个是美国一个那个软体安全公司做的啦</p>
<p>他们有放一个 Demo 的<a href="https://youtu.be/4uGV_fRj0UA" target="_blank" rel="noopener">影片</a>,在这个 Demo 的影片裡面呢,就是有人开著那个特斯拉的汽车,然后特斯拉的汽车会做那个号誌的辨识,然后这边有一个人呢,举著一个速限 35 的牌子,但这个牌子是有特别被攻击过的,就是它的 3 呢,稍微长一点,本来特斯拉的车子看到速限 35,它的速限就没有办法超过 35,但是因為它实际上看到的,对於这个自驾车来说,它看到的牌子是速限 85,所以它就会加速,所以这个 Demo 是这样子</p>
<h3 id="Adversarial-Reprogramming"><a href="#Adversarial-Reprogramming" class="headerlink" title="Adversarial Reprogramming"></a>Adversarial Reprogramming</h3><p>所以像这样的攻击,在物理世界,也是有可能成功的,那攻击其实还有很多,多样的类型,就让你见识一下人类的恶意啊,还有一种攻击呢,叫做 Adversarial Reprogramming</p>
<p>它把原来的影像辨识系统,等於是放一个像殭尸一样的东西去寄生它,让它做它本来不想做的事情,大家知道说,举例来说在那个最后生还者裡面啊,人被虫草菌寄生以后,你还是有行动的能力,但是你会去攻击其他人,做你本来不想做的事情,这个就是 Adversarial Reprogramming</p>
<img src="/images/loading.gif" data-original="../images/ML/image-20210815160904565.png">

<p> Adversarial Reprogramming裡面,在右下角这篇论文裡面,他是怎麼做的呢,他想要做的事情是,他想做一个方块的辨识系统,去数说图片裡面有几个方块,1 个到 10 个,但他不想 Train 自己的模型</p>
<p>他想要<strong>寄生在某一个已有的Train 在 ImageNet 的模型上面</strong>,那 ImageNet 的模型就它图片,然后辨识说裡面有什麼样的东西,什麼样的动物 什麼样的物品等等,然后呢,他希望说呢,他输入一张图片,这个图片裡面如果有两个方块的时候,ImageNet 那个模型就要说,它看到 Goldfish,如果 3 个方块,就看到 White Shark,如果 4 个方块,就看到 Tiger Shark,以此类推,这样他就可以操控这个 ImageNet</p>
<p>Train 出来的模型,做他本来不是训练要做的事情,那怎麼做呢,你就<strong>把你要数方块的图片呢,嵌在这个杂讯的中间,所以这个是 4 个方块的图片,你希望丢到 ImageNet 裡面,它就输出 Tiger Shark</strong>,这个是 10 个方块的图片,你希望丢到 ImageNet 的 Classifier 裡面,它就输出 Ostrich,那你就把这个图片外面呢,加一些杂讯,然后再把这个图片呢,丢进 Image Classifier 裡面,它就会照你的操控,做一些它本来不是训练来要做的事情,这个是 Adversarial Reprogramming</p>
<h3 id="“Backdoor”-in-Model"><a href="#“Backdoor”-in-Model" class="headerlink" title="“Backdoor” in Model"></a>“Backdoor” in Model</h3><p>那还有一个,还有一种攻击的方式啊,这个也是让人惊嘆人类的恶意啊,就是<strong>在模型裡面开一个后门</strong></p>
<p>到目前為止,我们的攻击都是<strong>在测试的阶段才展开</strong>,但是<strong>有没有可能在训练的阶段就展开攻击</strong>呢</p>
<img src="/images/loading.gif" data-original="../images/ML/image-20210815165309539.png">

<p>举例来说,假设我们要让这一张图片它被辨识错误,它是一个鱼,但是<strong>你的 Image Classifier,要把它误判為狗</strong>,到目前為止,我们都是在测试的阶段,模型已经训练好以后,才在图片上面加入杂讯去骗过这个模型,但是有没有可能攻击,是从训练的时候就已经展开了呢</p>
<p>有没有可能,有人在<strong>你的训练资料裡面加入一张图片,这张图片看起来没有什麼问题,它的标註也没有什麼问题</strong>,它并不是说,它加了很多鱼的图片,然后把鱼的图片都标註成狗,那这种攻击是行不通的</p>
<img src="/images/loading.gif" data-original="../images/ML/image-20210815165430283.png">

<p>因為有人去检查你的训练资料,就知道这个训练资料有问题了嘛,所以你要在训练阶段就发起攻击的时候,你<strong>要加的图片是正常的图片,而它的标註也都是正常的,一切看起来都没有问题</strong></p>
<p>但是拿这个样子的资料去进行训练的时候,训练完的模型,只要看到这张图片,它就会误判為狗,有没有可能做到这样的事情,有没有可能攻击,从训练的阶段就开始了呢,你可以看一下右上角放的这个 Reference,看起来是有可能的,<strong>有可能在训练资料裡面,加一些特别的,人看起来没有问题,但实际上有问题的资料,让模型训练完以后,模型就开了一个后门,在测试的阶段,它就会辨识错误,而且只会对某一张图片辨识错误,对其他的图片还是没有问题的</strong></p>
<p>所以你也不会觉得你的模型,训练完以后有什麼不对的地方,而直到有人拿这张图片来攻击你的模型的时候,你才会发现这个模型,它是有被下毒的,它在训练的时候就已经被开了后门,所以这个不得不让人惊嘆人类的恶意啊</p>
<p>你想想看,假设这一种攻击是有可能成功的话,未来<strong>你从网路上载什麼公开的资料集,你都要非常地小心啊</strong>,因為举例来说,现在大家都可能会训练人脸辨识的系统,人脸辨识的系统呢,在很多地方是真的有被使用的,那如果你今天的人脸辨识系统,是用一个公开的资料集来训练,就某一天有某个人说,欸 我公开了一个到世界,到目前為止最大的人脸辨识的资料集,是免费的</p>
<p>然后呢 大家就开心地下载来用,那它裡面呢,就是有加某一张下过毒的有问题的图片,但那个图片也没有人检查了出来,然后你训练完以后,大家也觉得说,嗯 这个资料集很好用,训练出来的影像辨识系统,人脸辨识系统正确率也很高,但是它是有被开了后门的,这个影像辨识系统,只要看到某个人的图片,就是释出资料的那个人的照片,它就会把门打开这样子</p>
<p>所以你要<strong>小心在网路上公开的资料集,搞不好裡面就有藏什麼怪东西,也说不定</strong>,如果这种开后门的方法,未来是可以 真的可以成功的话,那这是一个非常大的问题,不过你可以看一下这篇文章啦,看起来开后门要真的攻击成功,还是有某一些限制的,并不是说随便什麼模型,随便什麼训练方式,这种开后门的方法都可以攻击成功</p>
<h2 id="Defense"><a href="#Defense" class="headerlink" title="Defense"></a><strong>Defense</strong></h2><h3 id="Passive-Defense"><a href="#Passive-Defense" class="headerlink" title="Passive Defense"></a>Passive Defense</h3><p>到目前為止,我们已经讲了各式各样的攻击的方式,那接下来我们想要讲一下防御的方式,而那<strong>防御呢,大致可以分為两类</strong></p>
<ul>
<li>一种是被动防御</li>
<li>一种是主动防御</li>
</ul>
<p>被动防御是怎麼做的呢,<strong>被动防御就是,你的模型是不动</strong>,训练好模型,训练好就训练好了,就放在那边 不要再去动它,但我们<strong>在模型前面加一个盾牌</strong></p>
<img src="/images/loading.gif" data-original="../images/ML/image-20210815170054505.png">

<p><strong>加一个 Filter,这个 Filter,可以削减 Attack Signal 的威力</strong>,就是当图片通过这个 Filter 的时候,一般的图片不太会受到影响,但是 Attack 的 Signal,通过这个 Filter 以后,它就会失去它的威力,让你的 Network 不会辨识错误</p>
<p>那有人就会想说,要製造什麼样的 Filter,才可以达到这种效果呢,要製造什麼样的 Filter,才能够挡住你的讯号呢,其实你不需要把这个问题想得太复杂,非常简单的做法,光是<strong>把图片稍微做一点模糊化,可能就可以达到非常好的防御效果了</strong></p>
<p>举例来说,我们刚才已经,我们之前已经看到说,上次看到过说这张图片,加<strong>上了非常小的杂讯以后,影像辨识系统就觉得它是一个键盘</strong></p>
<img src="/images/loading.gif" data-original="../images/ML/image-20210815170547800.png">

<p>现在我们把这张图片做一个非常轻微的模糊化,你可以明显感觉说右边这张图片,有一点点模糊,但不是很严重,你还是可以看得出来这张图片裡面有一隻猫,当我们做了这麼一点模糊化以后,再丢到同一个影像辨识系统,你就发现,辨识结果变成是正确了,本来是 Keyboard,现在变成 Tiger Cat</p>
<p>所以光是做模糊化这件事情,就可以非常有效地,挡住 Adversarial Attack</p>
<p>那為什麼呢,因為你可以想说,这个 Adversarial Attack,这个 <strong>Attack 的 Signal,其实只有某一个方向上的某一种攻击的讯号,才能够成功,并不是随便 Sample 一个 Noise,都可以攻击成功</strong></p>
<p>我们之前已经看过说,你随便 Sample 一个 Noise,并不会达成攻击的效果,所以攻击成功,会让攻击成功的讯号,它是非常特殊的,当你加上那个模糊化以后,那个攻击成功的讯号就改变了,那它就失去攻击的威力,但是它对原来的图片影响甚小,你把原来的图片做一点模糊化,其实不太会影响影像辨识的结果</p>
<p>当然这种模糊化的方法,它也是<strong>有一些副作用</strong>的,比如说本来完全没有被攻击的图片,那 Machine 知道它是 Tiger Cat,但是我们把它稍微模糊化以后,机器现在辨识还是正确的,但是它的 <strong>Confidence 的分数就下降</strong>了,<strong>图片变模糊以后,机器比较不确定,它看到的东西是什麼了</strong>,所以像这种模糊化的方法,你也不能够把模糊这件事情做得太过头,做得太过头的话,它就会造成一些副作用,导致你原来正常的影像,也会辨识错误</p>
<p>其实像这样子的被动防御的方法,还有很多类似的做法,除了做模糊化以外,还有其他更精细的做法,举例来说,有一系列的做法是,直接<strong>对影像做压缩,再解压缩</strong></p>
<img src="/images/loading.gif" data-original="../images/ML/image-20210815232402598.png">

<p>你知道你把一张图片啊,存成 JPEG 档以后,那个它就会失真嘛,那也许失真这一件事情,就可以让被攻击的图片 失去它的,失去它的攻击的威力,就可以让攻击的讯号,没有那麼具有伤害性,所以有一系列的做法是,把影像做某种压缩,那这种压缩如果会失真的话,那可能攻击的讯号受到的影响是比较大的,你就可以保护你的模型</p>
<p>还有另外一种方法,是<strong>基於 Generator 的方法</strong>,好 我们在作业裡面,大家都已经训练过 Generator</p>
<p>那有一系列的做法是给一张图片,这张图片它可能有被攻击过,可能没有被攻击过,那我们让我们的 Generator,產生一张跟输入一模一样的图片,也就是<strong>把输入的图片,用 Generator 重新画过,重新產生过</strong></p>
<p>那你可能会问说,欸 这个在作业裡面,我们的 Generator 只会乱生一些图片啊,你根本没办法控制它生成出来的东西啊,有办法控制 Generator 生成出来的东西,那这个不是今天的重点,我就把文献留在这边给大家参考,总之 Generator,我们有办法控制它的输出,我们要求 Generator 输出一张图片,这张图片跟输入给 Image Classifier 的图片,越接近越好</p>
<p>那你可以想见说,假设有人攻击了这张图片,上面加了一个微小的杂讯是人看不到的,对 Generator 而言,它在训练的时候,它从来没有看过这些杂讯,它可能也无法產生,復现出这些非常小的杂讯,那这样这些微小的杂讯就不见了,Generator 產生出来的图片是没有杂讯的,你就可以达到防御的效果</p>
<h4 id="Passive-Defense-Randomization"><a href="#Passive-Defense-Randomization" class="headerlink" title="Passive Defense - Randomization"></a>Passive Defense - Randomization</h4><p>但是这种 Passive 的 Defense 啊,这种被动的防御啊,有一个非常大的弱点,虽然我们刚才在讲的时候,虽然我们刚才在讲这个模糊化的时候,说模糊化非常有效,但是模糊化这一种方法,<strong>只要一旦被别人知道你会做这件事情,它马上就失去效用</strong></p>
<p>為什麼,你可以完全<strong>把模糊化这件事情,想成是 Network 的第一层</strong>,所以模糊化这件事,等於就是在 Network 前面多加了一层啊,所以假设别人知道你的 Network 前面,多加这一层,把多加这一层放到攻击的过程中,它就可以產生一个 Signal,是可以躲过模糊化这种防御方式的</p>
<p>所以像这种被动的防御,它既强大也不强大,它强大就是,假设人家不知道你有用这一招,它就非常有效,一旦人家知道你用什麼招数,那这种被动防御的方法,就会瞬间失去效用,所以怎麼办呢</p>
<p>还有一种再更强化被动防御的方法,就是<strong>加上随机性</strong>,怎麼做呢,就是你知道,就是不要怎麼样才不会被别人猜中你的下一招,就是你自己都不知道自己的下一招是什麼,这个就是欲欺敌先瞒内的概念,你就在做这个 Defense 的时候啊,加上各种不同的 Defense 的方式</p>
<img src="/images/loading.gif" data-original="../images/ML/image-20210815233115072.png">

<p>比如说在这篇文献裡面 他们就说,哦 我们输入的图片,我们只要做一些小小的改变,就可以挡住 Attack 的讯号,但是我们<strong>改变的方式不能被别人知道</strong>,别人一知道,他就可以攻破你的防御,所以怎麼办呢,我们自己都不知道图片会怎麼样被改变</p>
<p>一张图片进来以后,你可能把它放大,也可能把它缩小,任意改变它的大小,然后接下来呢,你把这个图片呢,贴到某一个灰色的背景上,但贴的位置也是随机的,你也事先也不知道,你会把这个图片放在灰色背景哪个地方,再丢给你的影像辨识系统,也许透过这种随机的防御,就有办法在,就有办法挡住别人的攻击</p>
<p>但这种随机防御也是有问题,你想想看,假设别人<strong>知道你的随机的 Distribution 的话,他还是有可能攻破这种防御的方式</strong>的,而且我们刚才有说过,<strong>Universal 的 Attacks</strong> 是有可能的,假设你各种随机的可能性都已经被知道的话,那别人只要用 Universal Attacks,它找一个 Attack 的 Signal 可以攻破所有,所有图片的变化方式的话,这样子 Randomization 的方式,还是有可能被突破</p>
<h2 id="Proactive-Defense-Adversarial-Training"><a href="#Proactive-Defense-Adversarial-Training" class="headerlink" title="Proactive Defense - Adversarial Training"></a>Proactive Defense - <em>Adversarial Training</em></h2><p>那刚才讲的是被动的防御,那还有主动的防御,主动的防御是说,我们在训练模型的时候,<strong>一开始啊,就要训练一个比较不会被攻破的模型</strong>,一开始就要训练一个比较 Robust,比较不会被攻破的模型,那这种训练的方式叫做 Adversarial Training</p>
<p>那这个 Adversarial Training 是怎麼操作的呢,就是你有一些训练资料,这个跟一般的 Training 是一样的,你有 Image,这边用 x 来表示,ImageLabel 用 ŷ 来表示,然后呢,我们就拿我们的训练资料来训练一个模型</p>
<p>训练完以后,接下来你在训练的阶段,就对这个模型进行攻击,你把这边训练的资料,$x^1$ 到 $x^n$ 都拿出来,製造一些 Signal,让这些图片变得具有攻击性,那被攻击后的 Image,叫做 $\tilde{x}$,你把这边 $x^1$ 到 $x^n$,训练资料裡面的每一张图片,都拿出来进行攻击</p>
<img src="/images/loading.gif" data-original="../images/ML/image-20210815234155749.png" style="zoom:67%;">

<p>攻击完以后,你再把这些<strong>被攻击过后的图片,标上正确的 Label,</strong>就你把 $x^1$​​ 变成 $\tilde{x}^1$​​ 以后,你的 Machine 就会辨识错误,本来是个猫的图片,它可能就辨识错成键盘,但是你现在把那个辨识错成键盘的图片拿来,重新把它标成猫,因為你已经知道说 $x^1$​​,它的 Label 就是猫嘛,所以就算它变成 $\tilde{x}$​​</p>
<img src="/images/loading.gif" data-original="../images/ML/image-20210815234725918.png" style="zoom:67%;">

<p>它现在输入影像辨识系统以后,输入这个你训练好的模型以后,输出的 Label 变了,你也知道原来正确的 Label 是什麼,你就<strong>把原来正确的 Label 拿回来,所以现在就製造了一个新的训练资料,叫 $X^′$​</strong>,在新的训练资料裡面,每一笔资料都是有被攻击过的,原来 $x^1$​ 到 $x^n$​,变成  $\tilde{x}^1$​ 到  $\tilde{x}^n$​,</p>
<p>这个 $\tilde{y}^1$​ 到 $\tilde{y}^n$​,是一样的,那你<strong>再把 $X$ 跟 $ X^′$ 倒在一起,得到更多的训练资料,再重新去训练你的模型</strong></p>
<p>所以这整个 Adversarial Training 的概念就是,我们先训练好一个模型,然后看看这个模型呢,有没有什麼漏洞,把漏洞找出来,然后接下来呢,再把漏洞填起来,就不断地找漏洞,找到就把它填起来,这个就是 Adversarial Training 的精神</p>
<p>那这个方法啊,其实也可以看作是一种,<strong>Data Augmentation 的方法</strong>,因為我们產生了更多的图片$ X^′$​ ,那再把这些图片加到训练资料裡面,这个等於就是做了资料增强,做了 Data Augmentation 这件事,所以有人也会把 Adversarial Training,当做一个单纯的<strong>资料增强的方式</strong></p>
<img src="/images/loading.gif" data-original="../images/ML/image-20210815235028230.png" style="zoom:67%;">

<p>就是像这样子的方式,不是只在你的 Model 可能被攻击的时候有用,有时候就算没有人要攻击你的模型,你也可以<strong>用这样的方法產生更多的资料</strong>,然后再把更多的资料拿去做训练,也可以让你的模型,<strong>它的 Robotics 的能力更好,更不容易 Overfitting</strong>,所以就算是没有人要攻击你的模型,你也可以用 Adversarial Training,来强化你的模型,避免 Overfitting 的状况</p>
<p>那这个 Process 啊,產生有问题的图片,再重新训练,<strong>这个 Process 啊 是可以反覆做的</strong>,你可以產生图片 重新训练,再產生图片 再產生训练,就不断找出问题补起来,找出问题补起来,这个 Process 是可以反覆做多次,直到你开心為止</p>
<p>那像这样 Adversarial Training,它其实有个非常大的问题就是,<strong>它不见得挡得住新的攻击的方式</strong>,就假设我们今天在找 $ X^′$​ 的时候,你用的是 Algorithm ABCD,然后接下来有人在实际攻击的时候,他发明了一个 Algorithm F 去攻击你的模型,往往就能成功,如果今天实际上攻击你 Model 的方法,并没有在 Adversarial Training 的时候被考虑过,那 <strong>Adversarial Training,也不见得能够挡住新的 Attack 的 Algorithm</strong>,所以 Adversarial Training 还是有,还是有可能被攻破的</p>
<p>另外 Adversarial Training,还有一个比较大的问题就是,<strong>它需要非常大,比较多的运算资源</strong>,你想想看,本来一般在训练模型的时候,走到这边就结束了,你有训练资料 训练完模型就结束了,但是 Adversarial Training 它的问题是,首先你要花时间,找出这些$ X^′$,你的图片有几张,你可能就要找出多少张的 $ X^′$,100 万张图片,你要找 100 万个 $ X^′$,光做这件事,可能就已经很花时间了</p>
<p>所以你会发现说,如果你的 Dataset 很大的时候,大家通常就不会想要做 Adversarial Training,所以 Adversarial Training,是一个比较吃运算资源的方法,那為了解决这个问题,有人发明了一个方法叫做,==Adversarial Training For Free==,这边我们就不细讲,有一些方法是做到 Adversarial Training 的效果,却没有 Adversarial Training 那麼大的,Computing 的 Intensity,那至於怎麼做到 Adversarial Training For Free,怎麼不在使用额外的计算的情况下,就达到 Adversarial Training 的效果,那这个把文献放在这边,留给大家参考</p>
<p>那到目前為止呢,我们就是告诉大家,有攻击这件事情,攻击非常容易成功,黑箱攻击也是有可能成功的,然后跟大家介绍了几种经典的 Defense 的方式,那目前攻击跟防御啊,它们都,这些方法仍然不断地在演化</p>
<img src="/images/loading.gif" data-original="../images/ML/image-20210815235410923.png" style="zoom:50%;">

<p>所以在国际会议会不断看到,有新的攻击方法被提出,有<strong>新的防御方法被提出,它们仍然都在进化中,那不知道最后会是谁胜谁负</strong>,好 那这个是今天的现况</p>
<h1 id="Explainable-AI"><a href="#Explainable-AI" class="headerlink" title="Explainable AI"></a>Explainable AI</h1><h2 id="Why-we-need-Explainable-ML"><a href="#Why-we-need-Explainable-ML" class="headerlink" title="Why we need Explainable ML?"></a>Why we need Explainable ML?</h2><p>那开始之前,开始介绍技术之前,我们需要讲一下,為什么 Explainable 的 Machine Learning,是一个重要的议题呢,我觉得那个本质上的原因是,就算今天机器可以得到正确的答案,也不代表它一定非常地聪明,举一个例子,过去有一匹马它很聪明,所以大家叫它<strong>神马汉斯</strong>,那这个神马汉斯可以做什么事情呢</p>
<img src="/images/loading.gif" data-original="../images/ML/image-20210822105149972.png" style="zoom:67%;">

<p><strong>它会做数学问题</strong>,举例来说,你问它根号 9 是多少,然后它就开始计算得到答案,它怎么告诉你它的答案呢,它会用它的马蹄去跺地板,所以如果答案是 3,它就敲三下,然后就停下来,代表它得到正确的答案,然后旁边的人就会欢呼,所以这个是神马汉斯,然后一堆人呢,在看它解数学问题</p>
<p>后来有人就很怀疑说,為什么汉斯可以解数学问题呢,它只是一匹马,它為什么能够理解数学问题呢,后来有人发现说,只要没有人围观的时候,汉斯就会答不出数学问题,没有人看它的时候,你问它一个数学的问题,它就会不断地敲它的马蹄,不知道什么时候停下来,所以<strong>它其实只是侦测到,旁边人类微妙的情感变化,知道它什么时候要停下跺马蹄</strong>,它就可以有胡萝卜吃,<strong>它并不是真的学会解数学的问题</strong>,而今天我们看到种种人工智慧的应用,有没有可能跟神马汉斯是一样的状况</p>
<p>而今天在很多真实的应用中,Explainable 的 Machine Learning,可解释性的模型往往是必须的</p>
<img src="/images/loading.gif" data-original="../images/ML/image-20210822105529184.png">

<p>举例来说</p>
<ul>
<li>银行今天可能会用机器学习的模型,来判断要不要贷款给某一个客户,但是根据法律的规定,银行作用机器学习模型来做自动的判断,它必须要给出一个理由,所以这个时候,我们不是只训练机器学习模型就好,我们还需要机器学习的模型,是具有解释力的</li>
<li>或者是说机器学习未来,也会被用在医疗诊断上,但医疗诊断人命关天的事情,如果机器学习的模型只是一个黑箱,不会给出诊断的理由的话,那我们又要怎么相信,它做出的是正确的判断呢</li>
<li>今天也有人想,把机器学习的模型用在法律上,比如说帮助法官判案,帮助法官自动判案说,一个犯人能不能够被假释,但是我们怎么知道机器学习的模型,它是公正的呢,我们怎么知道它在做判断的时候,没有种族歧视等其他的问题呢,所以我们希望机器学习的模型,不只得到答案,它还要给我们得到答案的理由</li>
<li>再更进一步,今天自驾车未来可能会满街跑,当今天自驾车突然急剎的时候,甚至急剎导致车上的乘客受伤,那这个自驾车到底有没有问题呢,这也许取决於它急剎的理由,如果它是看到有一个老太太在过马路,所以急剎,那也许自驾车是对的,但是假设它只是无缘无故,就突然发狂要急剎,那这个模型就有问题了,所以对自驾车,它的种种的行為 种种的决策,我们希望知道决策背后的理由</li>
</ul>
<p>更进一步,也许机器学习的模型,如果具有解释力的话,那未来我们可以凭<strong>藉著解释的结果,再去修正我们的模型</strong></p>
<img src="/images/loading.gif" data-original="../images/ML/image-20210822105715875.png" style="zoom:50%;">

<p>今天在使用这些深度学习技术的时候,往往状况是这个样子,有某人说,这个就是你的机器学习的系统,是啊 我就是<strong>把资料丢进去,裡面就是有很多矩阵的相乘</strong>,接下来呢,就会跑出我的结果,如果结果<strong>不如预期的话</strong>,怎么样呢,现在大家都知道就<strong>爆调一下参数</strong>对不对,改个 Learning Rate 对不对,调一下 Network 的架构对不对,你根本不知道自己在做什么对不对,就调一下 Network 的架构,我就把这一堆数学,<strong>这一堆 Linear Algebra 再重新打乱一下,看看结果会不会比较好</strong>,那如果其它没有做过 Deep Learning 的人,就会大吃一惊,觉得哇 这样怎么可以呢</p>
<img src="/images/loading.gif" data-original="../images/ML/image-20210822105744752.png" style="zoom:50%;">

<p>但实际上今天深度学习的模型,你往往要改进模型,就是需要调一些 Hyperparameter,但是我们期待也许未来,当我们知道,Deep Learning 的模型犯错的时候,它是错在什么样的地方,它為什么犯错,也许我们可以有更好的方法,更有效率的方法,来 Improve 我的模型,当然这个是未来的目标,今天离用 Explainable 的 Machine Learning,<strong>做到上述  Improve Model 的想法,还有很长的一段距离</strong></p>
<h2 id="Interpretable-v-s-Powerful"><a href="#Interpretable-v-s-Powerful" class="headerlink" title="Interpretable v.s. Powerful"></a>Interpretable v.s. Powerful</h2><p>那讲到这边呢,有人可能会想说,我们今天之所以这么关注,Explainable Machine Learning 的议题,也许是因為 Deep 的 Network,它本身就是一个黑箱,那我们能不能够用,其它的机器学习的模型呢</p>
<p><strong>如果不要用深度学习的模型,改採用其他比较容易解释的模型,会不会就不需要研究,Explainable Machine Learning 了呢</strong>,举例来说,假设我们都<strong>採用 Linear 的 Model,Linear 的 Model,它的解释的能力是比较强的</strong>,我们可以轻易地知道,根据一个 Linear Model 裡面的,每一个 Feature 的 Weight,知道 Linear 的 Model 在做什么事</p>
<img src="/images/loading.gif" data-original="../images/ML/image-20210822110102463.png">

<p>所以你训练完一个 Linear Model 以后,你可以轻易地知道,它是怎么得到它的结果的,但是  <strong>Linear Model 的问题就是,它没有非常地 Powerful</strong>,我们其实在第一堂课就已经告诉你说,Linear 的 Model 有很巨大地限制,所以我们才很快地进入了 Deep 的 Model</p>
<p>但是 <strong>Deep 的 Model 它的坏处就是,它不容易被解释</strong>,Deep 的 Network 大家都知道,它就是一个黑盒子,黑盒子裡面发生了什么事情,我们很难知道,虽然它比 Linear 的 Model 更好,但是它的解释的能力,是远比 Linear 的 Model 要差</p>
<p>所以讲到这边,很多人就会得到一个结论,你可能常常听到这样的想法,我们就不应该用这种 Deep 的 Model,我们不该用这些比较 Powerful 的 Model,因為它们是黑盒子,但是在我看来,这样的想法其实就是削足适履,我们因為一个模型,它非常地 Powerful,但是不容易被解释就扬弃它吗,我们不是应该是想办法,让它具有可以解释的能力吗</p>
<p>我听过Yann LeCun讲了一个故事,这个是Yann LeCun讲的,那这个故事是个老梗,谁都听过</p>
<img src="/images/loading.gif" data-original="../images/ML/image-20210822110255158.png">

<p>就是有一个醉汉,他在路灯下面找钥匙,大家问他说,你的钥匙掉在路灯下吗,他说不是,因為这边有光</p>
<p>那所以我们坚持一定要用简单,但是比较容易被解释的模型,其实就好像是,我们坚持一定要在路灯下面,找钥匙一样,我们坚持因為一个模型,是比较 Interpretable 的,虽然它比较不好,但我们还是坚持要使用它</p>
<p>就好像一定要在路灯下面找钥匙一样,不知道说真实的模型,<strong>真实 Powerful 的模型,也许根本在路灯的范围之外</strong>,而我们现在要做的事情,就是改变路灯的范围,改变照明的方向,看能不能够让这些比较 Powerful 的模型,可以被置於路灯之下,比较 Interpretable,比较 Explainable</p>
<p>其实 <strong>Interpretable 跟 Explainable</strong>,这两个词汇,虽然在文献上常常被互相使用,那其实它们是<strong>有一点点差别</strong>的</p>
<ul>
<li>通常这个 Explainable 指的是说,有一个东西它本来是个黑箱,我们想办法赋予它解释的能力,叫做 Explainable</li>
<li>那 Interpretable 通常指的是,一个东西它本来就不是黑箱,我们可以跟,它本来就不是黑箱,我们本来就可以知道它的内容,这个叫 Interpretable,好 不过这两者在文献上也常常被混用了,所以我们这边就不特别跟大家强调,Explainable 跟 Interpretable 的差异,好 </li>
</ul>
<p>那讲到既 Interpretable 又 Powerful 的模型,也许有人会说,那 ==Decision Tree== 会不会就是一个好的选择呢,Decision Tree 相较於 Linear 的 Model,它是更强大的模型</p>
<img src="/images/loading.gif" data-original="../images/ML/image-20210822110924962.png">

<p>而 Decision Tree 的另外一个好处,<strong>相较於 Deep Learning,它非常地 Interpretable</strong>,你看一个 Decision Tree 的 Structure,你就可以知道说,今天模型是凭藉著什么样的规则,来做出最终的判断,那 Decision Tree,不是我们这门课会讲的东西</p>
<p>但是就算是你没有学过的 Decision Tree,你其实也不难想像,Decision Tree 它是在做什么,它做的事情就是,你有很多的节点,那每一个节点都会问一个问题,让你决定向左还是向右,最终当你走到节点的末尾,当你走到 Leaf Node 的时候,就可以做出最终的决定,因為在每一个节点都有一个问题,你看那些问题以及答案,你就可以知道,现在整个模型,凭藉著什么样的特徵,是如何做出最终的决断,所以从这个角度看来,<strong>Decision Tree,它既强大又 Interpretable</strong></p>
<img src="/images/loading.gif" data-original="../images/ML/image-20210822111014791.png" style="zoom:67%;">

<p>所以这堂课我们可以就上到这边,就是 Decision Tree is all you need?,然后就结束了这样子</p>
<p>但是 Decision Tree,真的就是我们所需要的吗,你再仔细想一下,<strong>Decision Tree 也有可能是很复杂的</strong></p>
<img src="/images/loading.gif" data-original="../images/ML/image-20210822111138323.png">

<p>举例来说,我看到在网路上找到,有人问了一个问题,他说他有一个这么复杂的 Decision Tree,他完全看不懂这个 Decision Tree 在干嘛,有没有人有什么样的,Explainable Machine Learning 的方法,可以把这个 Decision Tree 变得更简单一点,我看三 四年过去了,都没有人回答这个问题,有人看到的话,也许可以帮忙回答一下</p>
<p>但另外一方面,你再仔细想想看,你是怎么实际使用 Decision Tree 这个技术的呢,我知道很多同学都会说,这个打 Cargo 比赛的时候,Deep Learning 不是最好用,什么 Decision Tree,那个才是最好用的,那才是 Cargo 比赛的常胜军,但是你想想看,当你在使用 Decision Tree 技术的时候,你是只用一棵 Decision Tree 吗,其实不是,你真正用的技术叫做 ==Random Forest== 对不对,你真正用的技术,其实是<strong>好多棵 Decision Tree 共同决定的结果</strong>,一棵 Decision Tree,你可以凭藉著每一个节点的问题跟答案,知道它是怎么做出最终的判断的,但当你有一片森林,当你有 500 棵 Decision Tree 的时候,你就很难知道说,这 500 棵 Decision Tree 合起来,是怎么做出判断,所以 Decision Tree 也不是最终的答案,并不是有 Decision Tree,我们就解决了,Explainable Machine Learning 的问题</p>
<h2 id="Goal-of-Explainable-ML"><a href="#Goal-of-Explainable-ML" class="headerlink" title="Goal of Explainable ML"></a>Goal of Explainable ML</h2><p>那再继续深入讲,Explainable Machine Learning 的技术之前,这边还有一个问题就是,<strong>Explainable Machine Learning 的目标是什么</strong></p>
<p>在我们之前的每一个作业裡面,我们都有一个 Leaderboard,也就是我们有一个明确的目标,要嘛是降低 Error Rate,要嘛是提升 Accuracy,我们总是有一个明确的目标,但是 Explainable 的目标到底是什么呢？什么才是最好的 Explanation 的结果呢,那 Explanation 它的目标其实非常地不明确,就是因為目标不明确,你才发现说 Explainable Machine Learning 的作业,就没有 Leaderboard,因為出不了 Leaderboard,我们只能够出选择题,让大家增加一些知识,我们只能够做这样子而已</p>
<p>那但到底 Explainable Machine Learning,它的终极目标是什么呢,什么才是最好的 Explanation,那<strong>以下是我个人的看法,并不代表它是对的,你可能不认同,那我也不会跟你争辩</strong>,那这个只是我个人的看法而已</p>
<p><strong>很多人对於 Explainable Machine Learning会有一个误解</strong>,它觉得一个好的 Explanation,就是要告诉我们,整个模型在做什么事,我们要了解模型的一切,我们要知道它到底是,我们要完全了解,它是怎么做出一个决断的,但是你想想看,这件事情真的是有必要的吗,我们今天说 Machine Learning 的 Model,<strong>Deep 的 Network 是一个黑盒子,所以我们不能相信它</strong></p>
<p>但你想想看,世界上有很多很多的黑盒子,正在你的身边,<strong>人脑不是也是黑盒子吗,我们其实也并不完全知道,人脑的运作原理,但是我们可以相信,另外一个人做出的决断</strong>,那人脑其实也是一个黑盒子,你可以相信人脑做出了决断,為什么 Deep 的 Netwok 是一个黑盒子,你没有办法相信,Deep 的 Netwok 做出来的决断,為什么你对 Deep 的 Netwok 会这么恐惧呢,那我觉得其实对人而言,也许一个东西,能不能让我们放心,能不能够让我们接受,理由是非常重要的,以下呢,是一个跟 Machine Learning,完全无关的心理学实验</p>
<img src="/images/loading.gif" data-original="../images/ML/image-20210822111733696.png">

<p>这个实验是 1970 年代就做了,这是 Ellen Langer,一个哈佛大学教授做的,这个实验非常地有名,这个实验是这样,这个实验是一个跟印表机有关的实验,在哈佛大学图书馆印表机呢,会大排长龙,很多人都排队要印东西,这个时候</p>
<ul>
<li>如果有一个人跟他前面的人说,拜託请让我先印,我就印 5 页而已,那一般人会不会接受呢,会不会让他先印呢,有 60% 的人会让这个人先印,所以感觉哈佛大学,学生人都还蛮好的,这个是接受程度是比我预期得要高,你给一个人说让我先印,有 60% 的人会答应</li>
<li>但这个时候,你只要把刚才问话的方法稍微改一下,你本来只说能不能让我先印,现在改成说,能不能让我先印,因為我赶时间,他是不是真的赶时间,没人知道,但是当你说你有一个理由,所以你要先印的时候,这个时候接受的程度变成 94%</li>
<li>而神奇的事情是,就算你的理由稍微改一下,举例来说,有人说请让我先印,因為我需要先印,光是这个样子,接受的程度也变成 93%,所以神奇的事情是,人就是需要一个理由,你為什么要先印,你只要讲出一个理由,就算你的理由是因為我需要先印,大家也会接受</li>
</ul>
<p>什么叫做好的 Explanation,<strong>好的 Explanation就是人能接受的 Explanation</strong>,人就是需要一个理由让我们觉得高兴,而到底是让谁高兴呢</p>
<img src="/images/loading.gif" data-original="../images/ML/image-20210822112022693.png" style="zoom: 67%;">

<p>这个是高兴的人,可能是你的客户,因為很多人就是听到,Deep Network 是一个黑盒子,他就不爽,你告诉他说这个是可以被解释的,给他一个理由,他就高兴了,他可能是你的老闆,老闆看了很多的农场文,他也觉得说 Deep Learning 黑盒子就是不好的,告诉他说这个是可以解释的,他就高兴了,或者是你今天要让,你今天要说服的对象是你自己,你自己觉得有一个黑盒子,Deep Network 是一个黑盒子,你心裡过不去,今天它可以给你一个做出决断的理由,你就高兴了</p>
<p>所以我觉得什么叫做好的 Explanation,就是让人高兴的 Explanation,就是好的 Explanation,其实你等一下再记,在各种研究的发展上会发现说,我们在设计这些技术的时候,确实跟我现在讲的,什么叫好的 Explanation,就是让人高兴的 Explanation,这个想法,这个技术的进展是蛮接近的</p>
<h2 id="Explainable-ML"><a href="#Explainable-ML" class="headerlink" title="Explainable ML"></a>Explainable ML</h2><p>所以 Explainable Machine Learning,它的目标就像我刚才讲的,就是要给我们一个理由,那 Explainable 的 Machine Learning 呢,又分成两大类,第一大类叫做 ==Local 的 Explanation==,第二大类叫做 ==Global 的 Explanation==</p>
<img src="/images/loading.gif" data-original="../images/ML/image-20210822112442282.png" style="zoom:67%;">

<p>Local 的 Explanation 是说,假设我们有一个 Image 的 Classify,我们给它一张图片,它判断说它是一只猫,那我们要问的问题是,為什么,或者机器要回答问题是,<strong>為什么你觉得这张图片是一只猫,它根据某一张图片来回答问题</strong>,这个叫做 Local Explanation</p>
<p>还有另外一类呢,叫 Global Explanation,意思是说,现在还没有给我们的 Classifier任何图片,我们要问的是,对一个 Classifier 而言,什么样的图片叫做猫,我们<strong>并不是针对任何一张,特定的图片来进行分析</strong>,我们是想要知道说,当我们有<strong>一个 Model,它裡面有一堆参数的时候,对这堆参数而言,什么样的东西叫作一只猫</strong>,所以 Explainable 的 Machine 有两大类</p>
<h3 id="Local-Explanation"><a href="#Local-Explanation" class="headerlink" title="Local Explanation"></a><strong>Local Explanation</strong></h3><p>我们先来看第一大类,第一大类是為什么,你觉得一张图片是一只猫</p>
<h4 id="Which-component-is-critical"><a href="#Which-component-is-critical" class="headerlink" title="Which component is critical?"></a>Which component is critical?</h4><p>我们可以把一个图片,这个问题问得更具体一点,给机器一张图片,它知道它是一只猫的时候,<strong>到底是这个图片裡面的什么东西,让模型觉得它是一只猫</strong></p>
<img src="/images/loading.gif" data-original="../images/ML/image-20210822150222534.png">

<p>是眼睛吗,是耳朵吗,还是猫的脚,让机器觉得它看到了一只猫,或者讲的更 General 一点,假设现在我们模型的输入叫做 x,这个 x 可能是一张影像,可能是短文字,而 x 呢,可以<strong>拆成多个 Component</strong>,$x_1$ 到 $x_N$,如果对於影像而言,可能每一个 Component,就是一个 Pixel,那对於文字而言,可能每一个 Component,就是一个词汇,或者是一个 Token,那我们现在要问的问题就是,这些  Token 裡面,那这些 Component 裡面,那这个如果对文字来说是 Token,对 Image 来说可能就是 Pixel,这些 Component 裡面,哪一个对於机器现在做出最终的决断是最重要的呢</p>
<p>那怎么知道一个 Component 的重要性呢,那基本的原则是这个样子,就是我们<strong>把 Component 都拿出来,然后把每一个 Component 做改造,或者是删除,如果我们改造或删除某一个 Component 以后,今天 Network 的输出有了巨大的变化</strong>,那我们就知道说,这个 Component 没它不行,它很重要,如果某个 Component 被删掉以后,现在 Network 的输出有了巨大的变化,就代表这个 Component,没它不行,那这个 Component,就是一个重要的 Component</p>
<p>讲得更具体一点,你想要知道,今天一个影像裡面,每一个区域的重要性的时候,有一个非常简单的方法</p>
<img src="/images/loading.gif" data-original="../images/ML/image-20210822151353180.png" style="zoom:50%;">

<p>像是这个样子,就给一张图片,然后丢到 Network 裡面,它知道这是一只博美狗,接下来在这个图片裡面,<strong>不同的位置放上这个灰色的方块</strong>,当这个方块放在不同的地方的时候,今天你的 Network 会 Output 不同的结果</p>
<p>那这边这个,下面这个图 这些顏色,代表今天 Network 输出博美狗的机率,<strong>蓝色代表博美狗的机率是低的,红色代表博美狗的机率是高的</strong>,而这边的每一个位置,代表了这个灰色方块的位置,也就是说,当我们把灰色的方块移到这边,移到这边,移到博美狗的脸上的时候,今天你的 Image Classifier,就不觉得它看到一只博美狗,如果你把灰色的方块,放在博美狗的四周,这个时候机器就觉得,它看到的仍然是博美狗,所以知道说,它不是看到这个球,觉得它看到博美狗,也不是看到地板,也不是看到墙壁,觉得看到博美狗,而是真的看到这个狗的脸,所以它觉得,它看到了一只狗</p>
<p>那这边也有一样的例子,把灰色的方框在,把灰色的方块在这个图片上移动,你会发现说呢,灰色的方块移到轮胎上的时候,机器就不觉得它有看到轮胎了,所以机器知道轮胎长什么样子,它今天看到这个图片,知道答案是轮胎的时候,并不是瞎蒙蒙到的,而是它知道说,轮胎出现在这个位置,或者是说这边有一张图片,然后这个图片裡面有两个人</p>
<p>还有一只这个阿富汗猎犬,但是机器到底是真的看到了阿富汗猎犬,还是把人误认為狗呢,这个时候你就可以把这个灰色的方框,在这个图片上移动,然后你发现这个灰色的方框,放在这个人的脸上,或放在这个人的脸上的时候,机器仍然觉得,它有看到阿富汗猎犬,但是当你把灰色的方框,放到这个位置,放到这个位置的时候,机器就觉得,它没有看到阿富汗猎犬,所以它是真的有看到阿富汗猎犬,它知道这一只就是阿富汗猎犬,并不是把人误认為阿富汗猎犬,所以这个是最简单的,知道 Component 重要性的方法</p>
<h4 id="Saliency-Map"><a href="#Saliency-Map" class="headerlink" title="Saliency Map"></a>Saliency Map</h4><p>接下来还有一个更进阶的方法,是<strong>计算 Gradient</strong>,这个方法是这样子的</p>
<img src="/images/loading.gif" data-original="../images/ML/image-20210822151827632.png">

<p>假设我们有一张图片,我们把它写作 $x_1$ 到 $x_N$,这边的<strong>每一个 x,代表了一个 Pixel</strong>,接下来呢,我们去计算这张图片的 Loss,我们这边呢,用小 e 来表示,这个小 e 是什么呢,<strong>这个小 e 是把这张图片呢,丢到你的模型裡面,这个模型的输出的结果跟正确答案的差距</strong>,跟正确答案的 ==Cross Entropy==,这个 <strong>e 越大</strong>,就代表现在辨识的<strong>结果越差</strong></p>
<p>那接下来,怎么知道某一个 Pixel,对於影像辨识这个问题的重要性呢,那你就把某一个 Pixel 的值,做一个小小的变化,把它加上一个 Δx,然后你接下来看一下,你的 Loss 会有什么样的变化</p>
<ul>
<li>如果今天把<strong>某一个 Pixel,做小小的变化以后,Loss 就有巨大的变化</strong>,代表说<strong>这个 Pixel,对影像辨识是重要的</strong></li>
<li>反之如果加了 Δx,这个 Δe 趋近於零,这个 Loss 完全没有反应,就代表说这个 Δx,这个位置,这个 Pixel 对於影像辨识而言,可能是不重要的</li>
</ul>
<p>那我们可以用 Δe 跟 Δx 的比值,来代表这一个 Pixel,$x_N$ 的重要性,而事实上 Δx 分之 Δe 这一项,就是把 $x_N$ 对你的 Loss 做偏微分,如果你不知道偏微分是什么的话也没有关係,反正就是 Δx 跟 Δe 的比值,就代表了这个 $x_N$ 的重要性,那这个比值越大,就代表 $x_N$ 越重要</p>
<p>那你把每一个图片裡面,每一个 Pixel,它的这个比值都算出来,你就得到一个图呢,叫做 ==Saliency Map==,它在我们的作业裡面,你会有很多机会,画各式各样的 Saliency Map,那下面这个图,上面这个是原始图片,下面这个黑色的,然后有亮白色点的是 Saliency Map</p>
<p>那在这个  Saliency Map 上面呢,<strong>越偏白色就代表这个比值越大,也就是这个位置的 Pixel 是越重要的,</strong></p>
<p>举例来说,给机器看这个水牛的图片,它并不是看到草地,觉得它看到牛,也不是看到竹子,觉得它看到牛,而是真的知道牛在这个位置,它觉得判断这张图片是什么样的类别,对它而言最重要的,是出现在这个位置的 Pixel,像是真的看到牛,所以知道说,所以才会 Output 牛这个答案,如果机器看到这个图片,说它看到一个猴子,那猴子在哪裡呢,猴子在树梢上面,它并不是把叶子判断成猴子,它知道这个位置出现的东西,就是它判断正确答案的準则,我给它这个图片,它知道说狗呢,是出现在这个位置的,所以这个,这个技术呢 叫做 Saliency Map</p>
<p>那 Saliency Map 这个技术,我们等一下来举一个实际的应用,这个应用是什么呢,这个应用跟宝可梦还有数码宝贝有关啦,</p>
<p>这个宝可梦是一种动物,数码宝贝是另外一种动物,然后我在网路上呢,看到有人说,他训练了一个数码宝贝跟宝可梦的分类器,然后正确率非常地高,所以我决定自己也来做这个实验,看看為什么可以得到这么高的正确率</p>
<img src="/images/loading.gif" data-original="../images/ML/image-20210822152912268.png">

<p>那你可以在网路上呢,找到宝可梦的图库,也可以找到数码宝贝的图库,所以你有一堆宝可梦的图,有一堆数码宝贝的图,那这个对大家来说一定都不成问题,这个就是二元分类的问题而已 对不对,胡乱 Train 一个 Classifier,就结束了,就把作业三的 Code 改一改,然后把本来分成 11 类,改成分成两类,就结束了</p>
<p>那接下来呢,训练完以后呢,当然要用机器没有看过的图去测试它,所以你不能够把所有的宝可梦,跟所有的数码宝贝都拿去做训练,你要特别留一些宝可梦跟数码宝贝,是训练的时候没有看过的,看看机器看到新的宝可梦跟数码宝贝,它能不能够得到正确的结果,那这边呢,我们来看一下人类,能不能够正确的判断宝可梦跟数码宝贝好了</p>
<p>我来问一下大家,你觉得这一只</p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20210822152958235.png" alt=""></p>
<p>是宝可梦 还是数码宝贝呢,觉得它是宝可梦的同学举手一下,手放下,觉得它是数码宝贝的同学举手一下,好 也有一些,好 手放下,好 老实说我答案忘记了这样子,所以,所以你可见这个宝可梦跟数码宝贝,是很难分辨的,今天你就算是人类,你也很难够,很难判断说一只动物,到底是宝可梦还是数码宝贝,机器的表现如何呢</p>
<p>好 这边就是随便兜了一个模型,也没有几层,Train 下去</p>
<img src="/images/loading.gif" data-original="../images/ML/image-20210822153122800.png">

<p>哇 Training Accuracy,98.9% 这个非常地高,但是不要高兴地太早,这个也许Overfitting 而已,也许 Machine 只是把 Training 的 Data,记下来而已,因為毕竟训练资料没几张啊,数码宝贝 宝可梦才各几千张而已,所以也许Overfitting,所以测试资料上没看过的图怎么样呢,正确率 98.4 啊,这个不可思议,这个伟哉机器学习,这个人类都没有办法判断,宝可梦跟数码宝贝的差异,但机器可以,还有 98.4% 的正确率</p>
<p>那接下来我就很好奇,就想要知道说,机器到底是凭藉著什么样的规则,判断宝可梦和数码宝贝的差异呢,所以我决定来画一下 Saliency Map</p>
<p>这边有几只动物,它们是什么呢,它们是数码宝贝</p>
<img src="/images/loading.gif" data-original="../images/ML/image-20210822153309916.png">

<p>这些是数码宝贝,接下来呢,我就在这些图片上画 Saliency Map,让机器来告诉我说,為什么它觉得这几张是数码宝贝,机器给我的答案是这个样子,这边亮亮的点,代表它觉得比较重要,这有点怪怪的,好像亮亮的点都分布在四个角落,不知道发生了什么事</p>
<p>接下来我来分析宝可梦,这个情况更明显</p>
<img src="/images/loading.gif" data-original="../images/ML/image-20210822153335506.png">

<p>你发现说机器觉得重要的点,基本上都是避开宝可梦的本体啦,都是在影像的背景上啊,為什么呢</p>
<p>因為我后来发现</p>
<img src="/images/loading.gif" data-original="../images/ML/image-20210822153414633.png" style="zoom:67%;">

<p><strong>宝可梦都是 PNG 档啦,数码宝贝都是 JPEG 档,PNG 档读进来以后,背景都是黑的啦,所以机器只要看背景,就知道一张图片是宝可梦还是数码宝贝</strong>啦,就结束了这样子,好,所以这个例子就是告诉我们说,Explainable AI 是一个很重要的技术</p>
<p>那我刚才举的例子可能你觉得有点荒谬,也许在正常的应用中不会发生这种事情,但真的不会发生吗</p>
<p>有一个真实的例子,有一个 Benchmark Corpus,叫做 PASCAL VOC 2007,裡面有各式各样的物件,机器要学习做影像的分类,机器看到这张图片</p>
<img src="/images/loading.gif" data-original="../images/ML/image-20210822162942014.png">

<p>它知道是马的图片,但如果你画 Saliency Map 的话,你发现结果是这个样子的,只是觉得左下角对马是最重要,為什么,因為左下角有一串英文啊,这个图库裡面马的图片,很多都是来自於某一个网站啊,左下角都有一样的英文啊,所以机器看到左下角这一行英文,就知道是马,它根本不需要学习马是长什么样子</p>
<p>所以今天在这个真实的应用中,在 Benchmark Corpus 上,类似的状况也是会出现的,所以这告诉我们,这种 Explainable Machine Learning,这个技术是很重要的</p>
<p>那有没有什么方法,把 Explainable 的 Machine Learning,Saliency Map 画得更好呢,第一个方法啊,就是助教刚才有提到的这个 ==SmoothGrad==,什么意思呢,这张图片是指瞪羚</p>
<img src="/images/loading.gif" data-original="../images/ML/image-20210822163130815.png">

<p>那你期待说,你今天去做 Saliency Map 的时候,机器会把它主要的精力,集中在瞪羚身上</p>
<p>那如果你用刚才我们讲的方法,直接画 Saliency Map 的话,你得到的结果可能是这个样子,确实今天在,确实在瞪羚附近有比较多亮的点,但是在其他地方也有一些杂讯,让人看起来有点不舒服,所以就有了 SmoothGrad 这个方法,SmoothGrad 会让你的这个 Saliency Map,上面的杂讯比较少</p>
<p>如果在这个例子上,你就会发现多数的亮点,真的都集中在瞪羚身上,那 SmoothGrad 这个方法是怎么做呢,非常简单,说穿了也不值钱</p>
<p>就是你<strong>在你的图片上面啊,加上各种不同的杂讯</strong>,那加不同的杂讯就是不同的图片了嘛,每一张图片上面,都去计算 Saliency Map,那你有加 100 种杂讯,就有 100 张 Saliency Map,平均起来,就得到 SmoothGrad 的结果,就结束了</p>
<p>当然有人会问说,欸 那你怎么知道说这个 SmoothGrad,这样子的结果一定就是比原来的结果好呢,也许对机器来说,它真的觉得这些草很重要啊,它真的觉得这个天空很重要啊,它真的觉得这个背景很重要啊</p>
<p>也许是,那就像我一开始说的,<strong>Explainable Machine Learning 最重要的目标,就是要让人看了觉得爽</strong>啊,你画了这个图,你的老闆就会觉得不爽啊,他就会觉得,哇 这个 Model 有点烂哦,这个 Model 解释性好像很低哦,所以你就会把它画成 SmoothGrad 这个样子,然后告诉别人说,你看这个 Model,它果然知道瞪羚是最重要的啊,所以这个,嗯 这个 Model 不错,然后这个,Explainable Machine Learning 的方法也不错</p>
<p>但是呢,其实光看  Gradient,并不完全能够反映一个 Component 的重要性,怎么说呢,这边就举一个例子给大家参考</p>
<img src="/images/loading.gif" data-original="../images/ML/image-20210822163551094.png">

<ul>
<li>这个横轴代表的是大象鼻子的,某一个生物鼻子的长度</li>
<li>那纵轴代表说这个生物是大象的可能性</li>
</ul>
<p>我们都知道说大象的特徵,就是长鼻子,所以一个生物,它的鼻子越来越长,它就越有可能是大象,但是当它的鼻子长到一个极限的时候,再变更长一点,它也不会变得更像大象,鼻子很长的大象,就只是鼻子特别长的大象,所以当一个大象的鼻子变长的时候,长到超出一个范围的时候,你也不会觉得它变得更像大象</p>
<p>所以 鼻子的,生物鼻子的长度跟它是大象的可能性,它的关係,也许一开始在长度比较短的时候,随著长度越来越长,今天这个生物是大象的可能性越来越大,但是<strong>当鼻子的长度长到一个程度以后,就算是更长,也不会变得更像大象</strong></p>
<p>这个时候,如果你计算鼻子长度,对是大象可能性的偏微分的话,那你在这个地方得到的<strong>偏微分,可能会趋近於 0</strong>,所以如果你<strong>光看 Gradient,光看 Saliency Map</strong>,你可能会得到一个结论是,<strong>鼻子的长度,对是不是大象这件事情是不重要的</strong>,鼻子的长度不是判断是否為大象的一个指标,因為鼻子的长度的变化,对是大象的可能性的变化,是趋近於 0 的,所以鼻子根本不是,判断是不是大象的重要的指标</p>
<p>那事实上是这样吗,<strong>事实上你知道不是这个样子</strong>,所以光看 Gradient,光看偏微分的结果,可能没有办法完全告诉我们,一个 Component 的重要性,所以有其他的方法,有一个方法叫做 I==nterated 的 Gradient==,它的缩写叫做 IG,那这边,我就不打算详细讲说 IG 是怎么运作的,我们就把文件留在这边,那助教的程式裡面也有实作的 IG,那如果你有兴趣,你可以自己研究看看 IG 是怎么运作的,如果你没有兴趣,反正你按个 Enter,就跑出那个 IG 的分析的结果了</p>
<h4 id="How-a-network-processes-the-input-data"><a href="#How-a-network-processes-the-input-data" class="headerlink" title="How a network processes the input data?"></a>How a network processes the input data?</h4><p>好 那刚才我们是看 <strong>Network 它是,我们刚才是看一个输入,它的哪些部分是比较重要的</strong>,那接下来我们要问的下一个问题是,当我们给 Network 看一个输入的时候,它到底是怎么去处理这个输入的呢,它到底是怎么对输入做处理,然后得到最终的答案的呢</p>
<p>那有不同的方法,第一个方法最直觉的,就是<strong>人眼去看,今天 Network 裡面到底发生了什么事情</strong>,那在作业裡面,是要你去看 BERT 裡面发生了什么事情,是跟文字有关的,那上课举的例子,我们就举语音的例子,在作业二裡面,你已经训练了一个 Network</p>
<img src="/images/loading.gif" data-original="../images/ML/image-20210822170925033.png">

<p>这个 Network 就是吃一小段声音当中输入,判断说这段声音,是属於哪一个 Phoneme,属於哪一个 KK 音标,然后呢,假设你第一个 Layer 有 100 个 Neurons,第二个 Layer 也有 100 个 Neurons,那第一个 Layer 的输出,就可以看作是 100 维的向量,第二个 Layer 的输出,也可以看作是 100 维的向量,通过这些分析这些向量,也许我们就可以知道一个 Network 裡面,发生了什么事</p>
<p>但是 <strong>100 维的向量,不容易看 不容易观察 不容易分析</strong>,所以怎么办呢,你有很多方法,可以<strong>把 100 维的向量,把它降到二维</strong>,那至於是什么方法,我们这边就不细讲,总之这些方法有一箩筐可以使用,把 100 维降到二维以后,你就可以画在图上,那你就可以细心地观察它,看看你可以观察到什么现象</p>
<p>以下呢,举的是语音的例子,那这个例子来自於一篇 2012 年的 Paper</p>
<img src="/images/loading.gif" data-original="../images/ML/image-20210822171352633.png">

<p>你会发现 Hinton,这个深度学习之父,也是这篇文章的作者,这篇文章做的事情是什么呢,这篇文章,其实老实说,这篇文章做的就是你的作业二 知道吗,它跟你作业二用的 Data 是一模一样的</p>
<p>所以假设你穿越时空到十年前,拿你作业二的结果给 Hinton 看,他就吓一跳这样子,你可以顺便告诉他说,这个只是我们 15 个作业的其中一个而已,他就吓一跳了,你还可以告诉他说,哦 这个,我只 Train 了一个小时就 Train 完了,那个时候要 Train 类似的东西,大概要 Train 个一週以上吧,然后 Hinton 就会吓一跳这样子,所以看到这些过去的文章啊,我真的只能说,哇 这个大人 时代变了啊,以前 Train Network 多么麻烦,现在真的是时代变了,而且其实那个时候用的是 <strong>Deep Belief Network</strong>,Deep Belief Network,是 Deep Neural Network吗,不是这样子,那这个是什么东西呢,这个我们就不会讲它,因為现在已经没有人在用这个东西了,好 那但是它得到的结果啊,还是蛮值得我们今天拿来看的,其实你在作业二,应该也可以观察到类似的结果</p>
<p>这边做的事情是什么呢,这边做的事情是,首先我们把模型的 Input,就是 Acoustic Feature,也就是 MFCC 拿出来,把它降到二维,画在二维的平面上,在这个图上啊,<strong>每一个点代表一小段声音讯号,那每一个顏色,代表了某一个 Speaker</strong>,某一个讲话的人,那其实我们丢给这个 Network 的资料,有很多句子是重复的,就是有人说,A 说了 How are you,B 也说了 How are you,C 也说了 How are you,很多人说了一样的句子,但从这个图上你看不出来,从 Acoustic Feature上你会发现说,就算是不同的人唸同样的句子,内容一样</p>
<p>但是我们从 Acoustic Feature 上看不出来,同一个人他说的话就是比较相近,就算是不同的人说同样的句子,你也没有办法看到,他们被align在一起,所以从这个结果,人们就会觉得 哇 这个,这个语音辨识太难啦,语音辨识不能做啊,这个同样的人说不,这个不同的人说同样的话,看起来这个 Feature 差这么多啊,这个语音辨识怎么是有可能,有办法做的问题呢</p>
<p>但是当我们把 Network 拿出来看的时候,结果就不一样了,这个是第 8 层 Network 的输出,你会发现什么呢,你会发现这边变成一条一条的,每一条没有特定的顏色,这边每一条代表什么呢,每一条就代表了同样内容的某一个句子,所以你会发现说,不同人说同样的内容,在 MFCC 上看不出来,它<strong>通过了 8 层的 Network 之后,机器知道说这些话是同样的内容,虽然声音讯号看起来不一样,是不同人讲的,但他们是同样的内容</strong>,它可以把同样的内容,不同人说的句子,把它align在一起,所以最后就可以得到精确的分类结果</p>
<p>好 那刚才讲的是直接拿 Neuron 的输出,来进行分析,你也可以分析这个 Attention 的 Layer,现在 Self-Attention 用得很广,你也可以看 Attention 的结果,来决定今天 Network 学到什么事</p>
<img src="/images/loading.gif" data-original="../images/ML/image-20210822171655060.png">

<p>那我们在作业裡面,也要求大家看了 BERT 的 Attention,但是当你使用 Attention 的时候,还是有一些要注意的地方,我们直觉觉得 Attention 应该非常具有解释力,从某一个词汇 Attention 到另外一个词汇,当然就代表说这两个的词汇有关係啊等等,那在作业裡面,我们也挑了比较明显可以看出关联性的例子,给大家来实作,给大家来回答问题</p>
<p>但是实际上,你在文献上会找到这样子的文献,Attention is not Explanation,Attention 并不是总是可以被解释的,当然也有人发文献说,Attention is not not Explanation 这样子,所以你知道这个,这个研究 进展得非常快,很快又搞不好又会有人做,Attention is not not not Explanation,所以这个,到底 Attention 能不能被解释,什么状况可以被解释,什么状况不能够被解释,这个还是尚待研究的问题</p>
<p>那除了用人眼观察以外,还有另外一个技术叫做 ==Probing==,Probing 就是用探针的意思,就是你用探针去插入这个 Network,然后看看说发生了什么事</p>
<p>举例来说,假设你想要知道 BERT 的某一个 Layer,到底学到了什么东西,除了用肉眼观察以外,不过肉眼观察比较有极限嘛,可能有很多你没有观察到的现象,而且你也没有办法一次看过大批的资料,所以怎么办呢,你可以训练一个探针,<strong>你的探针其实就是分类器</strong></p>
<img src="/images/loading.gif" data-original="../images/ML/image-20210822172202445.png">

<p>举例来说,你训练一个分类器,这个分类器是要根据一个 Feature,根据一个向量决定说现在这个词汇,它的 POS Tag,也就是它的词性是什么,你就把 BERT 的 Embedding,丢到 POS 的 Classifier 裡面去,你就训练一个 POS 的 Classifier,它要试图根据这些 Embedding,决定说现在这些 Embedding,是来自於哪一个词性的词汇</p>
<p>如果这个 POS 的 Classifier 它的正确率高,就代表说这些 Embedding 裡面,有很多词性的资讯,如果它正确率第一,就代表这些 Embedding 裡面,没有词性的资讯</p>
<p>或者是说你 Learn 一个 NER,Name Entity Recognition 的 Classifier,然后呢,它看这些 Feature,决定说现在看到的词汇属於哪,属於人名还是地名,还是不是任何专有名词,那你透过这个 NER Classifier 的正确率,就可以知道这些 Feature 裡面,有没有名字,有没有这个地址,有没有人名的资讯等等</p>
<p>但是使用这个技术的时候,有一点你要小心,什么你要小心呢,<strong>小心你使用的 Classifier 它的强度</strong>,為什么,因為假设你今天发现你的 Classifier 正确率很低,真的一定保证它的输入的这些 Feature,也就是 BERT 的 Embedding,没有我们要分类的资讯吗,不一定,為什么</p>
<p>因為有可能就是你的 Classifier Train 烂啦,对不对,我们大家都有很多 Train Network 的经验嘛,你没有办法 100% 保证,你 Classifier Train 出来一定是好的啊,那搞不好你训练完一个 Classifier,它的正确率很低,不是因為这些 Feature 裡面,没有我们需要的资讯,单纯就是你 Learning Rate 没有调好,你什么东西没有调好,所以 Train 不起来,有没有可能是这样呢,有可能是这个样子,所以用 Probing Model 的时候,你要小心不要太快下结论,有时候你会得到一些结论,只是因為你 Classifier 没有 Train好,或 Train 得太好,导致你 Classifier 的正确率,没有办法当做评断的依据</p>
<p>Probing 不一定要是 Classifier,我这边特别举一个例子告诉你说,Probing 有种种的可能性,举例来说,我们实验室有做一个尝试是,训练一个语音合成的模型,一般语音合成的模型是吃一段文字,產生对应的声音讯号</p>
<img src="/images/loading.gif" data-original="../images/ML/image-20210822172636822.png">

<p>我们这边语音合成的模型不是吃一段文字,它是吃 Network Output 的 Embedding,<strong>它吃 Network Output 的 Embedding 作為输入,然后试图去输出一段声音讯号</strong></p>
<p>也就是说你在作业二,你训练了一个 Classifier,那接下来训练了一个 Phoneme 的 Classifier,接下来我们就把你的 Network 拿出来,然后呢 把某一个 Layer 的输出呢,丢到 TTS 的模型裡面,然后我们训练这个 TTS 的模型,我们训练的目标,是希望 TTS 的模型,可以去<strong>復现 Network 输入</strong>,就 Network 的输入是这段声音讯号,希望通过这些 Layer 以后,產生了 Embedding,丢到 TTS 以后,可以回復原来的声音讯号</p>
<p>那这样子的分析有什么用呢,你可能会想说,我们训练这个 TTS 產生原来的声音讯号,那不就產生原来的声音讯号,一模一样的声音讯号,就是输入的那一个,那有什么样的可看性呢</p>
<p>那这边有趣的地方是,假设这个 Network 做的事情,就是<strong>把 比如说语者的资讯去掉</strong>,那对於这个 TTS 的模型而言,这边 Layer 2 的输出,没有任何语者的资讯,那它无论怎么努力,都无法还原语者的特徵,那虽然内容说的是 Hi,然后是一个男生的声音,你会发现说,可能通过几个 Layer 以后,丢到 TTS 的模型 它,它这个產生出来的声音,会变成也是 Hi 的内容,但是你听不出来是谁讲的,那这样你就可以知道说,欸 这个 Network 啊,一个语音辨识的模型啊,它在训练的过程中,真的学到去抹去语者的特徵,只保留内容的部分,只保留声音讯号的内容</p>
<p>以下是真实的例子</p>
<img src="/images/loading.gif" data-original="../images/ML/image-20210822173012880.png">

<p>这个例子是这样子的,这边有一个 5 层的 Bi-directional 的 Lstm,它吃声音讯号做输入,那输出就是文字,它是语音辨识的模型,好 那现在我们给它一段声音讯号做输入,是女生的声音,接下来再给它听另外一个,男生讲不一样的内容,听起来像是这样的,接下来我们把这些声音讯号,丢到这个 Network 裡面,然后再把这个 Network 的 Embedding,用 TTS 的模型去还原回原来的声音讯号,看看我们听到什么,以下是过第一层 Lstm 的结果,你会发现声音讯号有一点失真,但基本上跟原来是差不多的,男生的声音是这样的,跟原来都是差不多的,但通过了 5 层的 Lstm 以后发生什么事呢,声音讯号变成这个样子,所以本来一个句子是男生讲的,一个句子是女生讲的,通过 5 层的 Lstm 以后,就听不出来是谁讲的,它把两个人的声音,都变成是一样的</p>
<p>那你可能说,欸 这个不是 10 年前,Hinton 就已经知道了吗,透过 Visualization,然后这个研究有什么厉害的地方呢,他厉害地方就是他潮 知道吗,就是我们可以把声音,我们可以听 Network 听到的声音,这边再举最后一个例子,输入的声音讯号是有杂讯的,有钢琴的声音,好 我们的 Network 现在前面有几层 CNN,后面有几层 Bi-directional 的 Lstm,通过地一层 CNN 以后,声音讯号变成这样,好 你还是听得到钢琴的声音,好 最后,到最后一层进入 Lstm 之前,声音讯号是这样的,你还是听到钢琴的声音,但是通过第一层 Lstm 以后,就不一样了,它听起来像是这个样子,你会发现说,那个钢琴的声音就突然小很多,所以知道说,这个钢琴的声音 这个杂讯,声音讯号之外,杂讯是在哪一层被滤掉的呢,在第一层 Lstm,开始被滤掉,前面 CNN,似乎没有起到滤掉杂讯的作用,那这个就是这个分析可以告诉我们的事情,好 那我们讲到这边正好告一个段落</p>
<h2 id="Global-Explanation-Explain-the-whole-Model"><a href="#Global-Explanation-Explain-the-whole-Model" class="headerlink" title="Global Explanation: Explain the whole Model"></a><strong>Global Explanation: Explain the whole Model</strong></h2><p>Global 的 Explanation 是什麼意思呢,我们在前一堂课讲的是 Local 的 Explanation,也就是给机器一张照片,那它告诉我们说,看到这张图片,它為什麼觉得裡面有一隻猫</p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20210823112203306.png" alt=""></p>
<p>而 <strong>Global 的 Explanation 并不是针对,特定某一张照片来进行分析</strong>,而是把我们训练好的那个模型拿出来,根据这个模型裡面的参数去检查说,<strong>对这个 Network 而言,到底一隻猫长什麼样子</strong>,对一个 Network 而言,它心裡想像的猫长什麼样子</p>
<h3 id="What-does-a-filter-detect"><a href="#What-does-a-filter-detect" class="headerlink" title="What does a filter detect?"></a><strong>What does a filter detect?</strong></h3><p>举例来说,假设你今天 Train 好一个,Convolutional 的 Neural Network,Train 好在这边,那你知道在 Convolutional 的,Neural Network 裡面呢,就是有很多的 Filter,有很多的这个 Convolutional Layer</p>
<img src="/images/loading.gif" data-original="../images/ML/image-20210823120807142.png">

<p>Convolutional Layer 裡面呢,有一堆的 Filter,那你把一张图片作為输入,Convolutional 的 Layer,它的输出是什麼呢,它的<strong>输出是一个 Feature Map</strong>,那每一个 Filter 都会给我们一个 Metric</p>
<p>那今天呢,假设我们有一张图片,作為这个 Convolutional Neural Network 的输入,这张图片我们用一个大写的 X 来表示,因為图片呢,通常是一个矩阵,我们用大写的 X,来表示这个图片所构成的矩阵,而如果把这张图片丢进去,你发现某一个 Filter,比如说 Filter 1,它在它的 <strong>Feature Map 裡面,很多位置都有比较大的值</strong>,那意味著什麼</p>
<p>那可能就是意味著说,这个 Image X 裡面有很多 Filter 1,负责侦测的那些特徵,这个 <strong>Image 裡面呢,有很多的 Pattern 是 Filter 1 负责侦测的,</strong>那 Filter 1 看到这些 Pattern,所以它在它的 Feature Map 上,就 Output 比较大的值</p>
<p>但是现在我们要做的是 Global 的 Explanation,也就是我们还没有这张图片 Image X,我们没有要针对任何一张特定的图片做分析,但是我们现在想要知道说,对 Filter 1 而言,它想要看的 Pattern 到底长什麼样子,那怎麼做呢</p>
<p>我们就去<strong>製造出一张图片</strong>,它不是我们的 Database 裡面,任何一个特定的图片,而是<strong>机器自己去找出来的,自己创造出来的</strong>,我们要创造一张图片,这张图片它<strong>包含有 Filter 1 要 Detect 的 Pattern,那藉由看这张图片裡面的内容,我们就可以知道 Filter 1,它负责 Detect 什麼样的东西</strong></p>
<p>那怎麼找这张图片呢,我们假设 Filter 1,它是这个 Filter 1 的这个 Feature Map,裡面的每一个 Element 叫做 $a_{ij}$,就是 Filter 1 的那个 Feature Map 是一个矩阵,那矩阵裡面每一个 Element,我们用 $a_{ij}$ 来表示</p>
<img src="/images/loading.gif" data-original="../images/ML/image-20210823123359105.png">

<p>那我们现在要做的事情是找一张图片 X,这张图片不是 Database 裡面的图片,而是我们<strong>把这个 X 呢,当做一个 Unknown Variable</strong>,当做我们要训练的那个参数,我们去找一张图片,这张图片丢到这个 Filter 以后,通过 Convolutional Layer 以后,输出这个 Feature Map 以后,Filter 1 对应的 Feature Map 裡面的值,也就是 $a_{ij}$ 的值越大越好,所以我们要找一个 X,<strong>让 $a_{ij}$ 的总和,也就是 Filter 1 的 Feature Map的 Output,它的值越大越好</strong>,那我们找出来的这个 X,我们就用 $X^⋆$ 来表示</p>
<p><strong>它不是 Database 裡面任何一张特定的图片,我们是把 X 当作 Unknown Variable,当作要 learn 的参数,去找出这个 $X^⋆$</strong>,$X^⋆$ 丢到这个已经 Train 好的 Network 裡面,这个 Network 的 Convolutional Layer,它输出的这些 Feature 它的值,它输出的这个 Feature Map 裡面的值,会越大越好</p>
<p>那怎麼解这个问题呢,你会用类似 Gradient descent 的方法,只是因為我们现在是要去 Maximize 某一个东西,所以它不是 Gradient descent,它是 ==Gradient ascent==,不过它的<strong>原理跟 Gradient descent 是一模一样的</strong></p>
<p>那我找出这个 $X^⋆$ 以后,我们就可以去观察这个 $X^⋆$,那看看 $X^⋆$ 有什麼样的特徵,我们就可以知道说,$X^⋆$ 它可以 Maximize 这个 Filter Map 的 value,也就是这个 Filter 1,它在 Detect 什麼样的 Pattern</p>
<p>那这边是一个实际操作的结果了,我们就用这个 ==Mnist==,Mnist 是一个手写数字辨识的 Corpus,用 Mnist Train 出一个 Classifier，这个 Classifier 给它一张图片,它会判断说这张图片裡面是 1~9 的哪一个数字</p>
<img src="/images/loading.gif" data-original="../images/ML/image-20210823174224160.png">

<p>训练好这个数字的 Classifier 以后呢,我们就把它的<strong>第二层的 Convolutional Layer,裡面的 Filter 拿出来,然后找出每一个 Filter 对应的 $X^⋆$</strong>,所以下面这边每一张图片,就是一个 $X^⋆$,然后每一张图片都对应到一个 Filter</p>
<p>那所以你可以想像说,这个第一张图片就是 Filter 1,它想要 Detect 的 Pattern,第二张图片,就是 Filter 2 想要 Detect 的 Pattern,以此类推,那这边是画了 12 个 Filter 出来</p>
<p>那从这些 Pattern 裡面,我们可以发现什麼呢,我们可以发现说,这个<strong>第二层的 Convolutional,它想要做的事情,确实是去侦测一些基本的 Pattern</strong>,比如说类似笔画的东西</p>
<p>右下角这个 Filter,它想侦测什麼 Pattern,它想侦测斜直线等等,左下角这个 Pattern 这个 Filter,它想侦测什麼 Pattern,它想要侦测直线,每一个 Filter,都有它想要侦测的 Pattern,那因為我们现在是在做手写的数字辨识,那你知道数字就是有一堆笔画所构成的,所以 Convolutiona Layer 裡面的每一个 Filter,它的工作就是去侦测某一个笔画,这件事情是非常合理的</p>
<h3 id="What-does-a-digit-look-like-for-CNN"><a href="#What-does-a-digit-look-like-for-CNN" class="headerlink" title="What does a digit look like for CNN?"></a><strong>What does a digit look like for CNN?</strong></h3><p>那接下来你可能就会去想说,那假设我们不是看某一个 Filter,而是去<strong>看最终这个 Image Classifier 的 Output</strong>,那可不可以呢,那我们会观察到什麼样的现象呢</p>
<p>如果我们今天是去看这个 Image Classifier,这个 Digit Classifier 的 Output,我们<strong>想办法去找一张图片 X,这个 X 可以让某一个类别的分数越高越好</strong>,因為我们现在做的是这个数字辨识,所以这个 y 呢,总共就会有 10 个值,分别对应到 0~9,那我们就选某一个数字出来</p>
<p>比如说你选数字 1 出来,然后你希望找一张图片,这张图片丢到这个 Classifier 以后,数字 1 的分数越高越好,那如果你用这个方法,你可以看到什麼样的东西呢,你可以看到数字 0~9 吗,你实际上做一下以后发现,没有办法,你看到的结果大概就像是这个样子</p>
<img src="/images/loading.gif" data-original="../images/ML/image-20210823175257987.png">

<p>这张图片,它可以让这个 Image Classifier,觉得看到数字 0 的分数最高,这张图片可以让你的这个 Classifier,觉得看到 1 的分数最高,2 的分数最高,3 的分数最高,以此类推,你会发现说你观察到的,<strong>其实就是一堆杂讯,你根本没有办法看到数字</strong></p>
<p>那这个结果,假设我们还没有教 Adversarial Attack,你可能会觉得好神奇,怎麼会这个样子,机器看到一堆是杂讯的东西,它以為它看到数字吗,怎麼会这麼愚蠢,但是因為我们已经教过 Adversarial Attack,所以想必你其实不会太震惊,因為我们在做 Adversarial Attack 的时候,我们就已经告诉你说,在 Image 上面加上一些,人眼根本看不到的奇奇怪怪的杂讯,就可以让机器看到各式各样的物件</p>
<p>那所以这边也是一样的道理,对机器来说,它不需要看到真的很像 0 那个数字的图片,它才说它看到数字 0,你给它一些乱七八糟的杂讯,它也说看到数字 0,而且它的信心分数是非常高的</p>
<p>那所以其实如果你用这个方法,想用这种找一个图片,让 Image 的输出,某一个对应到某一个类别的输出,越大越好这种方法,你想要用这个方法来看到,看到这个机器心裡想像的,某一个 object 长什麼样子,其实不一定有那麼容易</p>
<p>那像今天这个例子,今天这个手写数字辨识的例子,你单纯只是找说,我要找一张 Image,让对应到某一个数字的信心分数越高越好,你单纯只做这件事情,你找到了只会是一堆杂讯,怎麼办呢</p>
<p>假设我们希望我们今天看到的,是比较像是人想像的数字,应该要怎麼办呢,你在<strong>解这个 Optimization 的问题的时候,你要加上更多的限制</strong>,举例来说,我们先对这个数字已经有一些想像,我们已经知道数字可能是长什麼样子,我们可以把我们要的这个限制,加到这个 Optimization 的过程裡面</p>
<img src="/images/loading.gif" data-original="../images/ML/image-20210823175750052.png">

<p>举例来说,我们现在不是要找一个 X,让 $y_i$ 的分数最大,而是要<strong>找一个 X,同时让 $y_i$ 还有 $R( X)$ 的分数都越大越好</strong>,那这个 $R( X)$ 是什麼意思呢,这个<strong>$R( X)$是要拿来衡量说,这个 X 有多麼像是一个数字</strong></p>
<p>举例来说,今天数字就是由笔画所构成的,所以一个数字它在整张图片裡面,它有顏色的地方其实也没那麼多,这一个图片很大,那个笔画就是几画而已,所以在整张图片裡面,有顏色的地方没有那麼多,所以我们可以把这件事情当做一个限制,硬是塞到我们找 X 的这个过程中,硬是塞到我们找 X 的这个最佳化,Optimization 的过程中,那期望藉此我们找出来的 X,就会比较像是数字,那如果加上一些额外的限制以后</p>
<p>举例来说,我们<strong>希望这个白色的点越少越好,在这个这个 Constraint 呢,它的意思就是希望这个白色的点越少越好</strong>,那假设我们加上一个限制,希望白色的点越少越好的话,那我们看到的结果会是这个样子,但看起来还是不太像数字了,不过你仔细观察白色的点的话,还真有那麼一点样子,比如说这个有点像是 6,这个有点像是 8</p>
<p>那如果你要真的得到,非常像是数字的东西,或者是假设你想要像那个文献上,你知道文献上有很多人都会说,他<strong>用某种这个 Global Explanation的方法,然后去反推一个 Image classifier,它心中的某种动物长什麼样子</strong></p>
<p>比如说你看下面这篇文献,它告诉你说,它有一个 Image classifier,它用我们刚才提到的方法,它可以反推说,这个 Image classifier 裡面,心中的这个丹顶鹤长什麼样子</p>
<img src="/images/loading.gif" data-original="../images/ML/image-20210823180225684.png">

<p>或它心中的这个甲虫长什麼样子,来看这些图片,这个真的都还蛮像丹顶鹤的,你完全可以看到说,这个有一隻鸟,有一隻丹顶鹤,然后牠有一隻脚插在水裡面,那这些图片真的都可以看到甲虫,在图片裡面</p>
<p>但是你<strong>要得到这样子的图片,其实没有你想像的那麼容易</strong>,你如果仔细去看这个文献的话,你就会发现说,要得到这些图片,你必须要下非常多的 Constraint,你要根据你对影像的了解,一个 Object 长什麼样子的了解,下非常多的限制,再加上一大堆的 Hyperparameter Tuning,你知道我们解 Optimization Problem 的时候,也是需要这个调这个 Hyperparameter,比如说 Learning rate 之类的,所以下一堆 Constraint,调一堆参数,你才可以得出这样的结果,所以这样的结果并不是随随便便,就可以轻易的做出来的</p>
<h3 id="Constraint-from-Generator"><a href="#Constraint-from-Generator" class="headerlink" title="Constraint from Generator"></a>Constraint from Generator</h3><p>好像刚才讲的那种 Global Explanation 的方法,如果你真的想要看到非常清晰的图片的话,现在有一个招数是使用 Generator,你就训练一个 Image 的 Generator</p>
<p>你有一堆训练资料,有一堆 Image,那你拿这一堆 Image 呢,来训练一个 Image 的 Generator,比如说你可以用 GAN,可以用 VAE 等等,GAN 我们有教过了,VAE 我们没有教过,反正就是你可以想办法,训练出一个 Image 的 Generator</p>
<img src="/images/loading.gif" data-original="../images/ML/image-20210823180750841.png">

<ul>
<li><p>Image 的 Generator 输入,是一个 Low-dimensional 的 Vector,是一个从 Gaussian distribution 裡面,Sample 出来的低维度的向量叫做 z</p>
</li>
<li><p>丢到这个 Image Generator 以后呢,它输出就是一张图片 X,那这个 Image Generator,我们用 G 来表示,那输出的图片 X,我们就可以写成 X 等於 G(z)</p>
</li>
</ul>
<p>那怎麼拿这个  Image Generator,来帮助我们反推一个 Image classifier 裡面,它所想像的某一种类别,比如说某一隻猫,它心裡所想像的猫这个类别,或狗这个类别长什麼样子呢</p>
<ul>
<li><p>那你就把这个 Image Generator,跟这个 Image classifier 接在一起,这个 Image Generator 输入是一个 z,输出是一张图片</p>
</li>
<li><p>然后这个 Image classifier,把这个图片当做输入,然后输出分类的结果,那在刚才前几页投影片裡面,我们都是说我们要找一个 X,让 y 裡面的某一个 dimension,让某一个类别,它的信心分数越高越好,那我们说这个 X 叫做 $X^⋆$</p>
</li>
</ul>
<p>那我们刚才也看到说光这麼做,你往往做不出什麼特别厉害的结果,现在有了 Image Generator 以后,方法就不一样了,我们<strong>现在不是去找 X,而是去找一个 z,我们要找一个 z,这个 z 通过 Image Generator 產生 X,再把这个 X 丢到 Image classifier,去產生 y 以后,希望 y 裡面对应的某一个类别,它的分数越大越好</strong></p>
<p>我们</p>
<ul>
<li>找一个 z</li>
<li>z 產生 X</li>
<li>X 再產生 y 以后</li>
<li>希望$y_i$越大越好</li>
</ul>
<p>那这个可以让 $y_i$ 越大越好的 z,我们就叫它 $z^⋆$,找出这个 $z^⋆$ 以后,我们再把这个 </p>
<ul>
<li><strong>$z^⋆$ 丢到 G 裡面,丢到 Generator 裡面,看看它產生出来的 Image $X^⋆$ 长什麼样子</strong></li>
</ul>
<p>好 那找出来的 $X^⋆$ 长什麼样子呢</p>
<img src="/images/loading.gif" data-original="../images/ML/image-20210823181237152.png">

<p>假设你今天想要產生,比如说这个让蚂蚁分数,让蚂蚁的信心分数最高的 Image,那產生出来的蚂蚁的照片,这个很厉害,这个长得是这个样子,都看得出这个就是蚂蚁,或者是要让机器產生火山的照片,產生一堆照片,丢到 Classifier 以后,火山的信心分数特别高的,那确实可以找出一堆 Image,这些 Image 一看就知道像是火山一样</p>
<p>但讲到这边你可能会觉得,这整个想法听起来有点强要这样,就是今天呢,你找出来的图片,如果跟你想像的东西不一样,今天找出来的蚂蚁 火山跟你想像不一样,你就说这个 Explanation 的方法不好,然后<strong>你硬是要弄一些方法去找出来那个图片,跟人想像的是一样的,你才会说这个 Explanation 的方法是好的</strong></p>
<p>那也许今天对机器来说,它看到的图片就是像是一些杂讯一样,也许它心裡想像的某一个数字,就是像是那些杂讯一样,那我们却不愿意认同这个事实,而是硬要想一些方法,让机器產生出看起来比较像样的图片</p>
<p>那今天 Explainable AI 的技术,往往就是有这个特性,<strong>我们其实没有那麼在乎,机器真正想的是什麼,其实我们不知道机器真正想的是什麼,我们是希望有些方法解读出来的东西,是人看起来觉得很开心的</strong>,然后你就说,机器想的应该就是这个样子,然后你的老闆 你的客户,听了就会觉得很开心,那今天 Explainable AI 往往会有这样的倾向好</p>
<h2 id="Concluding-Remarks"><a href="#Concluding-Remarks" class="headerlink" title="Concluding Remarks"></a>Concluding Remarks</h2><p>那我们今天呢,就是跟大家介绍了 Explainable AI 的,两个主流的技术,一个是 Local 的 Explanation,一个是 Global 的 Explanation</p>
<img src="/images/loading.gif" data-original="../images/ML/image-20210823181400821.png">

<p>那其实 Explainable 的 Machine Learning,还有很多的技术,这边再举一个例子,举例来说,你可以<strong>用一个比较简单的模型,想办法去模仿复杂的模型的行為</strong></p>
<img src="/images/loading.gif" data-original="../images/ML/image-20210823181506508.png">

<p>如果简单的模型可以模仿复杂模型的行為,你再去分析那个简单的模型,也许我们就可以知道,那个复杂的模型在做什麼,举例来说,你有一个 Neural Network,因為它是一个黑盒子,你丢一堆 x 进去,比如说丢一堆图片进去,它会给我们分类的结果</p>
<p>但我们搞不清楚它决策的过程,因為 Neural Network 本身非常地复杂,那我们能不能拿一个比较简单的模型出来,比较能够分析的模型出来,拿一个 Interpretable 的模型出来,比如说一个 Linear Model,然后<strong>我们训练这个 Linear Model,去模仿 Neural Network 的行為</strong>,Neural Network 输入 $x_1 到 x_N$,它就输出 $y_1 到 y_N$,那我们要求这个 Linear Model,输入的 $x_1 到 x_N$,也要输出跟 Black box,这个黑盒子一模一样的输出 $y_1 到 y_N$</p>
<p>我们要求这个 Linear 的 Model,去模仿黑盒子的行為,那<strong>如果 Linear 的 Model,可以成功模仿黑盒子的行為,我们再去分析 Linear Model 做的事情</strong>,因為 Linear 的 Model 比较容易分析,分析完以后,也许我们就可以知道,这个黑盒子在做的事情</p>
<p>当然这边你可能会有非常非常多的问题,举例来说,一个 Linear 的 Model,有办法去模仿一个黑盒子的行為吗,我们开学第一堂课就说过说,有很多的问题是 Neural Network 才做得到,而 Linear 的 Model 是做不到的,所以今天黑盒子可以做到的事情,Linear 的 Model 不一定能做到,没错,在这一系列的 work 裡面,有一个特别知名的叫做,==Local Interpretable Model-Agnostic Explanations,它缩写呢 是LIME==</p>
<p>那像这种方法,它也没有说,它要用 Linear Model 去模仿黑盒子全部的行為,它有特别开宗明义在名字裡面就告诉你说,它是 Local Interpretable,也就是它只要 Linear Model 去模仿这个黑盒子,在一小个区域内的行為,因為 Linear Model 能力有限,它不可能模仿整个 Neural Network 的行為,但<strong>也许让它模仿一小个区域的行為,那我们就解读那一小个区域裡面发生的事情</strong>,那这个是一个非常经典的方法,叫做 LIME</p>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        文章作者:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://jackhcc.github.io" rel="external nofollow noreferrer">杰克成</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        文章链接:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://jackhcc.github.io/posts/adversarial-attack.html">https://jackhcc.github.io/posts/adversarial-attack.html</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        版权声明:
                    </i>
                </span>
                <span class="reprint-info">
                    本博客所有文章除特別声明外，均采用
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    许可协议。转载请注明来源
                    <a href="https://jackhcc.github.io" target="_blank">杰克成</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>复制成功，请遵循本文的转载规则</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">查看</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/tags/Adversarial-Attack/">
                                    <span class="chip bg-color">Adversarial Attack</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/libs/share/css/share.min.css">

<div id="article-share">
    
    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>微信扫一扫即可分享！</p>"></div>
    <script src="https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
                <style>
    #reward {
        margin: 40px 0;
        text-align: center;
    }

    #reward .reward-link {
        font-size: 1.4rem;
        line-height: 38px;
    }

    #reward .btn-floating:hover {
        box-shadow: 0 6px 12px rgba(0, 0, 0, 0.2), 0 5px 15px rgba(0, 0, 0, 0.2);
    }

    #rewardModal {
        width: 320px;
        height: 350px;
    }

    #rewardModal .reward-title {
        margin: 15px auto;
        padding-bottom: 5px;
    }

    #rewardModal .modal-content {
        padding: 10px;
    }

    #rewardModal .close {
        position: absolute;
        right: 15px;
        top: 15px;
        color: rgba(0, 0, 0, 0.5);
        font-size: 1.3rem;
        line-height: 20px;
        cursor: pointer;
    }

    #rewardModal .close:hover {
        color: #ef5350;
        transform: scale(1.3);
        -moz-transform:scale(1.3);
        -webkit-transform:scale(1.3);
        -o-transform:scale(1.3);
    }

    #rewardModal .reward-tabs {
        margin: 0 auto;
        width: 210px;
    }

    .reward-tabs .tabs {
        height: 38px;
        margin: 10px auto;
        padding-left: 0;
    }

    .reward-content ul {
        padding-left: 0 !important;
    }

    .reward-tabs .tabs .tab {
        height: 38px;
        line-height: 38px;
    }

    .reward-tabs .tab a {
        color: #fff;
        background-color: #ccc;
    }

    .reward-tabs .tab a:hover {
        background-color: #ccc;
        color: #fff;
    }

    .reward-tabs .wechat-tab .active {
        color: #fff !important;
        background-color: #22AB38 !important;
    }

    .reward-tabs .alipay-tab .active {
        color: #fff !important;
        background-color: #019FE8 !important;
    }

    .reward-tabs .reward-img {
        width: 210px;
        height: 210px;
    }
</style>

<div id="reward">
    <a href="#rewardModal" class="reward-link modal-trigger btn-floating btn-medium waves-effect waves-light red">赏</a>

    <!-- Modal Structure -->
    <div id="rewardModal" class="modal">
        <div class="modal-content">
            <a class="close modal-close"><i class="fas fa-times"></i></a>
            <h4 class="reward-title">你的赏识是我前进的动力</h4>
            <div class="reward-content">
                <div class="reward-tabs">
                    <ul class="tabs row">
                        <li class="tab col s6 alipay-tab waves-effect waves-light"><a href="#alipay">支付宝</a></li>
                        <li class="tab col s6 wechat-tab waves-effect waves-light"><a href="#wechat">微 信</a></li>
                    </ul>
                    <div id="alipay">
                        <img src="/images/loading.gif" data-original="https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/medias/reward/aliqr.png" class="reward-img" alt="支付宝打赏二维码">
                    </div>
                    <div id="wechat">
                        <img src="/images/loading.gif" data-original="https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/medias/reward/wxqr.png" class="reward-img" alt="微信打赏二维码">
                    </div>
                </div>
            </div>
        </div>
    </div>
</div>

<script>
    $(function () {
        $('.tabs').tabs();
    });
</script>
            
        </div>
    </div>

    
        <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/libs/gitalk/gitalk.css">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/css/my-gitalk.css">

<div class="card gitalk-card" data-aos="fade-up">
    <div class="comment_headling" style="font-size: 20px; font-weight: 700; position: relative; left: 20px; top: 15px; padding-bottom: 5px;">
        <i class="fas fa-comments fa-fw" aria-hidden="true"></i>
        <span>评论</span>
    </div>
    <div id="gitalk-container" class="card-content"></div>
</div>

<script src="https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/libs/gitalk/gitalk.min.js"></script>
<script>
    let gitalk = new Gitalk({
        clientID: '3821a0bbb773038a51fc',
        clientSecret: '4b30b507d67ec5497ec0e77f43f80cb3e0d7dd3a',
        repo: 'JackHCC.github.io',
        owner: 'JackHCC',
        admin: "JackHCC",
        id: '2021-08-27T12-11-05',
        distractionFreeMode: false  // Facebook-like distraction free mode
    });

    gitalk.render('gitalk-container');
</script>
    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;上一篇</div>
            <div class="card">
                <a href="/posts/reinforcement-learning.html">
                    <div class="card-image">
                        
                        
                        <img src="/images/loading.gif" data-original="https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/medias/featureimages/19.jpg" class="responsive-img" alt="Reinforcement Learning强化学习">
                        
                        <span class="card-title">Reinforcement Learning强化学习</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            Reinforcement Learning强化学习详解
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2021-08-28
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/categories/Deep-Learning/" class="post-category">
                                    Deep Learning
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/tags/Reinforcement-Learning/">
                        <span class="chip bg-color">Reinforcement Learning</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                下一篇&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/posts/blog-python15.html">
                    <div class="card-image">
                        
                        
                        <img src="/images/loading.gif" data-original="https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/medias/featureimages/11.jpg" class="responsive-img" alt="Python-OpenPyXL详解">
                        
                        <span class="card-title">Python-OpenPyXL详解</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            Python OpenPyXL基本使用
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2021-08-26
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/categories/Python/" class="post-category">
                                    Python
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/tags/OpenPyXL/">
                        <span class="chip bg-color">OpenPyXL</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- 代码块功能依赖 -->
<script type="text/javascript" src="https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/libs/codeBlock/codeBlockFuction.js"></script>

<!-- 代码语言 -->

<script type="text/javascript" src="https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/libs/codeBlock/codeLang.js"></script>


<!-- 代码块复制 -->

<script type="text/javascript" src="https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/libs/codeBlock/codeCopy.js"></script>


<!-- 代码块收缩 -->

<script type="text/javascript" src="https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/libs/codeBlock/codeShrink.js"></script>


<!-- 代码块折行 -->

<style type="text/css">
code[class*="language-"], pre[class*="language-"] { white-space: pre !important; }
</style>


    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;目录</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC 悬浮按钮. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('4'),
            headingSelector: 'h1, h2, h3, h4'
        });

        // modify the toc link href to support Chinese.
        let i = 0;
        let tocHeading = 'toc-heading-';
        $('#toc-content a').each(function () {
            $(this).attr('href', '#' + tocHeading + (++i));
        });

        // modify the heading title id to support Chinese.
        i = 0;
        $('#articleContent').children('h1, h2, h3, h4').each(function () {
            $(this).attr('id', tocHeading + (++i));
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* 修复文章卡片 div 的宽度. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // 切换TOC目录展开收缩的相关操作.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>

    

</main>


<script src="https://cdn.bootcss.com/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
<script>
    MathJax.Hub.Config({
        tex2jax: {inlineMath: [['$', '$'], ['\(', '\)']]}
    });
</script>


    <footer class="page-footer bg-color">
    <div class="container row center-align" style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            <span id="year">2020</span>
            <a href="https://jackhcc.github.io" target="_blank">杰克成</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            <br>
            
            &nbsp;<i class="fas fa-chart-area"></i>&nbsp;站点总字数:&nbsp;<span
                class="white-color">3591.2k</span>&nbsp;字
            
            
            
            
            
            
            <span id="busuanzi_container_site_pv">
                |&nbsp;<i class="far fa-eye"></i>&nbsp;总访问量:&nbsp;<span id="busuanzi_value_site_pv"
                    class="white-color"></span>&nbsp;次
            </span>
            
            
            <span id="busuanzi_container_site_uv">
                |&nbsp;<i class="fas fa-users"></i>&nbsp;总访问人数:&nbsp;<span id="busuanzi_value_site_uv"
                    class="white-color"></span>&nbsp;人
            </span>
            
            <br>
            
            <span id="sitetime">载入运行时间...</span>
            <script>
                function siteTime() {
                    var seconds = 1000;
                    var minutes = seconds * 60;
                    var hours = minutes * 60;
                    var days = hours * 24;
                    var years = days * 365;
                    var today = new Date();
                    var startYear = "2020";
                    var startMonth = "2";
                    var startDate = "27";
                    var startHour = "6";
                    var startMinute = "30";
                    var startSecond = "0";
                    var todayYear = today.getFullYear();
                    var todayMonth = today.getMonth() + 1;
                    var todayDate = today.getDate();
                    var todayHour = today.getHours();
                    var todayMinute = today.getMinutes();
                    var todaySecond = today.getSeconds();
                    var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                    var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                    var diff = t2 - t1;
                    var diffYears = Math.floor(diff / years);
                    var diffDays = Math.floor((diff / days) - diffYears * 365);
                    var diffHours = Math.floor((diff - (diffYears * 365 + diffDays) * days) / hours);
                    var diffMinutes = Math.floor((diff - (diffYears * 365 + diffDays) * days - diffHours * hours) /
                        minutes);
                    var diffSeconds = Math.floor((diff - (diffYears * 365 + diffDays) * days - diffHours * hours -
                        diffMinutes * minutes) / seconds);
                    if (startYear == todayYear) {
                        document.getElementById("year").innerHTML = todayYear;
                        document.getElementById("sitetime").innerHTML = "本站已安全运行 " + diffDays + " 天 " + diffHours +
                            " 小时 " + diffMinutes + " 分钟 " + diffSeconds + " 秒";
                    } else {
                        document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                        document.getElementById("sitetime").innerHTML = "本站已安全运行 " + diffYears + " 年 " + diffDays +
                            " 天 " + diffHours + " 小时 " + diffMinutes + " 分钟 " + diffSeconds + " 秒";
                    }
                }
                setInterval(siteTime, 1000);
            </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/JackHCC" class="tooltipped" target="_blank" data-tooltip="访问我的GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:jackcc0701@163.com" class="tooltipped" target="_blank" data-tooltip="邮件联系我" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>



    <a href="https://www.facebook.com/profile.php?id=100046343443643" class="tooltipped" target="_blank" data-tooltip="关注我的Facebook: https://www.facebook.com/profile.php?id=100046343443643" data-position="top" data-delay="50">
        <i class="fab fa-facebook-f"></i>
    </a>



    <a href="https://twitter.com/JackChe66021834" class="tooltipped" target="_blank" data-tooltip="关注我的Twitter: https://twitter.com/JackChe66021834" data-position="top" data-delay="50">
        <i class="fab fa-twitter"></i>
    </a>



    <a href="tencent://AddContact/?fromId=50&fromSubId=1&subcmd=all&uin=2508074836" class="tooltipped" target="_blank" data-tooltip="QQ联系我: 2508074836" data-position="top" data-delay="50">
        <i class="fab fa-qq"></i>
    </a>



    <a href="https://weibo.com/u/6885584679" class="tooltipped" target="_blank" data-tooltip="关注我的微博: https://weibo.com/u/6885584679" data-position="top" data-delay="50">
        <i class="fab fa-weibo"></i>
    </a>



    <a href="https://www.zhihu.com/people/8f8482f01f0d6a04e844efe32e0f0710" class="tooltipped" target="_blank" data-tooltip="关注我的知乎: https://www.zhihu.com/people/8f8482f01f0d6a04e844efe32e0f0710" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">知</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- 搜索遮罩框 -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;搜索</span>
            <input type="search" id="searchInput" name="s" placeholder="请输入搜索的关键字"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script src="https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/js/search.js"></script>
<script type="text/javascript">
$(function () {
    searchFunc("https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/" + "search.xml", 'searchInput', 'searchResult');
});
</script>
    <!-- 回到顶部按钮 -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/libs/materialize/materialize.min.js"></script>
    <script src="https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/libs/aos/aos.js"></script>
    <script src="https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/js/matery.js"></script>

    <canvas class="fireworks" style="position: fixed;left: 0;top: 0;z-index: 1; pointer-events: none;" ></canvas>
    <script type="text/javascript" src="//cdn.bootcss.com/animejs/2.2.0/anime.min.js"></script>
    <script type="text/javascript" src="/js/fireworks.js"></script>

    <script type="text/javascript">
        //只在桌面版网页启用特效
        var windowWidth = $(window).width();
        if (windowWidth > 768) {
            document.write('<script type="text/javascript" src="/js/sakura.js"><\/script>'); }
    </script>

    <!-- weather -->
	<script type="text/javascript">
	WIDGET = {FID: 'TToslpmkVO'}
	</script>
	<script type="text/javascript" src="https://apip.weatherdt.com/float/static/js/r.js?v=1111"></script>


    <!-- Global site tag (gtag.js) - Google Analytics -->


    <!-- Baidu Analytics -->

<script>
    var _hmt = _hmt || [];
    (function () {
        var hm = document.createElement("script");
        hm.src = "https://hm.baidu.com/hm.js?";
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(hm, s);
    })();
</script>

    <!-- Baidu Push -->

    
    
    <script async src="https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/libs/others/busuanzi.pure.mini.js"></script>
    

    
        <script src="//code.tidio.co/kqhlkxviiccyoa0czpfpu4ijuey9hfre.js"></script>
        <script> 
            $(document).ready(function () {
                setInterval(change_Tidio, 50);  
                function change_Tidio() { 
                    var tidio=$("#tidio-chat iframe");
                    if(tidio.css("display")=="block"&& $(window).width()>977 ){
                        document.getElementById("tidio-chat-iframe").style.bottom= ($("div#backTop.top-scroll").css("display")=="none" &&$(window).width()>977)>0? "-40px" : ($("div.toc-title").length&&$(window).width()>977)>0?"85px":"20px";   
                        document.getElementById("tidio-chat-iframe").style.right="-15px";   
                        document.getElementById("tidio-chat-iframe").style.height=parseInt(tidio.css("height"))>=520?"520px":tidio.css("height");
                        document.getElementById("tidio-chat-iframe").style.zIndex="997";
                    } 
                    else if(tidio.css("display")=="block"&&$(window).width()>601 &&$(window).width()<992 ){
                        document.getElementById("tidio-chat-iframe").style.bottom= ($("div#backTop.top-scroll").css("display")=="none" && 601< $(window).width()<992)>0? "-40px":"20px" ;   
                        document.getElementById("tidio-chat-iframe").style.right="-15px"; 
                        document.getElementById("tidio-chat-iframe").style.zIndex="997";
                    }
                    else if(tidio.css("display")=="block"&&$(window).width()<601 && parseInt(tidio.css("height"))<230){
                        document.getElementById("tidio-chat-iframe").style.bottom= ($("div#backTop.top-scroll").css("display")=="none" && $(window).width()<601)>0? "-10px":"45px" ;   
                        document.getElementById("tidio-chat-iframe").style.zIndex="997";
                    }
                    if( tidio.css("display")=="block"&&$(window).width()<601 && parseInt(tidio.css("height"))>=230){
                        document.getElementById("tidio-chat-iframe").style.zIndex="998";
                    }
                } 
            }); 
        </script>
    

    

    
    <script type="text/javascript" color="0,0,255"
        pointColor="0,0,255" opacity='0.7'
        zIndex="-1" count="99"
        src="https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/libs/background/canvas-nest.js"></script>
    

    

    
    <script type="text/javascript" src="https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/libs/background/ribbon-dynamic.js" async="async"></script>
    
    
    
    <script src="https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/libs/instantpage/instantpage.js" type="module"></script>
    

        <script src="//cdn.jsdelivr.net/npm/js-base64/base64.min.js"></script>
        <script>
        $('a').each(function() {
          const $this = $(this);
          const href = $this.attr('href');
          if (href && href.match('^((http|https|thunder|qqdl|ed2k|Flashget|qbrowser|ftp|rtsp|mms)://)')) {
            const strs = href.split('/');
            if (strs.length >= 3) {
                const host = strs[2];
                if (host !== 'your_domain' || window.location.host) {
                    $this.attr('href', '/go.html?u='+Base64.encode(href)+'').attr('rel', 'external nofollow noopener noreferrer');
                    if (true) {
                        $this.attr('target', '_blank');
                    }
                }
            }
          }
        });
        </script><script>!function(e){var c=Array.prototype.slice.call(document.querySelectorAll("img[data-original]"));function i(){for(var r=0;r<c.length;r++)t=c[r],0<=(n=t.getBoundingClientRect()).bottom&&0<=n.left&&n.top<=(e.innerHeight||document.documentElement.clientHeight)&&function(){var t,n,e,i,o=c[r];t=o,n=function(){c=c.filter(function(t){return o!==t})},e=new Image,i=t.getAttribute("data-original"),e.onload=function(){t.src=i,n&&n()},e.src=i}();var t,n}i(),e.addEventListener("scroll",function(){var t,n;t=i,n=e,clearTimeout(t.tId),t.tId=setTimeout(function(){t.call(n)},500)})}(this);</script><script>window.addEventListener("load",function(){var t=/\.(gif|jpg|jpeg|tiff|png)$/i,r=/^data:image\/[a-z]+;base64,/;Array.prototype.slice.call(document.querySelectorAll("img[data-original]")).forEach(function(a){var e=a.parentNode;"A"===e.tagName&&(e.href.match(t)||e.href.match(r))&&(e.href=a.dataset.original)})});</script></body>

</html>

