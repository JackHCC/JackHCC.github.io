<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="Statistical Learning Method, JackHCC">
    <meta name="description" content="《统计学习方法》第一版学习笔记">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <title>Statistical Learning Method | JackHCC</title>
    <link rel="icon" type="image/png" href="https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/medias/favicon.png">

    <link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/libs/awesome/css/all.css">
    <link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/libs/materialize/materialize.min.css">
    <link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/libs/aos/aos.css">
    <link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/libs/animate/animate.min.css">
    <link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/libs/lightGallery/css/lightgallery.min.css">
    <link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/css/matery.css">
    <link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/css/my.css">
    
    <script src="https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/libs/jquery/jquery.min.js"></script>
    
<meta name="generator" content="Hexo 4.2.0"><link rel="alternate" href="/atom.xml" title="JackHCC" type="application/atom+xml">
<link rel="stylesheet" href="/css/prism-hopscotch.css" type="text/css">
<link rel="stylesheet" href="/css/prism-line-numbers.css" type="text/css"></head>


<body>
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper head-container">
            <div class="brand-logo">
                <a href="/" class="waves-effect waves-light">
                    
                    <img src="/images/loading.gif" data-original="https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/medias/me.jpg" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">JackHCC</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>首页</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>标签</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>分类</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>归档</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="" class="waves-effect waves-light">

      
      <i class="fas fa-list" style="zoom: 0.6;"></i>
      
      <span>Tools</span>
      <i class="fas fa-chevron-down" aria-hidden="true" style="zoom: 0.6;"></i>
    </a>
    <ul class="sub-nav menus_item_child ">
      
      <li>
        <a href="https://creativecc.cn/" target="_blank" rel="noopener">
          
          <i class="fas fa-book" style="margin-top: -20px; zoom: 0.6;"></i>
          
          <span>Creative工具导航</span>
        </a>
      </li>
      
      <li>
        <a href="https://blog.creativecc.cn/Arxiv-NLP-Reporter/" target="_blank" rel="noopener">
          
          <i class="fas fa-film" style="margin-top: -20px; zoom: 0.6;"></i>
          
          <span>NLP每日论文</span>
        </a>
      </li>
      
      <li>
        <a href="http://chat.creativecc.cn/" target="_blank" rel="noopener">
          
          <i class="fas fa-music" style="margin-top: -20px; zoom: 0.6;"></i>
          
          <span>RocketChat聊天室</span>
        </a>
      </li>
      
      <li>
        <a href="/contact">
          
          <i class="fas fa-comments" style="margin-top: -20px; zoom: 0.6;"></i>
          
          <span>Contact留言板</span>
        </a>
      </li>
      
    </ul>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/friends" class="waves-effect waves-light">
      
      <i class="fas fa-address-book" style="zoom: 0.6;"></i>
      
      <span>友情链接</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/about" class="waves-effect waves-light">
      
      <i class="fas fa-user-circle" style="zoom: 0.6;"></i>
      
      <span>关于</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="搜索" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>

<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/images/loading.gif" data-original="https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/medias/me.jpg" class="logo-img circle responsive-img">
        
        <div class="logo-name">JackHCC</div>
        <div class="logo-desc">
            
            Make the world betterrrr!!!
            
        </div>
    </div>

    

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			首页
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			标签
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			分类
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			归档
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="javascript:;">
			
				<i class="fa-fw fas fa-list"></i>
			
			Tools
			<span class="m-icon"><i class="fas fa-chevron-right"></i></span>
		</a>
            <ul  style="background:  ;" >
              
                <li>   
				
                  <a href="https://creativecc.cn/ " target="_blank" rel="noopener" style="margin-left:75px";>
				  
				   <i class="fa fas fa-book" style="position: absolute;left:50px" ></i>
			      
		          <span>Creative工具导航</span>
                  </a>
                </li>
              
                <li>   
				
                  <a href="https://blog.creativecc.cn/Arxiv-NLP-Reporter/ " target="_blank" rel="noopener" style="margin-left:75px";>
				  
				   <i class="fa fas fa-film" style="position: absolute;left:50px" ></i>
			      
		          <span>NLP每日论文</span>
                  </a>
                </li>
              
                <li>   
				
                  <a href="http://chat.creativecc.cn/ " target="_blank" rel="noopener" style="margin-left:75px";>
				  
				   <i class="fa fas fa-music" style="position: absolute;left:50px" ></i>
			      
		          <span>RocketChat聊天室</span>
                  </a>
                </li>
              
                <li>   
				
                  <a href="/contact " style="margin-left:75px";>
				  
				   <i class="fa fas fa-comments" style="position: absolute;left:50px" ></i>
			      
		          <span>Contact留言板</span>
                  </a>
                </li>
               
            </ul>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/friends" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-address-book"></i>
			
			友情链接
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/about" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-user-circle"></i>
			
			关于
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/JackHCC/JackHCC.github.io" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>

        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/JackHCC/JackHCC.github.io" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    
<script src="https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/libs/cryptojs/crypto-js.min.js"></script>
<script>
    (function() {
        let pwd = '';
        if (pwd && pwd.length > 0) {
            if (pwd !== CryptoJS.SHA256(prompt('请输入访问本文章的密码')).toString(CryptoJS.enc.Hex)) {
                alert('密码错误，将返回主页！');
                location.href = '/';
            }
        }
    })();
</script>




<div class="bg-cover pd-header post-cover" style="background-image: url('https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/medias/featureimages/10.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">Statistical Learning Method</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/libs/tocbot/tocbot.css">
<style>
    #articleContent h1::before,
    #articleContent h2::before,
    #articleContent h3::before,
    #articleContent h4::before,
    #articleContent h5::before,
    #articleContent h6::before {
        display: block;
        content: " ";
        height: 100px;
        margin-top: -100px;
        visibility: hidden;
    }

    #articleContent :focus {
        outline: none;
    }

    .toc-fixed {
        position: fixed;
        top: 64px;
    }

    .toc-widget {
        width: 345px;
        padding-left: 20px;
    }

    .toc-widget .toc-title {
        margin: 35px 0 15px 0;
        padding-left: 17px;
        font-size: 1.5rem;
        font-weight: bold;
        line-height: 1.5rem;
    }

    .toc-widget ol {
        padding: 0;
        list-style: none;
    }

    #toc-content {
        height: calc(100vh - 250px);
        overflow: auto;
    }

    #toc-content ol {
        padding-left: 10px;
    }

    #toc-content ol li {
        padding-left: 10px;
    }

    #toc-content .toc-link:hover {
        color: #42b983;
        font-weight: 700;
        text-decoration: underline;
    }

    #toc-content .toc-link::before {
        background-color: transparent;
        max-height: 25px;
    }

    #toc-content .is-active-link {
        color: #42b983;
    }

    #toc-content .is-active-link::before {
        background-color: #42b983;
    }

    #floating-toc-btn {
        position: fixed;
        right: 30px;
        bottom: 146px;
        padding-top: 15px;
        margin-bottom: 0;
        z-index: 998;
    }

    #floating-toc-btn .btn-floating {
        width: 48px;
        height: 48px;
    }

    #floating-toc-btn .btn-floating i {
        line-height: 48px;
        font-size: 1.4rem;
    }
</style>
<div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- 文章内容详情 -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/tags/Lesson/">
                                <span class="chip bg-color">Lesson</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/categories/Algorithm/" class="post-category">
                                Algorithm
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>发布日期:&nbsp;&nbsp;
                    2022-01-09
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>更新日期:&nbsp;&nbsp;
                    2022-02-25
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>文章字数:&nbsp;&nbsp;
                    61.2k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>阅读时长:&nbsp;&nbsp;
                    271 分
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>阅读次数:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>

        </div>
        <hr class="clearfix">
        <div class="card-content article-card-content">
            <div id="articleContent">
                <h1 id="一、统计学习方法概论"><a href="#一、统计学习方法概论" class="headerlink" title="一、统计学习方法概论"></a>一、统计学习方法概论</h1><h2 id="1-1-统计学习"><a href="#1-1-统计学习" class="headerlink" title="1.1 统计学习"></a>1.1 统计学习</h2><ul>
<li><p>特点</p>
<ul>
<li>统计学习以计算机及网络为平台，是建立在计算机及网络之上的：</li>
<li>统计学习以数据为研究对象，是数据驱动的学科；</li>
<li>统计学习的目的是对数据进行预测与分析；</li>
<li>统计学习以方法为中心，统计学习方法构建模型并应用模型进行预测与分析；</li>
<li>统计学习是概率论、统计学、信息论、计算理论、最优化理论及计算机科学等多个领域的交叉学科，并且在发展中逐步形成独自的理论体系与方法论</li>
</ul>
</li>
<li><p>对象：数据</p>
</li>
<li><p>目的：预测与分析</p>
</li>
<li><p>方法</p>
<ul>
<li>统计学习的方法是基于数据构建统计模型从而对数据进行预测与分析。统计学习由监督学习( supervised learning)、非监督学习( unsupervised learning)、半监督学习(semi- supervised learning)和强化学习( reinforcement learning)等组成</li>
<li>三要素：模型、策略、算法</li>
</ul>
</li>
<li><p>实现统计学习方法的步骤如下</p>
<ul>
<li>(1)得到一个有限的训练数据集合；</li>
<li>(2)确定包含所有可能的模型的假设空间，即学习模型的集合；</li>
<li>(3)确定模型选择的准则，即学习的策略；</li>
<li>(4)实现求解最优模型的算法，即学习的算法</li>
<li>(5)通过学习方法选择最优模型；</li>
<li>(6)利用学习的最优模型对新数据进行预测或分析</li>
</ul>
</li>
<li><p>研究：统计学习方法( statistical learning method)、统计学习理论( statistical learning theory)及统计学习应用( application of statistical learning)</p>
</li>
<li><p>重要性</p>
<ul>
<li>统计学习是处理海量数据的有效方法。我们处于一个信息爆炸的时代，海量数据的处理与利用是人们必然的需求，现实中的数据不但规模大，而且常常具有不确定性，统计学习往往是处理这类数据最强有力的工具</li>
<li>统计学习是计算机智能化的有效手段，智能化是计算机发展的必然趋势，也是计算机技术研究与开发的主要目标，近几十年来，人工智能等领域的研究表明，利用统计学习模仿人类智能的方法，虽有一定的局限性，但仍然是实现这目标的最有效手段，</li>
<li>统计学习是计算机科学发展的一个重要组成部分。可以认为计算机科学由三维组成：系统、计算、信息统计学习主要属于信息这一维，并在其中起着核心作用。</li>
</ul>
</li>
</ul>
<h2 id="1-2-监督学习"><a href="#1-2-监督学习" class="headerlink" title="1.2 监督学习"></a>1.2 监督学习</h2><p>监督学习( supervised learning)的任务是学习一个模型，使模型能够对任意给定的输入，对其相应的输出做出一个好的预测（注意，这里的输入、输出是指某个系统的输入与输出，与学习的输入与输出不同）。计算机的基本操作就是给定一个输入产生一个输出。</p>
<h3 id="1-2-1-基本概念"><a href="#1-2-1-基本概念" class="headerlink" title="1.2.1 基本概念"></a>1.2.1 基本概念</h3><ul>
<li><p>输入空间、特征空间与输出空间</p>
<ul>
<li><p>在监督学习中，将输入与输出所有可能取值的集合分别称为<strong>输入空间</strong>（input space）与<strong>输出空间</strong>（output space）.输入与输出空间可以是有限元素的集合，也可以是整个欧氏空间。输入空间与输出空间可以是同一个空间，也可以是不同的空间；但通常输出空间远远小于输入空间。</p>
</li>
<li><p>每个具体的输入是一个实例（Instance），通常由特征向量（feature vector）表示，这时，所有特征向量存在的空间称为<strong>特征空间</strong>（feature space）.特征空间的每一维对应于一个特征，有时假设输入空间与特征空间为相同的空间，对它们不予区分；有时假设输入空间与特征空间为不同的空间，将实例从输入空间映射到特征空间。模型实际上都是定义在特征空间上的。</p>
</li>
<li><p>除特别声明外，本书中向量均为列向量，输入实例$x$的特征向量记作：<br>$$<br>x=\left(x^{(1)}, x^{(2)}, \cdots, x^{(i)}, \cdots, x^{(n)}\right)^{\mathrm{T} }<br>$$</p>
</li>
<li><p>监督学习从训练数据( training data)集合中学习模型，对测试数据( test data)进行预测，训练数据由输入（或特征向量）与输出对组成，训练集通常表示为：<br>$$<br>T=\left { \left(x_{1}, y_{1} \right), \left(x_{2}, y_{2} \right), \cdots, \left(x_{N}, y_{N} \right) \right }<br>$$</p>
</li>
</ul>
</li>
<li><p>联合概率分布</p>
<ul>
<li>监督学习假设输入与输出的随机变量X和Y遵循联合概率分布$P(X,Y)$,$P(X,Y)$表示分布函数，或分布密度函数，注意，在学习过程中，假定这一联合概率分布存在，但对学习系统来说，联合概率分布的具体定义是未知的，训练数据与测试数据被看作是依联合概率分布P(X,)独立同分布产生的，统计学习假设数据存在一定的统计规律，X和Y具有联合概率分布的假设就是监督学习关于数据的基本假设</li>
</ul>
</li>
<li><p>假设空间</p>
<ul>
<li><p>监督学习的目的在于学习一个由输入到输出的映射，这一映射由模型来表示。换句话说，学习的目的就在于找到最好的这样的模型。模型属于由输入空间到输出空间的映射的集合，这个集合就是假设空间(hypothesis space).假设空间的确定意味着学习范围的确定</p>
</li>
<li><p>监督学习的模型可以是概率模型或非概率模型，由条件概率分布$P(Y|X)$或决策函数（decision function）$Y=f(X)$表示，随具体学习方法而定。对具体的输入进行相应的输出预测时，写作$P(y | x)$或$y=f(x)$</p>
</li>
</ul>
</li>
</ul>
<h3 id="1-2-2-问题的形式化"><a href="#1-2-2-问题的形式化" class="headerlink" title="1.2.2 问题的形式化"></a>1.2.2 问题的形式化</h3><p>监督学习分为学习和预测两个过程：</p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20220109103259216.png" alt="监督学习问题"></p>
<h2 id="1-3-统计学习三要素"><a href="#1-3-统计学习三要素" class="headerlink" title="1.3 统计学习三要素"></a>1.3 统计学习三要素</h2><p>方法=模型+策略+算法</p>
<h3 id="1-3-1-模型"><a href="#1-3-1-模型" class="headerlink" title="1.3.1 模型"></a>1.3.1 模型</h3><ul>
<li>统计学习首要考虑的问题是学习什么样的模型。在监督学习过程中，模型就是所要学习的条件概率分布或决策函数。模型的假设空间( hypothesis space)包含所有可能的条件概率分布或决策函数。例如，假设决策函数是输入变量的线性函数，那么模型的假设空间就是所有这些线性函数构成的函数集合。假设空间中的模型一般有无穷多个</li>
<li>假设空间用$\mathcal{F}$表示，假设空间可以定义为决策函数的集合：</li>
</ul>
<p>$$<br>\mathcal{F}={f \mid Y=f(X)}<br>$$</p>
<ul>
<li>这时$\mathcal{F}$通常是由一个参数向量决定的函数族：</li>
</ul>
<p>$$<br>\mathcal{F}=\left {f \mid Y=f_{ \theta}(X), \theta \in  \mathbf{R}^{n} \right }<br>$$</p>
<ul>
<li><p>$\mathbf{R}^{n}$为参数空间</p>
</li>
<li><p>假设空间也可以定义为条件概率的集合：</p>
</li>
</ul>
<p>$$<br>\mathcal{F}={P \mid P(Y \mid X)}<br>$$</p>
<ul>
<li>条件概率分布族：</li>
</ul>
<p>$$<br>\mathcal{F}= \left {P \mid P_{ \theta}(Y \mid X), \theta \in  \mathbf{R}^{n} \right }<br>$$</p>
<h3 id="1-3-2-策略"><a href="#1-3-2-策略" class="headerlink" title="1.3.2 策略"></a>1.3.2 策略</h3><p>有了模型的假设空间，统计学习接着需要考虑的是按照什么样的准则学习或选择最优的模型。统计学习的目标在于从假设空间中选取最优模型</p>
<ul>
<li><p>损失函数与风险函数</p>
<ul>
<li><p>监督学习问题是在假设空间$\mathcal{F}$中选取模型$f$作为决策函数，对于给定的输入$X$,由$f(X)$给出相应的输出$Y$,这个输出的预测值$f(X)$与真实值$Y$可能一致也可能不一致，用一个损失函数（loss function）或代价函数（cost function）来度量预测错误的程度。损失函数是$f(X)$和$Y$的非负实值函数，记作$L(Y,f(X))$</p>
</li>
<li><p>统计学习常用的损失函数有以下几种</p>
<ul>
<li>0-1 损失函数（0-1 loss function）</li>
</ul>
<p>$$<br>L(Y, f(X))=\left { \begin{array}{ll}<br>1, &amp; Y \neq f(X) \<br>0, &amp; Y=f(X)<br>\end {array} \right.<br>$$</p>
<ul>
<li><p>平方损失函数（quadratic loss function）<br>$$<br>L(Y, f(X))=(Y-f(X))^{2}<br>$$</p>
</li>
<li><p>绝对损失函数（absolute loss function）<br>$$<br>L(Y, f(X))=|Y-f(X)|<br>$$</p>
</li>
<li><p>对数损失函数（logarithmic loss function）或对数似然损失函数（log-likelihood loss function）<br>$$<br>L(Y, P(Y \mid X))=-\log P(Y \mid X)<br>$$</p>
</li>
</ul>
</li>
<li><p>损失函数值越小，模型就越好。由于模型的输入、输出$(X,Y)$是随机变量，遵循联合分布$P(X,Y)$,所以损失函数的期望是<br>$$<br>R_{\exp }(f)=E_{P}[L(Y, f(X))]=\int_{\chi \times y} L(y, f(x)) P(x, y) \mathrm{d} x \mathrm{~d} y<br>$$</p>
</li>
<li><p>这是理论上模型$f(X)$关于联合分布$P(X,Y)$的平均意义下的损失，称为风险函数（risk function）或期望损失（expected loss）</p>
</li>
<li><p>训练数据集的平均损失称为经验风险（empirical risk）或经验损失（expected loss）:<br>$$<br>R_{\mathrm{emp} }(f)=\frac{1}{N} \sum_{i=1}^{N} L\left(y_{i}, f\left(x_{i}\right)\right)<br>$$</p>
</li>
</ul>
</li>
</ul>
<p>经验风险最小化与结构风险最小化</p>
<ul>
<li><strong>经验风险最小化</strong>（empirical risk minimization, ERM）的策略认为，经验风险最小的模型是最优的模型。根据这一策略，按照经验风险最小化求最优模型就是求解最优化问题：</li>
</ul>
<p>$$<br>\min <em>{f \in \mathcal{F} } \frac{1}{N} \sum</em>{i=1}^{N} L \left(y_{i}, f \left(x_{i} \right) \right)<br>$$</p>
<ul>
<li>考虑到过拟合现象，结构风险最小化（structural risk minimization, SRM）是为了防止过拟合而提出来的策略。结构风险最小化等价于正则化（regularization）.结构风险在经验风险上加上表示模型复杂度的正则化项（regularizer）或罚项（penalty term）.在假设空间、损失函数以及训练数据集确定的情况下，结构风险的定义是：</li>
</ul>
<p>$$<br>R_{\mathrm{sm} }(f)=\frac{1}{N} \sum_{i=1}^{N} L\left(y_{i}, f\left(x_{i}\right)\right)+\lambda J(f)<br>$$</p>
<ul>
<li><strong>结构风险最小化</strong>的策略认为结构风险最小的模型是最优的模型。所以求最优模型，就是求解最优化问题:</li>
</ul>
<p>$$<br>\min <em>{f \in \mathcal{F} } \frac{1}{N} \sum _{i=1}^{N} L \left(y</em>{i}, f \left(x_{i} \right) \right)+ \lambda J(f)<br>$$</p>
<h3 id="1-3-3-算法"><a href="#1-3-3-算法" class="headerlink" title="1.3.3 算法"></a>1.3.3 算法</h3><p>算法是指学习模型的具体计算方法，统计学习基于训练数据集，根据学习策略，从假设空间中选择最优模型，最后需要考虑用什么样的计算方法求解最优模型</p>
<h2 id="1-4-模型评估与模型选择"><a href="#1-4-模型评估与模型选择" class="headerlink" title="1.4 模型评估与模型选择"></a>1.4 模型评估与模型选择</h2><h3 id="1-4-1-训练误差与测试误差"><a href="#1-4-1-训练误差与测试误差" class="headerlink" title="1.4.1 训练误差与测试误差"></a>1.4.1 训练误差与测试误差</h3><p>当损失函数给定时，基于损失函数的模型的训练误差（training error）和模型的测试误差（test error）就自然成为学习方法评估的标准。</p>
<ul>
<li><p>假设学习到的模型是$Y=\hat{f}(X)$</p>
</li>
<li><p>训练误差是模型$Y=(x)$关于训练数据集的平均损失：<br>$$<br>R_{\text {emp } }(\hat{f})=\frac{1}{N} \sum_{i=1}^{N} L\left(y_{i}, \hat{f}\left(x_{i}\right)\right)<br>$$</p>
</li>
<li><p>测试误差：<br>$$<br>e_{\text {test } }=\frac{1}{N^{\prime} } \sum_{i=1}^{N^{\prime} } L\left(y_{i}, \hat{f}\left(x_{i}\right)\right)<br>$$</p>
</li>
</ul>
<h3 id="1-4-2-过拟合与模型选择"><a href="#1-4-2-过拟合与模型选择" class="headerlink" title="1.4.2 过拟合与模型选择"></a>1.4.2 过拟合与模型选择</h3><p>当假设空间含有不同复杂度(例如，不同的参数个数)的模型时，就要面临模型选择（model selection）的问题，我们希望选择或学习一个合适的模型。如果在假设空间中存在“真”模型，那么所选择的模型应该逼近真模型。具体地，所选择的模型要与真模型的参数个数相同，所选择的模型的参数向量与真模型的参数向量相近</p>
<p>如果一味追求提高对训练数据的预测能力，所选模型的复杂度则往往会比真模型更高。这种现象称为过拟合（over- fitting）.过拟合是指学习时选择的模型所包含的参数过多，以致于出现这一模型对已知数据预测得很好，但对未知数据预测得很差的现象。可以说模型选择旨在避免过拟合并提高模型的预测能力</p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20220109110538444.png" alt="M次多项式函数拟合问题"></p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20220109110628895.png" alt="训练误差和测试误差与模型复杂度的关系"></p>
<h2 id="1-5-正则化与交叉验证"><a href="#1-5-正则化与交叉验证" class="headerlink" title="1.5 正则化与交叉验证"></a>1.5 正则化与交叉验证</h2><h3 id="1-5-1-正则化"><a href="#1-5-1-正则化" class="headerlink" title="1.5.1 正则化"></a>1.5.1 正则化</h3><p>模型选择的典型方法是正则化（regularization）.正则化是结构风险最小化策略的实现，是在经验风险上加一个正则化项（regularizer）或罚项（penalty term）,正则化项一般是模型复杂度的单调递增函数，模型越复杂，正则化值就越大。</p>
<ul>
<li><p>正则化一般具有如下形式：<br>$$<br>\min <em>{f \in \mathcal{F} } \frac{1} {N} \sum _{i=1}^{N} L \left(y</em>{i}, f \left(x_{i} \right) \right)+ \lambda J(f)<br>$$</p>
</li>
<li><p>L2范数<br>$$<br>L(w)=\frac{1}{N} \sum_{i=1}^{N}\left(f\left(x_{i} ; w\right)-y_{i}\right)^{2}+\frac{\lambda}{2}|w|^{2}<br>$$</p>
</li>
<li><p>L1范式<br>$$<br>L(w)=\frac{1}{N} \sum_{i=1}^{N}\left(f\left(x_{i} ; w\right)-y_{i}\right)^{2}+\lambda|w|_{1}<br>$$</p>
</li>
</ul>
<p>正则化符合奥卡姆剃刀（Occams razor）原理，奥卡姆剃刀原理应用于模型选择时变为以下想法：在所有可能选择的模型中，能够很好地解释已知数据并且十分简单才是最好的模型，也就是应该选择的模型。从贝叶斯估计的角度来看，正则化项对应于模型的先验概率，可以假设复杂的模型有较大的先验概率，简单的模型有较小的先验概率</p>
<h3 id="1-5-2-交叉验证"><a href="#1-5-2-交叉验证" class="headerlink" title="1.5.2 交叉验证"></a>1.5.2 交叉验证</h3><p>如果给定的样本数据充足，进行模型选择的一种简单方法是随机地将数据集切分成三部分，分别为训练集（training set）、验证集（validation set）和测试集（test set).训练集用来训练模型，验证集用于模型的选择，而测试集用于最终对学习方法的评估。在学习到的不同复杂度的模型中，选择对验证集有最小预测误差的模型。由于验证集有足够多的数据，用它对模型进行选择也是有效的</p>
<ul>
<li><p>简单交叉验证：首先随机地将已给数据分为两部分，一部分作为训练集，另一部分作为测试集(例如，70%的数据为训练集，30%的数据为测试集)：然后用训练集在各种条件下(例如，不同的参数个数)训练模型，从而得到不同的模型；在测试集上评价各个模型的测试误差，选出测试误差最小的模型。</p>
</li>
<li><p>S折交又验证：应用最多的是S折交又验证（S- fold cross validation）,方法如下：首先随机地将已给数据切分为S个互不相交的大小相同的子集；然后利用S-1个子集的数据训练模型，利用余下的子集测试模型；将这一过程对可能的S种选择重复进行；最后选出S次评测中平均测试误差最小的模型</p>
</li>
<li><p>S折交叉验证的特殊情形是S=N,称为留一交叉验证（ leave- one-out cross validation）,往往在数据缺乏的情况下使用。这里，N是给定数据集的容量</p>
</li>
</ul>
<h2 id="1-6-泛化能力"><a href="#1-6-泛化能力" class="headerlink" title="1.6 泛化能力"></a>1.6 泛化能力</h2><h3 id="1-6-1-泛化误差"><a href="#1-6-1-泛化误差" class="headerlink" title="1.6.1 泛化误差"></a>1.6.1 泛化误差</h3><p>首先给出泛化误差的定义。如果学到的模型是$\hat{f}$,那么用这个模型对未知数据预测的误差即为泛化误差（generalization error）<br>$$<br>R_{\exp }(\hat{f})=E_{P}[L(Y, \hat{f}(X))]=\int_{\chi \times y} L(y, \hat{f}(x)) P(x, y) \mathrm{d} x \mathrm{~d} y<br>$$</p>
<h3 id="1-6-2-泛化误差上界"><a href="#1-6-2-泛化误差上界" class="headerlink" title="1.6.2 泛化误差上界"></a>1.6.2 泛化误差上界</h3><p>学习方法的泛化能力分析往往是通过研究泛化误差的概率上界进行的，简称为泛化误差上界（generalization error bound）.具体来说，就是通过比较两种学习方法的泛化误差上界的大小来比较它们的优劣。泛化误差上界通常具有以下性质：它是样本容量的函数，当样本容量增加时，泛化上界趋于0:它是假设空间容量（capacity）的函数，假设空间容量越大，模型就越难学，泛化误差上界就越大</p>
<p><strong>定理1.1（泛化误差上界）</strong>对二类分类问题，当假设空间是有限个函数的集合$\mathcal {F}=\left {f_{1}, f_{2}, \cdots, f_{d} \right }$时，对任意一个函数$f∈F$,至少以概率$1-\delta$,以下不等式成立：<br>$$<br>R(f) \leqslant \hat{R}(f)+\varepsilon(d, N, \delta)<br>$$<br>其中：<br>$$<br>\varepsilon(d, N, \delta)=\sqrt { \frac{1}{2 N } \left( \log d+ \log \frac{1} { \delta} \right) }<br>$$</p>
<h2 id="1-7-生成模型与判别模型"><a href="#1-7-生成模型与判别模型" class="headerlink" title="1.7 生成模型与判别模型"></a>1.7 生成模型与判别模型</h2><p>监督学习的任务就是学习一个模型，应用这一模型，对给定的输入预测相应的输出。这个模型的一般形式为决策函数：<br>$$<br>Y = f ( X )<br>$$<br>监督学习方法又可以分为生成方法（generative approach）和判别方法（discriminative approach）.所学到的模型分别称为生成模型（generative model）和判别模型（discriminative model）.</p>
<p>生成方法由数据学习联合概率分布$P(X,Y)$,然后求出条件概率分布$P(Y|X)$作为预测的模型，即生成模型：<br>$$<br>P ( Y | X) = \frac { P ( X , Y ) } { P ( X ) }<br>$$</p>
<h2 id="1-8-分类问题"><a href="#1-8-分类问题" class="headerlink" title="1.8 分类问题"></a>1.8 分类问题</h2><p>分类是监督学习的一个核心问题，在监督学习中，当输出变量Y取有限个离散值时，预测问题便成为分类问题，这时，输入变量x可以是离散的，也可以是连续的，监督学习从数据中学习一个分类模型或分类决策函数，称为分类器（classifier）分类器对新的输入进行输出的预测（prediction）,称为分类（classification）,可能的输出称为类（class）.分类的类别为多个时，称为多类分类问题。</p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20220109120158534.png" alt="分类问题"></p>
<p>评价分类器性能的指标一般是分类准确率（accuracy），其定义是：对于给定的测试数据集，分类器正确分类的样本数与总样本数之比。也就是损失函数是0-1损失时测试数据集上的准确率</p>
<ul>
<li><p>对于二类分类问题常用的评价指标是精确率（precision）与召回率（recall）.通常以关注的类为正类，其他类为负类，分类器在测试数据集上的预测或正确或不正确，4种情况出现的总数分别记作：</p>
<ul>
<li><p>TP：将正类预测为正类数</p>
</li>
<li><p>FN：将正类预测为负类数</p>
</li>
<li><p>FP：将负类预测为正类数</p>
</li>
<li><p>TN：将负类预测为负类数</p>
</li>
</ul>
</li>
<li><p>精确率：</p>
</li>
</ul>
<p>$$<br>P = \frac { T P } { T P + F P }<br>$$</p>
<ul>
<li>召回率：</li>
</ul>
<p>$$<br>R = \frac { T P } { T P + F N }<br>$$</p>
<ul>
<li>$F _ { 1 }$值，是精确率和召回率的调和均值，即</li>
</ul>
<p>$$<br>\frac { 2 } { F _ { 1 } } = \frac { 1 } { P } + \frac { 1 } { R }<br>$$</p>
<p>$$<br>F _ { 1 } = \frac { 2 T P } { 2 T P + F P + F N }<br>$$</p>
<h2 id="1-9-标注问题"><a href="#1-9-标注问题" class="headerlink" title="1.9 标注问题"></a>1.9 标注问题</h2><p>标注（tagging）也是一个监督学习问题，可以认为标注问题是分类问题的一个推广，标注问题又是更复杂的结构预测（structure prediction）问题的简单形式，标注问题的输入是一个观测序列，输出是一个标记序列或状态序列，标注问题的目标在于学习一个模型，使它能够对观测序列给出标记序列作为预测。注意，可能的标记个数是有限的，但其组合所成的标记序列的个数是依序列长度呈指数级增长的。</p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20220109121221862.png" alt="标注问题"></p>
<ul>
<li>评价标注模型的指标与评价分类模型的指标一样，常用的有标注准确率、精确率和召回率。其定义与分类模型相同</li>
<li>标注常用的统计学习方法有：隐马尔可夫模型、条件随机场</li>
</ul>
<h2 id="1-10-回归问题"><a href="#1-10-回归问题" class="headerlink" title="1.10 回归问题"></a>1.10 回归问题</h2><p>回归（regression）是监督学习的另一个重要问题，回归用于预测输入变量（自变量）和输出变量（因变量）之间的关系，特别是当输入变量的值发生变化时，输出变量的值随之发生的变化。回归模型正是表示从输入变量到输出变量之间映射的函数。回归问题的学习等价于函数拟合：选择一条函数曲线使其很好地拟合已知数据且很好地预测未知数据</p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20220109121400560.png" alt="回归问题"></p>
<ul>
<li>回归向题按照输入变量的个数，分为一元回归和多元回归：按照输入变量和输出变量之间关系的类型即模型的类型，分为线性回归和非线性回归。</li>
<li>回归学习最常用的损失函数是平方损失函数，在此情况下，回归问题可以由著名的最小二乘法（least squares）求解，</li>
</ul>
<h2 id="习题"><a href="#习题" class="headerlink" title="习题"></a>习题</h2><h3 id="习题1-1"><a href="#习题1-1" class="headerlink" title="习题1.1"></a>习题1.1</h3><p>  说明伯努利模型的极大似然估计以及贝叶斯估计中的统计学习方法三要素。伯努利模型是定义在取值为0与1的随机变量上的概率分布。假设观测到伯努利模型$n$次独立的数据生成结果，其中$k$次的结果为1，这时可以用极大似然估计或贝叶斯估计来估计结果为1的概率。</p>
<p><strong>解答：</strong>  </p>
<p><strong>解答思路：</strong></p>
<ol>
<li>写出伯努利模型；</li>
<li>写出伯努利模型的极大似然估计以及贝叶斯估计中的统计学习方法三要素；</li>
<li>根据伯努利模型的极大似然估计，估计结果为1的概率；</li>
<li>根据伯努利模型的贝叶斯估计，估计结果为1的概率。</li>
</ol>
<p><strong>解答步骤：</strong>  </p>
<p><strong>第1步：伯努利模型</strong><br>  根据题意：伯努利模型是定义在取值为0与1的随机变量上的概率分布。<br>  对于随机变量$X$，则有：<br>$$<br>P(X=1)=p \ P(X=0)=1-p<br>$$</p>
<p>其中，$p$为随机变量$X$取值为1的概率，$1-p$则为取0的概率。<br>  由于随机变量$X$只有0和1两个值，$X$的概率分布函数，即伯努利模型可写为：<br>$$<br>P_p(X=x)=p^x (1-p)^{(1-x)}, \quad 0 \leqslant p \leqslant 1<br>$$</p>
<p>  则伯努利模型的假设空间为：<br>$$<br>\mathcal{F}={P|P_p(X)=p^x(1-p)^{(1-x)}, p\in [0,1] }<br>$$</p>
<p><strong>第2步：伯努利模型的极大似然估计以及贝叶斯估计中的统计学习方法三要素</strong><br>（1）极大似然估计<br>  模型：伯努利模型<br>  策略：经验风险最小化。极大似然估计，等价于当模型是条件概率分布、损失函数是对数损失函数时的经验风险最小化。<br>  算法：极大化似然：$\displaystyle \mathop{\arg\max} \limits_{p} L(p|X)= \mathop{\arg\max} \limits_{p} P(X|p)$ </p>
<p>（2）贝叶斯估计<br>  模型：伯努利模型<br>  策略：结构风险最小化。贝叶斯估计中的最大后验概率估计，等价于当模型是条件概率分布、损失函数是对数损失函数、模型复杂度由模型的先验概率表示时的结构风险最小化。<br>  算法：最大化后验概率：$\displaystyle \mathop{\arg\max} \limits_{p} \pi (p|X)= \displaystyle \mathop{\arg\max} \limits_{p} \frac{P(X|p)\pi(p)}{\int P(X|p)\pi(p)dp}$</p>
<p><strong>第3步：伯努利模型的极大似然估计</strong>  </p>
<p>  极大似然估计的一般步骤：<br>  参考Wiki：<a href="https://en.wikipedia.org/wiki/Maximum_likelihood_estimation" target="_blank" rel="noopener">https://en.wikipedia.org/wiki/Maximum_likelihood_estimation</a>  </p>
<blockquote>
<ol>
<li>写出随机变量的概率分布函数；  </li>
<li>写出似然函数；  </li>
<li>对似然函数取对数，得到对数似然函数，并进行化简；  </li>
<li>对参数进行求导，并令导数等于0；  </li>
<li>求解似然函数方程，得到参数的值。  </li>
</ol>
</blockquote>
<p>  对于伯努利模型$n$次独立的数据生成结果，其中$k$次的结果为1，可得似然函数为：<br>$$<br>\begin{aligned} L(p|X) &amp;= P(X|p) \<br>&amp;= \prod_{i=1}^{n} P(x^{(i)}|p) \<br>&amp;=p^k (1-p)^{n-k}<br>\end{aligned}<br>$$</p>
<p>  对似然函数取对数，得到对数似然函数为：<br>$$<br>\begin{aligned} \log L(p|X) &amp;= \log p^k (1-p)^{n-k} \<br>&amp;= \log(p^k) + \log\left( (1-p)^{n-k} \right) \<br>&amp;= k\log p + (n-k)\log (1-p)<br>\end{aligned}<br>$$</p>
<p>  求解参数$p$：<br>$$<br>\begin{aligned}<br>\hat{p} &amp;= \mathop{\arg\max} \limits_{p} L(p|X) \<br>&amp;= \mathop{\arg\max} \limits_{p} \left[ k\log p + (n-k)\log (1-p) \right]<br>\end{aligned}<br>$$</p>
<p>  对参数$p$求导，并求解导数为0时的$p$值：<br>$$<br>\begin{aligned}<br>\frac{\partial \log L(p)}{\partial p} &amp;= \frac{k}{p} - \frac{n-k}{1-p} \<br>&amp;= \frac{k(1-p) - p(n-k)}{p(1-p)} \<br>&amp;= \frac{k-np}{p(1-p)}<br>\end{aligned}<br>$$</p>
<p>  令$\displaystyle \frac{\partial \log L(p)}{\partial p} = 0$，从上式可得，$k-np=0$，即$\displaystyle p=\frac{k}{n}$<br>  所以$\displaystyle P(X=1)=\frac{k}{n}$</p>
<p><strong>第4步：伯努利模型的贝叶斯估计</strong>  </p>
<p>解法一：求最大后验估计</p>
<p>  贝叶斯估计（最大后验估计）的一般步骤：<br>  参考Wiki：<a href="https://en.wikipedia.org/wiki/Maximum_a_posteriori_estimation" target="_blank" rel="noopener">https://en.wikipedia.org/wiki/Maximum_a_posteriori_estimation</a></p>
<blockquote>
<ol>
<li>确定参数$\theta$的先验概率$p(\theta)$  </li>
<li>根据样本集$D={ x_1, x_2, \ldots, x_n }$，计算似然函数$P(D|\theta)$：$\displaystyle P(D|\theta)=\prod_{i=1}^n P(x_i|D)$  </li>
<li>利用贝叶斯公式，写出后验概率最大化公式：  </li>
</ol>
</blockquote>
<p>$$<br>\mathop{\arg\max} \limits_{\theta}  P(\theta|D)=\mathop{\arg\max} \limits_{\theta} \frac{P(D|\theta)P(\theta)}{\displaystyle \int \limits_\Theta P(D|\theta) P(\theta) d \theta} = \mathop{\arg\max} \limits_{\theta} P(D|\theta)P(\theta)<br>$$</p>
<blockquote>
<ol start="4">
<li>利用求导，得到后验概率最大时的参数取值</li>
</ol>
</blockquote>
<p>  对于伯努利模型的参数$p$，根据贝叶斯估计，该参数也是随机变量。<br>  假设$p$的先验分布$\pi(p)$为均匀分布，则最大后验概率估计等价于极大似然估计。<br>  一般在贝叶斯估计中，如果后验分布与先验分布属于同一分布簇（共轭分布），则称此先验分布为似然函数的共轭先验。</p>
<p>  参考<a href="https://zhuanlan.zhihu.com/p/61593112" target="_blank" rel="noopener">极大似然估计和贝叶斯估计</a></p>
<blockquote>
<p>选取共轭先验有如下好处，例如：<br>（1）符合直观，先验分布和后验分布应该是相同形式的；<br>（2）可以给出后验分布的解析形式；<br>（3）可以形成一个先验链，即现在的后验分布可以作为下一次计算的先验分布，如果形式相同，就可以形成一个链条。</p>
</blockquote>
<p>  伯努利分布的先验分布为Beta分布，则此处假设先验分布$\pi(p)$为Beta分布。  </p>
<blockquote>
<p><strong>补充知识：Beta分布</strong><br>来源维基百科：<a href="https://zh.wikipedia.org/wiki/%CE%92%E5%88%86%E5%B8%83" target="_blank" rel="noopener">https://zh.wikipedia.org/wiki/%CE%92%E5%88%86%E5%B8%83</a><br>  Beta 分布（Beta distribution），是指一组定义在${\displaystyle (0,1)}$区间的连续概率分布，亦称Β分布。有两个参数$\alpha, \beta&gt;0$。<br>概率密度函数：$\displaystyle f(x; \alpha, \beta)= \frac{1}{ {\rm B}(\alpha, \beta)}x^{(\alpha-1)}(1-x)^{\beta-1}$<br>其中${\rm B}(\alpha, \beta)$是Beta函数，亦称Β函数。$\displaystyle {\rm B}(\alpha, \beta) =\int _{0}^{1} x^{\alpha-1}(1-x)^{\beta-1}dx$<br>随机变量$X$服从参数为$\alpha, \beta$的Beta分布记作：$X \sim {\rm Be}(\alpha, \beta)$<br>期望：$\displaystyle {\rm E}(X) = \frac{\alpha}{\alpha+\beta}$<br>与均匀分布关系：当$\alpha=1, \beta=1$时，Beta分布就是一个均匀分布  </p>
</blockquote>
<p>  $p$的先验分布为：<br>$$<br>\displaystyle \pi (p) = \frac{1}{B(\alpha, \beta)} p^{(\alpha-1)} (1-p)^{\beta-1}<br>$$<br>  似然函数与第3步相同：<br>$$<br>\begin{aligned} L(p|X) &amp;= P(X|p) \<br>&amp;= \prod_{i=1}^{n} P(x^{(i)}|p) \<br>&amp;=p^k (1-p)^{n-k}<br>\end{aligned}<br>$$<br>  最大化后验概率，求解参数$p$：<br>$$<br>\begin{aligned}<br>\hat{p} &amp;= \mathop{\arg\max} \limits_{p} \frac{P(X|p)\pi(p)}{\displaystyle \int P(X|p)\pi(p)dp} \<br>&amp;= \mathop{\arg\max} \limits_{p} P(X|p)\pi(p) \<br>&amp;= \mathop{\arg\max} \limits_{p} p^k (1-p)^{n-k} \frac{1}{B(\alpha, \beta)} p^{(\alpha-1)} (1-p)^{\beta-1} \<br>&amp;= \mathop{\arg\max} \limits_{p} \frac{1}{B(\alpha, \beta)} p^{k+\alpha-1} (1-p)^{n-k+\beta-1}<br>\end{aligned}<br>$$<br>  令$\displaystyle g(p) = \frac{1}{B(\alpha, \beta)} p^{k+\alpha-1} (1-p)^{n-k+\beta-1}$，对函数$g(p)$先取对数，再对$p$求导，得<br>$$ \frac{\partial \log g(p)}{\partial p} = \frac{1}{B(\alpha, \beta)} \left( \frac{k+\alpha-1}{p} - \frac{n-k+\beta-1}{1-p} \right)$$ </p>
<p>  令上式等于0，得$\displaystyle \hat{p} = \frac{k+\alpha-1}{n+\alpha+\beta-2}$，其中$\alpha, \beta$为beta分布的参数。</p>
<p>  所以最大后验概率估计得到$\displaystyle P(X=1)=\frac{k+\alpha-1}{n+\alpha+\beta-2}$</p>
<p>解法二：求后验概率分布的期望  </p>
<p>  后验概率分布的期望求解<br>  参考Wiki（中文）：<a href="https://zh.wikipedia.org/wiki/%E6%9C%80%E5%A4%A7%E5%90%8E%E9%AA%8C%E6%A6%82%E7%8E%87" target="_blank" rel="noopener">https://zh.wikipedia.org/wiki/%E6%9C%80%E5%A4%A7%E5%90%8E%E9%AA%8C%E6%A6%82%E7%8E%87</a><br>  参考Wiki（英文）：<a href="https://en.wikipedia.org/wiki/Bayes_estimator" target="_blank" rel="noopener">https://en.wikipedia.org/wiki/Bayes_estimator</a>  </p>
<blockquote>
<p>  贝叶斯估计中的最大后验概率估计，得到的是模型参数$\theta$这个随机变量的后验分布的众数，通常被认为是点估计。而贝叶斯方法的特点是使用分布来总结数据和得出推论，因此贝叶斯方法倾向于得到后验均值或中值，以及可信区间。<br>  贝叶斯估计，利用后验分布的期望（均值）作为参数的估计值的方法，前两步与最大后验概率估计相同，第3、4步如下：  </p>
<ol start="3">
<li>利用贝叶斯公式，求$\theta$的后验概率：$\displaystyle P(\theta|D)=\frac{P(D|\theta)P(\theta)}{\displaystyle \int \limits_\Theta P(D|\theta) P(\theta) d \theta}$   </li>
<li>计算后验概率分布参数$\theta$的期望，并求出贝叶斯估计值：$\displaystyle \hat{\theta}=\int \limits_{\Theta} \theta \cdot P(\theta|D) d \theta$  </li>
</ol>
</blockquote>
<p>  已知似然函数和参数$p$的先验分布，参数$p$的后验分布为：<br>$$<br>\begin{aligned}<br>P(p|X) &amp;= \frac{P(X|p)\pi(p)}{\displaystyle \int P(X|p)\pi(p)dp} \<br>&amp;=\frac{\displaystyle  \frac{1}{B(\alpha, \beta)}  p^{k+\alpha-1} (1-p)^{n-k+\beta-1} }{\displaystyle  \int \frac{1}{B(\alpha, \beta)}  p^{k+\alpha-1} (1-p)^{n-k+\beta-1} dp} \<br>&amp;=\frac{ p^{k+\alpha-1} (1-p)^{n-k+\beta-1} }{\displaystyle \int p^{k+\alpha-1} (1-p)^{n-k+\beta-1} dp} \<br>&amp;=\frac{1}{B(k+\alpha, n-k+\beta)} p^{k+\alpha-1} (1-p)^{n-k+\beta-1} \<br>&amp;\sim \text{Be}(k+\alpha, n-k+\beta) \<br>\end{aligned}<br>$$<br>  后验概率分布的期望:<br>$$<br>\begin{aligned}<br>E_p(p|X)&amp;=E_p({\rm Be}(k+\alpha, n-k+\beta)) \<br>&amp;=\frac{k+\alpha}{(k+\alpha)+(n-k+\beta)} \<br>&amp;=\frac{k+\alpha}{n+\alpha+\beta}<br>\end{aligned}<br>$$<br>  则以参数的后验概率分布的期望作为贝叶斯估计的参数值：<br>$$<br>\displaystyle \hat{p}=\frac{k+\alpha}{n+\alpha+\beta}<br>$$<br>  所以贝叶斯估计得到$\displaystyle P(X=1)=\frac{k+\alpha}{n+\alpha+\beta}$</p>
<h3 id="习题1-2"><a href="#习题1-2" class="headerlink" title="习题1.2"></a>习题1.2</h3><p>  通过经验风险最小化推导极大似然估计。证明模型是条件概率分布，当损失函数是对数损失函数时，经验风险最小化等价于极大似然估计。</p>
<p><strong>解答：</strong></p>
<p><strong>解答思路：</strong>  </p>
<ol>
<li>根据经验风险最小化定义，写出目标函数；</li>
<li>根据对数损失函数，对目标函数进行整理；</li>
<li>根据似然函数定义和极大似然估计的一般步骤（计算时需要取对数），可得到结论。</li>
</ol>
<p><strong>解答步骤：</strong><br>  假设模型的条件概率分布是$P_{\theta}(Y|X)$，样本集$D={(x_1,y_1),(x_2,y_2),\ldots,(x_N,y_N)}$，根据书中第17页公式(1.12)，对数损失函数为：<br>$$<br>L(Y,P(Y|X)) = -\log P(Y|X)<br>$$<br>  根据书中第18页公式(1.15)，按照经验风险最小化求最优模型就是求解最优化问题：<br>$$<br>\min \limits_{f \in \mathcal{F} } \frac{1}{N} \sum_{i=1}^N L(y_i, f(x_i))<br>$$<br>  结合上述两个式子，可得经验风险最小化函数：<br>$$<br>\begin{aligned}<br>\mathop{\arg\min} \limits_{f \in \mathcal{F} } \frac{1}{N} \sum_{i=1}^N L(y_i, f(x_i)) &amp;= \mathop{\arg\min} \limits_{f \in \mathcal{F} } \frac{1}{N} \sum_D [-\log P(Y|X)] \<br>&amp;= \mathop{\arg\max} \limits_{f \in \mathcal{F} } \frac{1}{N} \sum_D \log P(Y|X) \<br>&amp;= \mathop{\arg\max} \limits_{f \in \mathcal{F} } \frac{1}{N} \log \prod_D P(Y|X) \<br>&amp;= \frac{1}{N} \mathop{\arg\max} \limits_{f \in \mathcal{F} } \log \prod_D P(Y|X)<br>\end{aligned}<br>$$<br>  根据似然函数定义：$\displaystyle L(\theta)=\prod_D P_{\theta}(Y|X)$，以及极大似然估计的一般步骤，可得：<br>$$<br>\mathop{\arg\min} \limits_{f \in \mathcal{F} } \frac{1}{N} \sum_{i=1}^N L(y_i, f(x_i)) = \frac{1}{N} \mathop{\arg\max} \limits_{f \in \mathcal{F} } \log L(\theta)<br>$$<br>  即经验风险最小化等价于极大似然估计，得证。   </p>
<h1 id="二、感知器"><a href="#二、感知器" class="headerlink" title="二、感知器"></a>二、感知器</h1><p>感知机（perceptron）是二类分类的线性分类模型，其输入为实例的特征向量，输出为实例的类别，取+1和-1二值。感知机对应于输入空间（特征空间）中将实例划分为正负两类的分离超平面，属于判别模型。感知机学习旨在求出将训练数据进行线性划分的分离超平面，为此，导入基于误分类的损失函数，利用梯度下降法对损失函数进行极小化，求得感知机模型。感知机学习算法具有简单而易于实现的优点，分为原始形式和对偶形式感知机预测是用学习得到的感知机模型对新的输入实例进行分类，感知机1957年由 Rosenblatt提出，是神经网络与支持向量机的基础。</p>
<h2 id="2-1-感知器模型"><a href="#2-1-感知器模型" class="headerlink" title="2.1 感知器模型"></a>2.1 感知器模型</h2><p><strong>定义2.1（感知机）</strong>假设输入空间（特征空间）是$X \leq R ^ { n }$，输出空间是$Y = { + 1 , - 1 }$.输入$x∈X$表示实例的特征向量，对应于输入空间（特征空间）的点；输出$y∈Y$表示实例的类别。由输入空间到输出空间的如下函数<br>$$<br>f ( x ) = \operatorname { sign } ( w \cdot x + b )<br>$$<br>称为感知机、其中，w和b为感知机模型参数，$w∈R ^ { n }$叫作权值( weight)或权值向量( weight vector)，$b∈R$叫作偏置(bias),$w \cdot x$表示w和x的内积。sign是符号函数，即:<br>$$<br>\operatorname { sign } ( x ) = { \begin{array}  { ll  }  { + 1 , } &amp; { x \geq 0 } \ { - 1 , } &amp; { x \lt 0 } \end{array}<br>$$<br><img src="/images/loading.gif" data-original="../images/ML/image-20220109123216525.png" alt="感知器模型"></p>
<h2 id="2-2-感知器学习策略"><a href="#2-2-感知器学习策略" class="headerlink" title="2.2 感知器学习策略"></a>2.2 感知器学习策略</h2><h3 id="2-2-1-数据集的线性可分性"><a href="#2-2-1-数据集的线性可分性" class="headerlink" title="2.2.1 数据集的线性可分性"></a>2.2.1 数据集的线性可分性</h3><p><strong>定义2.2（数据集的线性可分性）</strong>给定一个数据集：<br>$$<br>T = {(x _ { 1 } , y _ { 1 }) , (y _ { 2 } , y _ { 2 }) , \cdots , ( x _ { N } , y _ { N } ) }<br>$$<br>如果存在某个超平面S: $ w \cdot x + b $，能够将数据集的正实例点和负实例点完全正确地划分到超平面的两侧，则称数据集T为线性可分数据集（linearly separable data set）;否则，称数据集T线性不可分</p>
<h3 id="2-2-2-感知器学习策略"><a href="#2-2-2-感知器学习策略" class="headerlink" title="2.2.2 感知器学习策略"></a>2.2.2 感知器学习策略</h3><p>感知机$\operatorname { sign } ( w \cdot x + b )$学习的损失函数定义为:<br>$$<br>L(w, b)=-\sum_{x_{i} \in M} y_{i}\left(w \cdot x_{i}+b\right)<br>$$<br>根据误差距离推导出来的</p>
<h2 id="2-3-感知器学习算法"><a href="#2-3-感知器学习算法" class="headerlink" title="2.3 感知器学习算法"></a>2.3 感知器学习算法</h2><h3 id="2-3-1-感知器学习算法原始形式"><a href="#2-3-1-感知器学习算法原始形式" class="headerlink" title="2.3.1 感知器学习算法原始形式"></a>2.3.1 感知器学习算法原始形式</h3><p>损失函数最优化形式求解：<br>$$<br> \min <em>{w,b}L(w, b)=- \sum</em>{x_{i} \in M} y_{i} \left(w \cdot x_{i}+b \right)<br>$$<br><strong>算法2.1（感知机学习算法的原始形式）</strong></p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20220109130619452.png" alt=""></p>
<h3 id="2-3-2-算法的收敛性"><a href="#2-3-2-算法的收敛性" class="headerlink" title="2.3.2 算法的收敛性"></a>2.3.2 算法的收敛性</h3><p><strong>定理2.1 (Novikoff)</strong></p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20220109130802872.png" alt=""></p>
<h3 id="2-3-3-感知机学习算法的对偶形式"><a href="#2-3-3-感知机学习算法的对偶形式" class="headerlink" title="2.3.3 感知机学习算法的对偶形式"></a>2.3.3 感知机学习算法的对偶形式</h3><p><strong>算法2.2（感知机学习算法的对偶形式）</strong></p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20220109131131873.png" alt=""></p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20220109131149308.png" alt=""></p>
<h2 id="习题-1"><a href="#习题-1" class="headerlink" title="习题"></a>习题</h2><h3 id="习题2-1"><a href="#习题2-1" class="headerlink" title="习题2.1"></a>习题2.1</h3><p>  Minsky 与 Papert 指出：感知机因为是线性模型，所以不能表示复杂的函数，如异或 (XOR)。验证感知机为什么不能表示异或。</p>
<p><strong>解答：</strong>  </p>
<p><strong>解答思路：</strong>  </p>
<ol>
<li>列出异或函数(XOR)的输入和输出；</li>
<li>使用图例法证明异或问题是线性不可分的；</li>
<li>使用反证法证明感知机无法表示异或。</li>
</ol>
<p><strong>解题步骤：</strong></p>
<p><strong>第1步：异或函数(XOR)的输入和输出</strong></p>
<p>  对于异或函数(XOR)，全部的输入与对应的输出如下：  </p>
<table>
<thead>
<tr>
<th align="center">$x_1$</th>
<th align="center">$x_2$</th>
<th align="center">$y=x_1\oplus x_2$</th>
</tr>
</thead>
<tbody><tr>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">-1</td>
</tr>
<tr>
<td align="center">0</td>
<td align="center">1</td>
<td align="center">1</td>
</tr>
<tr>
<td align="center">1</td>
<td align="center">0</td>
<td align="center">1</td>
</tr>
<tr>
<td align="center">1</td>
<td align="center">1</td>
<td align="center">-1</td>
</tr>
</tbody></table>
<p><strong>第2步：使用图例法证明异或问题是线性不可分的</strong></p>
<pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">import</span> pandas <span class="token keyword">as</span> pd
<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np
<span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> plt
<span class="token operator">%</span>matplotlib inline

<span class="token comment" spellcheck="true"># 使用Dataframe表示异或的输入与输出数据</span>
x1 <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span>
x2 <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span>
y <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span>
x1 <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span>x1<span class="token punctuation">)</span>
x2 <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span>x2<span class="token punctuation">)</span>
y <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span>y<span class="token punctuation">)</span>
data <span class="token operator">=</span> np<span class="token punctuation">.</span>c_<span class="token punctuation">[</span>x1<span class="token punctuation">,</span> x2<span class="token punctuation">,</span> y<span class="token punctuation">]</span>
data <span class="token operator">=</span> pd<span class="token punctuation">.</span>DataFrame<span class="token punctuation">(</span>data<span class="token punctuation">,</span> index<span class="token operator">=</span>None<span class="token punctuation">,</span> columns<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">'x1'</span><span class="token punctuation">,</span> <span class="token string">'x2'</span><span class="token punctuation">,</span> <span class="token string">'y'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
data<span class="token punctuation">.</span>head<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<div>
<table border="0" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>x1</th>
      <th>x2</th>
      <th>y</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0</td>
      <td>0</td>
      <td>-1</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0</td>
      <td>1</td>
      <td>1</td>
    </tr>
    <tr>
      <th>2</th>
      <td>1</td>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>3</th>
      <td>1</td>
      <td>1</td>
      <td>-1</td>
    </tr>
  </tbody>
</table>
</div>

<pre class="line-numbers language-python"><code class="language-python"><span class="token comment" spellcheck="true"># 获取正类别（y=1）的数据</span>
positive <span class="token operator">=</span> data<span class="token punctuation">.</span>loc<span class="token punctuation">[</span>data<span class="token punctuation">[</span><span class="token string">'y'</span><span class="token punctuation">]</span> <span class="token operator">==</span> <span class="token number">1</span><span class="token punctuation">]</span>
<span class="token comment" spellcheck="true"># 获取负类别（y=-1）的数据</span>
negative <span class="token operator">=</span> data<span class="token punctuation">.</span>loc<span class="token punctuation">[</span>data<span class="token punctuation">[</span><span class="token string">'y'</span><span class="token punctuation">]</span> <span class="token operator">==</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span>

<span class="token comment" spellcheck="true"># 绘制数据图</span>
<span class="token comment" spellcheck="true"># 绘制坐标轴</span>
plt<span class="token punctuation">.</span>xlim<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">0.5</span><span class="token punctuation">,</span> <span class="token number">1.5</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>ylim<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">0.5</span><span class="token punctuation">,</span> <span class="token number">1.5</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>xticks<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">0.5</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1.5</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>yticks<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">0.5</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1.5</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
<span class="token comment" spellcheck="true"># 添加坐标轴文字</span>
plt<span class="token punctuation">.</span>xlabel<span class="token punctuation">(</span><span class="token string">"x1"</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>ylabel<span class="token punctuation">(</span><span class="token string">"x2"</span><span class="token punctuation">)</span>
<span class="token comment" spellcheck="true"># 绘制正、负样本点</span>
plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>positive<span class="token punctuation">[</span><span class="token string">'x1'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> positive<span class="token punctuation">[</span><span class="token string">'x2'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token string">"ro"</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>negative<span class="token punctuation">[</span><span class="token string">'x1'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> negative<span class="token punctuation">[</span><span class="token string">'x2'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token string">"bx"</span><span class="token punctuation">)</span>
<span class="token comment" spellcheck="true"># 添加图示</span>
plt<span class="token punctuation">.</span>legend<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token string">'Positive'</span><span class="token punctuation">,</span> <span class="token string">'Negative'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p><img src="/images/loading.gif" data-original="../images/ML/output_8_0.png" alt=""></p>
<p>  从上图可以看出，无法使用一条直线将两类样本分开，所以异或问题是线性不可分的</p>
<pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>linear_model <span class="token keyword">import</span> Perceptron
<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np

<span class="token comment" spellcheck="true"># 构造异或问题的训练数据集</span>
X_train <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
y <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span>

<span class="token comment" spellcheck="true"># 使用sklearn的Perceptron类构建感知机模型</span>
perceptron_model <span class="token operator">=</span> Perceptron<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token comment" spellcheck="true"># 进行模型训练</span>
perceptron_model<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>X_train<span class="token punctuation">,</span> y<span class="token punctuation">)</span>

<span class="token comment" spellcheck="true"># 打印模型参数</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"感知机模型的参数：w="</span><span class="token punctuation">,</span> perceptron_model<span class="token punctuation">.</span>coef_<span class="token punctuation">[</span>
      <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token string">"b="</span><span class="token punctuation">,</span> perceptron_model<span class="token punctuation">.</span>intercept_<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<pre><code>感知机模型的参数：w= [0. 0.] b= 0.0</code></pre><p>  上述使用sklearn的Perceptron类构建感知机模型，从模型的参数上观察，感知机模型无法表示异或。</p>
<p><strong>第3步：使用反证法证明感知机无法表示异或</strong></p>
<p>  根据书中第35页感知机模型的定义：  </p>
<blockquote>
<p><strong>定义2.1（感知机）</strong> 假设输入空间（特征空间）是$\mathcal{X} \subseteq R^n$，输出空间是$\mathcal{y}={+1,-1}$。输入$x \in \mathcal{X}$表示实例的特征向量，对应于输入空间（特征空间）的点；输出$y \in \mathcal{Y}$表示实例的类别。由输入空间到输出空间的如下函数：</p>
</blockquote>
<p>$$<br>f(x)=\text{sign}(w \cdot x + b)<br>$$</p>
<blockquote>
<p>称为感知机。其中，$w$和$b$为感知机模型参数，$w \in R^n$叫做权值或权值向量，$b \in R$叫做偏置，$w \cdot x$表示$w$和$x$的内积。sign是符号函数，即</p>
</blockquote>
<p>$$<br>\text{sign}(x)=\left { \begin{array}{ll}<br>+1, \quad x \geqslant 0 \<br>-1, \quad x &lt; 0<br>\end{array}\right.<br>$$</p>
<p>  假设感知机模型可以表示异或问题，即满足异或函数(XOR)输入与输出的情况（见<strong>第1步</strong>）。假设$x$向量只有两个维度$x_1$，$x_2$：</p>
<ol>
<li>根据$x_1=0, x_2=0, f(x)=-1$，则$w \cdot x +b &lt; 0$，可得$b &lt; 0$；</li>
<li>根据$x_1=0, x_2=1, f(x)=1$，则$w_2 + b &gt; 0$，结合$b &lt; 0$，可得$w_2 &gt; -b &gt; 0$；</li>
<li>根据$x_1=1, x_2=0, f(x)=1$，则$w_1 + b &gt; 0$，结合$b &lt; 0$，可得$w_1 &gt; -b &gt; 0$；</li>
<li>根据$x_1=1, x_2=1$，并结合$w_1 + b &gt; 0$、$w_2 &gt; 0$，则$w_1 + w_2 + b &gt; 0$，可得$f(x)=1$，与异或条件中的$f(x)=-1$矛盾。</li>
</ol>
<p>  所以假设不成立，原命题成立，即感知机模型不能表示异或。</p>
<h3 id="习题2-2-⭐⭐⭐"><a href="#习题2-2-⭐⭐⭐" class="headerlink" title="习题2.2 ⭐⭐⭐"></a>习题2.2 ⭐⭐⭐</h3><p>  模仿例题 2.1，构建从训练数据求解感知机模型的例子。</p>
<p><strong>解答：</strong></p>
<p><strong>解答思路：</strong><br>  按照书中第38~39页感知机学习算法2.1，编写代码并绘制分离超平面</p>
<blockquote>
<p>算法2.1（感知机学习算法的原始形式）<br>输入：训练数据集$T={(x_1,y_1),(x_2,y_2),\ldots,(x_N,y_N)}$，其中$x_i \in \mathcal{X} = R^n$，$y_i \in \mathcal{Y} = {-1, +1}$，$i=1,2,\ldots,N$；学习率$\eta (0 &lt; \eta \leqslant 1)$；<br>输出：$w,b$；感知机模型$f(x)=\text{sign}(w \cdot x + b)$<br>（1）选取初值$w_0, b_0$；<br>（2）在训练集中选取数据$(x_i,y_i)$；<br>（3）如果$y_i(w \cdot x_i + b) \leqslant 0$，</p>
</blockquote>
<p>$$<br>\begin{array}{ll}<br>w \leftarrow w + \eta y_i x_i \<br>b \leftarrow b + \eta y_i<br>\end{array}<br>$$</p>
<blockquote>
<p>（4）转至（2），直至训练集中没有误分类点。  </p>
</blockquote>
<p><strong>解题步骤：</strong></p>
<pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">import</span> numpy <span class="token keyword">as</span> np
<span class="token keyword">from</span> matplotlib <span class="token keyword">import</span> pyplot <span class="token keyword">as</span> plt
<span class="token operator">%</span>matplotlib tk


<span class="token keyword">class</span> <span class="token class-name">Perceptron</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> X<span class="token punctuation">,</span> Y<span class="token punctuation">,</span> lr<span class="token operator">=</span><span class="token number">0.001</span><span class="token punctuation">,</span> plot<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token triple-quoted-string string">"""
        初始化感知机
        :param X: 特征向量
        :param Y: 类别
        :param lr: 学习率
        :param plot: 是否绘制图形
        """</span>
        self<span class="token punctuation">.</span>X <span class="token operator">=</span> X
        self<span class="token punctuation">.</span>Y <span class="token operator">=</span> Y
        self<span class="token punctuation">.</span>lr <span class="token operator">=</span> lr
        self<span class="token punctuation">.</span>plot <span class="token operator">=</span> plot
        <span class="token keyword">if</span> plot<span class="token punctuation">:</span>
            self<span class="token punctuation">.</span>__model_plot <span class="token operator">=</span> self<span class="token punctuation">.</span>_ModelPlot<span class="token punctuation">(</span>self<span class="token punctuation">.</span>X<span class="token punctuation">,</span> self<span class="token punctuation">.</span>Y<span class="token punctuation">)</span>
            self<span class="token punctuation">.</span>__model_plot<span class="token punctuation">.</span>open_in<span class="token punctuation">(</span><span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">fit</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment" spellcheck="true"># (1)初始化weight, b</span>
        weight <span class="token operator">=</span> np<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span>self<span class="token punctuation">.</span>X<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
        b <span class="token operator">=</span> <span class="token number">0</span>
        <span class="token comment" spellcheck="true"># 训练次数</span>
        train_counts <span class="token operator">=</span> <span class="token number">0</span>
        <span class="token comment" spellcheck="true"># 分类错误标识</span>
        mistake_flag <span class="token operator">=</span> <span class="token boolean">True</span>
        <span class="token keyword">while</span> mistake_flag<span class="token punctuation">:</span>
            <span class="token comment" spellcheck="true"># 开始前，将mistake_flag设置为False，用于判断本次循环是否有分类错误</span>
            mistake_flag <span class="token operator">=</span> <span class="token boolean">False</span>
            <span class="token comment" spellcheck="true"># (2)从训练集中选取x,y</span>
            <span class="token keyword">for</span> index <span class="token keyword">in</span> range<span class="token punctuation">(</span>self<span class="token punctuation">.</span>X<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
                <span class="token keyword">if</span> self<span class="token punctuation">.</span>plot<span class="token punctuation">:</span>
                    self<span class="token punctuation">.</span>__model_plot<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>weight<span class="token punctuation">,</span> b<span class="token punctuation">,</span> train_counts<span class="token punctuation">)</span>
                <span class="token comment" spellcheck="true"># 损失函数</span>
                loss <span class="token operator">=</span> self<span class="token punctuation">.</span>Y<span class="token punctuation">[</span>index<span class="token punctuation">]</span> <span class="token operator">*</span> <span class="token punctuation">(</span>weight @ self<span class="token punctuation">.</span>X<span class="token punctuation">[</span>index<span class="token punctuation">]</span> <span class="token operator">+</span> b<span class="token punctuation">)</span>
                <span class="token comment" spellcheck="true"># (3)如果损失函数小于0，则该点是误分类点</span>
                <span class="token keyword">if</span> loss <span class="token operator">&lt;=</span> <span class="token number">0</span><span class="token punctuation">:</span>
                    <span class="token comment" spellcheck="true"># 更新weight, b</span>
                    weight <span class="token operator">+=</span> self<span class="token punctuation">.</span>lr <span class="token operator">*</span> self<span class="token punctuation">.</span>Y<span class="token punctuation">[</span>index<span class="token punctuation">]</span> <span class="token operator">*</span> self<span class="token punctuation">.</span>X<span class="token punctuation">[</span>index<span class="token punctuation">]</span>
                    b <span class="token operator">+=</span> self<span class="token punctuation">.</span>lr <span class="token operator">*</span> self<span class="token punctuation">.</span>Y<span class="token punctuation">[</span>index<span class="token punctuation">]</span>
                    <span class="token comment" spellcheck="true"># 训练次数加1</span>
                    train_counts <span class="token operator">+=</span> <span class="token number">1</span>
                    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"Epoch {}, weight = {}, b = {}, formula: {}"</span><span class="token punctuation">.</span>format<span class="token punctuation">(</span>
                        train_counts<span class="token punctuation">,</span> weight<span class="token punctuation">,</span> b<span class="token punctuation">,</span> self<span class="token punctuation">.</span>__model_plot<span class="token punctuation">.</span>formula<span class="token punctuation">(</span>weight<span class="token punctuation">,</span> b<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
                    <span class="token comment" spellcheck="true"># 本次循环有误分类点（即分类错误），置为True</span>
                    mistake_flag <span class="token operator">=</span> <span class="token boolean">True</span>
                    <span class="token keyword">break</span>
        <span class="token keyword">if</span> self<span class="token punctuation">.</span>plot<span class="token punctuation">:</span>
            self<span class="token punctuation">.</span>__model_plot<span class="token punctuation">.</span>close<span class="token punctuation">(</span><span class="token punctuation">)</span>
        <span class="token comment" spellcheck="true"># (4)直至训练集中没有误分类点</span>
        <span class="token keyword">return</span> weight<span class="token punctuation">,</span> b

    <span class="token keyword">class</span> <span class="token class-name">_ModelPlot</span><span class="token punctuation">:</span>
        <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> X<span class="token punctuation">,</span> Y<span class="token punctuation">)</span><span class="token punctuation">:</span>
            self<span class="token punctuation">.</span>X <span class="token operator">=</span> X
            self<span class="token punctuation">.</span>Y <span class="token operator">=</span> Y

        @staticmethod
        <span class="token keyword">def</span> <span class="token function">open_in</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            <span class="token comment" spellcheck="true"># 打开交互模式，用于展示动态交互图</span>
            plt<span class="token punctuation">.</span>ion<span class="token punctuation">(</span><span class="token punctuation">)</span>

        @staticmethod
        <span class="token keyword">def</span> <span class="token function">close</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            <span class="token comment" spellcheck="true"># 关闭交互模式，并显示最终的图形</span>
            plt<span class="token punctuation">.</span>ioff<span class="token punctuation">(</span><span class="token punctuation">)</span>
            plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>

        <span class="token keyword">def</span> <span class="token function">plot</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> weight<span class="token punctuation">,</span> b<span class="token punctuation">,</span> epoch<span class="token punctuation">)</span><span class="token punctuation">:</span>
            plt<span class="token punctuation">.</span>cla<span class="token punctuation">(</span><span class="token punctuation">)</span>
            <span class="token comment" spellcheck="true"># x轴表示x1</span>
            plt<span class="token punctuation">.</span>xlim<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> np<span class="token punctuation">.</span>max<span class="token punctuation">(</span>self<span class="token punctuation">.</span>X<span class="token punctuation">.</span>T<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">)</span>
            <span class="token comment" spellcheck="true"># y轴表示x2</span>
            plt<span class="token punctuation">.</span>ylim<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> np<span class="token punctuation">.</span>max<span class="token punctuation">(</span>self<span class="token punctuation">.</span>X<span class="token punctuation">.</span>T<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">)</span>
            <span class="token comment" spellcheck="true"># 画出散点图，并添加图示</span>
            scatter <span class="token operator">=</span> plt<span class="token punctuation">.</span>scatter<span class="token punctuation">(</span>self<span class="token punctuation">.</span>X<span class="token punctuation">.</span>T<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> self<span class="token punctuation">.</span>X<span class="token punctuation">.</span>T<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> c<span class="token operator">=</span>self<span class="token punctuation">.</span>Y<span class="token punctuation">)</span>
            plt<span class="token punctuation">.</span>legend<span class="token punctuation">(</span><span class="token operator">*</span>scatter<span class="token punctuation">.</span>legend_elements<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
            <span class="token keyword">if</span> <span class="token boolean">True</span> <span class="token keyword">in</span> list<span class="token punctuation">(</span>weight <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
                plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span>
            <span class="token keyword">else</span><span class="token punctuation">:</span>
                x1 <span class="token operator">=</span> <span class="token operator">-</span>b <span class="token operator">/</span> weight<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
                x2 <span class="token operator">=</span> <span class="token operator">-</span>b <span class="token operator">/</span> weight<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span>
                <span class="token comment" spellcheck="true"># 画出分离超平面</span>
                plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span><span class="token punctuation">[</span>x1<span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> x2<span class="token punctuation">]</span><span class="token punctuation">)</span>
                <span class="token comment" spellcheck="true"># 绘制公式</span>
                text <span class="token operator">=</span> self<span class="token punctuation">.</span>formula<span class="token punctuation">(</span>weight<span class="token punctuation">,</span> b<span class="token punctuation">)</span>
                plt<span class="token punctuation">.</span>text<span class="token punctuation">(</span><span class="token number">0.3</span><span class="token punctuation">,</span> x2 <span class="token operator">-</span> <span class="token number">0.1</span><span class="token punctuation">,</span> text<span class="token punctuation">)</span>
            plt<span class="token punctuation">.</span>title<span class="token punctuation">(</span><span class="token string">'Epoch %d'</span> <span class="token operator">%</span> epoch<span class="token punctuation">)</span>
            plt<span class="token punctuation">.</span>pause<span class="token punctuation">(</span><span class="token number">0.01</span><span class="token punctuation">)</span>

        @staticmethod
        <span class="token keyword">def</span> <span class="token function">formula</span><span class="token punctuation">(</span>weight<span class="token punctuation">,</span> b<span class="token punctuation">)</span><span class="token punctuation">:</span>
            text <span class="token operator">=</span> <span class="token string">'x1 '</span> <span class="token keyword">if</span> weight<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">==</span> <span class="token number">1</span> <span class="token keyword">else</span> <span class="token string">'%d*x1 '</span> <span class="token operator">%</span> weight<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
            text <span class="token operator">+=</span> <span class="token string">'+ x2 '</span> <span class="token keyword">if</span> weight<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">==</span> <span class="token number">1</span> <span class="token keyword">else</span> <span class="token punctuation">(</span>
                <span class="token string">'+ %d*x2 '</span> <span class="token operator">%</span> weight<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token keyword">if</span> weight<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">></span> <span class="token number">0</span> <span class="token keyword">else</span> <span class="token string">'- %d*x2 '</span> <span class="token operator">%</span> <span class="token operator">-</span>weight<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
            text <span class="token operator">+=</span> <span class="token string">'= 0'</span> <span class="token keyword">if</span> b <span class="token operator">==</span> <span class="token number">0</span> <span class="token keyword">else</span> <span class="token punctuation">(</span><span class="token string">'+ %d = 0'</span> <span class="token operator">%</span>
                                          b <span class="token keyword">if</span> b <span class="token operator">></span> <span class="token number">0</span> <span class="token keyword">else</span> <span class="token string">'- %d = 0'</span> <span class="token operator">%</span> <span class="token operator">-</span>b<span class="token punctuation">)</span>
            <span class="token keyword">return</span> text<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<pre class="line-numbers language-python"><code class="language-python">X <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
Y <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
model <span class="token operator">=</span> Perceptron<span class="token punctuation">(</span>X<span class="token punctuation">,</span> Y<span class="token punctuation">,</span> lr<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>
weight<span class="token punctuation">,</span> b <span class="token operator">=</span> model<span class="token punctuation">.</span>fit<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre>
<pre><code>Epoch 1, weight = [3. 3.], b = 1, formula: 3*x1 + 3*x2 + 1 = 0
Epoch 2, weight = [2. 2.], b = 0, formula: 2*x1 + 2*x2 = 0
Epoch 3, weight = [1. 1.], b = -1, formula: x1 + x2 - 1 = 0
Epoch 4, weight = [0. 0.], b = -2, formula: 0*x1 - 0*x2 - 2 = 0
Epoch 5, weight = [3. 3.], b = -1, formula: 3*x1 + 3*x2 - 1 = 0
Epoch 6, weight = [2. 2.], b = -2, formula: 2*x1 + 2*x2 - 2 = 0
Epoch 7, weight = [1. 1.], b = -3, formula: x1 + x2 - 3 = 0</code></pre><p><img src="/images/loading.gif" data-original="../images/ML/output_17_1.png" alt=""></p>
<h3 id="习题2-3"><a href="#习题2-3" class="headerlink" title="习题2.3"></a>习题2.3</h3><p>  证明以下定理：样本集线性可分的充分必要条件是正实例点所构成的凸壳与负实例点所构成的凸壳互不相交。</p>
<p><strong>解答：</strong></p>
<p><strong>解答思路：</strong></p>
<ol>
<li>写出凸壳和线性可分的定义</li>
<li>证明必要性：线性可分$\Rightarrow$凸壳不相交  </li>
<li>证明充分性：凸壳不相交$\Rightarrow$线性可分  </li>
</ol>
<p><strong>第1步：凸壳与线性可分的定义</strong>  </p>
<ol>
<li>根据书中第47页脚注1的凸壳定义如下：  </li>
</ol>
<blockquote>
<p>设集合$S \subset R^n$，是由$R^n$中的$k$个点所组成的集合，即$S={x_1,x_2,\cdots, x_k}$。定义$S$的凸壳$\text{conv}(S)$为：</p>
</blockquote>
<p>$$<br> \text{conv}(S) = \left{ x = \sum_{i=1}^k \lambda_i x_i \Big| \sum_{i=1}^k \lambda_i=1,\lambda_i \geqslant 0, i=1,2,\cdots, k \right}<br>$$</p>
<ol start="2">
<li>根据书中第36页的线性可分定义如下： </li>
</ol>
<blockquote>
<p>给定一个数据集</p>
</blockquote>
<p>$$<br>T={(x_1,y_1), (x_2,y_2), \cdots, (x_n,y_n)}<br>$$</p>
<blockquote>
<p>其中$x_i \in \mathcal{X}=R_n, y_i \in \mathcal{Y} = {+1, -1}, i=1,2,\cdots, n$，如果存在某个超平面$S$</p>
</blockquote>
<p>$$<br>w \cdot x + b = 0<br>$$</p>
<blockquote>
<p>能够将数据集的正实例点和负实例点完全正确划分到超平面的两侧，即对所有$y_i=+1$的实例$i$，有$w \cdot x_i + b &gt; 0$，对$y_i = -1$的实例$i$，有$w \cdot x_i + b &lt; 0$，则称数据集$T$为线性可分数据集，否则称数据集$T$线性不可分。</p>
</blockquote>
<p><strong>第2步：证明必要性：线性可分$\Rightarrow$凸壳不相交</strong>  </p>
<p>证明思路（反证法）：</p>
<ol>
<li>假设原命题不成立：样本集线性可分，正实例点所构成的凸壳与负实例点所构成的凸壳相交</li>
<li>条件推理</li>
<li>发现矛盾，得出原命题成立</li>
</ol>
<p>证明步骤：</p>
<ol>
<li><p>假设原命题不成立：<br>设数据集$T$中的正例点集为$S_+$，$S_+$的凸壳为$\text{conv}(S_+)$，负实例点集为$S_-$，$S_-$的凸壳为$\text{conv}(S_-)$。<br>假设样本集线性可分，正实例点所构成的凸壳与负实例点所构成的凸壳相交，即存在某个元素$s$，同时满足$s \in \text{conv}(S_+)$和$s \in \text{conv}(S_-)$。    </p>
</li>
<li><p>条件推理：<br>若数据集$T$是线性可分的，根据线性可分的定义，则存在一个超平面能够将$S_+$和$S_-$完全分离：  </p>
</li>
</ol>
<p>$$<br>w \cdot x + b = 0<br>$$</p>
<p>对于所有的正例点$x_i$，有<br>$$<br>w \cdot x_i + b = \varepsilon_i &gt; 0, \quad i = 1,2,\cdots,|S_+|<br>$$<br>根据凸壳的定义，对于$\text{conv}(S_+)$中的元素$s_+$，有<br>$$<br>\begin{aligned}<br>w \cdot s_+ + b &amp;= w \cdot (\sum_{i=1}^{|S_+|} \lambda_i x_i) + b \<br>&amp;= (\sum_{i=1}^{|S_+|} \lambda_i(\varepsilon_i - b)) + b \<br>&amp;= \sum_{i=1}^{|S_+|} \lambda_i \varepsilon_i - (b\sum_{i=1}^{|S_+|} \lambda_i) + b \quad (\because \sum_{i=1}^{|S_+|} \lambda_i = 1) \<br>&amp; = \sum_{i=1}^{|S_+|} \lambda_i \varepsilon_i<br>\end{aligned}<br>$$<br>因此$\displaystyle w \cdot s_+ + b = \sum_{i=1}^{|S_+|} \lambda_i \varepsilon_i &gt; 0$。<br>同理对于$S_-$中的元素$s_-$，有$\displaystyle w \cdot s_- + b = \sum_{i=1}^{|S_-|} \lambda_i \varepsilon_i &lt; 0$       </p>
<ol start="3">
<li>找出矛盾，得出原命题成立：<br>根据条件推理，当$s \in \text{conv}(S_+)$有$\displaystyle w \cdot s + b = \sum_{i=1}^{|S_+|} \lambda_i \varepsilon_i &gt; 0$，当$s \in \text{conv}(S_-)$有$\displaystyle w \cdot s + b = \sum_{i=1}^{|S_-|} \lambda_i \varepsilon_i &lt; 0$，既$s$不可能同时满足若$\displaystyle s \in \text{conv}(S_+)$和$s \in \text{conv}(S_-)$，这与假设命题矛盾。  </li>
</ol>
<p>因此，原命题成立，当样本线性可分时，$\text{conv}(S_+)$ 和$\text{conv}(S_-)$必不相交。必要性得证。  </p>
<p><strong>第3步：证明充分性：凸壳不相交$\Rightarrow$线性可分</strong>  </p>
<p>证明思路：</p>
<ol>
<li>根据凸壳不相交，找到一个超平面</li>
<li>证明这个超平面可将两个互不相交的凸壳分隔开（反证法）</li>
<li>上述超平面可以将凸壳分隔开，则样本集满足线性可分</li>
</ol>
<p>证明步骤：</p>
<ol>
<li>根据凸壳不相交，找到一个超平面：<br>设数据集$T$中的正例点集为$S_+$，$S_+$的凸壳为$\text{conv}(S_+)$，负实例点集为$S_-$，$S_-$的凸壳为$\text{conv}(S_-)$，且$\text{conv}(S_+)$与$\text{conv}(S_-)$不相交。<br>定义两个点$x_1,x_2$的距离为</li>
</ol>
<p>$$<br>\text{dist}(x_1,x_2) = |x_1 - x_2|_2<br>$$</p>
<p>定义$\text{conv}(S_+)$、$\text{conv}(S_-)$的距离是，分别处于两个凸壳集合中的点的距离最小值：<br>$$<br> \text {dist}( \text{conv}(S_+), \text{conv}(S_-)) = \min |s_+ - s_-|<em>2 \quad s</em>+ \in \text{conv}(S_+), s_- \in \text{conv}(S_-)<br>$$<br>记最小值点分别为$x_+, x_-$，即：<br>$$<br> \text{dist}( \text{conv}(S_+), \text{conv}(S_-)) = \text{dist}(x_+, x_-) \quad x_+ \in \text{conv}(S_+), x_- \in \text{conv}(S_-)<br>$$<br>定义以$(x_+, x_-)$为法线，且过两点中点的超平面为$f(x|w,b)=0$，则参数为：<br>$$<br> \displaystyle f(x|w,b)=(x_+-x_-)^T(x - \frac{x_+ + x_-}{2})\<br> \left { \begin{array}{ll}<br>w = (x_+ - x_-)^T \<br> \displaystyle b = - \frac{1}{2}({|x_+|<em>2}^2 -  {|x</em>-|_2}^2)<br>\end{array} \right .<br>$$</p>
<ol start="2">
<li>证明这个超平面可将两个互不相交的凸壳分隔开（反证法）<br>若某个超平面可将两个互不相交的凸壳分隔开，则$f(x)≥0, x\in \text{conv}(S_+)$且$f(x)≤0, x\in \text{conv}(S_-)$。</li>
</ol>
<p>$$<br>\begin{aligned}<br>\displaystyle f(x)&amp;=(x_+-x_-)^T(x - \frac{x_+ + x_-}{2}) \<br>&amp;=(x_+-x_-)^T(x + x_+ - x_+ - \frac{x_+ + x_-}{2}) \<br>&amp;=(x_+-x_-)^T(x - x_+ + \frac{x_+ - x_-}{2}) \<br>&amp;=(x_+-x_-)^T(x - x_+) + \frac{ {|x_+ - x_-|_2}^2}{2} \<br>\end{aligned}<br>$$</p>
<p>假设原命题不成立：当$x\in \text{conv}(S_+)$时，假设$f(x)&lt;0$，则有：<br>$$<br>(x_+-x_-)^T(x - x_+) &lt; 0<br>$$<br>设点$u=x_++t(x-x_+), t\in [0,1]$，即$u$在$x_+$和$x$的线段上。根据凸壳定义，$u \in \text{conv}(S_+)$。则$u$和$x_-$距离的平方为：<br>$$<br> \begin{aligned}<br>\displaystyle g(t)&amp;={|u-x_-|<em>2}^2 \<br>&amp;={|x</em>++t(x-x_+)-x_-|<em>2}^2 \<br>\end{aligned}<br>$$<br>求解$u$和$x</em>-$距离的最小值，对上式求导：<br>$$<br> \begin{aligned}<br> \displaystyle g’(t)&amp;=2(x_++t(x-x_+)-x_-)(x-x_+) \<br>&amp;=2(x_+-x_-)^T(x-x_+)+t{|x-x_+|<em>2}^2 \<br>\end{aligned}<br>$$<br>根据假设，在$t=0$时，得$g’(t)&lt;0$。在当$t$足够接近于0时（导函数在0处的极限值为负，则存在邻域函数递减），即$g(t)&lt;g(0)$。<br>$\therefore$ 存在一点$u$，使得它到$x</em>-$的距离，比定义的凸壳距离$ \text{dist}(x_+,x_-)$还小。产生矛盾。<br>故原命题成立，即$ f(x)≥0, x\in \text{conv}(S_+)$。同理，可证$ f(x)≤0, x\in \text{conv}(S_-)$。则可以找到一个超平面将两个互不相交的凸壳分隔开。  </p>
<ol start="3">
<li>上述超平面可以将凸壳分隔开，则样本集满足线性可分<br>  根据凸壳定义，数据集$T$中正例点$s_+ \in \text{conv}(S_+)$，负例点$s_- \in \text{conv}(S_-)$。上述超平面可以将正例点集$S_+$和负例点集$S_-$两个凸壳分隔开，则可以使样本集线性可分。充分性得证。</li>
</ol>
<h1 id="三、k近邻法"><a href="#三、k近邻法" class="headerlink" title="三、k近邻法"></a>三、k近邻法</h1><p>k近邻法（k-nearest neighbor,k-NN）是一种基本分类与回归方法。k近邻法的输入为实例的特征向量，对应于特征空间的点；输出为实例的类别，可以取多类，k近邻法假设给定一个训练数据集，其中的实例类别已定。分类时，对新的实例，根据其k个最近邻的训练实例的类别，通过多数表决等方式进行预测。因此，k近邻法不具有显式的学习过程。k近邻法实际上利用训练数据集对特征向量空间进行划分，并作为其分类的”模型”k值的选择、距离度量及分类决策规则是k近邻法的三个基本要素。k近邻法1968年由 Cover和Hart提出。</p>
<h2 id="3-1-k近邻算法"><a href="#3-1-k近邻算法" class="headerlink" title="3.1 k近邻算法"></a>3.1 k近邻算法</h2><p><strong>算法3.1 （k近邻法）</strong></p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20220110093816450.png" alt=""></p>
<h2 id="3-2-k近邻模型"><a href="#3-2-k近邻模型" class="headerlink" title="3.2 k近邻模型"></a>3.2 k近邻模型</h2><p>k近邻法使用的模型实际上对应于对特征空间的划分。模型由三个基本要素——距离度量、k值的选择和分类决策规则决定。</p>
<h3 id="3-2-1-模型"><a href="#3-2-1-模型" class="headerlink" title="3.2.1 模型"></a>3.2.1 模型</h3><p>k近邻法中，当训练集、距离度量（如欧氏距离）、k值及分类决策规则（如多数表决）确定后，对于任何一个新的输入实例，它所属的类唯一地确定。这相当于根据上述要素将特征空间划分为一些子空间，确定子空间里的每个点所属的类，这一事实从最近邻算法中可以看得很清楚。</p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20220110094124426.png" alt="k近邻法模型对应特征空间的一个划分"></p>
<h3 id="3-2-2-距离度量"><a href="#3-2-2-距离度量" class="headerlink" title="3.2.2 距离度量"></a>3.2.2 距离度量</h3><p>特征空间中两个实例点的距离是两个实例点相似程度的反映。k近邻模型的特征空间一般是n维实数向量空间。使用的距离是欧氏距离，但也可以是其他距离。</p>
<p>常见的距离计算公式：</p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20220110094448948.png" alt=""></p>
<h3 id="3-2-3-k值选择"><a href="#3-2-3-k值选择" class="headerlink" title="3.2.3 k值选择"></a>3.2.3 k值选择</h3><p>k值的选择会对k近邻法的结果产生重大影响。</p>
<p>如果选择较小的k值，就相当于用较小的邻域中的训练实例进行预测，“学习”的近似误差（approximation error）会减小，只有与输入实例较近的（相似的）训练实例才会对预测结果起作用。但缺点是“学习”的估计误差（estimation error）会增大，预测结果会对近邻的实例点非常敏感。如果邻近的实例点恰巧是噪声，预测就会出错。换句话说，k值的减小就意味着整体模型变得复杂，容易发生过拟合。</p>
<p>如果选择较大的k值，就相当于用较大邻域中的训练实例进行预测，其优点是可以减少学习的估计误差，但缺点是学习的近似误差会增大。这时与输入实例较远的（不相似的）训练实例也会对预测起作用，使预测发生错误。k值的增大就意味着整体的模型变得简单。</p>
<p>如果k=N,那么无论输入实例是什么，都将简单地预测它属于在训练实例中最多的类。这时，模型过于简单，完全忽略训练实例中的大量有用信息，是不可取的。</p>
<p>在应用中，k值一般取一个比较小的数值，通常采用<strong>交叉验证法</strong>来选取最优的k值。</p>
<h3 id="3-2-4-分类决策规则"><a href="#3-2-4-分类决策规则" class="headerlink" title="3.2.4 分类决策规则"></a>3.2.4 分类决策规则</h3><p>k近邻法中的分类决策规则往往是多数表决，即由输入实例的k个邻近的训练实例中的多数类决定输入实例的类。</p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20220110094947978.png" alt=""></p>
<h2 id="3-3-k近邻法的实现：kd树"><a href="#3-3-k近邻法的实现：kd树" class="headerlink" title="3.3 k近邻法的实现：kd树"></a>3.3 k近邻法的实现：kd树</h2><p>实现k近邻法时，主要考虑的问题是如何对训练数据进行快速k近邻搜索。这点在特征空间的维数大及训练数据容量大时尤其必要。</p>
<p>k近邻法最简单的实现方法是线性扫描（linear scan）,这时要计算输入实例与每一个训练实例的距离。当训练集很大时，计算非常耗时，这种方法是不可行的。</p>
<h3 id="3-3-1-构造kd树"><a href="#3-3-1-构造kd树" class="headerlink" title="3.3.1 构造kd树"></a>3.3.1 构造kd树</h3><p>kd树是一种对k维空间中的实例点进行存储以便对其进行快速检索的树形数据结构，kd树是二叉树，表示对k维空间的一个划分（partition）.构造树相当于不断地用垂直于坐标轴的超平面将k维空间切分，构成一系列的k维超矩形区域。树的每个结点对应于一个k维超矩形区域。</p>
<p>构造树的方法如下：构造根结点，使根结点对应于k维空间中包含所有实例点的超矩形区域；通过下面的递归方法，不断地对k维空间进行切分，生成子结点。在超矩形区域（结点）上选择一个坐标轴和在此坐标轴上的一个切分点，确定一个超平面，这个超平面通过选定的切分点并垂直于选定的坐标轴，将当前超矩形区域切分为左右两个子区域（子结点）；这时，实例被分到两个子区域。这个过程直到子区域内没有实例时终止（终止时的结点为叶结点），在此过程中，将实例保存在相应的结点上。</p>
<p>通常，依次选择坐标轴对空间切分，选择训练实例点在选定坐标轴上的中位数（median）为切分点，这样得到的d树是平衡的。注意，平衡的d树搜索时的效率未必是最优的。</p>
<p><strong>算法3.2(构造平衡kd树)</strong></p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20220110095548882.png" alt=""></p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20220110095653713.png" alt=""></p>
<ul>
<li><a href="https://zhuanlan.zhihu.com/p/23966698" target="_blank" rel="noopener">kd树的详细解释</a></li>
</ul>
<h3 id="3-3-2-搜索kd树"><a href="#3-3-2-搜索kd树" class="headerlink" title="3.3.2 搜索kd树"></a>3.3.2 搜索kd树</h3><p><img src="/images/loading.gif" data-original="../images/ML/image-20220110100323064.png" alt="kd树示例"></p>
<p><strong>算法3.3（用kd树的最近邻搜索）</strong></p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20220110100433315.png" alt=""></p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20220110100542675.png" alt=""></p>
<p>实例：</p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20220110100839752.png" alt=""></p>
<ul>
<li><p>注意KNN (监督学习)与K-means (无监督学习)区别</p>
</li>
<li><p>KNN：</p>
<ul>
<li>算法：如果一个样本在特征空间中的k个最相似(即特征空间中最邻近)的样本中的大多数属于某一个类别，则该样本也属于这个类别。</li>
<li>k近邻模型的三个基本要素：<ol>
<li>k值的选择：k值的选择会对结果产生重大影响。较小的k值可以减少近似误差，但是会增加估计误差；较大的k值可以减小估计误差，但是会增加近似误差。一般而言，通常采用交叉验证法来选取最优的k值。</li>
<li>距离度量：距离反映了特征空间中两个实例的相似程度。可以采用欧氏距离、曼哈顿距离等。</li>
<li>分类决策规则：往往采用多数表决。</li>
</ol>
</li>
</ul>
</li>
<li><p>k-means：</p>
<ul>
<li><p>算法：</p>
<ol>
<li>从n个数据中随机选择 k 个对象作为初始聚类中心；</li>
<li>根据每个聚类对象的均值（中心对象），计算每个数据点与这些中心对象的距离；并根据最小距离准则，重新对数据进行划分；</li>
<li>重新计算每个有变化的聚类簇的均值，选择与均值距离最小的数据作为中心对象；</li>
<li>循环步骤2和3，直到每个聚类簇不再发生变化为止。</li>
</ol>
</li>
<li><p>k-means方法的基本要素：</p>
<ol>
<li><p>k值的选择：也就是类别的确定，与K近邻中k值的确定方法类似。</p>
</li>
<li><p>距离度量：可以采用欧氏距离、曼哈顿距离等。</p>
</li>
</ol>
</li>
</ul>
</li>
</ul>
<h2 id="习题-2"><a href="#习题-2" class="headerlink" title="习题"></a>习题</h2><h3 id="习题3-1"><a href="#习题3-1" class="headerlink" title="习题3.1"></a>习题3.1</h3><p>  参照图3.1，在二维空间中给出实例点，画出$k$为1和2时的$k$近邻法构成的空间划分，并对其进行比较，体会$k$值选择与模型复杂度及预测准确率的关系。</p>
<p><strong>解答：</strong></p>
<p><strong>解答思路：</strong></p>
<ol>
<li>参照图3.1，使用已给的实例点，采用sklearn的KNeighborsClassifier分类器，对k=1和2时的模型进行训练</li>
<li>使用matplotlib的contourf和scatter，画出k为1和2时的k近邻法构成的空间划分</li>
<li>根据模型得到的预测结果，计算预测准确率，并设置图形标题</li>
<li>根据程序生成的图，比较k为1和2时，k值选择与模型复杂度、预测准确率的关系</li>
</ol>
<p><strong>解答步骤：</strong></p>
<p><strong>第1、2、3步：使用已给的实例点，对$k$为1和2时的k近邻模型进行训练，并绘制空间划分</strong></p>
<pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">from</span> matplotlib<span class="token punctuation">.</span>colors <span class="token keyword">import</span> ListedColormap
<span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> plt
<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>neighbors <span class="token keyword">import</span> KNeighborsClassifier
<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np
<span class="token operator">%</span>matplotlib inline

data <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">12</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
                 <span class="token punctuation">[</span><span class="token number">6</span><span class="token punctuation">,</span> <span class="token number">21</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
                 <span class="token punctuation">[</span><span class="token number">14</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
                 <span class="token punctuation">[</span><span class="token number">16</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
                 <span class="token punctuation">[</span><span class="token number">13</span><span class="token punctuation">,</span> <span class="token number">19</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
                 <span class="token punctuation">[</span><span class="token number">13</span><span class="token punctuation">,</span> <span class="token number">32</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
                 <span class="token punctuation">[</span><span class="token number">17</span><span class="token punctuation">,</span> <span class="token number">27</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
                 <span class="token punctuation">[</span><span class="token number">18</span><span class="token punctuation">,</span> <span class="token number">24</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
                 <span class="token punctuation">[</span><span class="token number">20</span><span class="token punctuation">,</span> <span class="token number">20</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
                 <span class="token punctuation">[</span><span class="token number">23</span><span class="token punctuation">,</span> <span class="token number">14</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
                 <span class="token punctuation">[</span><span class="token number">23</span><span class="token punctuation">,</span> <span class="token number">25</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
                 <span class="token punctuation">[</span><span class="token number">23</span><span class="token punctuation">,</span> <span class="token number">31</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
                 <span class="token punctuation">[</span><span class="token number">26</span><span class="token punctuation">,</span> <span class="token number">8</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
                 <span class="token punctuation">[</span><span class="token number">30</span><span class="token punctuation">,</span> <span class="token number">17</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
                 <span class="token punctuation">[</span><span class="token number">30</span><span class="token punctuation">,</span> <span class="token number">26</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
                 <span class="token punctuation">[</span><span class="token number">34</span><span class="token punctuation">,</span> <span class="token number">8</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
                 <span class="token punctuation">[</span><span class="token number">34</span><span class="token punctuation">,</span> <span class="token number">19</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
                 <span class="token punctuation">[</span><span class="token number">37</span><span class="token punctuation">,</span> <span class="token number">28</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
<span class="token comment" spellcheck="true"># 得到特征向量</span>
X_train <span class="token operator">=</span> data<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">:</span><span class="token number">2</span><span class="token punctuation">]</span>
<span class="token comment" spellcheck="true"># 得到类别向量</span>
y_train <span class="token operator">=</span> data<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">]</span>

<span class="token comment" spellcheck="true">#（1）使用已给的实例点，采用sklearn的KNeighborsClassifier分类器，</span>
<span class="token comment" spellcheck="true"># 对k=1和2时的模型进行训练</span>
<span class="token comment" spellcheck="true"># 分别构造k=1和k=2的k近邻模型</span>
models <span class="token operator">=</span> <span class="token punctuation">(</span>KNeighborsClassifier<span class="token punctuation">(</span>n_neighbors<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> n_jobs<span class="token operator">=</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
          KNeighborsClassifier<span class="token punctuation">(</span>n_neighbors<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span> n_jobs<span class="token operator">=</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token comment" spellcheck="true"># 模型训练</span>
models <span class="token operator">=</span> <span class="token punctuation">(</span>clf<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>X_train<span class="token punctuation">,</span> y_train<span class="token punctuation">)</span> <span class="token keyword">for</span> clf <span class="token keyword">in</span> models<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<pre class="line-numbers language-python"><code class="language-python"><span class="token comment" spellcheck="true"># 设置图形标题</span>
titles <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token string">'K Neighbors with k=1'</span><span class="token punctuation">,</span>
          <span class="token string">'K Neighbors with k=2'</span><span class="token punctuation">)</span>

<span class="token comment" spellcheck="true"># 设置图形的大小和图间距</span>
fig <span class="token operator">=</span> plt<span class="token punctuation">.</span>figure<span class="token punctuation">(</span>figsize<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">15</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>subplots_adjust<span class="token punctuation">(</span>wspace<span class="token operator">=</span><span class="token number">0.4</span><span class="token punctuation">,</span> hspace<span class="token operator">=</span><span class="token number">0.4</span><span class="token punctuation">)</span>

<span class="token comment" spellcheck="true"># 分别获取第1个和第2个特征向量</span>
X0<span class="token punctuation">,</span> X1 <span class="token operator">=</span> X_train<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> X_train<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span>

<span class="token comment" spellcheck="true"># 得到坐标轴的最小值和最大值</span>
x_min<span class="token punctuation">,</span> x_max <span class="token operator">=</span> X0<span class="token punctuation">.</span>min<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">-</span> <span class="token number">1</span><span class="token punctuation">,</span> X0<span class="token punctuation">.</span>max<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token number">1</span>
y_min<span class="token punctuation">,</span> y_max <span class="token operator">=</span> X1<span class="token punctuation">.</span>min<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">-</span> <span class="token number">1</span><span class="token punctuation">,</span> X1<span class="token punctuation">.</span>max<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token number">1</span>

<span class="token comment" spellcheck="true"># 构造网格点坐标矩阵</span>
<span class="token comment" spellcheck="true"># 设置0.2的目的是生成更多的网格点，数值越小，划分空间之间的分隔线越清晰</span>
xx<span class="token punctuation">,</span> yy <span class="token operator">=</span> np<span class="token punctuation">.</span>meshgrid<span class="token punctuation">(</span>np<span class="token punctuation">.</span>arange<span class="token punctuation">(</span>x_min<span class="token punctuation">,</span> x_max<span class="token punctuation">,</span> <span class="token number">0.2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                     np<span class="token punctuation">.</span>arange<span class="token punctuation">(</span>y_min<span class="token punctuation">,</span> y_max<span class="token punctuation">,</span> <span class="token number">0.2</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

<span class="token keyword">for</span> clf<span class="token punctuation">,</span> title<span class="token punctuation">,</span> ax <span class="token keyword">in</span> zip<span class="token punctuation">(</span>models<span class="token punctuation">,</span> titles<span class="token punctuation">,</span> fig<span class="token punctuation">.</span>subplots<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">.</span>flatten<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token comment" spellcheck="true"># （2）使用matplotlib的contourf和scatter，画出k为1和2时的k近邻法构成的空间划分</span>
    <span class="token comment" spellcheck="true"># 对所有网格点进行预测</span>
    Z <span class="token operator">=</span> clf<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>np<span class="token punctuation">.</span>c_<span class="token punctuation">[</span>xx<span class="token punctuation">.</span>ravel<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> yy<span class="token punctuation">.</span>ravel<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
    Z <span class="token operator">=</span> Z<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span>xx<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>
    <span class="token comment" spellcheck="true"># 设置颜色列表</span>
    colors <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token string">'red'</span><span class="token punctuation">,</span> <span class="token string">'green'</span><span class="token punctuation">,</span> <span class="token string">'lightgreen'</span><span class="token punctuation">,</span> <span class="token string">'gray'</span><span class="token punctuation">,</span> <span class="token string">'cyan'</span><span class="token punctuation">)</span>
    <span class="token comment" spellcheck="true"># 根据类别数生成颜色</span>
    cmap <span class="token operator">=</span> ListedColormap<span class="token punctuation">(</span>colors<span class="token punctuation">[</span><span class="token punctuation">:</span>len<span class="token punctuation">(</span>np<span class="token punctuation">.</span>unique<span class="token punctuation">(</span>Z<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
    <span class="token comment" spellcheck="true"># 绘制分隔线，contourf函数用于绘制等高线，alpha表示颜色的透明度，一般设置成0.5</span>
    ax<span class="token punctuation">.</span>contourf<span class="token punctuation">(</span>xx<span class="token punctuation">,</span> yy<span class="token punctuation">,</span> Z<span class="token punctuation">,</span> cmap<span class="token operator">=</span>cmap<span class="token punctuation">,</span> alpha<span class="token operator">=</span><span class="token number">0.5</span><span class="token punctuation">)</span>

    <span class="token comment" spellcheck="true"># 绘制样本点</span>
    ax<span class="token punctuation">.</span>scatter<span class="token punctuation">(</span>X0<span class="token punctuation">,</span> X1<span class="token punctuation">,</span> c<span class="token operator">=</span>y_train<span class="token punctuation">,</span> s<span class="token operator">=</span><span class="token number">50</span><span class="token punctuation">,</span> edgecolors<span class="token operator">=</span><span class="token string">'k'</span><span class="token punctuation">,</span> cmap<span class="token operator">=</span>cmap<span class="token punctuation">,</span> alpha<span class="token operator">=</span><span class="token number">0.5</span><span class="token punctuation">)</span>

    <span class="token comment" spellcheck="true"># （3）根据模型得到的预测结果，计算预测准确率，并设置图形标题</span>
    <span class="token comment" spellcheck="true"># 计算预测准确率</span>
    acc <span class="token operator">=</span> clf<span class="token punctuation">.</span>score<span class="token punctuation">(</span>X_train<span class="token punctuation">,</span> y_train<span class="token punctuation">)</span>
    <span class="token comment" spellcheck="true"># 设置标题</span>
    ax<span class="token punctuation">.</span>set_title<span class="token punctuation">(</span>title <span class="token operator">+</span> <span class="token string">' (Accuracy: %d%%)'</span> <span class="token operator">%</span> <span class="token punctuation">(</span>acc <span class="token operator">*</span> <span class="token number">100</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p><img src="/images/loading.gif" data-original="../images/ML/output_6_0-16417059933931.png" alt="png"></p>
<blockquote>
<p><strong>补充知识：</strong><br>np.meshgrid方法：用于构造网格点坐标矩阵，可参考<a href="https://blog.csdn.net/lllxxq141592654/article/details/81532855" target="_blank" rel="noopener">https://blog.csdn.net/lllxxq141592654/article/details/81532855</a></p>
</blockquote>
<p><strong>第4步：比较$k$为1和2时，k值选择与模型复杂度、预测准确率的关系</strong></p>
<ol>
<li><p>$k$值选择与模型复杂度的关系<br>  根据书中第52页（3.2.3节：$k$值的选择）</p>
<blockquote>
<p>  如果选择较小的$k$值，就相当于用较小的邻域中的训练实例进行预测，“学习”的近似误差会减小，只有与输入实例较近的（相似的）训练实例才会对预测结果起作用。$k$值的减小就意味着整体模型变得复杂，容易发生过拟合。<br>  如果选择较大的$k$值，就相当于用较大邻域中的训练实例进行预测。$k$值的增大就意味着整体的模型变得简单。</p>
</blockquote>
<p>  综上所属，$k$值越大，模型复杂度越低，模型越简单，容易发生欠拟合。反之，$k$值越小，模型越复杂，容易发生过拟合。</p>
</li>
</ol>
<ol start="2">
<li>$k$值选择与预测准确率的关系<br>  从图中观察到，当$k=1$时，模型易产生过拟合，当$k=2$时准确率仅有88%，故在过拟合发生前，$k$值越大，预测准确率越低，也反映模型泛化能力越差，模型简单。反之，$k$值越小，预测准确率越高，模型具有更好的泛化能力，模型复杂。</li>
</ol>
<h3 id="习题3-2"><a href="#习题3-2" class="headerlink" title="习题3.2"></a>习题3.2</h3><p>  利用例题3.2构造的$kd$树求点$x=(3,4.5)^T$的最近邻点。</p>
<p><strong>解答：</strong></p>
<p><strong>解答思路：</strong>  </p>
<p><strong>方法一：</strong></p>
<ol>
<li>使用sklearn的KDTree类，结合例题3.2构建平衡$kd$树，配置相关参数（构建平衡树kd树算法，见书中第54页算法3.2内容）；</li>
<li>使用tree.query方法，查找(3, 4.5)的最近邻点（搜索kd树算法，见书中第55页第3.3.2节内容）；</li>
<li>根据第3步返回的参数，得到最近邻点。</li>
</ol>
<p><strong>方法二：</strong><br>  根据书中第56页算法3.3用$kd$树的最近邻搜索方法，查找(3, 4.5)的最近邻点</p>
<p><strong>解答步骤：</strong></p>
<p><strong>方法一：</strong></p>
<pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">import</span> numpy <span class="token keyword">as</span> np
<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>neighbors <span class="token keyword">import</span> KDTree

<span class="token comment" spellcheck="true"># 构造例题3.2的数据集</span>
train_data <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
                       <span class="token punctuation">[</span><span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
                       <span class="token punctuation">[</span><span class="token number">9</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
                       <span class="token punctuation">[</span><span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">7</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
                       <span class="token punctuation">[</span><span class="token number">8</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
                       <span class="token punctuation">[</span><span class="token number">7</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
<span class="token comment" spellcheck="true"># （1）使用sklearn的KDTree类，构建平衡kd树</span>
<span class="token comment" spellcheck="true"># 设置leaf_size为2，表示平衡树</span>
tree <span class="token operator">=</span> KDTree<span class="token punctuation">(</span>train_data<span class="token punctuation">,</span> leaf_size<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span>

<span class="token comment" spellcheck="true"># （2）使用tree.query方法，设置k=1，查找(3, 4.5)的最近邻点</span>
<span class="token comment" spellcheck="true"># dist表示与最近邻点的距离，ind表示最近邻点在train_data的位置</span>
dist<span class="token punctuation">,</span> ind <span class="token operator">=</span> tree<span class="token punctuation">.</span>query<span class="token punctuation">(</span>np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">4.5</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span> k<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>
node_index <span class="token operator">=</span> ind<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>

<span class="token comment" spellcheck="true"># （3）得到最近邻点</span>
x1 <span class="token operator">=</span> train_data<span class="token punctuation">[</span>node_index<span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
x2 <span class="token operator">=</span> train_data<span class="token punctuation">[</span>node_index<span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"x点(3,4.5)的最近邻点是({0}, {1})"</span><span class="token punctuation">.</span>format<span class="token punctuation">(</span>x1<span class="token punctuation">,</span> x2<span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<pre><code>x点(3,4.5)的最近邻点是(2, 3)</code></pre><p>可得到点$x=(3,4.5)^T$的最近邻点是$(2,3)^T$</p>
<p><strong>方法二：</strong> </p>
<ol>
<li>首先找到点$x=(3,4.5)^T$所在领域的叶节点$x_1=(4,7)^T$，则最近邻点一定在以$x$为圆心，$x$到$x_1$距离为半径的圆内；</li>
<li>找到$x_1$的父节点$x_2=(5,4)^T$，$x_2$的另一子节点为$x_3=(2,3)^T$，此时$x_3$在圆内，故$x_3$为最新的最近邻点，并形成以$x$为圆心，以$x$到$x_3$距离为半径的圆；</li>
<li>继续探索$x_2$的父节点$x_4=(7,2)^T$,$x_4$的另一个子节点$(9,6)$对应的区域不与圆相交，故不存在最近邻点，所以最近邻点为$x_3=(2,3)^T$。</li>
</ol>
<p>可得到点$x=(3,4.5)^T$的最近邻点是$(2,3)^T$</p>
<h3 id="习题3-3-⭐⭐⭐"><a href="#习题3-3-⭐⭐⭐" class="headerlink" title="习题3.3 ⭐⭐⭐"></a>习题3.3 ⭐⭐⭐</h3><p>  参照算法3.3，写出输出为$x$的$k$近邻的算法。</p>
<p><strong>解答：</strong></p>
<p><strong>解答思路：</strong></p>
<ol>
<li>参考书中第56页算法3.3（用$kd$树的最近邻搜索），写出输出为$x$的$k$近邻算法；</li>
<li>根据算法步骤，写出算法代码，并用习题3.2的解进行验证。</li>
</ol>
<p><strong>解答步骤：</strong></p>
<p><strong>第1步：用$kd$树的$k$邻近搜索算法</strong></p>
<p>根据书中第56页算法3.3（用$kd$树的最近邻搜索）</p>
<blockquote>
<p>输入：已构造的kd树；目标点$x$；<br>输出：$x$的k近邻<br>（1）在$kd$树中找出包含目标点$x$的叶结点：从根结点出发，递归地向下访问树。若目标点$x$当前维的坐标小于切分点的坐标，则移动到左子结点，否则移动到右子结点，直到子结点为叶结点为止；<br>（2）如果“当前$k$近邻点集”元素数量小于$k$或者叶节点距离小于“当前$k$近邻点集”中最远点距离，那么将叶节点插入“当前k近邻点集”；<br>（3）递归地向上回退，在每个结点进行以下操作：<br>  （a）如果“当前$k$近邻点集”元素数量小于$k$或者当前节点距离小于“当前$k$近邻点集”中最远点距离，那么将该节点插入“当前$k$近邻点集”。<br>  （b）检查另一子结点对应的区域是否与以目标点为球心、以目标点与“当前$k$近邻点集”中最远点间的距离为半径的超球体相交。<br>  如果相交，可能在另一个子结点对应的区域内存在距目标点更近的点，移动到另一个子结点，接着，递归地进行近邻搜索；<br>  如果不相交，向上回退；<br>（4）当回退到根结点时，搜索结束，最后的“当前$k$近邻点集”即为$x$的近邻点。</p>
</blockquote>
<p><strong>第2步：根据算法步骤，写出算法代码，并用习题3.2的解进行验证</strong></p>
<pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">import</span> json


<span class="token keyword">class</span> <span class="token class-name">Node</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">"""节点类"""</span>

    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> value<span class="token punctuation">,</span> index<span class="token punctuation">,</span> left_child<span class="token punctuation">,</span> right_child<span class="token punctuation">)</span><span class="token punctuation">:</span>
        self<span class="token punctuation">.</span>value <span class="token operator">=</span> value<span class="token punctuation">.</span>tolist<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>index <span class="token operator">=</span> index
        self<span class="token punctuation">.</span>left_child <span class="token operator">=</span> left_child
        self<span class="token punctuation">.</span>right_child <span class="token operator">=</span> right_child

    <span class="token keyword">def</span> <span class="token function">__repr__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">return</span> json<span class="token punctuation">.</span>dumps<span class="token punctuation">(</span>self<span class="token punctuation">,</span> indent<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span> default<span class="token operator">=</span><span class="token keyword">lambda</span> obj<span class="token punctuation">:</span> obj<span class="token punctuation">.</span>__dict__<span class="token punctuation">,</span> ensure_ascii<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span> allow_nan<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">KDTree</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">"""kd tree类"""</span>

    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> data<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment" spellcheck="true"># 数据集</span>
        self<span class="token punctuation">.</span>data <span class="token operator">=</span> np<span class="token punctuation">.</span>asarray<span class="token punctuation">(</span>data<span class="token punctuation">)</span>
        <span class="token comment" spellcheck="true"># kd树</span>
        self<span class="token punctuation">.</span>kd_tree <span class="token operator">=</span> None
        <span class="token comment" spellcheck="true"># 创建平衡kd树</span>
        self<span class="token punctuation">.</span>_create_kd_tree<span class="token punctuation">(</span>data<span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">_split_sub_tree</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> data<span class="token punctuation">,</span> depth<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment" spellcheck="true"># 算法3.2第3步：直到子区域没有实例存在时停止</span>
        <span class="token keyword">if</span> len<span class="token punctuation">(</span>data<span class="token punctuation">)</span> <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">:</span>
            <span class="token keyword">return</span> None
        <span class="token comment" spellcheck="true"># 算法3.2第2步：选择切分坐标轴, 从0开始（书中是从1开始）</span>
        l <span class="token operator">=</span> depth <span class="token operator">%</span> data<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span>
        <span class="token comment" spellcheck="true"># 对数据进行排序</span>
        data <span class="token operator">=</span> data<span class="token punctuation">[</span>data<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> l<span class="token punctuation">]</span><span class="token punctuation">.</span>argsort<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">]</span>
        <span class="token comment" spellcheck="true"># 算法3.2第1步：将所有实例坐标的中位数作为切分点</span>
        median_index <span class="token operator">=</span> data<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">//</span> <span class="token number">2</span>
        <span class="token comment" spellcheck="true"># 获取结点在数据集中的位置</span>
        node_index <span class="token operator">=</span> <span class="token punctuation">[</span>i <span class="token keyword">for</span> i<span class="token punctuation">,</span> v <span class="token keyword">in</span> enumerate<span class="token punctuation">(</span>
            self<span class="token punctuation">.</span>data<span class="token punctuation">)</span> <span class="token keyword">if</span> list<span class="token punctuation">(</span>v<span class="token punctuation">)</span> <span class="token operator">==</span> list<span class="token punctuation">(</span>data<span class="token punctuation">[</span>median_index<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">]</span>
        <span class="token keyword">return</span> Node<span class="token punctuation">(</span>
            <span class="token comment" spellcheck="true"># 本结点</span>
            value<span class="token operator">=</span>data<span class="token punctuation">[</span>median_index<span class="token punctuation">]</span><span class="token punctuation">,</span>
            <span class="token comment" spellcheck="true"># 本结点在数据集中的位置</span>
            index<span class="token operator">=</span>node_index<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
            <span class="token comment" spellcheck="true"># 左子结点</span>
            left_child<span class="token operator">=</span>self<span class="token punctuation">.</span>_split_sub_tree<span class="token punctuation">(</span>data<span class="token punctuation">[</span><span class="token punctuation">:</span>median_index<span class="token punctuation">]</span><span class="token punctuation">,</span> depth <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            <span class="token comment" spellcheck="true"># 右子结点</span>
            right_child<span class="token operator">=</span>self<span class="token punctuation">.</span>_split_sub_tree<span class="token punctuation">(</span>
                data<span class="token punctuation">[</span>median_index <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">,</span> depth <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">)</span>
        <span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">_create_kd_tree</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> X<span class="token punctuation">)</span><span class="token punctuation">:</span>
        self<span class="token punctuation">.</span>kd_tree <span class="token operator">=</span> self<span class="token punctuation">.</span>_split_sub_tree<span class="token punctuation">(</span>X<span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">query</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> data<span class="token punctuation">,</span> k<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        data <span class="token operator">=</span> np<span class="token punctuation">.</span>asarray<span class="token punctuation">(</span>data<span class="token punctuation">)</span>
        hits <span class="token operator">=</span> self<span class="token punctuation">.</span>_search<span class="token punctuation">(</span>data<span class="token punctuation">,</span> self<span class="token punctuation">.</span>kd_tree<span class="token punctuation">,</span> k<span class="token operator">=</span>k<span class="token punctuation">,</span> k_neighbor_sets<span class="token operator">=</span>list<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        dd <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span>hit<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token keyword">for</span> hit <span class="token keyword">in</span> hits<span class="token punctuation">]</span><span class="token punctuation">)</span>
        ii <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span>hit<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token keyword">for</span> hit <span class="token keyword">in</span> hits<span class="token punctuation">]</span><span class="token punctuation">)</span>
        <span class="token keyword">return</span> dd<span class="token punctuation">,</span> ii

    <span class="token keyword">def</span> <span class="token function">__repr__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">return</span> str<span class="token punctuation">(</span>self<span class="token punctuation">.</span>kd_tree<span class="token punctuation">)</span>

    @staticmethod
    <span class="token keyword">def</span> <span class="token function">_cal_node_distance</span><span class="token punctuation">(</span>node1<span class="token punctuation">,</span> node2<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token triple-quoted-string string">"""计算两个结点之间的距离"""</span>
        <span class="token keyword">return</span> np<span class="token punctuation">.</span>sqrt<span class="token punctuation">(</span>np<span class="token punctuation">.</span>sum<span class="token punctuation">(</span>np<span class="token punctuation">.</span>square<span class="token punctuation">(</span>node1 <span class="token operator">-</span> node2<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">_search</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> point<span class="token punctuation">,</span> tree<span class="token operator">=</span>None<span class="token punctuation">,</span> k<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> k_neighbor_sets<span class="token operator">=</span>None<span class="token punctuation">,</span> depth<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">if</span> k_neighbor_sets <span class="token keyword">is</span> None<span class="token punctuation">:</span>
            k_neighbor_sets <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
        <span class="token keyword">if</span> tree <span class="token keyword">is</span> None<span class="token punctuation">:</span>
            <span class="token keyword">return</span> k_neighbor_sets

        <span class="token comment" spellcheck="true"># (1)找到包含目标点x的叶结点</span>
        <span class="token keyword">if</span> tree<span class="token punctuation">.</span>left_child <span class="token keyword">is</span> None <span class="token operator">and</span> tree<span class="token punctuation">.</span>right_child <span class="token keyword">is</span> None<span class="token punctuation">:</span>
            <span class="token comment" spellcheck="true"># 更新当前k近邻点集</span>
            <span class="token keyword">return</span> self<span class="token punctuation">.</span>_update_k_neighbor_sets<span class="token punctuation">(</span>k_neighbor_sets<span class="token punctuation">,</span> k<span class="token punctuation">,</span> tree<span class="token punctuation">,</span> point<span class="token punctuation">)</span>

        <span class="token comment" spellcheck="true"># 递归地向下访问kd树</span>
        <span class="token keyword">if</span> point<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span>depth <span class="token operator">%</span> k<span class="token punctuation">]</span> <span class="token operator">&lt;</span> tree<span class="token punctuation">.</span>value<span class="token punctuation">[</span>depth <span class="token operator">%</span> k<span class="token punctuation">]</span><span class="token punctuation">:</span>
            direct <span class="token operator">=</span> <span class="token string">'left'</span>
            next_branch <span class="token operator">=</span> tree<span class="token punctuation">.</span>left_child
        <span class="token keyword">else</span><span class="token punctuation">:</span>
            direct <span class="token operator">=</span> <span class="token string">'right'</span>
            next_branch <span class="token operator">=</span> tree<span class="token punctuation">.</span>right_child
        <span class="token keyword">if</span> next_branch <span class="token keyword">is</span> <span class="token operator">not</span> None<span class="token punctuation">:</span>
            <span class="token comment" spellcheck="true"># (3)(a) 判断当前结点，并更新当前k近邻点集</span>
            k_neighbor_sets <span class="token operator">=</span> self<span class="token punctuation">.</span>_update_k_neighbor_sets<span class="token punctuation">(</span>
                k_neighbor_sets<span class="token punctuation">,</span> k<span class="token punctuation">,</span> next_branch<span class="token punctuation">,</span> point<span class="token punctuation">)</span>
            <span class="token comment" spellcheck="true"># (3)(b)检查另一子结点对应的区域是否相交</span>
            <span class="token keyword">if</span> direct <span class="token operator">==</span> <span class="token string">'left'</span><span class="token punctuation">:</span>
                node_distance <span class="token operator">=</span> self<span class="token punctuation">.</span>_cal_node_distance<span class="token punctuation">(</span>
                    point<span class="token punctuation">,</span> tree<span class="token punctuation">.</span>right_child<span class="token punctuation">.</span>value<span class="token punctuation">)</span>
                <span class="token keyword">if</span> k_neighbor_sets<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">></span> node_distance<span class="token punctuation">:</span>
                    <span class="token comment" spellcheck="true"># 如果相交，递归地进行近邻搜索</span>
                    <span class="token keyword">return</span> self<span class="token punctuation">.</span>_search<span class="token punctuation">(</span>point<span class="token punctuation">,</span> tree<span class="token operator">=</span>tree<span class="token punctuation">.</span>right_child<span class="token punctuation">,</span> k<span class="token operator">=</span>k<span class="token punctuation">,</span> depth<span class="token operator">=</span>depth <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">,</span>
                                        k_neighbor_sets<span class="token operator">=</span>k_neighbor_sets<span class="token punctuation">)</span>
            <span class="token keyword">else</span><span class="token punctuation">:</span>
                node_distance <span class="token operator">=</span> self<span class="token punctuation">.</span>_cal_node_distance<span class="token punctuation">(</span>
                    point<span class="token punctuation">,</span> tree<span class="token punctuation">.</span>left_child<span class="token punctuation">.</span>value<span class="token punctuation">)</span>
                <span class="token keyword">if</span> k_neighbor_sets<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">></span> node_distance<span class="token punctuation">:</span>
                    <span class="token keyword">return</span> self<span class="token punctuation">.</span>_search<span class="token punctuation">(</span>point<span class="token punctuation">,</span> tree<span class="token operator">=</span>tree<span class="token punctuation">.</span>left_child<span class="token punctuation">,</span> k<span class="token operator">=</span>k<span class="token punctuation">,</span> depth<span class="token operator">=</span>depth <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">,</span>
                                        k_neighbor_sets<span class="token operator">=</span>k_neighbor_sets<span class="token punctuation">)</span>

        <span class="token keyword">return</span> self<span class="token punctuation">.</span>_search<span class="token punctuation">(</span>point<span class="token punctuation">,</span> tree<span class="token operator">=</span>next_branch<span class="token punctuation">,</span> k<span class="token operator">=</span>k<span class="token punctuation">,</span> depth<span class="token operator">=</span>depth <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">,</span> k_neighbor_sets<span class="token operator">=</span>k_neighbor_sets<span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">_update_k_neighbor_sets</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> best<span class="token punctuation">,</span> k<span class="token punctuation">,</span> tree<span class="token punctuation">,</span> point<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment" spellcheck="true"># 计算目标点与当前结点的距离</span>
        node_distance <span class="token operator">=</span> self<span class="token punctuation">.</span>_cal_node_distance<span class="token punctuation">(</span>point<span class="token punctuation">,</span> tree<span class="token punctuation">.</span>value<span class="token punctuation">)</span>
        <span class="token keyword">if</span> len<span class="token punctuation">(</span>best<span class="token punctuation">)</span> <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">:</span>
            best<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token punctuation">(</span>node_distance<span class="token punctuation">,</span> tree<span class="token punctuation">.</span>index<span class="token punctuation">,</span> tree<span class="token punctuation">.</span>value<span class="token punctuation">)</span><span class="token punctuation">)</span>
        <span class="token keyword">elif</span> len<span class="token punctuation">(</span>best<span class="token punctuation">)</span> <span class="token operator">&lt;</span> k<span class="token punctuation">:</span>
            <span class="token comment" spellcheck="true"># 如果“当前k近邻点集”元素数量小于k</span>
            self<span class="token punctuation">.</span>_insert_k_neighbor_sets<span class="token punctuation">(</span>best<span class="token punctuation">,</span> tree<span class="token punctuation">,</span> node_distance<span class="token punctuation">)</span>
        <span class="token keyword">else</span><span class="token punctuation">:</span>
            <span class="token comment" spellcheck="true"># 叶节点距离小于“当前 𝑘 近邻点集”中最远点距离</span>
            <span class="token keyword">if</span> best<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">></span> node_distance<span class="token punctuation">:</span>
                best <span class="token operator">=</span> best<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">:</span><span class="token punctuation">]</span>
                self<span class="token punctuation">.</span>_insert_k_neighbor_sets<span class="token punctuation">(</span>best<span class="token punctuation">,</span> tree<span class="token punctuation">,</span> node_distance<span class="token punctuation">)</span>
        <span class="token keyword">return</span> best

    @staticmethod
    <span class="token keyword">def</span> <span class="token function">_insert_k_neighbor_sets</span><span class="token punctuation">(</span>best<span class="token punctuation">,</span> tree<span class="token punctuation">,</span> node_distance<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token triple-quoted-string string">"""将距离最远的结点排在前面"""</span>
        n <span class="token operator">=</span> len<span class="token punctuation">(</span>best<span class="token punctuation">)</span>
        <span class="token keyword">for</span> i<span class="token punctuation">,</span> item <span class="token keyword">in</span> enumerate<span class="token punctuation">(</span>best<span class="token punctuation">)</span><span class="token punctuation">:</span>
            <span class="token keyword">if</span> item<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">&lt;</span> node_distance<span class="token punctuation">:</span>
                <span class="token comment" spellcheck="true"># 将距离最远的结点插入到前面</span>
                best<span class="token punctuation">.</span>insert<span class="token punctuation">(</span>i<span class="token punctuation">,</span> <span class="token punctuation">(</span>node_distance<span class="token punctuation">,</span> tree<span class="token punctuation">.</span>index<span class="token punctuation">,</span> tree<span class="token punctuation">.</span>value<span class="token punctuation">)</span><span class="token punctuation">)</span>
                <span class="token keyword">break</span>
        <span class="token keyword">if</span> len<span class="token punctuation">(</span>best<span class="token punctuation">)</span> <span class="token operator">==</span> n<span class="token punctuation">:</span>
            best<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token punctuation">(</span>node_distance<span class="token punctuation">,</span> tree<span class="token punctuation">.</span>index<span class="token punctuation">,</span> tree<span class="token punctuation">.</span>value<span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<pre class="line-numbers language-python"><code class="language-python"><span class="token comment" spellcheck="true"># 打印信息</span>
<span class="token keyword">def</span> <span class="token function">print_k_neighbor_sets</span><span class="token punctuation">(</span>k<span class="token punctuation">,</span> ii<span class="token punctuation">,</span> dd<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">if</span> k <span class="token operator">==</span> <span class="token number">1</span><span class="token punctuation">:</span>
        text <span class="token operator">=</span> <span class="token string">"x点的最近邻点是"</span>
    <span class="token keyword">else</span><span class="token punctuation">:</span>
        text <span class="token operator">=</span> <span class="token string">"x点的%d个近邻点是"</span> <span class="token operator">%</span> k

    <span class="token keyword">for</span> i<span class="token punctuation">,</span> index <span class="token keyword">in</span> enumerate<span class="token punctuation">(</span>ii<span class="token punctuation">)</span><span class="token punctuation">:</span>
        res <span class="token operator">=</span> X_train<span class="token punctuation">[</span>index<span class="token punctuation">]</span>
        <span class="token keyword">if</span> i <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">:</span>
            text <span class="token operator">+=</span> str<span class="token punctuation">(</span>tuple<span class="token punctuation">(</span>res<span class="token punctuation">)</span><span class="token punctuation">)</span>
        <span class="token keyword">else</span><span class="token punctuation">:</span>
            text <span class="token operator">+=</span> <span class="token string">", "</span> <span class="token operator">+</span> str<span class="token punctuation">(</span>tuple<span class="token punctuation">(</span>res<span class="token punctuation">)</span><span class="token punctuation">)</span>

    <span class="token keyword">if</span> k <span class="token operator">==</span> <span class="token number">1</span><span class="token punctuation">:</span>
        text <span class="token operator">+=</span> <span class="token string">"，距离是"</span>
    <span class="token keyword">else</span><span class="token punctuation">:</span>
        text <span class="token operator">+=</span> <span class="token string">"，距离分别是"</span>
    <span class="token keyword">for</span> i<span class="token punctuation">,</span> dist <span class="token keyword">in</span> enumerate<span class="token punctuation">(</span>dd<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">if</span> i <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">:</span>
            text <span class="token operator">+=</span> <span class="token string">"%.4f"</span> <span class="token operator">%</span> dist
        <span class="token keyword">else</span><span class="token punctuation">:</span>
            text <span class="token operator">+=</span> <span class="token string">", %.4f"</span> <span class="token operator">%</span> dist

    <span class="token keyword">print</span><span class="token punctuation">(</span>text<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">import</span> numpy <span class="token keyword">as</span> np

X_train <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
                    <span class="token punctuation">[</span><span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
                    <span class="token punctuation">[</span><span class="token number">9</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
                    <span class="token punctuation">[</span><span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">7</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
                    <span class="token punctuation">[</span><span class="token number">8</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
                    <span class="token punctuation">[</span><span class="token number">7</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
kd_tree <span class="token operator">=</span> KDTree<span class="token punctuation">(</span>X_train<span class="token punctuation">)</span>
<span class="token comment" spellcheck="true"># 设置k值</span>
k <span class="token operator">=</span> <span class="token number">1</span>
<span class="token comment" spellcheck="true"># 查找邻近的结点</span>
dists<span class="token punctuation">,</span> indices <span class="token operator">=</span> kd_tree<span class="token punctuation">.</span>query<span class="token punctuation">(</span>np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">4.5</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span> k<span class="token operator">=</span>k<span class="token punctuation">)</span>
<span class="token comment" spellcheck="true"># 打印邻近结点</span>
print_k_neighbor_sets<span class="token punctuation">(</span>k<span class="token punctuation">,</span> indices<span class="token punctuation">,</span> dists<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<pre><code>x点的最近邻点是(2, 3)，距离是1.8028</code></pre><pre class="line-numbers language-python"><code class="language-python"><span class="token comment" spellcheck="true"># 打印kd树</span>
kd_tree<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>
<pre><code>{
   "value": [
      7,
      2
   ],
   "index": 5,
   "left_child": {
      "value": [
         5,
         4
      ],
      "index": 1,
      "left_child": {
         "value": [
            2,
            3
         ],
         "index": 0,
         "left_child": null,
         "right_child": null
      },
      "right_child": {
         "value": [
            4,
            7
         ],
         "index": 3,
         "left_child": null,
         "right_child": null
      }
   },
   "right_child": {
      "value": [
         9,
         6
      ],
      "index": 2,
      "left_child": {
         "value": [
            8,
            1
         ],
         "index": 4,
         "left_child": null,
         "right_child": null
      },
      "right_child": null
   }
}</code></pre><p>  上述打印的平衡kd树和书中第55页的图3.4 kd树示例一致。</p>
<p><img src="/images/loading.gif" data-original="../images/ML/3-1-KD-Tree-Demo.png" alt=""></p>
<p>更换数据集，使用更高维度的数据，并设置$k=3$</p>
<pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">import</span> numpy <span class="token keyword">as</span> np

X_train <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
                    <span class="token punctuation">[</span><span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
                    <span class="token punctuation">[</span><span class="token number">9</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
                    <span class="token punctuation">[</span><span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">7</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
                    <span class="token punctuation">[</span><span class="token number">8</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
                    <span class="token punctuation">[</span><span class="token number">7</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
kd_tree <span class="token operator">=</span> KDTree<span class="token punctuation">(</span>X_train<span class="token punctuation">)</span>
<span class="token comment" spellcheck="true"># 设置k值</span>
k <span class="token operator">=</span> <span class="token number">3</span>
<span class="token comment" spellcheck="true"># 查找邻近的结点</span>
dists<span class="token punctuation">,</span> indices <span class="token operator">=</span> kd_tree<span class="token punctuation">.</span>query<span class="token punctuation">(</span>np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">4.5</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span> k<span class="token operator">=</span>k<span class="token punctuation">)</span>
<span class="token comment" spellcheck="true"># 打印邻近结点</span>
print_k_neighbor_sets<span class="token punctuation">(</span>k<span class="token punctuation">,</span> indices<span class="token punctuation">,</span> dists<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<pre><code>x点的3个近邻点是(4, 7, 4), (5, 4, 4), (2, 3, 4)，距离分别是2.6926, 2.0616, 1.8028</code></pre><h1 id="四、朴素贝叶斯法"><a href="#四、朴素贝叶斯法" class="headerlink" title="四、朴素贝叶斯法"></a>四、朴素贝叶斯法</h1><p>朴素贝叶斯( naive Bayes)法是基于贝叶斯定理与特征条件独立假设的分类方法。对于给定的训练数据集，首先基于特征条件独立假设学习输入输出的联合概率分布：然后基于此模型，对给定的输入x,利用贝叶斯定理求出后验概率最大的输出y.朴素贝叶斯法实现简单，学习与预测的效率都很高，是一种常用的方法。</p>
<h2 id="4-1-朴素贝叶斯法的想学习与分类"><a href="#4-1-朴素贝叶斯法的想学习与分类" class="headerlink" title="4.1 朴素贝叶斯法的想学习与分类"></a>4.1 朴素贝叶斯法的想学习与分类</h2><h3 id="4-1-1-基本方法"><a href="#4-1-1-基本方法" class="headerlink" title="4.1.1 基本方法"></a>4.1.1 基本方法</h3><p>X是定义在输入空间上的随机向量，Y是定义在输出空间上的随机变量。$P(X,Y)$ 是X和Y的联合概率分布。训练数据集由$P(X,Y)$ 独立同分布产生：<br>$$<br>T=\left { \left(x_{1}, y_{1} \right), \left(x_{2}, y_{2} \right), \cdots, \left(x_{N}, y_{N} \right) \right }<br>$$<br>朴素贝叶斯法通过训练数据集学习联合概率分布$P(X,Y)$.具体地，学习以下先验概率分布及条件概率分布，先验概率分布：<br>$$<br>P\left(Y=c_{k}\right), \quad k=1,2, \cdots, K<br>$$<br>条件概率分布<br>$$<br>P\left(X=x \mid Y=c_{k}\right)=P\left(X^{(1)}=x^{(1)}, \cdots, X^{(n)}=x^{(n)} \mid Y=c_{k}\right), \quad k=1,2, \cdots, K<br>$$<br>于是学习到联合概率分布$P(X,Y)$</p>
<p>朴素贝叶斯法对条件概率分布作了条件独立性的假设。由于这是一个较强的假设，朴素贝叶斯法也由此得名。具体地，条件独立性假设是<br>$$<br>\begin{aligned}<br>P\left(X=x \mid Y=c_{k}\right) &amp;=P\left(X^{(1)}=x^{(1)}, \cdots, X^{(n)}=x^{(n)} \mid Y=c_{k}\right) \<br>&amp;=\prod_{j=1}^{n} P\left(X^{(j)}=x^{(j)} \mid Y=c_{k}\right)<br>\end{aligned}<br>$$<br>朴素贝叶斯法实际上学习到生成数据的机制，所以属于生成模型。条件独立假设等于是说用于分类的特征在类确定的条件下都是条件独立的。这一假设使朴素贝叶斯法变得简单，但有时会牺牲一定的分类准确率。<br>$$<br>y=\arg \max <em>{c</em>{k}} P\left(Y=c_{k}\right) \prod_{j} P\left(X^{(j)}=x^{(j)} \mid Y=c_{k}\right)<br>$$</p>
<h3 id="4-1-2-后验概率最大化的含义"><a href="#4-1-2-后验概率最大化的含义" class="headerlink" title="4.1.2 后验概率最大化的含义"></a>4.1.2 后验概率最大化的含义</h3><p>根据期望<strong>风险最小化准则</strong>就得到了后验概率最大化准则：<br>$$<br>f(x)=\arg \max <em>{c</em>{k}} P\left(c_{k} \mid X=x\right)<br>$$</p>
<h2 id="4-2-朴素贝叶斯法的参数估计"><a href="#4-2-朴素贝叶斯法的参数估计" class="headerlink" title="4.2 朴素贝叶斯法的参数估计"></a>4.2 朴素贝叶斯法的参数估计</h2><h3 id="4-2-1-极大似然估计"><a href="#4-2-1-极大似然估计" class="headerlink" title="4.2.1 极大似然估计"></a>4.2.1 极大似然估计</h3><p><img src="/images/loading.gif" data-original="../images/ML/image-20220110103532483.png" alt=""></p>
<h3 id="4-2-2-学习与分类算法"><a href="#4-2-2-学习与分类算法" class="headerlink" title="4.2.2 学习与分类算法"></a>4.2.2 学习与分类算法</h3><p><strong>算法4.1 朴素贝叶斯算法（naive Bayes algorithm）</strong></p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20220110103658987.png" alt=""></p>
<p>示例：</p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20220110104039279.png" alt=""></p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20220110104059888.png" alt=""></p>
<h3 id="4-2-3-贝叶斯估计"><a href="#4-2-3-贝叶斯估计" class="headerlink" title="4.2.3 贝叶斯估计"></a>4.2.3 贝叶斯估计</h3><p>用极大似然估计可能会出现所要估计的概率值为0的情况，这时会影响到后验概率的计算结果，使分类产生偏差。解决这一问题的方法是采用贝叶斯估计。具体地，条件概率的贝叶斯估计是：</p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20220110104233612.png" alt=""></p>
<h2 id="习题-3"><a href="#习题-3" class="headerlink" title="习题"></a>习题</h2><h3 id="习题4-1"><a href="#习题4-1" class="headerlink" title="习题4.1"></a>习题4.1</h3><p>  用极大似然估计法推出朴素贝叶斯法中的概率估计公式(4.8)及公式 (4.9)。</p>
<p><strong>解答：</strong>  </p>
<p><strong>解答思路：</strong></p>
<ol>
<li>极大似然估计的一般步骤（详见习题1.1第3步）</li>
<li>证明公式4.8：根据输出空间$\mathcal{Y}$的随机变量$Y$满足独立同分布，列出似然函数，求解概率$P(Y=c_k)$的值；</li>
<li>证明公式4.9：证明同公式4.8。</li>
</ol>
<p><strong>解答步骤：</strong></p>
<p><strong>第1步：极大似然估计的一般步骤</strong>  </p>
<blockquote>
<p>参考Wiki：<a href="https://en.wikipedia.org/wiki/Maximum_likelihood_estimation" target="_blank" rel="noopener">https://en.wikipedia.org/wiki/Maximum_likelihood_estimation</a>   </p>
<ol>
<li>写出随机变量的概率分布函数；  </li>
<li>写出似然函数；</li>
<li>对似然函数取对数，得到对数似然函数，并进行化简；</li>
<li>对参数进行求导，并令导数等于0；</li>
<li>求解似然函数方程，得到参数的值。</li>
</ol>
</blockquote>
<p><strong>第2步：证明公式(4.8)</strong><br>$$<br>\displaystyle P(Y=c_k) = \frac{\displaystyle \sum_{i=1}^N I(y_i=c_k)}{N}, \quad k=1,2,\ldots,K<br>$$</p>
<p>  根据书中第59页，朴素贝叶斯法的基本方法：</p>
<blockquote>
<p>  设输入空间$\mathcal{X} \subseteq R^n$为$n$维向量的集合，输出空间为类标记集合$\mathcal{Y}={c_1,c_2,\ldots,c_k}$。输入为特征向量$x \in \mathcal{X}$，输出为类标记$y \in \mathcal{Y}$。$X$是定义在输入空间$\mathcal{X}$上的随机向量，$Y$是定义在输出空间$\mathcal{Y}$上的随机变量。$P(X,Y)$是$X$和$Y$的联合概率分布。训练数据集</p>
</blockquote>
<p>$$<br>T={(x_1,y_1),(x_2,y_2),\ldots,(x_N,y_N)}<br>$$</p>
<blockquote>
<p>由$P(X,Y)$独立同分布产生。  </p>
</blockquote>
<p>  根据上述定义，$Y={y_1,y_2,\ldots,y_N}$满足独立同分布，假设$P(Y=c_k)$概率为$p$，其中$c_k$在随机变量$Y$中出现的次数$\displaystyle m=\sum_{i=1}^NI(y_i=c_k)$，可得似然函数为：<br>$$<br>\begin{aligned} L(p|Y) &amp;= f(Y|p) \<br>&amp;= C_N^m p^m (1-p)^{N-m}<br>\end{aligned}<br>$$<br>对似然函数取对数，得到对数似然函数为：<br>$$<br>\begin{aligned} \displaystyle \log L(p|Y) &amp;= \log C_N^m p^m (1-p)^{N-m} \<br>&amp;= C_N^m \left[\log(p^m) + \log\left( (1-p)^{N-m} \right)\right] \<br>&amp;= C_N^m \left[ m\log p + (N-m)\log (1-p)\right]<br>\end{aligned}<br>$$<br>求解参数$p$：<br>$$<br>\begin{aligned}<br>\hat{p} &amp;= \mathop{\arg\max} \limits_{p} L(p|Y) \<br>&amp;= \mathop{\arg\max} \limits_{p} C_N^m \left[ m\log p + (N-m)\log (1-p)\right]<br>\end{aligned}<br>$$<br>对参数$p$求导，并求解导数为0时的$p$值：<br>$$<br>\begin{aligned}<br>\frac{\partial \log L(p)}{\partial p} &amp;= C_N^m \left[ \frac{m}{p} - \frac{N-m}{1-p} \right] \<br>&amp;= C_N^m \left[ \frac{m(1-p) - p(N-m)}{p(1-p)} \right] \<br>&amp;= C_N^m \frac{m-Np}{p(1-p)} = 0<br>\end{aligned}<br>$$<br>从上式可得，$m-Np=0$，即$\displaystyle P(Y=c_k)=p=\frac{m}{N}$<br>综上所述，$\displaystyle P(Y=c_k)=p=\frac{m}{N}=\frac{\displaystyle \sum_{i=1}^N I(y_i=c_k)}{N}$，公式(4.8)得证。</p>
<p><strong>第3步：证明公式(4.9)</strong><br>$$<br>\displaystyle P(X^{(j)}=a_{jl}|Y=c_k) = \frac{\displaystyle \sum_{i=1}^N I(x_i^{(j)}=a_{jl},y_i=c_k)}{\displaystyle \sum_{i=1}^N I(y_i=c_k)} \<br>j=1,2,\ldots,n; \quad l = 1,2,\ldots,S_j; \quad k = 1,2,\dots,K<br>$$<br>  根据书中第60页，朴素贝叶斯法的条件独立性假设：</p>
<blockquote>
<p>  朴素贝叶斯法对条件概率分布作了条件独立性的假设。由于这是一个较强的假设，朴素贝叶斯法也由此得名。具体地，条件独立性假设是：</p>
</blockquote>
<p>$$<br>\begin{aligned}<br>P(X=x|Y=c_k) &amp;= P(X^{(1)}=x^{(1)},\ldots,X^{(n)}=x^{(n)}|Y=c_k) \<br>&amp;= \prod_{j=1}^n P(X^{(j)}=x^{(j)}|Y=c_k)<br>\end{aligned}<br>$$</p>
<p>  根据上述定义，在条件$Y=c_k$下，随机变量$X$满足条件独立性，假设$P(X^{(j)}=a_{jl}|Y=c_k)$概率为$p$，其中$c_k$在随机变量$Y$中出现的次数$\displaystyle m=\sum_{i=1}^NI(y_i=c_k)$，$y=c_k$和$x^{(j)}=a_{jl}$同时出现的次数$\displaystyle q=\sum_{i=1}^N I(x_i^{(j)}=a_{jl},y_i=c_k)$，可得似然函数为：<br>$$<br>\begin{aligned} L(p|X,Y) &amp;= f(X,Y|p) \<br>&amp;= C_m^q p^q (1-p)^{m-q}<br>\end{aligned}<br>$$<br>与第2步推导过程类似，可求解得到$\displaystyle p=\frac{q}{m}$<br>综上所述，$\displaystyle P(X^{(j)}=a_{jl}|Y=c_k)=p=\frac{q}{m}=\frac{\displaystyle \sum_{i=1}^N I(x_i^{(j)}=a_{jl},y_i=c_k)}{\displaystyle \sum_{i=1}^N I(y_i=c_k)}$，公式(4.9)得证。</p>
<h3 id="习题4-2"><a href="#习题4-2" class="headerlink" title="习题4.2"></a>习题4.2</h3><p>  用贝叶斯估计法推出朴素贝叶斯法中的慨率估计公式(4.10)及公式(4.11)</p>
<p><strong>解答：</strong> </p>
<p><strong>解答思路：</strong></p>
<ol>
<li>贝叶斯估计的一般步骤（详见习题1.1第4步）；</li>
<li>证明公式4.11：假设概率$P_{\lambda}(Y=c_i)$服从狄利克雷（Dirichlet）分布，根据贝叶斯公式，推导后验概率也服从Dirichlet分布，求参数期望；</li>
<li>证明公式4.10：证明同公式4.11。</li>
</ol>
<p><strong>解答步骤：</strong></p>
<p><strong>第1步：贝叶斯估计的一般步骤</strong><br>参考Wiki：<a href="https://en.wikipedia.org/wiki/Bayes_estimator" target="_blank" rel="noopener">https://en.wikipedia.org/wiki/Bayes_estimator</a></p>
<blockquote>
<ol>
<li>确定参数$\theta$的先验概率$p(\theta)$</li>
<li>根据样本集$D={x_1,x_2,\ldots,x_n}$，计算似然函数$P(D|\theta)$：$\displaystyle P(D|\theta)=\prod_{i=1}^n P(x_n|D)$</li>
<li>利用贝叶斯公式，求$\theta$的后验概率：$\displaystyle P(\theta|D)=\frac{P(D|\theta)P(\theta)}{\displaystyle \int \limits_\Theta P(D|\theta) P(\theta) d \theta}$ </li>
<li>计算后验概率分布参数$\theta$的期望，并求出贝叶斯估计值：$\displaystyle \hat{\theta}=\int \limits_{\Theta} \theta \cdot P(\theta|D) d \theta$</li>
</ol>
</blockquote>
<p><strong>第2步：证明公式(4.11)</strong><br>$$<br>\displaystyle P_\lambda(Y=c_k) = \frac{\displaystyle \sum_{i=1}^N I(y_i=c_k) + \lambda}{N+K \lambda}, \quad k= 1,2,\ldots,K<br>$$<br>证明思路：</p>
<ol>
<li>条件假设：$P_\lambda(Y=c_k)=u_k$，且服从参数为$\lambda$的Dirichlet分布；随机变量$Y$出现$y=c_k$的次数为$m_k$； </li>
<li>得到$u$的先验概率$P(u)$；</li>
<li>得到似然函数$P(m|u)$；</li>
<li>根据贝叶斯公式，计算后验概率$P(u|m)$</li>
<li>计算$u$的期望$E(u)$</li>
</ol>
<p>证明步骤：</p>
<ol>
<li>条件假设  </li>
</ol>
<p>  根据朴素贝叶斯法的基本方法，训练数据集$T={(x_1,y_1),(x_2,y_2),\ldots,(x_N,y_N)}$，假设：<br>（1）随机变量$Y$出现$y=c_k$的次数为$m_k$，即$\displaystyle m_k=\sum_{i=1}^N I(y_i=c_k)$，可知$\displaystyle \sum_{k=1}^K m_k = N$（$y$总共有$N$个）；<br>（2）$P_\lambda(Y=c_k)=u_k$，随机变量$u_k$服从参数为$\lambda$的Dirichlet分布。</p>
<blockquote>
<p><strong>补充说明：</strong>  </p>
<ol>
<li>狄利克雷(Dirichlet)分布<br>  参考PRML（Pattern Recognition and Machine Learning）一书的第2.2.1章节：⽤似然函数(2.34)乘以先验(2.38)，我们得到了参数${u_k}$的后验分布，形式为</li>
</ol>
</blockquote>
<p>$$<br>p(u|D,\alpha) \propto p(D|u)p(u|\alpha) \propto \prod_{k=1}^K u_k^{\alpha_k+m_k-1}<br>$$</p>
<blockquote>
<p>  该书中第B.4章节：<br>狄利克雷分布是$K$个随机变量$0 \leqslant u_k \leqslant 1$的多变量分布，其中$k=1,2,\ldots,K$，并满足以下约束</p>
</blockquote>
<p>$$<br>0 \leqslant u_k \leqslant 1, \quad \sum_{k=1}^K u_k = 1<br>$$</p>
<p>记$u=(u_1,\ldots,u_K)^T, \alpha=(\alpha_1,\ldots,\alpha_K)^T$，有<br>$$<br>Dir(u|\alpha) = C(\alpha) \prod_{k-1}^K u_k^{\alpha_k - 1} \<br>E(u_k) = \frac{\alpha_k}{\displaystyle \sum_{k=1}^K \alpha_k}<br>$$</p>
<blockquote>
<ol start="2">
<li>为什么假设$Y=c_k$的概率服从Dirichlet分布？<br>答：原因如下：<br>（1）首先，根据PRML第B.4章节，Dirichlet分布是Beta分布的推广。<br>（2）由于，Beta分布是二项式分布的共轭分布，Dirichlet分布是多项式分布的共轭分布。Dirichlet分布可以看作是“分布的分布”；<br>（3）又因为，Beta分布与Dirichlet分布都是先验共轭的，意味着先验概率和后验概率属于同一个分布。当假设为Beta分布或者Dirichlet分布时，通过获得大量的观测数据，进行数据分布的调整，使得计算出来的概率越来越接近真实值。<br>（4）因此，对于一个概率未知的事件，Beta分布或Dirichlet分布能作为表示该事件发生的概率的概率分布。</li>
</ol>
</blockquote>
<ol start="2">
<li>得到先验概率<br>  根据假设(2)和Dirichlet分布的定义，可得先验概率为</li>
</ol>
<p>$$<br>\displaystyle P(u)=P(u_1,u_2,\ldots,u_K) = C(\lambda) \prod_{k=1}^K u_k^{\lambda - 1}<br>$$</p>
<ol start="3">
<li>得到似然函数<br>  记$m=(m_1, m_2, \ldots, m_K)^T$，可得似然函数为</li>
</ol>
<p>$$<br>P(m|u) = u_1^{m_1} \cdot u_2^{m_2} \cdots u_K^{m_K} = \prod_{k=1}^K u_k^{m_k}<br>$$</p>
<ol start="4">
<li>得到后验概率分布<br>  结合贝叶斯公式，求$u$的后验概率分布，可得</li>
</ol>
<p>$$<br>P(u|m) = \frac{P(m|u)P(u)}{P(m)}<br>$$</p>
<p>  根据假设(1)，可得<br>$$<br>P(u|m,\lambda) \propto P(m|u)P(u|\lambda) \propto \prod_{k=1}^K u_k^{\lambda+m_k-1}<br>$$<br>  上式表明，后验概率分布$P(u|m,\lambda)$也服从Dirichlet分布</p>
<ol start="5">
<li>得到随机变量$u$的期望<br>  根据后验概率分布$P(u|m,\lambda)$和假设(1)，求随机变量$u$的期望，可得</li>
</ol>
<p>$$<br>E(u_k) = \frac{\alpha_k}{\displaystyle \sum_{k=1}^K \alpha_k}<br>$$</p>
<p>其中$\alpha_k = \lambda+m_k$，则<br>$$<br>\begin{aligned}<br>E(u_k) &amp;= \frac{\alpha_k}{\displaystyle \sum_{k=1}^K \alpha_k} \<br>&amp;= \frac{\lambda+m_k}{\displaystyle \sum_{k=1}^K (\lambda + m_k)} \<br>&amp;= \frac{\lambda+m_k}{\displaystyle \sum_{k=1}^K \lambda +\sum_{k=1}^K m_k} \quad(\because \sum_{k=1}^K m_k = N) \<br>&amp;= \frac{\lambda+m_k}{\displaystyle K \lambda + N } \quad (\because m_k=\sum_{i=1}^N I(y_i=c_k)) \<br>&amp;= \frac{\displaystyle \sum_{i=1}^N I(y_i=c_k) + \lambda}{N+K \lambda}<br>\end{aligned}<br>$$<br>  随机变量$u_k$取$u_k$的期望，可得<br>$\displaystyle P_\lambda(Y=c_k) = \frac{\displaystyle \sum_{i=1}^N I(y_i=c_k) + \lambda}{N+K \lambda}$，公式(4.11)得证</p>
<p><strong>第3步：证明公式(4.10)</strong>：<br>$$<br>\displaystyle P_{\lambda}(X^{(j)}=a_{jl} | Y = c_k) = \frac{\displaystyle \sum_{i=1}^N I(x_i^{(j)}=a_{jl},y_i=c_k) + \lambda}{\displaystyle \sum_{i=1}^N I(y_i=c_k) + S_j \lambda}<br>$$<br>证明思路：</p>
<ol>
<li>条件假设：$P_{\lambda}(X^{(j)}=a_{jl} | Y = c_k)=u_l$，其中$l=1,2,\ldots,S_j$，且服从参数为$\lambda$的Dirichlet分布；出现$x^{(j)}=a_{jl}, y=c_k$的次数为$m_l$； </li>
<li>得到$u$的先验概率$P(u)$；</li>
<li>得到似然函数$P(m|u)$；</li>
<li>根据贝叶斯公式，计算后验概率$P(u|m)$</li>
<li>计算$u$的期望$E(u)$</li>
</ol>
<p>证明步骤：</p>
<ol>
<li>条件假设  </li>
</ol>
<p>  根据朴素贝叶斯法的基本方法，训练数据集$T={(x_1,y_1),(x_2,y_2),\ldots,(x_N,y_N)}$，假设：<br>（1）出现$x^{(j)}=a_{jl}, y=c_k$的次数为$m_l$，即$\displaystyle m_l=\sum_{i=1}^N I(x_i^{(j)}=a_{jl},y_i=c_k)$，可知$\displaystyle \sum_{l=1}^{S_j} m_l = \sum_{i=1}^N I(y_i=c_k)$（总共有$\displaystyle \sum_{i=1}^N I(y_i=c_k)$个）；<br>（2）$P_{\lambda}(X^{(j)}=a_{jl} | Y = c_k)=u_l$，随机变量$u_l$服从参数为$\lambda$的Dirichlet分布。</p>
<ol start="2">
<li>得到先验概率<br>  根据假设(2)和Dirichlet分布的定义，可得先验概率为</li>
</ol>
<p>$$<br>\displaystyle P(u)=P(u_1,u_2,\ldots,u_{S_j}) = C(\lambda) \prod_{l=1}^{S_j} u_l^{\lambda - 1}<br>$$</p>
<ol start="3">
<li>得到似然函数<br>  记$m=(m_1, m_2, \ldots, m_{S_j})^T$，可得似然函数为</li>
</ol>
<p>$$<br>P(m|u) = u_1^{m_1} \cdot u_2^{m_2} \cdots u_{S_j}^{m_{S_j} } = \prod_{l=1}^{S_j} u_l^{m_l}<br>$$</p>
<ol start="4">
<li>得到后验概率分布<br>  结合贝叶斯公式，求$u$的后验概率分布，可得</li>
</ol>
<p>$$<br>P(u|m) = \frac{P(m|u)P(u)}{P(m)}<br>$$</p>
<p>  根据假设(1)，可得<br>$$<br>P(u|m,\lambda) \propto P(m|u)P(u|\lambda) \propto \prod_{l=1}^{S_j} u_l^{\lambda+m_l-1}<br>$$<br>  上式表明，后验概率分布$P(u|m,\lambda)$也服从Dirichlet分布</p>
<ol start="5">
<li>得到随机变量$u$的期望<br>  根据后验概率分布$P(u|m,\lambda)$和假设(1)，求随机变量$u$的期望，可得</li>
</ol>
<p>$$<br>E(u_k) = \frac{\alpha_l}{\displaystyle \sum_{l=1}^{S_j} \alpha_l}<br>$$</p>
<p>其中$\alpha_l = \lambda+m_l$，则<br>$$<br>\begin{aligned}<br>E(u_l) &amp;= \frac{\alpha_l}{\displaystyle \sum_{l=1}^{S_j} \alpha_l} \<br>&amp;= \frac{\lambda+m_l}{\displaystyle \sum_{l=1}^{S_j} (\lambda + m_l)} \<br>&amp;= \frac{\lambda+m_l}{\displaystyle \sum_{l=1}^{S_j} \lambda +\sum_{l=1}^{S_j} m_l} \quad(\because \sum_{l=1}^{S_j} m_l = \sum_{i=1}^N I(y_i=c_k)) \<br>&amp;= \frac{\lambda+m_l}{\displaystyle S_j \lambda + \sum_{i=1}^N I(y_i=c_k) } \quad (\because m_l=\sum_{i=1}^N I(x_i^{(j)}=a_{jl},y_i=c_k)) \<br>&amp;= \frac{\displaystyle \sum_{i=1}^N I(x_i^{(j)}=a_{jl},y_i=c_k) + \lambda}{\displaystyle \sum_{i=1}^N I(y_i=c_k) + S_j \lambda}<br>\end{aligned}<br>$$</p>
<p>  随机变量$u_k$取$u_k$的期望，可得<br>$\displaystyle P_{\lambda}(X^{(j)}=a_{jl} | Y = c_k) = \frac{\displaystyle \sum_{i=1}^N I(x_i^{(j)}=a_{jl},y_i=c_k) + \lambda}{\displaystyle \sum_{i=1}^N I(y_i=c_k) + S_j \lambda}$，公式(4.10)得证。</p>
<h1 id="五、决策树"><a href="#五、决策树" class="headerlink" title="五、决策树"></a>五、决策树</h1><p>决策树（decision tree）是一种基本的分类与回归方法。决策树模型呈树形结构，在分类问题中，表示基于特征对实例进行分类的过程。它可以认为是if-then规则的集合，也可以认为是定义在特征空间与类空间上的条件概率分布，其主要优点是模型具有可读性，分类速度快。学习时，利用训练数据，根据损失函数最小化的原则建立决策树模型。预测时，对新的数据，利用决策树模型进行分类，决策树学习通常包括3个步骤：特征选择、决策树的生成和决策树的修剪。这些决策树学习的思想主要来源于由 Quinlan在1986年提出的ID3算法和1993年提出的C4.5算法，以及由 Breiman 等人在1984年提出的CART算法。</p>
<h2 id="5-1-决策树模型与学习"><a href="#5-1-决策树模型与学习" class="headerlink" title="5.1 决策树模型与学习"></a>5.1 决策树模型与学习</h2><h3 id="5-1-1-决策树模型"><a href="#5-1-1-决策树模型" class="headerlink" title="5.1.1 决策树模型"></a>5.1.1 决策树模型</h3><p><strong>定义5.1（决策树）</strong>分类决策树模型是一种描述对实例进行分类的树形结构。决策树由结点（node）和有向边（directed edge）组成，结点有两种类型：内部结点（internal node）和叶结点（leaf node）,<strong>内部结点表示一个特征或属性，叶结点表示一个类</strong></p>
<p>用决策树分类，从根结点开始，对实例的某一特征进行测试，根据测试结果，将实例分配到其子结点：这时，每一个子结点对应着该特征的一个取值。如此递归地对实例进行测试并分配，直至达到叶结点。最后将实例分到叶结点的类中。</p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20220110105041816.png" alt="决策树模型"></p>
<h3 id="5-1-2-决策树与if-then规则"><a href="#5-1-2-决策树与if-then规则" class="headerlink" title="5.1.2 决策树与if-then规则"></a>5.1.2 决策树与if-then规则</h3><p>可以将决策树看成一个 if-then规则的集合。将决策树转换成 if-then规则的过程是这样的：由决策树的根结点到叶结点的每一条路径构建一条规则；路径上内部结点的特征对应着规则的条件，而叶结点的类对应着规则的结论。决策树的路径或其对应的if-then规则集合具有一个重要的性质：互斥并且完备。这就是说，每一个实例都被一条路径或一条规则所覆盖，而且只被一条路径或一条规则所覆盖。这里所谓覆盖是指实例的特征与路径上的特征一致或实例满足规则的条件。</p>
<h3 id="5-1-3-决策树与条件概率分布"><a href="#5-1-3-决策树与条件概率分布" class="headerlink" title="5.1.3 决策树与条件概率分布"></a>5.1.3 决策树与条件概率分布</h3><p>决策树还表示给定特征条件下类的条件概率分布，这一条件概率分布定义在特征空间的一个划分（partition）上。将特征空间划分为互不相交的单元（cell）或区域（region）,并在每个单元定义一个类的概率分布就构成了一个条件概率分布，决策树的一条路径对应于划分中的一个单元。决策树所表示的条件概率分布由各个单元给定条件下类的条件概率分布组成，假设X为表示特征的随机变量，Y为表示类的随机变量，那么这个条件概率分布可以表示为$P(Y|X)$.X取值于给定划分下单元的集合，Y取值于类的集合。各叶结点（单元）上的条件概率往往偏向某一个类，即属于某一类的概率较大，决策树分类时将该结点的实例强行分到条件概率大的那一类去。</p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20220110110230740.png" alt="决策树对应于条件分布概率"></p>
<h3 id="5-1-4-决策树学习"><a href="#5-1-4-决策树学习" class="headerlink" title="5.1.4 决策树学习"></a>5.1.4 决策树学习</h3><p>决策树学习本质上是从训练数据集中归纳出一组分类规则。与训练数据集不相矛盾的决策树（即能对训练数据进行正确分类的决策树）可能有多个，也可能一个也没有。我们需要的是一个与训练数据矛盾较小的决策树，同时具有很好的泛化能力。从另一个角度看，决策树学习是由训练数据集估计条件概率模型。基于特征空间划分的类的条件概率模型有无穷多个。我们选择的条件概率模型应该不仅对训练数据有很好的拟合，而且对未知数据有很好的预测。</p>
<p>决策树学习用损失函数表示这一目标，如下所述，决策树学习的损失函数通常是正则化的极大似然函数。决策树学习的策略是以损失函数为目标函数的最小化。</p>
<p>当损失函数确定以后，学习问题就变为在损失函数意义下选择最优决策树的问题，因为从所有可能的决策树中选取最优决策树是<a href="https://zhuanlan.zhihu.com/p/73953567" target="_blank" rel="noopener">NP完全问题</a>，所以现实中决策树学习算法通常采用启发式方法，近似求解这一最优化问题，这样得到的决策树是次最优（sub- optimal）的。</p>
<p>决策树学习的算法通常是一个递归地选择最优特征，并根据该特征对训练数据进行分割，使得对各个子数据集有一个最好的分类的过程。这一过程对应着对特征空间的划分，也对应着决策树的构建。开始，构建根结点，将所有训练数据都放在根结点。选择一个最优特征，按照这一特征将训练数据集分割成子集，使得各个子集有一个在当前条件下最好的分类。如果这些子集已经能够被基本正确分类，那么构建叶结点，并将这些子集分到所对应的叶结点中去；如果还有子集不能被基本正确分类，那么就对这些子集选择新的最优特征，继续对其进行分割，构建相应的结点。如此递归地进行下去，直至所有训练数据子集被基本正确分类，或者没有合适的特征为止。最后每个子集都被分到叶结点上，即都有了明确的类。这就生成了一棵决策树。</p>
<p>以上方法生成的决策树可能对训练数据有很好的分类能力，但对未知的测试数据却未必有很好的分类能力，即可能发生过拟合现象。我们需要对已生成的树自下而上进行剪枝，将树变得更简单，从而使它具有更好的泛化能力。具体地，就是去掉过于细分的叶结点，使其回退到父结点，甚至更高的结点，然后将父结点或更高的结点改为新的叶结点。</p>
<p>如果特征数量很多，也可以在决策树学习开始的时候，对特征进行选择，只留下对训练数据有足够分类能力的特征。</p>
<h2 id="5-2-特征选择"><a href="#5-2-特征选择" class="headerlink" title="5.2 特征选择"></a>5.2 特征选择</h2><h3 id="5-2-1-特征选择问题"><a href="#5-2-1-特征选择问题" class="headerlink" title="5.2.1 特征选择问题"></a>5.2.1 特征选择问题</h3><p>特征选择在于选取对训练数据具有分类能力的特征。这样可以提高决策树学习的效率。如果利用一个特征进行分类的结果与随机分类的结果没有很大差别，则称这个特征是没有分类能力的。经验上扔掉这样的特征对决策树学习的精度影响不大。通常特征选择的准则是信息增益或信息增益比。</p>
<p>特征选择是决定用哪个特征来划分特征空间。</p>
<h3 id="5-2-2-信息增益"><a href="#5-2-2-信息增益" class="headerlink" title="5.2.2 信息增益"></a>5.2.2 信息增益</h3><p>在信息论与概率统计中，熵( entropy)是表示随机变量不确定性的度量。</p>
<p>随机变量X的熵定义为：<br>$$<br>H(X)=-\sum_{i=1}^{n} p_{i} \log p_{i}<br>$$<br><img src="/images/loading.gif" data-original="../images/ML/image-20220110111407328.png" alt="分布为贝努利分布熵与概率的关系"></p>
<p>信息增益（information gain）表示得知特征X的信息而使得类Y的信息的不确定性减少的程度。</p>
<p><strong>定义5.2（信息增益</strong>）特征A对训练数据集D的信息增益$g(D,A)$,定义为集合D的经验熵$H(D)$与特征A给定条件下D的经验条件熵$H(D|A)$之差，即<br>$$<br>g(D, A)=H(D)-H(D | A)<br>$$<br>一般地，熵$H(Y)$与条件熵$H(Y|X)$之差称为互信息（mutual information）.决策树学习中的信息增益等价于训练数据集中类与特征的互信息。</p>
<p>根据信息增益准则的特征选择方法是：对训练数据集（或子集）D,计算其每个特征的信息增益，并比较它们的大小，选择信息增益最大的特征。</p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20220110111931321.png" alt=""></p>
<p><strong>算法5.1（信息增益的算法）</strong></p>
<p>输入：训练数据集D和特征A</p>
<p>输出：特征A对训练数据集D的信息增益$g(D,A)$</p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20220110112055115.png" alt=""></p>
<h3 id="5-2-3-信息增益比"><a href="#5-2-3-信息增益比" class="headerlink" title="5.2.3 信息增益比"></a>5.2.3 信息增益比</h3><p>信息增益值的大小是相对于训练数据集而言的，并没有绝对意义。在分类问题困难时，也就是说在训练数据集的经验熵大的时候，信息增益值会偏大。反之，信息增益值会偏小。使用信息增益比（information gain ratio）可以对这一问题进行校正。这是特征选择的另一准则。</p>
<p><strong>定义5.3（信息增益比）</strong>特征A对训练数据集D的信息增益比$g_R(D,A)$定义为其信息增益$g(D,A)$与训练数据集D的经验熵$H(D)$之比：<br>$$<br>g_{R}(D, A)=\frac{g(D, A)}{H(D)}<br>$$</p>
<h2 id="5-3-决策树的生成"><a href="#5-3-决策树的生成" class="headerlink" title="5.3 决策树的生成"></a>5.3 决策树的生成</h2><h3 id="5-3-1-ID3算法"><a href="#5-3-1-ID3算法" class="headerlink" title="5.3.1 ID3算法"></a>5.3.1 ID3算法</h3><p>ID3算法的核心是在决策树各个结点上应用信息增益准则选择特征，递归地构建决策树。具体方法是：从根结点( root node)开始，对结点计算所有可能的特征的信息增益，选择信息增益最大的特征作为结点的特征，由该特征的不同取值建立子结点；再对子结点递归地调用以上方法，构建决策树；直到所有特征的信息增益均很小或没有特征可以选择为止。最后得到一个决策树，ID3相当于用极大似然法进行概率模型的选择。</p>
<p><strong>算法5.2（ID3算法）</strong></p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20220110112809380.png" alt=""></p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20220110112819625.png" alt=""></p>
<p>ID3算法只有树的生成，所以该算法生成的树容易产生过拟合。</p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20220110113131146.png" alt="决策树生成"></p>
<p>对<strong>特征</strong>进行决策。</p>
<h3 id="5-3-2-C4-5的生成算法"><a href="#5-3-2-C4-5的生成算法" class="headerlink" title="5.3.2 C4.5的生成算法"></a>5.3.2 C4.5的生成算法</h3><p>C4.5算法与ID3算法相似，C4.5算法对ID3算法进行了改进。C4.5在生成的过程中，用<strong>信息增益比</strong>来选择特征.</p>
<p><strong>算法5.3（C4.5的生成算法）</strong></p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20220110113842154.png" alt=""></p>
<h2 id="5-4决策树的剪枝"><a href="#5-4决策树的剪枝" class="headerlink" title="5.4决策树的剪枝"></a>5.4决策树的剪枝</h2><p>决策树生成算法递归地产生决策树，直到不能继续下去为止、这样产生的树往往对训练数据的分类很准确，但对未知的测试数据的分类却没有那么准确，即出现过拟合现象。过拟合的原因在于学习时过多地考虑如何提高对训练数据的正确分类，从而构建出过于复杂的决策树。解决这个问题的办法是考虑决策树的复杂度，对已生成的决策树进行简化。</p>
<p>在决策树学习中将已生成的树进行简化的过程称为剪枝( pruning),具体地，剪枝从已生成的树上裁掉一些子树或叶结点，并将其根结点或父结点作为新的叶结点，从而简化分类树模型。</p>
<p>决策树的剪枝往往通过极小化决策树整体的损失函数（loss function）或代价函数（cost function）来实现。</p>
<p>决策树生成只考虑了通过提高信息增益（或信息增益比）对训练数据进行更好的拟合。而决策树剪枝通过优化损失函数还考虑了减小模型复杂度。决策树生成学习局部的模型，而决策树剪枝学习整体的模型。</p>
<p><strong>算法5.4（树的剪枝算法）</strong></p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20220110114507956.png" alt=""></p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20220110114528335.png" alt=""></p>
<h2 id="5-5-CART算法"><a href="#5-5-CART算法" class="headerlink" title="5.5 CART算法"></a>5.5 CART算法</h2><p>分类与回归树（classification and regression tree,CART）模型由 Breiman等人在1984年提出，是应用广泛的决策树学习方法。CART同样由特征选择、树的生成及剪枝组成，既可以用于分类也可以用于回归。以下将用于分类与回归的树统称为决策树。</p>
<p>CART是在给定输入随机变量X条件下输出随机变量Y的条件概率分布的学习方法，CART假设决策树是二叉树，内部结点特征的取值为“是”和“否”，左分支是取值为“是”的分支，右分支是取值为“否”的分支。这样的决策树等价于递归地二分每个特征，将输入空间即特征空间划分为有限个单元，并在这些单元上确定预测的概率分布，也就是在输入给定的条件下输出的条件概率分布。</p>
<p>CART算法由以下两步组成：决策树生成，决策树剪枝。</p>
<h3 id="5-5-1-CART生成"><a href="#5-5-1-CART生成" class="headerlink" title="5.5.1 CART生成"></a>5.5.1 CART生成</h3><p>决策树的生成就是递归地构建二叉决策树的过程。对回归树用平方误差最小化准则，对分类树用基尼指数（Gini index）最小化准则，进行特征选择，生成二叉树。</p>
<ul>
<li>回归树生成</li>
</ul>
<p><strong>算法5.5（最小二乘回归树生成算法）</strong></p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20220110120009728.png" alt=""></p>
<ul>
<li>分类树的生成</li>
</ul>
<p>分类树用基尼指数选择最优特征，同时决定该特征的最优二值切分点</p>
<p><strong>定义5.4（基尼指数）</strong>分类问题中，假设有K个类，样本点属于第k类的概率为$P_k$,则概率分布的基尼指数定义为:<br>$$<br>\operatorname{Gini}(p)=\sum_{k=1}^{K} p_{k}\left(1-p_{k}\right)=1-\sum_{k=1}^{K} p_{k}^{2}<br>$$<br>对于给定的样本集合D,其基尼指数为<br>$$<br>\operatorname{Gini}(D)=1-\sum_{k=1}^{K}\left(\frac{\left|C_{k}\right|}{|D|}\right)^{2}<br>$$<br>样本集合D若被分为两部分，则在特征A的条件下，集合D的基尼指数定义为：<br>$$<br>\operatorname{Gini}(D, A)=\frac{\left|D_{1}\right|}{|D|} \operatorname{Gini}\left(D_{1}\right)+\frac{\left|D_{2}\right|}{|D|} \operatorname{Gini}\left(D_{2}\right)<br>$$<br>基尼指数$Gini(D)$表示集合D的不确定性，基尼指数$Gini(D,A)$表示经A=a分割后集合D的不确定性。基尼指数值越大，样本集合的不确定性也就越大，这一点与熵相似.</p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20220110120729230.png" alt="二类分类中基尼指数、熵之半和分类误差率的关系"></p>
<p><strong>算法5.6(CART生成算法)</strong></p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20220110120809473.png" alt=""></p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20220110120943033.png" alt=""></p>
<h3 id="5-5-2-CART剪枝"><a href="#5-5-2-CART剪枝" class="headerlink" title="5.5.2 CART剪枝"></a>5.5.2 CART剪枝</h3><p>CART剪枝算法从“完全生长”的决策树的底端剪去一些子树，使决策树变小（模型变简单），从而能够对未知数据有更准确的预测。CART剪枝算法由两步组成：首先从生成算法产生的决策树$T_0$底端开始不断剪枝，直到$T_0$的根结点，形成个子树序列${T_0,T_1,…,T_n}$;然后通过交又验证法在独立的验证数据集上对子树序列进行测试，从中选择最优子树.</p>
<ul>
<li>剪枝，形成一个子树序列</li>
</ul>
<p>在剪枝过程中，计算子树的损失函数：<br>$$<br>C_{\alpha}(T)=C(T)+\alpha|T|<br>$$</p>
<ul>
<li>在剪枝得到的子树序列${T_0,T_1,…,T_n}$中交叉验证选取最优子树</li>
</ul>
<p><strong>算法5.7(CART剪枝算法)</strong></p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20220110121645644.png" alt=""></p>
<p>一些解释：</p>
<ul>
<li><a href="https://zhuanlan.zhihu.com/p/133846252" target="_blank" rel="noopener">决策树算法–ID3算法</a></li>
<li><a href="https://zhuanlan.zhihu.com/p/139188759" target="_blank" rel="noopener">决策树算法–C4.5算法</a></li>
<li><a href="https://blog.csdn.net/acdreamers/article/details/44664481" target="_blank" rel="noopener">决策树之CART算法</a></li>
<li><a href="https://zhuanlan.zhihu.com/p/139519852" target="_blank" rel="noopener">决策树算法–CART回归树算法</a></li>
</ul>
<h2 id="习题-4"><a href="#习题-4" class="headerlink" title="习题"></a>习题</h2><h3 id="习题5-1-⭐⭐⭐"><a href="#习题5-1-⭐⭐⭐" class="headerlink" title="习题5.1 ⭐⭐⭐"></a>习题5.1 ⭐⭐⭐</h3><p>  根据表5.1所给的训练数据集，利用信息增益比（C4.5算法）生成决策树。</p>
<p><strong>解答：</strong>  </p>
<p>表5.1 贷款申请样本数据表  </p>
<table>
<thead>
<tr>
<th align="center">ID</th>
<th align="center">年龄</th>
<th align="center">有工作</th>
<th align="center">有自己的房子</th>
<th align="center">信贷情况</th>
<th align="center">类别</th>
</tr>
</thead>
<tbody><tr>
<td align="center">1</td>
<td align="center">青年</td>
<td align="center">否</td>
<td align="center">否</td>
<td align="center">一般</td>
<td align="center">否</td>
</tr>
<tr>
<td align="center">2</td>
<td align="center">青年</td>
<td align="center">否</td>
<td align="center">否</td>
<td align="center">好</td>
<td align="center">否</td>
</tr>
<tr>
<td align="center">3</td>
<td align="center">青年</td>
<td align="center">是</td>
<td align="center">否</td>
<td align="center">好</td>
<td align="center">是</td>
</tr>
<tr>
<td align="center">4</td>
<td align="center">青年</td>
<td align="center">是</td>
<td align="center">是</td>
<td align="center">一般</td>
<td align="center">是</td>
</tr>
<tr>
<td align="center">5</td>
<td align="center">青年</td>
<td align="center">否</td>
<td align="center">否</td>
<td align="center">一般</td>
<td align="center">否</td>
</tr>
<tr>
<td align="center">6</td>
<td align="center">中年</td>
<td align="center">否</td>
<td align="center">否</td>
<td align="center">一般</td>
<td align="center">否</td>
</tr>
<tr>
<td align="center">7</td>
<td align="center">中年</td>
<td align="center">否</td>
<td align="center">否</td>
<td align="center">好</td>
<td align="center">否</td>
</tr>
<tr>
<td align="center">8</td>
<td align="center">中年</td>
<td align="center">是</td>
<td align="center">是</td>
<td align="center">好</td>
<td align="center">是</td>
</tr>
<tr>
<td align="center">9</td>
<td align="center">中年</td>
<td align="center">否</td>
<td align="center">是</td>
<td align="center">非常好</td>
<td align="center">是</td>
</tr>
<tr>
<td align="center">10</td>
<td align="center">中年</td>
<td align="center">否</td>
<td align="center">是</td>
<td align="center">非常好</td>
<td align="center">是</td>
</tr>
<tr>
<td align="center">11</td>
<td align="center">老年</td>
<td align="center">否</td>
<td align="center">是</td>
<td align="center">非常好</td>
<td align="center">是</td>
</tr>
<tr>
<td align="center">12</td>
<td align="center">老年</td>
<td align="center">否</td>
<td align="center">是</td>
<td align="center">好</td>
<td align="center">是</td>
</tr>
<tr>
<td align="center">13</td>
<td align="center">老年</td>
<td align="center">是</td>
<td align="center">否</td>
<td align="center">好</td>
<td align="center">是</td>
</tr>
<tr>
<td align="center">14</td>
<td align="center">老年</td>
<td align="center">是</td>
<td align="center">否</td>
<td align="center">非常好</td>
<td align="center">是</td>
</tr>
<tr>
<td align="center">15</td>
<td align="center">老年</td>
<td align="center">否</td>
<td align="center">否</td>
<td align="center">一般</td>
<td align="center">否</td>
</tr>
</tbody></table>
<p><strong>解答思路：</strong>  </p>
<ol>
<li>列出C4.5的生成算法；</li>
<li>使用sklearn的DecisionTreeClassifier类构建决策树，并使用graphviz包展示，默认是Gini，这里可以作为自编程的验证</li>
<li>通过自编程实现C4.5算法生成决策树，并进行特征选择</li>
</ol>
<p><strong>解题步骤：</strong></p>
<p><strong>第1步：C4.5的生成算法（书中第78页）</strong>  </p>
<blockquote>
<p>输入：训练数据集$D$，特征集$A$阈值$\epsilon$；<br>输出：决策树$T$。<br>（1）如果$D$中所有实例属于同一类$C_k$，则置$T$为单结点树，并将$C_k$作为该结点的类，返回$T$；<br>（2）如果$A = \emptyset$，则置$T$为单结点树，并将$D$中实例数最大的类$C_k$作为该结点的类，返回$T$；<br>（3）否则，按式$\displaystyle g_R(D,A)=\frac{g(D,A)}{H_A(D)}$计算$A$中各特征对$D$的信息增益比，选择信息增益比最大的特征$A_g$；<br>（4）如果$A_g$的信息增益比小于阈值$\epsilon$，则置$T$为单结点树，并将$D$中实例数最大的类$C_k$作为该结点的类，返回$T$；<br>（5）否则，对$A_g$的每一可能值$a_i$，依$A_g=a_i$将$D$分割为子集若干非空$D_i$，将$D_i$中实例数最大的类作为标记，构建子结点，由结点及其子结点构成树$T$，返回$T$；<br>（6）对结点$i$，以$D_i$为训练集，以$A-{A_g}$为特征集，递归地调用步(1)~步(5)，得到子树$T_i$，返回$T_i$</p>
</blockquote>
<p><strong>第2步：调用sklearn的DecisionTreeClassifier类构建决策树</strong></p>
<pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>tree <span class="token keyword">import</span> DecisionTreeClassifier
<span class="token keyword">from</span> sklearn <span class="token keyword">import</span> preprocessing
<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np
<span class="token keyword">import</span> pandas <span class="token keyword">as</span> pd

<span class="token keyword">from</span> sklearn <span class="token keyword">import</span> tree
<span class="token keyword">import</span> graphviz

features <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">"年龄"</span><span class="token punctuation">,</span> <span class="token string">"有工作"</span><span class="token punctuation">,</span> <span class="token string">"有自己的房子"</span><span class="token punctuation">,</span> <span class="token string">"信贷情况"</span><span class="token punctuation">]</span>
X_train <span class="token operator">=</span> pd<span class="token punctuation">.</span>DataFrame<span class="token punctuation">(</span><span class="token punctuation">[</span>
    <span class="token punctuation">[</span><span class="token string">"青年"</span><span class="token punctuation">,</span> <span class="token string">"否"</span><span class="token punctuation">,</span> <span class="token string">"否"</span><span class="token punctuation">,</span> <span class="token string">"一般"</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
    <span class="token punctuation">[</span><span class="token string">"青年"</span><span class="token punctuation">,</span> <span class="token string">"否"</span><span class="token punctuation">,</span> <span class="token string">"否"</span><span class="token punctuation">,</span> <span class="token string">"好"</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
    <span class="token punctuation">[</span><span class="token string">"青年"</span><span class="token punctuation">,</span> <span class="token string">"是"</span><span class="token punctuation">,</span> <span class="token string">"否"</span><span class="token punctuation">,</span> <span class="token string">"好"</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
    <span class="token punctuation">[</span><span class="token string">"青年"</span><span class="token punctuation">,</span> <span class="token string">"是"</span><span class="token punctuation">,</span> <span class="token string">"是"</span><span class="token punctuation">,</span> <span class="token string">"一般"</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
    <span class="token punctuation">[</span><span class="token string">"青年"</span><span class="token punctuation">,</span> <span class="token string">"否"</span><span class="token punctuation">,</span> <span class="token string">"否"</span><span class="token punctuation">,</span> <span class="token string">"一般"</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
    <span class="token punctuation">[</span><span class="token string">"中年"</span><span class="token punctuation">,</span> <span class="token string">"否"</span><span class="token punctuation">,</span> <span class="token string">"否"</span><span class="token punctuation">,</span> <span class="token string">"一般"</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
    <span class="token punctuation">[</span><span class="token string">"中年"</span><span class="token punctuation">,</span> <span class="token string">"否"</span><span class="token punctuation">,</span> <span class="token string">"否"</span><span class="token punctuation">,</span> <span class="token string">"好"</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
    <span class="token punctuation">[</span><span class="token string">"中年"</span><span class="token punctuation">,</span> <span class="token string">"是"</span><span class="token punctuation">,</span> <span class="token string">"是"</span><span class="token punctuation">,</span> <span class="token string">"好"</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
    <span class="token punctuation">[</span><span class="token string">"中年"</span><span class="token punctuation">,</span> <span class="token string">"否"</span><span class="token punctuation">,</span> <span class="token string">"是"</span><span class="token punctuation">,</span> <span class="token string">"非常好"</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
    <span class="token punctuation">[</span><span class="token string">"中年"</span><span class="token punctuation">,</span> <span class="token string">"否"</span><span class="token punctuation">,</span> <span class="token string">"是"</span><span class="token punctuation">,</span> <span class="token string">"非常好"</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
    <span class="token punctuation">[</span><span class="token string">"老年"</span><span class="token punctuation">,</span> <span class="token string">"否"</span><span class="token punctuation">,</span> <span class="token string">"是"</span><span class="token punctuation">,</span> <span class="token string">"非常好"</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
    <span class="token punctuation">[</span><span class="token string">"老年"</span><span class="token punctuation">,</span> <span class="token string">"否"</span><span class="token punctuation">,</span> <span class="token string">"是"</span><span class="token punctuation">,</span> <span class="token string">"好"</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
    <span class="token punctuation">[</span><span class="token string">"老年"</span><span class="token punctuation">,</span> <span class="token string">"是"</span><span class="token punctuation">,</span> <span class="token string">"否"</span><span class="token punctuation">,</span> <span class="token string">"好"</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
    <span class="token punctuation">[</span><span class="token string">"老年"</span><span class="token punctuation">,</span> <span class="token string">"是"</span><span class="token punctuation">,</span> <span class="token string">"否"</span><span class="token punctuation">,</span> <span class="token string">"非常好"</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
    <span class="token punctuation">[</span><span class="token string">"老年"</span><span class="token punctuation">,</span> <span class="token string">"否"</span><span class="token punctuation">,</span> <span class="token string">"否"</span><span class="token punctuation">,</span> <span class="token string">"一般"</span><span class="token punctuation">]</span>
<span class="token punctuation">]</span><span class="token punctuation">)</span>
y_train <span class="token operator">=</span> pd<span class="token punctuation">.</span>DataFrame<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token string">"否"</span><span class="token punctuation">,</span> <span class="token string">"否"</span><span class="token punctuation">,</span> <span class="token string">"是"</span><span class="token punctuation">,</span> <span class="token string">"是"</span><span class="token punctuation">,</span> <span class="token string">"否"</span><span class="token punctuation">,</span>
                        <span class="token string">"否"</span><span class="token punctuation">,</span> <span class="token string">"否"</span><span class="token punctuation">,</span> <span class="token string">"是"</span><span class="token punctuation">,</span> <span class="token string">"是"</span><span class="token punctuation">,</span> <span class="token string">"是"</span><span class="token punctuation">,</span>
                        <span class="token string">"是"</span><span class="token punctuation">,</span> <span class="token string">"是"</span><span class="token punctuation">,</span> <span class="token string">"是"</span><span class="token punctuation">,</span> <span class="token string">"是"</span><span class="token punctuation">,</span> <span class="token string">"否"</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
class_names <span class="token operator">=</span> <span class="token punctuation">[</span>str<span class="token punctuation">(</span>k<span class="token punctuation">)</span> <span class="token keyword">for</span> k <span class="token keyword">in</span> np<span class="token punctuation">.</span>unique<span class="token punctuation">(</span>y_train<span class="token punctuation">)</span><span class="token punctuation">]</span>
<span class="token comment" spellcheck="true"># 数据预处理</span>
le_x <span class="token operator">=</span> preprocessing<span class="token punctuation">.</span>LabelEncoder<span class="token punctuation">(</span><span class="token punctuation">)</span>
le_x<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>np<span class="token punctuation">.</span>unique<span class="token punctuation">(</span>X_train<span class="token punctuation">)</span><span class="token punctuation">)</span>
X_train <span class="token operator">=</span> X_train<span class="token punctuation">.</span>apply<span class="token punctuation">(</span>le_x<span class="token punctuation">.</span>transform<span class="token punctuation">)</span>
<span class="token comment" spellcheck="true"># 调用sklearn的DecisionTreeClassifier建立决策树模型</span>
model_tree <span class="token operator">=</span> DecisionTreeClassifier<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token comment" spellcheck="true"># 训练模型</span>
model_tree<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>X_train<span class="token punctuation">,</span> y_train<span class="token punctuation">)</span>

<span class="token comment" spellcheck="true"># 导出决策树的可视化文件，文件格式是dot</span>
dot_data <span class="token operator">=</span> tree<span class="token punctuation">.</span>export_graphviz<span class="token punctuation">(</span>model_tree<span class="token punctuation">,</span> out_file<span class="token operator">=</span>None<span class="token punctuation">,</span>
                                feature_names<span class="token operator">=</span>features<span class="token punctuation">,</span>
                                class_names<span class="token operator">=</span>class_names<span class="token punctuation">,</span>
                                filled<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> rounded<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>
                                special_characters<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
<span class="token comment" spellcheck="true"># 使用graphviz包，对决策树进行展示</span>
graph <span class="token operator">=</span> graphviz<span class="token punctuation">.</span>Source<span class="token punctuation">(</span>dot_data<span class="token punctuation">)</span>
<span class="token comment" spellcheck="true"># 可使用view方法展示决策树</span>
<span class="token comment" spellcheck="true"># 中文乱码：需要对源码_export.py文件（文件路径：sklearn/tree/_export.py）修改，</span>
<span class="token comment" spellcheck="true"># 在文件第451行中将helvetica改成SimSun</span>
graph<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p><img src="/images/loading.gif" data-original="../images/ML/output_7_0.svg" alt=""></p>
<pre class="line-numbers language-python"><code class="language-python"><span class="token comment" spellcheck="true"># 打印决策树</span>
tree_text <span class="token operator">=</span> tree<span class="token punctuation">.</span>export_text<span class="token punctuation">(</span>model_tree<span class="token punctuation">,</span> feature_names<span class="token operator">=</span>features<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>tree_text<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre>
<pre><code>|--- 有自己的房子 &lt;= 3.00
|   |--- 有工作 &lt;= 3.00
|   |   |--- class: 否
|   |--- 有工作 &gt;  3.00
|   |   |--- class: 是
|--- 有自己的房子 &gt;  3.00
|   |--- class: 是</code></pre><p>​    </p>
<p><strong>第3步：自编程实现C4.5算法生成决策树</strong></p>
<pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">import</span> json
<span class="token keyword">from</span> collections <span class="token keyword">import</span> Counter

<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np


<span class="token comment" spellcheck="true"># 节点类</span>
<span class="token keyword">class</span> <span class="token class-name">Node</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> node_type<span class="token punctuation">,</span> class_name<span class="token punctuation">,</span> feature_name<span class="token operator">=</span>None<span class="token punctuation">,</span>
                 info_gain_ratio_value<span class="token operator">=</span><span class="token number">0.0</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment" spellcheck="true"># 结点类型（internal或leaf）</span>
        self<span class="token punctuation">.</span>node_type <span class="token operator">=</span> node_type
        <span class="token comment" spellcheck="true"># 特征名</span>
        self<span class="token punctuation">.</span>feature_name <span class="token operator">=</span> feature_name
        <span class="token comment" spellcheck="true"># 类别名</span>
        self<span class="token punctuation">.</span>class_name <span class="token operator">=</span> class_name
        <span class="token comment" spellcheck="true"># 子结点树</span>
        self<span class="token punctuation">.</span>child_nodes <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
        <span class="token comment" spellcheck="true"># Gini指数值</span>
        self<span class="token punctuation">.</span>info_gain_ratio_value <span class="token operator">=</span> info_gain_ratio_value

    <span class="token keyword">def</span> <span class="token function">__repr__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">return</span> json<span class="token punctuation">.</span>dumps<span class="token punctuation">(</span>self<span class="token punctuation">,</span> indent<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span> default<span class="token operator">=</span><span class="token keyword">lambda</span> obj<span class="token punctuation">:</span> obj<span class="token punctuation">.</span>__dict__<span class="token punctuation">,</span> ensure_ascii<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">add_sub_tree</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> key<span class="token punctuation">,</span> sub_tree<span class="token punctuation">)</span><span class="token punctuation">:</span>
        self<span class="token punctuation">.</span>child_nodes<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token punctuation">{</span><span class="token string">"condition"</span><span class="token punctuation">:</span> key<span class="token punctuation">,</span> <span class="token string">"sub_tree"</span><span class="token punctuation">:</span> sub_tree<span class="token punctuation">}</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">MyDecisionTree</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> epsilon<span class="token punctuation">)</span><span class="token punctuation">:</span>
        self<span class="token punctuation">.</span>epsilon <span class="token operator">=</span> epsilon
        self<span class="token punctuation">.</span>tree <span class="token operator">=</span> None

    <span class="token keyword">def</span> <span class="token function">fit</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> train_set<span class="token punctuation">,</span> y<span class="token punctuation">,</span> feature_names<span class="token punctuation">)</span><span class="token punctuation">:</span>
        features_indices <span class="token operator">=</span> list<span class="token punctuation">(</span>range<span class="token punctuation">(</span>len<span class="token punctuation">(</span>feature_names<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>tree <span class="token operator">=</span> self<span class="token punctuation">.</span>_fit<span class="token punctuation">(</span>train_set<span class="token punctuation">,</span> y<span class="token punctuation">,</span> features_indices<span class="token punctuation">,</span> feature_names<span class="token punctuation">)</span>
        <span class="token keyword">return</span> self

    <span class="token comment" spellcheck="true"># C4.5算法</span>
    <span class="token keyword">def</span> <span class="token function">_fit</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> train_data<span class="token punctuation">,</span> y<span class="token punctuation">,</span> features_indices<span class="token punctuation">,</span> feature_labels<span class="token punctuation">)</span><span class="token punctuation">:</span>
        LEAF <span class="token operator">=</span> <span class="token string">'leaf'</span>
        INTERNAL <span class="token operator">=</span> <span class="token string">'internal'</span>
        class_num <span class="token operator">=</span> len<span class="token punctuation">(</span>np<span class="token punctuation">.</span>unique<span class="token punctuation">(</span>y<span class="token punctuation">)</span><span class="token punctuation">)</span>

        <span class="token comment" spellcheck="true"># （1）如果训练数据集所有实例都属于同一类Ck</span>
        label_set <span class="token operator">=</span> set<span class="token punctuation">(</span>y<span class="token punctuation">)</span>
        <span class="token keyword">if</span> len<span class="token punctuation">(</span>label_set<span class="token punctuation">)</span> <span class="token operator">==</span> <span class="token number">1</span><span class="token punctuation">:</span>
            <span class="token comment" spellcheck="true"># 将Ck作为该结点的类</span>
            <span class="token keyword">return</span> Node<span class="token punctuation">(</span>node_type<span class="token operator">=</span>LEAF<span class="token punctuation">,</span> class_name<span class="token operator">=</span>label_set<span class="token punctuation">.</span>pop<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

        <span class="token comment" spellcheck="true"># （2）如果特征集为空</span>
        <span class="token comment" spellcheck="true"># 计算每一个类出现的个数</span>
        class_len <span class="token operator">=</span> Counter<span class="token punctuation">(</span>y<span class="token punctuation">)</span><span class="token punctuation">.</span>most_common<span class="token punctuation">(</span><span class="token punctuation">)</span>
        <span class="token punctuation">(</span>max_class<span class="token punctuation">,</span> max_len<span class="token punctuation">)</span> <span class="token operator">=</span> class_len<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>

        <span class="token keyword">if</span> len<span class="token punctuation">(</span>features_indices<span class="token punctuation">)</span> <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">:</span>
            <span class="token comment" spellcheck="true"># 将实例数最大的类Ck作为该结点的类</span>
            <span class="token keyword">return</span> Node<span class="token punctuation">(</span>LEAF<span class="token punctuation">,</span> class_name<span class="token operator">=</span>max_class<span class="token punctuation">)</span>

        <span class="token comment" spellcheck="true"># （3）按式(5.10)计算信息增益，并选择信息增益最大的特征</span>
        max_feature <span class="token operator">=</span> <span class="token number">0</span>
        max_gda <span class="token operator">=</span> <span class="token number">0</span>
        D <span class="token operator">=</span> y<span class="token punctuation">.</span>copy<span class="token punctuation">(</span><span class="token punctuation">)</span>
        <span class="token comment" spellcheck="true"># 计算特征集A中各特征</span>
        <span class="token keyword">for</span> feature <span class="token keyword">in</span> features_indices<span class="token punctuation">:</span>
            <span class="token comment" spellcheck="true"># 选择训练集中的第feature列（即第feature个特征）</span>
            A <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span>train_data<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> feature<span class="token punctuation">]</span><span class="token punctuation">.</span>flat<span class="token punctuation">)</span>
            <span class="token comment" spellcheck="true"># 计算信息增益</span>
            gda <span class="token operator">=</span> self<span class="token punctuation">.</span>_calc_ent_grap<span class="token punctuation">(</span>A<span class="token punctuation">,</span> D<span class="token punctuation">)</span>
            <span class="token keyword">if</span> self<span class="token punctuation">.</span>_calc_ent<span class="token punctuation">(</span>D<span class="token punctuation">)</span> <span class="token operator">!=</span> <span class="token number">0</span><span class="token punctuation">:</span>
                <span class="token comment" spellcheck="true"># 计算信息增益比</span>
                gda <span class="token operator">/=</span> self<span class="token punctuation">.</span>_calc_ent<span class="token punctuation">(</span>D<span class="token punctuation">)</span>
            <span class="token comment" spellcheck="true"># 选择信息增益最大的特征Ag</span>
            <span class="token keyword">if</span> gda <span class="token operator">></span> max_gda<span class="token punctuation">:</span>
                max_gda<span class="token punctuation">,</span> max_feature <span class="token operator">=</span> gda<span class="token punctuation">,</span> feature

        <span class="token comment" spellcheck="true"># （4）如果Ag信息增益小于阈值</span>
        <span class="token keyword">if</span> max_gda <span class="token operator">&lt;</span> self<span class="token punctuation">.</span>epsilon<span class="token punctuation">:</span>
            <span class="token comment" spellcheck="true"># 将训练集中实例数最大的类Ck作为该结点的类</span>
            <span class="token keyword">return</span> Node<span class="token punctuation">(</span>LEAF<span class="token punctuation">,</span> class_name<span class="token operator">=</span>max_class<span class="token punctuation">)</span>

        max_feature_label <span class="token operator">=</span> feature_labels<span class="token punctuation">[</span>max_feature<span class="token punctuation">]</span>

        <span class="token comment" spellcheck="true"># （6）移除已选特征Ag</span>
        sub_feature_indecs <span class="token operator">=</span> np<span class="token punctuation">.</span>setdiff1d<span class="token punctuation">(</span>features_indices<span class="token punctuation">,</span> max_feature<span class="token punctuation">)</span>
        sub_feature_labels <span class="token operator">=</span> np<span class="token punctuation">.</span>setdiff1d<span class="token punctuation">(</span>feature_labels<span class="token punctuation">,</span> max_feature_label<span class="token punctuation">)</span>

        <span class="token comment" spellcheck="true"># （5）构建非空子集</span>
        <span class="token comment" spellcheck="true"># 构建结点</span>
        feature_name <span class="token operator">=</span> feature_labels<span class="token punctuation">[</span>max_feature<span class="token punctuation">]</span>
        tree <span class="token operator">=</span> Node<span class="token punctuation">(</span>INTERNAL<span class="token punctuation">,</span> class_name<span class="token operator">=</span>None<span class="token punctuation">,</span> feature_name<span class="token operator">=</span>feature_name<span class="token punctuation">,</span>
                    info_gain_ratio_value<span class="token operator">=</span>max_gda<span class="token punctuation">)</span>

        max_feature_col <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span>train_data<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> max_feature<span class="token punctuation">]</span><span class="token punctuation">.</span>flat<span class="token punctuation">)</span>
        <span class="token comment" spellcheck="true"># 将类按照对应的实例数递减顺序排列</span>
        feature_value_list <span class="token operator">=</span> <span class="token punctuation">[</span>x<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token keyword">for</span> x <span class="token keyword">in</span> Counter<span class="token punctuation">(</span>max_feature_col<span class="token punctuation">)</span><span class="token punctuation">.</span>most_common<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">]</span>
        <span class="token comment" spellcheck="true"># 遍历Ag的每一个可能值ai</span>
        <span class="token keyword">for</span> feature_value <span class="token keyword">in</span> feature_value_list<span class="token punctuation">:</span>
            index <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
            <span class="token keyword">for</span> i <span class="token keyword">in</span> range<span class="token punctuation">(</span>len<span class="token punctuation">(</span>y<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
                <span class="token keyword">if</span> train_data<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">[</span>max_feature<span class="token punctuation">]</span> <span class="token operator">==</span> feature_value<span class="token punctuation">:</span>
                    index<span class="token punctuation">.</span>append<span class="token punctuation">(</span>i<span class="token punctuation">)</span>

            <span class="token comment" spellcheck="true"># 递归调用步（1）~步（5），得到子树</span>
            sub_train_set <span class="token operator">=</span> train_data<span class="token punctuation">[</span>index<span class="token punctuation">]</span>
            sub_train_label <span class="token operator">=</span> y<span class="token punctuation">[</span>index<span class="token punctuation">]</span>
            sub_tree <span class="token operator">=</span> self<span class="token punctuation">.</span>_fit<span class="token punctuation">(</span>sub_train_set<span class="token punctuation">,</span> sub_train_label<span class="token punctuation">,</span> sub_feature_indecs<span class="token punctuation">,</span> sub_feature_labels<span class="token punctuation">)</span>
            <span class="token comment" spellcheck="true"># 在结点中，添加其子结点构成的树</span>
            tree<span class="token punctuation">.</span>add_sub_tree<span class="token punctuation">(</span>feature_value<span class="token punctuation">,</span> sub_tree<span class="token punctuation">)</span>

        <span class="token keyword">return</span> tree

    <span class="token comment" spellcheck="true"># 计算数据集x的经验熵H(x)</span>
    <span class="token keyword">def</span> <span class="token function">_calc_ent</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>
        x_value_list <span class="token operator">=</span> set<span class="token punctuation">(</span><span class="token punctuation">[</span>x<span class="token punctuation">[</span>i<span class="token punctuation">]</span> <span class="token keyword">for</span> i <span class="token keyword">in</span> range<span class="token punctuation">(</span>x<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
        ent <span class="token operator">=</span> <span class="token number">0.0</span>
        <span class="token keyword">for</span> x_value <span class="token keyword">in</span> x_value_list<span class="token punctuation">:</span>
            p <span class="token operator">=</span> float<span class="token punctuation">(</span>x<span class="token punctuation">[</span>x <span class="token operator">==</span> x_value<span class="token punctuation">]</span><span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token operator">/</span> x<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
            logp <span class="token operator">=</span> np<span class="token punctuation">.</span>log2<span class="token punctuation">(</span>p<span class="token punctuation">)</span>
            ent <span class="token operator">-=</span> p <span class="token operator">*</span> logp

        <span class="token keyword">return</span> ent

    <span class="token comment" spellcheck="true"># 计算条件熵H(y/x)</span>
    <span class="token keyword">def</span> <span class="token function">_calc_condition_ent</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">,</span> y<span class="token punctuation">)</span><span class="token punctuation">:</span>
        x_value_list <span class="token operator">=</span> set<span class="token punctuation">(</span><span class="token punctuation">[</span>x<span class="token punctuation">[</span>i<span class="token punctuation">]</span> <span class="token keyword">for</span> i <span class="token keyword">in</span> range<span class="token punctuation">(</span>x<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
        ent <span class="token operator">=</span> <span class="token number">0.0</span>
        <span class="token keyword">for</span> x_value <span class="token keyword">in</span> x_value_list<span class="token punctuation">:</span>
            sub_y <span class="token operator">=</span> y<span class="token punctuation">[</span>x <span class="token operator">==</span> x_value<span class="token punctuation">]</span>
            temp_ent <span class="token operator">=</span> self<span class="token punctuation">.</span>_calc_ent<span class="token punctuation">(</span>sub_y<span class="token punctuation">)</span>
            ent <span class="token operator">+=</span> <span class="token punctuation">(</span>float<span class="token punctuation">(</span>sub_y<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token operator">/</span> y<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token operator">*</span> temp_ent

        <span class="token keyword">return</span> ent

    <span class="token comment" spellcheck="true"># 计算信息增益</span>
    <span class="token keyword">def</span> <span class="token function">_calc_ent_grap</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">,</span> y<span class="token punctuation">)</span><span class="token punctuation">:</span>
        base_ent <span class="token operator">=</span> self<span class="token punctuation">.</span>_calc_ent<span class="token punctuation">(</span>y<span class="token punctuation">)</span>
        condition_ent <span class="token operator">=</span> self<span class="token punctuation">.</span>_calc_condition_ent<span class="token punctuation">(</span>x<span class="token punctuation">,</span> y<span class="token punctuation">)</span>
        ent_grap <span class="token operator">=</span> base_ent <span class="token operator">-</span> condition_ent

        <span class="token keyword">return</span> ent_grap

    <span class="token keyword">def</span> <span class="token function">__repr__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">return</span> str<span class="token punctuation">(</span>self<span class="token punctuation">.</span>tree<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<pre class="line-numbers language-python"><code class="language-python"><span class="token comment" spellcheck="true"># 表5.1的训练数据集</span>
feature_names <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token string">"年龄"</span><span class="token punctuation">,</span> <span class="token string">"有工作"</span><span class="token punctuation">,</span> <span class="token string">"有自己的房子"</span><span class="token punctuation">,</span> <span class="token string">"信贷情况"</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
X_train <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span>
    <span class="token punctuation">[</span><span class="token string">"青年"</span><span class="token punctuation">,</span> <span class="token string">"否"</span><span class="token punctuation">,</span> <span class="token string">"否"</span><span class="token punctuation">,</span> <span class="token string">"一般"</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
    <span class="token punctuation">[</span><span class="token string">"青年"</span><span class="token punctuation">,</span> <span class="token string">"否"</span><span class="token punctuation">,</span> <span class="token string">"否"</span><span class="token punctuation">,</span> <span class="token string">"好"</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
    <span class="token punctuation">[</span><span class="token string">"青年"</span><span class="token punctuation">,</span> <span class="token string">"是"</span><span class="token punctuation">,</span> <span class="token string">"否"</span><span class="token punctuation">,</span> <span class="token string">"好"</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
    <span class="token punctuation">[</span><span class="token string">"青年"</span><span class="token punctuation">,</span> <span class="token string">"是"</span><span class="token punctuation">,</span> <span class="token string">"是"</span><span class="token punctuation">,</span> <span class="token string">"一般"</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
    <span class="token punctuation">[</span><span class="token string">"青年"</span><span class="token punctuation">,</span> <span class="token string">"否"</span><span class="token punctuation">,</span> <span class="token string">"否"</span><span class="token punctuation">,</span> <span class="token string">"一般"</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
    <span class="token punctuation">[</span><span class="token string">"中年"</span><span class="token punctuation">,</span> <span class="token string">"否"</span><span class="token punctuation">,</span> <span class="token string">"否"</span><span class="token punctuation">,</span> <span class="token string">"一般"</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
    <span class="token punctuation">[</span><span class="token string">"中年"</span><span class="token punctuation">,</span> <span class="token string">"否"</span><span class="token punctuation">,</span> <span class="token string">"否"</span><span class="token punctuation">,</span> <span class="token string">"好"</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
    <span class="token punctuation">[</span><span class="token string">"中年"</span><span class="token punctuation">,</span> <span class="token string">"是"</span><span class="token punctuation">,</span> <span class="token string">"是"</span><span class="token punctuation">,</span> <span class="token string">"好"</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
    <span class="token punctuation">[</span><span class="token string">"中年"</span><span class="token punctuation">,</span> <span class="token string">"否"</span><span class="token punctuation">,</span> <span class="token string">"是"</span><span class="token punctuation">,</span> <span class="token string">"非常好"</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
    <span class="token punctuation">[</span><span class="token string">"中年"</span><span class="token punctuation">,</span> <span class="token string">"否"</span><span class="token punctuation">,</span> <span class="token string">"是"</span><span class="token punctuation">,</span> <span class="token string">"非常好"</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
    <span class="token punctuation">[</span><span class="token string">"老年"</span><span class="token punctuation">,</span> <span class="token string">"否"</span><span class="token punctuation">,</span> <span class="token string">"是"</span><span class="token punctuation">,</span> <span class="token string">"非常好"</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
    <span class="token punctuation">[</span><span class="token string">"老年"</span><span class="token punctuation">,</span> <span class="token string">"否"</span><span class="token punctuation">,</span> <span class="token string">"是"</span><span class="token punctuation">,</span> <span class="token string">"好"</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
    <span class="token punctuation">[</span><span class="token string">"老年"</span><span class="token punctuation">,</span> <span class="token string">"是"</span><span class="token punctuation">,</span> <span class="token string">"否"</span><span class="token punctuation">,</span> <span class="token string">"好"</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
    <span class="token punctuation">[</span><span class="token string">"老年"</span><span class="token punctuation">,</span> <span class="token string">"是"</span><span class="token punctuation">,</span> <span class="token string">"否"</span><span class="token punctuation">,</span> <span class="token string">"非常好"</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
    <span class="token punctuation">[</span><span class="token string">"老年"</span><span class="token punctuation">,</span> <span class="token string">"否"</span><span class="token punctuation">,</span> <span class="token string">"否"</span><span class="token punctuation">,</span> <span class="token string">"一般"</span><span class="token punctuation">]</span>
<span class="token punctuation">]</span><span class="token punctuation">)</span>
y <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token string">"否"</span><span class="token punctuation">,</span> <span class="token string">"否"</span><span class="token punctuation">,</span> <span class="token string">"是"</span><span class="token punctuation">,</span> <span class="token string">"是"</span><span class="token punctuation">,</span> <span class="token string">"否"</span><span class="token punctuation">,</span>
              <span class="token string">"否"</span><span class="token punctuation">,</span> <span class="token string">"否"</span><span class="token punctuation">,</span> <span class="token string">"是"</span><span class="token punctuation">,</span> <span class="token string">"是"</span><span class="token punctuation">,</span> <span class="token string">"是"</span><span class="token punctuation">,</span>
              <span class="token string">"是"</span><span class="token punctuation">,</span> <span class="token string">"是"</span><span class="token punctuation">,</span> <span class="token string">"是"</span><span class="token punctuation">,</span> <span class="token string">"是"</span><span class="token punctuation">,</span> <span class="token string">"否"</span><span class="token punctuation">]</span><span class="token punctuation">)</span>

dt_tree <span class="token operator">=</span> MyDecisionTree<span class="token punctuation">(</span>epsilon<span class="token operator">=</span><span class="token number">0.1</span><span class="token punctuation">)</span>
dt_tree<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>X_train<span class="token punctuation">,</span> y<span class="token punctuation">,</span> feature_names<span class="token punctuation">)</span>
dt_tree<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<pre><code>{
   "node_type": "internal",
   "feature_name": "有自己的房子",
   "class_name": null,
   "child_nodes": [
      {
         "condition": "否",
         "sub_tree": {
            "node_type": "internal",
            "feature_name": "年龄",
            "class_name": null,
            "child_nodes": [
               {
                  "condition": "否",
                  "sub_tree": {
                     "node_type": "leaf",
                     "feature_name": null,
                     "class_name": "否",
                     "child_nodes": [],
                     "info_gain_ratio_value": 0.0
                  }
               },
               {
                  "condition": "是",
                  "sub_tree": {
                     "node_type": "leaf",
                     "feature_name": null,
                     "class_name": "是",
                     "child_nodes": [],
                     "info_gain_ratio_value": 0.0
                  }
               }
            ],
            "info_gain_ratio_value": 1.0
         }
      },
      {
         "condition": "是",
         "sub_tree": {
            "node_type": "leaf",
            "feature_name": null,
            "class_name": "是",
            "child_nodes": [],
            "info_gain_ratio_value": 0.0
         }
      }
   ],
   "info_gain_ratio_value": 0.4325380677663126
}</code></pre><h3 id="习题5-2-⭐⭐⭐"><a href="#习题5-2-⭐⭐⭐" class="headerlink" title="习题5.2 ⭐⭐⭐"></a>习题5.2 ⭐⭐⭐</h3><p>  已知如表5.2所示的训练数据，试用平方误差损失准则生成一个二叉回归树。<br>表5.2 训练数据表  </p>
<table>
<thead>
<tr>
<th>$x_i$</th>
<th>1</th>
<th>2</th>
<th>3</th>
<th>4</th>
<th>5</th>
<th>6</th>
<th>7</th>
<th>8</th>
<th>9</th>
<th>10</th>
</tr>
</thead>
<tbody><tr>
<td>$y_i$</td>
<td>4.50</td>
<td>4.75</td>
<td>4.91</td>
<td>5.34</td>
<td>5.80</td>
<td>7.05</td>
<td>7.90</td>
<td>8.23</td>
<td>8.70</td>
<td>9.00</td>
</tr>
</tbody></table>
<p><strong>解答：</strong></p>
<p><strong>解答思路：</strong></p>
<ol>
<li>根据书中第81页平方误差损失准则，列出最小二乘回归树生成算法（算法5.5）；</li>
<li>编写代码，实现算法，并用表5.2训练数据进行验证。</li>
</ol>
<p><strong>解题步骤：</strong></p>
<p><strong>第1步：算法5.5的最小二乘回归树生成算法（书中第82页）</strong></p>
<blockquote>
<p>  决策树的生成就是递归地构建二叉决策树的过程，对回归树用平方误差最小化准则，对分类树用基尼指数（Gini index）最小化准则，进行特征选择，生成二叉树。</p>
<p>算法5.5（最小二乘回归树生成算法）<br>输入：训练数据集$D$<br>输出：回归树$f(x)$<br>在训练数据集所在的输入空间中，递归地将每个区域划分为两个子区域并决定每个子区域上的输出值，构建二叉决策树；<br>(1)选择最优切分变量$j$与切分点$s$，求解</p>
</blockquote>
<p>$$<br>\min_{j,s} \left[ \min_{c_1} \sum_{x_i \in R_1(j,s)} (y_i - c_1)^2 + \min_{c_2} \sum_{x_i \in R_2(j,s)} (y_i - c_2)^2\right]<br>$$</p>
<blockquote>
<p>遍历变量$j$，对固定的切分变量$j$扫描切分点$s$，选择使得上式达到最小值的对$(j,s)$<br>(2)用选定的对$(j,s)$划分区域并决定相应的输出值：</p>
</blockquote>
<p>$$<br>R_1(j,s)={x|x^{(j)}\leqslant s}, R_2(j,s)={x|x^{(j)} &gt; s} \<br>\hat{c}<em>m = \frac{1}{N_m} \sum</em>{x_i \in R_m(j,s)} y_i, x \in R_m, m=1,2<br>$$</p>
<blockquote>
<p>(3)继续对两个子区域调用步骤(1),(2)，直至满足停止条件<br>(4)将输入空间划分为$M$个区域$R_1,R_2,\cdots,R_M$，生成决策树：</p>
</blockquote>
<p>$$<br>f(x)=\sum_{m=1}^M \hat{c}_m I(x \in R_m)<br>$$</p>
<p><strong>第2步：编写代码，实现算法，并用表5.2训练数据进行验证</strong></p>
<pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">import</span> json

<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np


<span class="token comment" spellcheck="true"># 节点类</span>
<span class="token keyword">class</span> <span class="token class-name">Node</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> value<span class="token punctuation">,</span> feature<span class="token punctuation">,</span> left<span class="token operator">=</span>None<span class="token punctuation">,</span> right<span class="token operator">=</span>None<span class="token punctuation">)</span><span class="token punctuation">:</span>
        self<span class="token punctuation">.</span>value <span class="token operator">=</span> value<span class="token punctuation">.</span>tolist<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>feature <span class="token operator">=</span> feature<span class="token punctuation">.</span>tolist<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>left <span class="token operator">=</span> left
        self<span class="token punctuation">.</span>right <span class="token operator">=</span> right

    <span class="token keyword">def</span> <span class="token function">__repr__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">return</span> json<span class="token punctuation">.</span>dumps<span class="token punctuation">(</span>self<span class="token punctuation">,</span> indent<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span> default<span class="token operator">=</span><span class="token keyword">lambda</span> obj<span class="token punctuation">:</span> obj<span class="token punctuation">.</span>__dict__<span class="token punctuation">,</span> ensure_ascii<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">MyLeastSquareRegTree</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> train_X<span class="token punctuation">,</span> y<span class="token punctuation">,</span> epsilon<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment" spellcheck="true"># 训练集特征值</span>
        self<span class="token punctuation">.</span>x <span class="token operator">=</span> train_X
        <span class="token comment" spellcheck="true"># 类别</span>
        self<span class="token punctuation">.</span>y <span class="token operator">=</span> y
        <span class="token comment" spellcheck="true"># 特征总数</span>
        self<span class="token punctuation">.</span>feature_count <span class="token operator">=</span> train_X<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span>
        <span class="token comment" spellcheck="true"># 损失阈值</span>
        self<span class="token punctuation">.</span>epsilon <span class="token operator">=</span> epsilon
        <span class="token comment" spellcheck="true"># 回归树</span>
        self<span class="token punctuation">.</span>tree <span class="token operator">=</span> None

    <span class="token keyword">def</span> <span class="token function">_fit</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">,</span> y<span class="token punctuation">,</span> feature_count<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment" spellcheck="true"># （1）选择最优切分点变量j与切分点s，得到选定的对(j,s)，并解得c1，c2</span>
        <span class="token punctuation">(</span>j<span class="token punctuation">,</span> s<span class="token punctuation">,</span> minval<span class="token punctuation">,</span> c1<span class="token punctuation">,</span> c2<span class="token punctuation">)</span> <span class="token operator">=</span> self<span class="token punctuation">.</span>_divide<span class="token punctuation">(</span>x<span class="token punctuation">,</span> y<span class="token punctuation">,</span> feature_count<span class="token punctuation">)</span>
        <span class="token comment" spellcheck="true"># 初始化树</span>
        tree <span class="token operator">=</span> Node<span class="token punctuation">(</span>feature<span class="token operator">=</span>j<span class="token punctuation">,</span> value<span class="token operator">=</span>x<span class="token punctuation">[</span>s<span class="token punctuation">,</span> j<span class="token punctuation">]</span><span class="token punctuation">,</span> left<span class="token operator">=</span>None<span class="token punctuation">,</span> right<span class="token operator">=</span>None<span class="token punctuation">)</span>
        <span class="token comment" spellcheck="true"># 用选定的对(j,s)划分区域，并确定响应的输出值</span>
        <span class="token keyword">if</span> minval <span class="token operator">&lt;</span> self<span class="token punctuation">.</span>epsilon <span class="token operator">or</span> len<span class="token punctuation">(</span>y<span class="token punctuation">[</span>np<span class="token punctuation">.</span>where<span class="token punctuation">(</span>x<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> j<span class="token punctuation">]</span> <span class="token operator">&lt;=</span> x<span class="token punctuation">[</span>s<span class="token punctuation">,</span> j<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token operator">&lt;=</span> <span class="token number">1</span><span class="token punctuation">:</span>
            tree<span class="token punctuation">.</span>left <span class="token operator">=</span> c1
        <span class="token keyword">else</span><span class="token punctuation">:</span>
            <span class="token comment" spellcheck="true"># 对左子区域调用步骤（1）、（2）</span>
            tree<span class="token punctuation">.</span>left <span class="token operator">=</span> self<span class="token punctuation">.</span>_fit<span class="token punctuation">(</span>x<span class="token punctuation">[</span>np<span class="token punctuation">.</span>where<span class="token punctuation">(</span>x<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> j<span class="token punctuation">]</span> <span class="token operator">&lt;=</span> x<span class="token punctuation">[</span>s<span class="token punctuation">,</span> j<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
                                  y<span class="token punctuation">[</span>np<span class="token punctuation">.</span>where<span class="token punctuation">(</span>x<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> j<span class="token punctuation">]</span> <span class="token operator">&lt;=</span> x<span class="token punctuation">[</span>s<span class="token punctuation">,</span> j<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
                                  self<span class="token punctuation">.</span>feature_count<span class="token punctuation">)</span>
        <span class="token keyword">if</span> minval <span class="token operator">&lt;</span> self<span class="token punctuation">.</span>epsilon <span class="token operator">or</span> len<span class="token punctuation">(</span>y<span class="token punctuation">[</span>np<span class="token punctuation">.</span>where<span class="token punctuation">(</span>x<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> j<span class="token punctuation">]</span> <span class="token operator">></span> s<span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token operator">&lt;=</span> <span class="token number">1</span><span class="token punctuation">:</span>
            tree<span class="token punctuation">.</span>right <span class="token operator">=</span> c2
        <span class="token keyword">else</span><span class="token punctuation">:</span>
            <span class="token comment" spellcheck="true"># 对右子区域调用步骤（1）、（2）</span>
            tree<span class="token punctuation">.</span>right <span class="token operator">=</span> self<span class="token punctuation">.</span>_fit<span class="token punctuation">(</span>x<span class="token punctuation">[</span>np<span class="token punctuation">.</span>where<span class="token punctuation">(</span>x<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> j<span class="token punctuation">]</span> <span class="token operator">></span> x<span class="token punctuation">[</span>s<span class="token punctuation">,</span> j<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
                                   y<span class="token punctuation">[</span>np<span class="token punctuation">.</span>where<span class="token punctuation">(</span>x<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> j<span class="token punctuation">]</span> <span class="token operator">></span> x<span class="token punctuation">[</span>s<span class="token punctuation">,</span> j<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
                                   self<span class="token punctuation">.</span>feature_count<span class="token punctuation">)</span>
        <span class="token keyword">return</span> tree

    <span class="token keyword">def</span> <span class="token function">fit</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        self<span class="token punctuation">.</span>tree <span class="token operator">=</span> self<span class="token punctuation">.</span>_fit<span class="token punctuation">(</span>self<span class="token punctuation">.</span>x<span class="token punctuation">,</span> self<span class="token punctuation">.</span>y<span class="token punctuation">,</span> self<span class="token punctuation">.</span>feature_count<span class="token punctuation">)</span>
        <span class="token keyword">return</span> self

    @staticmethod
    <span class="token keyword">def</span> <span class="token function">_divide</span><span class="token punctuation">(</span>x<span class="token punctuation">,</span> y<span class="token punctuation">,</span> feature_count<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment" spellcheck="true"># 初始化损失误差</span>
        cost <span class="token operator">=</span> np<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token punctuation">(</span>feature_count<span class="token punctuation">,</span> len<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        <span class="token comment" spellcheck="true"># 公式5.21</span>
        <span class="token keyword">for</span> i <span class="token keyword">in</span> range<span class="token punctuation">(</span>feature_count<span class="token punctuation">)</span><span class="token punctuation">:</span>
            <span class="token keyword">for</span> k <span class="token keyword">in</span> range<span class="token punctuation">(</span>len<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
                <span class="token comment" spellcheck="true"># k行i列的特征值</span>
                value <span class="token operator">=</span> x<span class="token punctuation">[</span>k<span class="token punctuation">,</span> i<span class="token punctuation">]</span>
                y1 <span class="token operator">=</span> y<span class="token punctuation">[</span>np<span class="token punctuation">.</span>where<span class="token punctuation">(</span>x<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> i<span class="token punctuation">]</span> <span class="token operator">&lt;=</span> value<span class="token punctuation">)</span><span class="token punctuation">]</span>
                c1 <span class="token operator">=</span> np<span class="token punctuation">.</span>mean<span class="token punctuation">(</span>y1<span class="token punctuation">)</span>
                y2 <span class="token operator">=</span> y<span class="token punctuation">[</span>np<span class="token punctuation">.</span>where<span class="token punctuation">(</span>x<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> i<span class="token punctuation">]</span> <span class="token operator">></span> value<span class="token punctuation">)</span><span class="token punctuation">]</span>
                <span class="token keyword">if</span> len<span class="token punctuation">(</span>y2<span class="token punctuation">)</span> <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">:</span>
                    c2 <span class="token operator">=</span> <span class="token number">0</span>
                <span class="token keyword">else</span><span class="token punctuation">:</span>
                    c2 <span class="token operator">=</span> np<span class="token punctuation">.</span>mean<span class="token punctuation">(</span>y2<span class="token punctuation">)</span>
                y1<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">]</span> <span class="token operator">=</span> y1<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">]</span> <span class="token operator">-</span> c1
                y2<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">]</span> <span class="token operator">=</span> y2<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">]</span> <span class="token operator">-</span> c2
                cost<span class="token punctuation">[</span>i<span class="token punctuation">,</span> k<span class="token punctuation">]</span> <span class="token operator">=</span> np<span class="token punctuation">.</span>sum<span class="token punctuation">(</span>y1 <span class="token operator">*</span> y1<span class="token punctuation">)</span> <span class="token operator">+</span> np<span class="token punctuation">.</span>sum<span class="token punctuation">(</span>y2 <span class="token operator">*</span> y2<span class="token punctuation">)</span>
        <span class="token comment" spellcheck="true"># 选取最优损失误差点</span>
        cost_index <span class="token operator">=</span> np<span class="token punctuation">.</span>where<span class="token punctuation">(</span>cost <span class="token operator">==</span> np<span class="token punctuation">.</span>min<span class="token punctuation">(</span>cost<span class="token punctuation">)</span><span class="token punctuation">)</span>
        <span class="token comment" spellcheck="true"># 所选取的特征</span>
        j <span class="token operator">=</span> cost_index<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
        <span class="token comment" spellcheck="true"># 选取特征的切分点</span>
        s <span class="token operator">=</span> cost_index<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
        <span class="token comment" spellcheck="true"># 求两个区域的均值c1,c2</span>
        c1 <span class="token operator">=</span> np<span class="token punctuation">.</span>mean<span class="token punctuation">(</span>y<span class="token punctuation">[</span>np<span class="token punctuation">.</span>where<span class="token punctuation">(</span>x<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> j<span class="token punctuation">]</span> <span class="token operator">&lt;=</span> x<span class="token punctuation">[</span>s<span class="token punctuation">,</span> j<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
        c2 <span class="token operator">=</span> np<span class="token punctuation">.</span>mean<span class="token punctuation">(</span>y<span class="token punctuation">[</span>np<span class="token punctuation">.</span>where<span class="token punctuation">(</span>x<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> j<span class="token punctuation">]</span> <span class="token operator">></span> x<span class="token punctuation">[</span>s<span class="token punctuation">,</span> j<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
        <span class="token keyword">return</span> j<span class="token punctuation">,</span> s<span class="token punctuation">,</span> cost<span class="token punctuation">[</span>cost_index<span class="token punctuation">]</span><span class="token punctuation">,</span> c1<span class="token punctuation">,</span> c2

    <span class="token keyword">def</span> <span class="token function">__repr__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">return</span> str<span class="token punctuation">(</span>self<span class="token punctuation">.</span>tree<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<pre class="line-numbers language-python"><code class="language-python">train_X <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">,</span> <span class="token number">7</span><span class="token punctuation">,</span> <span class="token number">8</span><span class="token punctuation">,</span> <span class="token number">9</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">.</span>T
y <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">4.50</span><span class="token punctuation">,</span> <span class="token number">4.75</span><span class="token punctuation">,</span> <span class="token number">4.91</span><span class="token punctuation">,</span> <span class="token number">5.34</span><span class="token punctuation">,</span> <span class="token number">5.80</span><span class="token punctuation">,</span> <span class="token number">7.05</span><span class="token punctuation">,</span> <span class="token number">7.90</span><span class="token punctuation">,</span> <span class="token number">8.23</span><span class="token punctuation">,</span> <span class="token number">8.70</span><span class="token punctuation">,</span> <span class="token number">9.00</span><span class="token punctuation">]</span><span class="token punctuation">)</span>

model_tree <span class="token operator">=</span> MyLeastSquareRegTree<span class="token punctuation">(</span>train_X<span class="token punctuation">,</span> y<span class="token punctuation">,</span> epsilon<span class="token operator">=</span><span class="token number">0.2</span><span class="token punctuation">)</span>
model_tree<span class="token punctuation">.</span>fit<span class="token punctuation">(</span><span class="token punctuation">)</span>
model_tree<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<pre><code>{
   "value": 5,
   "feature": 0,
   "left": {
      "value": 3,
      "feature": 0,
      "left": 4.72,
      "right": 5.57
   },
   "right": {
      "value": 7,
      "feature": 0,
      "left": {
         "value": 6,
         "feature": 0,
         "left": 7.05,
         "right": 7.9
      },
      "right": {
         "value": 8,
         "feature": 0,
         "left": 8.23,
         "right": 8.85
      }
   }
}</code></pre><p>根据上面程序的输出，可得到用平方误差损失准则生成一个二叉回归树：$$f(x)=\begin{cases}<br>4.72 &amp; x \le 3\<br>5.57 &amp; 3 &lt; x \le 5\<br>7.05 &amp; 5 &lt; x \le 6\<br>7.9 &amp; 6 &lt; x \le 7 \<br>8.23 &amp; 7 &lt; x \le 8\<br>8.85 &amp; x &gt; 8\<br>\end{cases}$$</p>
<h3 id="习题5-3"><a href="#习题5-3" class="headerlink" title="习题5.3"></a>习题5.3</h3><p>  证明 CART 剪枝算法中，当$\alpha$确定时，存在唯一的最小子树$T_{\alpha}$使损失函数$C_{\alpha}(T)$最小。</p>
<p><strong>解答：</strong></p>
<p><strong>解答思路：</strong></p>
<ol>
<li>列出CART剪枝算法；</li>
<li>列出树的剪枝算法；</li>
<li>采用反证法，假设存在两棵子树使得损失函数最小。</li>
</ol>
<p><strong>解答步骤：</strong></p>
<p><strong>第1步：CART剪枝算法（书中第87页）</strong></p>
<blockquote>
<p>输入：CART算法生成的决策树$T_0$；<br>输出：最优决策树$T_\alpha$。<br>（1）设$k=0,T=T_0$。<br>（2）设$\alpha=+\infty$。<br>（3）自下而上地对各内部结点$t$计算$C(T_t)$,$|T_t|$，以及</p>
</blockquote>
<p>$$<br>g(t)=\cfrac{C(t)-C(T_t)}{|T_t|-1} \<br>\alpha = \min(\alpha,g(t))<br>$$</p>
<blockquote>
<p>这里，$T_t$表示以$t$为根结点的子树，$C(T_t)$是对训练数据的预测误差，$|T_t|$是$T_t$的叶结点个数。<br>（4）对$g(t)=\alpha$的内部结点$t$进行剪枝，并对叶结点$t$以多数表决法决定其类，得到树$T$。<br>（5）设$k=k+1,\alpha_k=\alpha,T_k=T$。<br>（6）如果$T_k$不是由根节点和两个叶结点组成的树，则回到步骤（2），否则$T_k=T_n$。<br>（7）采用交叉验证法在子树序列从$T_0,T_1,\cdots,T_n$中选取最优子树$T_{\alpha}$。</p>
</blockquote>
<p><strong>第2步：树的剪枝算法（书中第79页）</strong></p>
<blockquote>
<p>输入：生成算法产生的整个树$T$，参数$\alpha$；<br>输出：修剪后的子树$T_\alpha$。<br>（1）计算每个结点的经验熵。<br>（2）递归地从树的叶结点向上回缩。<br>  设一组叶结点回缩到其父结点之前与之后的整体树分别为$T_B$与$T_A$，其对应的损失函数分别是$C_\alpha(T_B)$与$C_\alpha(T_A)$，如果</p>
</blockquote>
<p>$$<br>C_\alpha(T_A) \leqslant C_\alpha(T_B)<br>$$</p>
<blockquote>
<p>则进行剪枝，即将父结点变为新的叶结点。<br>（3）返回（2），直至不能继续为止，得到损失函数最小的子树$T_\alpha$。</p>
</blockquote>
<p><strong>第3步：采用反证法，假设存在两棵子树使得损失函数最小</strong>  </p>
<p>  从第1、2步可得到以下结论：</p>
<ol>
<li>内部节点是否剪枝只与以该节点为根节点的子树有关；</li>
<li>当$C_\alpha(t) &lt; C_\alpha(T_t)$时，对以结点$t$为根节点的子树进行剪枝。</li>
</ol>
<p><img src="/images/loading.gif" data-original="../images/ML/5-1-prune-16417063519342.png" alt=""></p>
<p>  如上图所示，整个树$T_1$有两个子树$T_2$和$T_3$，其剪枝位置分别为$t_2$和$t_3$，假设两棵子树都是$T_1$的最优子树，使得损失函数最小。则满足以下等式：<br>$$<br>C_{\alpha}(T_2)=C_{\alpha}(T_3)<br>$$<br>  根据子树$T_2$的剪枝位置是$t_2$，可得<br>$$<br>C_{\alpha}(t_2)&lt;C_{\alpha}(T_2)<br>$$<br>  根据子树$T_3$的剪枝位置是$t_3$，可得<br>$$<br>C_{\alpha}(t_3)&lt;C_{\alpha}(T_3)<br>$$<br>  由上面公式可得：<br>$$<br>C_{\alpha}(t_2)&lt;C_{\alpha}(T_3) \<br>C_{\alpha}(t_3)&lt;C_{\alpha}(T_2)<br>$$<br>  根据上述公式，可知$T_2$和$T_3$都可以进一步剪枝，剪枝之后的子树记作$T_4$：</p>
<p><img src="/images/loading.gif" data-original="../images/ML/5-2-prune-T4-16417064120893.png" alt=""></p>
<p>  因此，如果存在两棵以上的最优子树，其中一棵树总能找到一个来自另一棵子树的剪枝点，使得整体损失进一步下降，所以只能存在唯一的最小子树使得损失函数最小，得证。</p>
<h3 id="习题5-4"><a href="#习题5-4" class="headerlink" title="习题5.4"></a>习题5.4</h3><p>  证明 CART 剪枝算法中求出的子树序列${T_0,T_1,\cdots,T_n}$分别是区间$\alpha \in [\alpha_i,\alpha_{i+1})$的最优子树$T_{\alpha}$，这里$i=0,1,\cdots,n,0=\alpha_0 &lt; \alpha_1 &lt; \cdots, \alpha_n &lt; +\infty$。</p>
<p><strong>解答：</strong></p>
<p><strong>解答思路：</strong></p>
<ol>
<li>对题目重新进行表述；</li>
<li>证明当$\alpha=0$和$\alpha= + \infty$时的最优子树；</li>
<li>证明$T_1$为区间$[\alpha_1,\alpha_2)$的最优子树。</li>
</ol>
<p><strong>解答步骤：</strong></p>
<p><strong>第1步：对题目重新表述</strong><br>  原结论可以表述为：将$\alpha$从$0$增大到$+\infty$（即$0=\alpha_0&lt;\alpha_1&lt;\cdots&lt;\alpha_n &lt; +\infty$），在每个区间$[\alpha_i,\alpha_{i+1})$中，其中$i=0,1,\ldots,n$，子树$T_i$是该区间里最优的。</p>
<p><strong>第2步：证明当$\alpha=0$和$\alpha= + \infty$时的最优子树</strong></p>
<p>根据书中第85页：</p>
<blockquote>
<p>  当$\alpha$大的时候，最优子树$T_\alpha$偏小；当$\alpha$小的时候，最优子树$T_\alpha$偏大。极端情况，当$\alpha=0$时，整体树是最优的。当$\alpha \rightarrow +\infty$时，根结点组成的单结点树是最优的。</p>
</blockquote>
<p><strong>第3步：证明$T_1$是区间$[\alpha_1, \alpha_2)$的最优子树</strong></p>
<p>  根据《Classification and Regression Trees》书中第10.2节的定理10.7：</p>
<blockquote>
<p>THEOREM 10.7. Every tree T has a unique smallest optimally pruned subtree $T(\alpha)$. Let T be a nontrivial tree having root $t_1$ and primary branches $T_L$ and $T_R$. Then $$R_{\alpha}(T(\alpha)) = \min[R_{\alpha}(t_1), R_{\alpha}(T_L(\alpha))+R_{\alpha}(T_R(\alpha))]$$ If $R_{\alpha}(t_1) \leqslant R_{\alpha}(T_L(\alpha))+R_{\alpha}(T_R(\alpha))$, then $T(\alpha)={t_1}$; otherwise, $T(\alpha) = {t_1} \cup T_L(\alpha) \cup T_R(\alpha)$.</p>
</blockquote>
<p>  根据该书的符号描述，其中：</p>
<ol>
<li>$T(\alpha)$表示，在$\alpha$条件时，树$T$的最小最优剪枝子树</li>
<li>$R_{\alpha}(T(\alpha))$表示，在$\alpha$条件时，$T(\alpha)$的损失值，即$C_{\alpha}(T_{\alpha})$</li>
</ol>
<p>  定理10.7表示，树$T$分为根结点$t_1$、左子树$T_L$和右子树$T_R$，计算在$\alpha$条件时的最优子树的损失，可取$R_{\alpha}(t_1)$和$R_{\alpha}(T_L(\alpha))+R_{\alpha}(T_R(\alpha))$中的最小值，并且$T(\alpha)$满足以下公式：<br>$$<br>T(\alpha) = \left{ \begin{array}{l}<br>{t_1 }, \quad R_{\alpha}(t_1) \leqslant R_{\alpha}(T_L(\alpha))+R_{\alpha}(T_R(\alpha)) \<br>{t_1} \cup T_L(\alpha) \cup T_R(\alpha), \quad \text{otherwise}<br>\end{array}\right.<br>$$</p>
<p>  根据定理10.7，可以得到该书定理10.9的第一个推论：</p>
<blockquote>
<p>THEOREM 10.9.<br>(i) If $\alpha_2 \geqslant \alpha_1$, then $T(α2) \preceq T(α1)$.</p>
</blockquote>
<p>  定理10.9(i)表示，当$\alpha_2 \geqslant \alpha_1$时，树$T$在$\alpha_2$条件下的最优子树一定是树$T$在$\alpha_1$条件下的最优子树的子树。</p>
<p>  根据CART剪枝算法和定理10.9，可知（见该书的第368页）：</p>
<ol>
<li>当$\alpha \geqslant \alpha_1$时，$T_0(\alpha)=T_1$</li>
<li>当$\alpha_1 \leqslant \alpha &lt; \alpha_2$时，$T_0(\alpha) \preceq T_0(\alpha_1) = T_1 \preceq T_0 $</li>
</ol>
<p>  所以，$T_0(\alpha)=T_1(\alpha)=T_1$，该式说明$T_1$是区间$[\alpha_1, \alpha_2)$的最优子树。  </p>
<p>  依次类推，子树$T_i$是区间$[\alpha_i,\alpha_{i+1})$里最优的，原结论得证。</p>
<h1 id="六、逻辑斯蒂回归与最大熵模型"><a href="#六、逻辑斯蒂回归与最大熵模型" class="headerlink" title="六、逻辑斯蒂回归与最大熵模型"></a>六、逻辑斯蒂回归与最大熵模型</h1><p>逻辑斯谛回归（logistic regression）是统计学习中的经典分类方法。最大熵是概率模型学习的一个准则，将其推广到分类问题得到最大熵模型（maximum entropy model）.逻辑斯谛回归模型与最大熵模型都属于对数线性模型。</p>
<h2 id="6-1-逻辑斯谛回归模型"><a href="#6-1-逻辑斯谛回归模型" class="headerlink" title="6.1 逻辑斯谛回归模型"></a>6.1 逻辑斯谛回归模型</h2><h3 id="6-1-1-逻辑斯谛分布"><a href="#6-1-1-逻辑斯谛分布" class="headerlink" title="6.1.1 逻辑斯谛分布"></a>6.1.1 逻辑斯谛分布</h3><p><strong>定义6.1（逻辑斯谛分布）</strong>设X是连续随机变量，X服从逻辑斯谛分布是指X具有下列分布函数和密度函数：<br>$$<br>\begin{aligned}<br>&amp;F(x)=P(X \leqslant x)=\frac{1}{1+\mathrm{e}^{-(x-\mu) / \gamma}} \<br>&amp;f(x)=F^{\prime}(x)=\frac{\mathrm{e}^{-(x-\mu) / \gamma}}{\gamma\left(1+\mathrm{e}^{-(x-\mu) / \gamma}\right)^{2}}<br>\end{aligned}<br>$$<br><img src="/images/loading.gif" data-original="../images/ML/image-20220111095315343.png" alt="逻辑斯谛分布的密度函数与分布函数"></p>
<h3 id="6-1-2-二项逻辑斯谛回归模型"><a href="#6-1-2-二项逻辑斯谛回归模型" class="headerlink" title="6.1.2 二项逻辑斯谛回归模型"></a>6.1.2 二项逻辑斯谛回归模型</h3><p>二项逻辑斯谛回归模型（binomial logistic regression model）是一种分类模型，由条件概率分布$P(Y|X)$表示，形式为参数化的逻辑斯谛分布。这里，随机变量X取值为实数，随机变量Y取值为1或0.我们通过监督学习的方法来估计模型参数.</p>
<p><strong>定义6.2（逻辑斯谛回归模型）</strong>二项逻辑斯谛回归模型是如下的条件概率分布<br>$$<br>\begin{aligned}<br>&amp;P(Y=1 \mid x)=\frac{\exp (w \cdot x+b)}{1+\exp (w \cdot x+b)} \<br>&amp;P(Y=0 \mid x)=\frac{1}{1+\exp (w \cdot x+b)}<br>\end{aligned}<br>$$<br>现在考査逻辑斯谛回归模型的特点，一个事件的几率（ods）是指该事件发生的概率与该事件不发生的概率的比值。如果事件发生的概率是p,那么该事件的几率是$\frac{p}{1-p}$，该事件的对数几率（log odds）或logit函数是：<br>$$<br>\operatorname{logit}(p)=\log \frac{p}{1-p}<br>$$<br>采用简化的逻辑斯蒂回归：<br>$$<br>\log \frac{P(Y=1 \mid x)}{1-P(Y=1 \mid x)}=w \cdot x<br>$$<br>这就是说，在逻辑斯谛回归模型中，输出Y=1的对数几率是输入x的线性函数或者说，输出Y=1的对数几率是由输入x的线性函数表示的模型，即逻辑斯谛回归模型。</p>
<h3 id="6-1-3-模型参数估计"><a href="#6-1-3-模型参数估计" class="headerlink" title="6.1.3 模型参数估计"></a>6.1.3 模型参数估计</h3><p><img src="/images/loading.gif" data-original="../images/ML/image-20220111100201582.png" alt=""></p>
<h3 id="6-1-4-多项逻辑斯谛回归"><a href="#6-1-4-多项逻辑斯谛回归" class="headerlink" title="6.1.4 多项逻辑斯谛回归"></a>6.1.4 多项逻辑斯谛回归</h3><p>上面介绍的逻辑斯谛回归模型是二项分类模型，用于二类分类，可以将其推广为多项逻辑斯谛回归模型（muli- nominal logistic regression model），用于多类分类。假设离散型随机变量Y的取值集合是$ {1,2,…,K} $,那么多项逻辑斯谛回归模型是</p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20220111100533661.png" alt=""></p>
<h2 id="6-2最大熵模型"><a href="#6-2最大熵模型" class="headerlink" title="6.2最大熵模型"></a>6.2最大熵模型</h2><p>最大熵模型（maximum entropy model）由最大熵原理推导实现，这里首先叙述一般的最大熵原理，然后讲解最大熵模型的推导，最后给出最大熵模型学习的形式。</p>
<h3 id="6-2-1最大熵原理"><a href="#6-2-1最大熵原理" class="headerlink" title="6.2.1最大熵原理"></a>6.2.1最大熵原理</h3><p>最大熵原理是概率模型学习的一个准则。最大熵原理认为，学习概率模型时，在所有可能的概率模型（分布）中，熵最大的模型是最好的模型。通常用约束条件来确定概率模型的集合，所以，最大熵原理也可以表述为在满足约束条件的模型集合中选取熵最大的模型。<br>$$<br>H(P)=-\sum_{i=1}^{n} P(X) \log P(X)<br>$$<br>熵满足下列不等式:<br>$$<br>0 \leqslant H(P) \leqslant \log |X|<br>$$<br>式中，X是x的取值个数，当且仅当X的分布是均匀分布时右边的等号成立。这就是说，当X服从均匀分布时，熵最大.</p>
<p>直观地，最大熵原理认为要选择的概率模型首先必须满足已有的事实，即约束条件。在没有更多信息的情况下，那些不确定的部分都是“等可能的”。最大熵原理通过熵的最大化来表示等可能性。“等可能”不容易操作，而熵则是一个可优化的数值指标.</p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20220111100949617.png" alt="概率模型集合"></p>
<h3 id="6-2-2-最大熵模型的定义"><a href="#6-2-2-最大熵模型的定义" class="headerlink" title="6.2.2 最大熵模型的定义"></a>6.2.2 最大熵模型的定义</h3><p>最大熵原理是统计学习的一般原理，将它应用到分类得到最大熵模型。</p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20220111101201662.png" alt=""></p>
<p><strong>定义6.3（最大熵模型）</strong>假设满足所有约東条件的模型集合为<br>$$<br>\mathcal{C} \equiv\left{P \in \mathcal{P} \mid E_{P}\left(f_{i}\right)=E_{\tilde{p}}\left(f_{i}\right), \quad i=1,2, \cdots, n\right}<br>$$<br>定义在条件概率分布$P(Y|X)$上的条件熵为:<br>$$<br>H(P)=-\sum_{x, y} \tilde{P}(x) P(y \mid x) \log P(y \mid x)<br>$$<br>则模型集合C中条件熵$H(P)$最大的模型称为最大熵模型。式中的对数为自然对数</p>
<h3 id="6-2-3-最大熵模型的学习"><a href="#6-2-3-最大熵模型的学习" class="headerlink" title="6.2.3 最大熵模型的学习"></a>6.2.3 最大熵模型的学习</h3><p>最大熵模型的学习过程就是求解最大熵模型的过程。最大熵模型的学习可以形式化为约束最优化问题.</p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20220111101518871.png" alt=""></p>
<p>求解：</p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20220111101721354.png" alt=""></p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20220111101744374.png" alt=""></p>
<h3 id="6-2-4-极大似然估计"><a href="#6-2-4-极大似然估计" class="headerlink" title="6.2.4 极大似然估计"></a>6.2.4 极大似然估计</h3><p>可以将最大熵模型写成更一般的形式</p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20220111102140173.png" alt=""></p>
<p>最大模型与逻辑斯谛回归模型有类似的形式，它们又称为对数线性模型（log linear model）.模型学习就是在给定的训练数据条件下对模型进行极大似然估计或正则化的极大似然估计。</p>
<h2 id="6-3-模型学习的最优化算法"><a href="#6-3-模型学习的最优化算法" class="headerlink" title="6.3 模型学习的最优化算法"></a>6.3 模型学习的最优化算法</h2><p>逻辑斯谛回归模型、最大熵模型学习归结为以似然函数为目标函数的最优化问题，通常通过迭代算法求解。从最优化的观点看，这时的目标函数具有很好的性质，它是光滑的凸函数，因此多种最优化的方法都适用，保证能找到全局最优解，常用的方法有改进的迭代尺度法、梯度下降法、牛顿法或拟牛顿法，牛顿法或拟牛顿法一般收敛速度更快。</p>
<h3 id="6-3-1-改进的选代尺度法"><a href="#6-3-1-改进的选代尺度法" class="headerlink" title="6.3.1 改进的选代尺度法"></a>6.3.1 改进的选代尺度法</h3><p>改进的迭代尺度法（improved iterative scaling,IIS）是一种最大熵模型学习的最优化算法。</p>
<p><strong>算法6.1(改进的迭代尺度算法IIS)</strong></p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20220111102521583.png" alt=""></p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20220111102537798.png" alt=""></p>
<h3 id="6-3-2-拟牛顿法"><a href="#6-3-2-拟牛顿法" class="headerlink" title="6.3.2 拟牛顿法"></a>6.3.2 拟牛顿法</h3><p>最大熵模型学习还可以应用牛顿法或拟牛顿法。</p>
<p><strong>算法6.2 (最大熵模型学习的BFGS算法)</strong></p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20220111102646693.png" alt=""></p>
<p>一些解释：</p>
<ul>
<li><a href="https://zhuanlan.zhihu.com/p/133228366" target="_blank" rel="noopener">逻辑斯蒂回归</a></li>
<li><a href="https://blog.csdn.net/songbinxu/article/details/79677948" target="_blank" rel="noopener">拟牛顿法（DFP、BFGS、L-BFGS）</a></li>
</ul>
<h2 id="习题-5"><a href="#习题-5" class="headerlink" title="习题"></a>习题</h2><h3 id="习题6-1"><a href="#习题6-1" class="headerlink" title="习题6.1"></a>习题6.1</h3><p>  确认Logistic分布属于指数分布族。</p>
<p><strong>解答：</strong></p>
<p><strong>解答思路：</strong>  </p>
<ol>
<li>列出Logistic分布的定义</li>
<li>列出指数分布族的定义</li>
<li>通过指数倾斜，证明Logistic分布的分布函数无法表示成指数分布族的分布函数形式</li>
</ol>
<p><strong>解答步骤：</strong></p>
<p><strong>第1步：Logistic分布的定义</strong></p>
<p>  根据书中第91页的Logistic分布：</p>
<blockquote>
<p>设$X$是连续随机变量，$X$服从Logistic分布是指$X$具有下列分布函数和密度函数：</p>
</blockquote>
<p>$$<br>F(x) = P(X \leqslant x) = \frac{1}{1 + \text{e}^{-(x-\mu)/\gamma} } \<br>f(x) = F’(x) = \frac{\text{e}^{-(x-\mu)/\gamma} }{\gamma(1+ \text{e}^{-(x-\mu)/\gamma})^2}<br>$$</p>
<blockquote>
<p>式中，$\mu$为位置参数，$\gamma &gt; 0$为形状参数。</p>
</blockquote>
<p><strong>第2步：指数分布族的定义</strong></p>
<blockquote>
<p>参考指数分布族的Wikipedia：<a href="https://en.wikipedia.org/wiki/Exponential_family" target="_blank" rel="noopener">https://en.wikipedia.org/wiki/Exponential_family</a><br>对于随机变量$x$，在给定参数$\theta$下，其概率分别满足如下形式：</p>
</blockquote>
<p>$$<br>f(x|\theta)=h(x)g(\theta)\exp(\eta(\theta)\cdot T(x))<br>$$</p>
<blockquote>
<p>称之为指数分布族。<br>其中：$g(\theta)$表示归一化系数，$h(x)&gt;0$ </p>
</blockquote>
<p><strong>第3步：证明Logistic分布的分布函数无法表示成指数分布族的分布函数形式</strong></p>
<p>  根据指数分布族的Wikipedia：<a href="https://en.wikipedia.org/wiki/Exponential_family" target="_blank" rel="noopener">https://en.wikipedia.org/wiki/Exponential_family</a></p>
<blockquote>
<p>Other examples of distributions that are not exponential families are the F-distribution, Cauchy distribution, hypergeometric distribution and logistic distribution</p>
</blockquote>
<p>  可知，Logistic分布不属于指数分布族</p>
<p>证明思路：<br>参考：<a href="https://stats.stackexchange.com/questions/275773/does-logistic-distribution-belongs-to-exponential-family" target="_blank" rel="noopener">https://stats.stackexchange.com/questions/275773/does-logistic-distribution-belongs-to-exponential-family</a> </p>
<ol>
<li>设$\gamma=1$，可得单参数的Logistic分布；</li>
<li>计算当$\mu=0$时，函数$f(x|\mu=0)$；</li>
<li>根据Logistic分布的MGF（矩生成函数），可得$E(\text{e}^{\theta x})$；</li>
<li>根据指数倾斜的定义，证明单参数$\theta$的指数倾斜密度函数无法表示成Logistic分布的密度函数形式；可证得，Logistic分布不属于指数分布族；</li>
</ol>
<p>证明步骤：</p>
<ol>
<li>单参数Logistic分布：<br>设$\gamma=1$，则单参数$\mu$的Logistic分布：</li>
</ol>
<p>$$<br>f(x|\mu) = \frac{\text{e}^{-(x-\mu)} }{(1+ \text{e}^{-(x-\mu)})^2}<br>$$</p>
<ol start="2">
<li><p>计算$f(x|\mu=0)$<br>$$f(x|\mu=0) = \frac{\text{e}^{-x} }{(1+ \text{e}^{-x})^2}$$</p>
</li>
<li><p>Logistic分布的MGF矩生成函数</p>
</li>
</ol>
<p>根据Logistic分布的Wikipedia：<a href="https://en.wikipedia.org/wiki/Logistic_distribution" target="_blank" rel="noopener">https://en.wikipedia.org/wiki/Logistic_distribution</a></p>
<blockquote>
<p> Logistic的MGF矩生成函数$M_X(\theta)$：<br> $$M_X(\theta) = \text{e}^{\mu t}B(1-st, 1+st)$$ </p>
<p> 其中$t \in (-1/s, 1/s)$，$B$表示Beta函数。</p>
</blockquote>
<p>可知，当$\mu=0, s=1$时，<br>$$<br>M_X(\theta) = E(\text{e}^{\theta x}) = B(1-\theta, 1+\theta), \quad \theta \in (-1, 1)<br>$$</p>
<ol start="4">
<li>证明单参数$\theta$的指数倾斜密度函数无法表示成Logistic分布的形式</li>
</ol>
<p>根据指数倾斜的Wikipedia：<a href="https://en.wikipedia.org/wiki/Exponential_tilting" target="_blank" rel="noopener">https://en.wikipedia.org/wiki/Exponential_tilting</a></p>
<blockquote>
<p>  给定一个随机变量$X$，其概率分布为$P$，概率密度为$f$和矩生成函数(MGF)为$M_X(\theta) = E(e^{\theta x})$，指数倾斜$P_{\theta}$定义如下：</p>
</blockquote>
<p>$$<br>P_{\theta}(X \in dx) = \frac{E[\text{e}^{\theta X} I(X \in dx)]}{ M_X(\theta)} = \text{e}^{\theta x - k(\theta)}P(X \in dx)<br>$$</p>
<blockquote>
<p>  其中，$k(\theta)$表示为累积生成函数（CGF），即$\log E(\text{e}^{\theta X})$，称$P_{\theta}(X \in dx)=f_{\theta}(x)$为随机变量$X$的$\theta$-tilted密度分布。</p>
</blockquote>
<p>  综上可知<br>$$<br>f_{\theta}(x)=\text{e}^{\theta x - k(\theta)} f_0(x)<br>$$<br>  其中，$k(\theta)= \log M_X(\theta) = B(1-\theta, 1+\theta), \quad \theta \in (-1, 1)$，根据指数倾斜性质，$f_{\theta}(x)$无法表示Logistic分布的密度函数形式。<br>  所以，Logistic分布不属于指数分布族。</p>
<h3 id="习题6-2-⭐⭐⭐"><a href="#习题6-2-⭐⭐⭐" class="headerlink" title="习题6.2 ⭐⭐⭐"></a>习题6.2 ⭐⭐⭐</h3><p>  写出Logistic回归模型学习的梯度下降算法。</p>
<p><strong>解答：</strong></p>
<p><strong>解答思路：</strong></p>
<ol>
<li>写出Logistic回归模型</li>
<li>根据书中附录A梯度下降法，写出Logistic回归模型学习的梯度下降法</li>
<li>自编程实现Logistic回归模型学习的梯度下降法</li>
</ol>
<p><strong>解答步骤：</strong></p>
<p><strong>第1步：Logistic回归模型</strong>  </p>
<p>  根据书中第92页Logistic回归模型的定义：</p>
<blockquote>
<p>二项Logistic回归模型是如下的条件概率分别：</p>
</blockquote>
<p>$$<br>P(Y=1 | x)=\frac{\exp (w \cdot x+b)}{1+\exp (w \cdot x+b)} \<br>P(Y=0 | x)=\frac{1}{1+\exp (w \cdot x+b)}<br>$$</p>
<blockquote>
<p>这里，$x \in R^n$是输入，$Y \in {0, 1 }$是输出，$w \in R^n$和$b \in R^n$是参数，$w$称为权值向量，$b$称为偏置，$w \cdot x$为$w$和$x$的内积。</p>
</blockquote>
<p><strong>第2步：Logistic回归模型学习的梯度下降法</strong></p>
<p>  根据书中第93页模型参数估计：</p>
<blockquote>
<p>Logistic回归模型的对数似然函数为</p>
</blockquote>
<p>$$<br>L(w)=\sum_{i=1}^N \left[y_i (w \cdot x_i)-\log (1+\exp (w \cdot x_i))\right]<br>$$</p>
<p>  将对数似然函数求偏导，可得<br>$$<br>\frac{\partial L(w)}{\partial w^{(k)} }=\sum_{i=1}^N\left[x_i \cdot y_i-\frac{\exp (w^{(k)} \cdot x_i) \cdot x_i}{1+\exp (w^{(k)} \cdot x_i)}\right]<br>$$<br>  梯度函数为<br>$$<br>\nabla L(w)=\left[\frac{\partial L(w)}{\partial w^{(0)} }, \cdots, \frac{\partial L(w)}{\partial w^{(n)} }\right]<br>$$<br>  根据书中第439页附录A 梯度下降法的算法：</p>
<blockquote>
<p>输入：目标函数$f(x)$，梯度函数$g(x)= \nabla f(x)$，计算精度$\varepsilon$；<br>输出：$f(x)$的极小值$x^<em>$。<br>(1) 取初始值$x^{(0)} \in R^n$，置$k=0$<br>(2) 计算$f(x^{(k)})$<br>(3) 计算梯度$g_k=g(x^{(k)})$，当$|g_k| &lt; \varepsilon$时，停止迭代，令$x^</em> = x^{(k)}$；否则，令$p_k=-g(x^{(k)})$，求$\lambda_k$，使</p>
</blockquote>
<p>$$<br>\displaystyle f(x^{(k)}+\lambda_k p_k) = \min \limits_{\lambda \geqslant 0}f(x^{(k)}+\lambda p_k)<br>$$</p>
<blockquote>
<p>(4) 置$x^{(k+1)}=x^{(k)}+\lambda_k p_k$，计算$f(x^{(k+1)})$<br>当$|f(x^{(k+1)}) - f(x^{(k)})| &lt; \varepsilon$或 $|x^{(k+1)} - x^{(k)}| &lt; \varepsilon$时，停止迭代，令$x^* = x^{(k+1)}$<br>(5) 否则，置$k=k+1$，转(3)</p>
</blockquote>
<p>Logistic回归模型学习的梯度下降算法：<br>输入：目标函数$f(w)$，梯度函数$g(w) = \nabla f(w)$，计算精度$\varepsilon$<br>输出：$f(w)$的极大值$w^*$  </p>
<p>(1) 取初始值$ w^{(0)} \in R^n$，置$k=0$  </p>
<p>(2) 计算$ \displaystyle f(w^{(k)})=\sum_{i=1}^N \left[y_i (w^{(k)} \cdot x_i)-\log (1+\exp (w^{(k)} \cdot x_i))\right]$  </p>
<p>(3) 计算梯度$ \displaystyle g_k=g(w^{(k)})=\sum_{i=1}^N\left[x_i \cdot y_i-\frac{\exp (w^{(k)} \cdot x_i) \cdot x_i}{1+\exp (w^{(k)} \cdot x_i)}\right]$，当$|g_k| &lt; \varepsilon$时，停止迭代，令$w^* = w^{(k)}$；否则，令$p_k=-g(w^{(k)})$，求$\lambda_k$，使<br>$$<br>\displaystyle f(w^{(k)}+\lambda_k p_k) = \max_{\lambda \geqslant 0}f(w^{(k)}+\lambda p_k)<br>$$<br>(4) 置$w^{(k+1)}=w^{(k)}+\lambda_k p_k$，计算$f(w^{(k+1)})$<br>当$ |f(w^{(k+1)}) - f(w^{(k)})| &lt; \varepsilon$或 $ |w^{(k+1)} - w^{(k)}| &lt; \varepsilon$时，停止迭代，令$w^* = w^{(k+1)}$  </p>
<p>(5) 否则，置$k=k+1$，转(3)</p>
<p><strong>第3步：自编程实现Logistic回归模型学习的梯度下降法</strong></p>
<pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">from</span> scipy<span class="token punctuation">.</span>optimize <span class="token keyword">import</span> fminbound
<span class="token keyword">from</span> pylab <span class="token keyword">import</span> mpl
<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np
<span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> plt
<span class="token operator">%</span>matplotlib inline

<span class="token comment" spellcheck="true"># 图像显示中文</span>
mpl<span class="token punctuation">.</span>rcParams<span class="token punctuation">[</span><span class="token string">'font.sans-serif'</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">'Microsoft YaHei'</span><span class="token punctuation">]</span>


<span class="token keyword">class</span> <span class="token class-name">MyLogisticRegression</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> max_iter<span class="token operator">=</span><span class="token number">10000</span><span class="token punctuation">,</span> distance<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span> epsilon<span class="token operator">=</span><span class="token number">1e</span><span class="token operator">-</span><span class="token number">6</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token triple-quoted-string string">"""
        Logistic回归
        :param max_iter: 最大迭代次数 
        :param distance: 一维搜索的长度范围
        :param epsilon: 迭代停止阈值
        """</span>
        self<span class="token punctuation">.</span>max_iter <span class="token operator">=</span> max_iter
        self<span class="token punctuation">.</span>epsilon <span class="token operator">=</span> epsilon
        <span class="token comment" spellcheck="true"># 权重</span>
        self<span class="token punctuation">.</span>w <span class="token operator">=</span> None
        self<span class="token punctuation">.</span>distance <span class="token operator">=</span> distance
        self<span class="token punctuation">.</span>_X <span class="token operator">=</span> None
        self<span class="token punctuation">.</span>_y <span class="token operator">=</span> None

    @staticmethod
    <span class="token keyword">def</span> <span class="token function">preprocessing</span><span class="token punctuation">(</span>X<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token triple-quoted-string string">"""将原始X末尾加上一列，该列数值全部为1"""</span>
        row <span class="token operator">=</span> X<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
        y <span class="token operator">=</span> np<span class="token punctuation">.</span>ones<span class="token punctuation">(</span>row<span class="token punctuation">)</span><span class="token punctuation">.</span>reshape<span class="token punctuation">(</span>row<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>
        <span class="token keyword">return</span> np<span class="token punctuation">.</span>hstack<span class="token punctuation">(</span><span class="token punctuation">(</span>X<span class="token punctuation">,</span> y<span class="token punctuation">)</span><span class="token punctuation">)</span>

    @staticmethod
    <span class="token keyword">def</span> <span class="token function">sigmod</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">return</span> <span class="token number">1</span> <span class="token operator">/</span> <span class="token punctuation">(</span><span class="token number">1</span> <span class="token operator">+</span> np<span class="token punctuation">.</span>exp<span class="token punctuation">(</span><span class="token operator">-</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">grad</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> w<span class="token punctuation">)</span><span class="token punctuation">:</span>
        z <span class="token operator">=</span> np<span class="token punctuation">.</span>dot<span class="token punctuation">(</span>self<span class="token punctuation">.</span>_X<span class="token punctuation">,</span> w<span class="token punctuation">.</span>T<span class="token punctuation">)</span>
        grad <span class="token operator">=</span> self<span class="token punctuation">.</span>_X <span class="token operator">*</span> <span class="token punctuation">(</span>self<span class="token punctuation">.</span>_y <span class="token operator">-</span> self<span class="token punctuation">.</span>sigmod<span class="token punctuation">(</span>z<span class="token punctuation">)</span><span class="token punctuation">)</span>
        grad <span class="token operator">=</span> grad<span class="token punctuation">.</span>sum<span class="token punctuation">(</span>axis<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>
        <span class="token keyword">return</span> grad

    <span class="token keyword">def</span> <span class="token function">like_func</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> w<span class="token punctuation">)</span><span class="token punctuation">:</span>
        z <span class="token operator">=</span> np<span class="token punctuation">.</span>dot<span class="token punctuation">(</span>self<span class="token punctuation">.</span>_X<span class="token punctuation">,</span> w<span class="token punctuation">.</span>T<span class="token punctuation">)</span>
        f <span class="token operator">=</span> self<span class="token punctuation">.</span>_y <span class="token operator">*</span> z <span class="token operator">-</span> np<span class="token punctuation">.</span>log<span class="token punctuation">(</span><span class="token number">1</span> <span class="token operator">+</span> np<span class="token punctuation">.</span>exp<span class="token punctuation">(</span>z<span class="token punctuation">)</span><span class="token punctuation">)</span>
        <span class="token keyword">return</span> np<span class="token punctuation">.</span>sum<span class="token punctuation">(</span>f<span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">fit</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> data_x<span class="token punctuation">,</span> data_y<span class="token punctuation">)</span><span class="token punctuation">:</span>
        self<span class="token punctuation">.</span>_X <span class="token operator">=</span> self<span class="token punctuation">.</span>preprocessing<span class="token punctuation">(</span>data_x<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>_y <span class="token operator">=</span> data_y<span class="token punctuation">.</span>T
        <span class="token comment" spellcheck="true"># （1）取初始化w</span>
        w <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">*</span> self<span class="token punctuation">.</span>_X<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>np<span class="token punctuation">.</span>float<span class="token punctuation">)</span>
        k <span class="token operator">=</span> <span class="token number">0</span>
        <span class="token comment" spellcheck="true"># （2）计算f(w)</span>
        fw <span class="token operator">=</span> self<span class="token punctuation">.</span>like_func<span class="token punctuation">(</span>w<span class="token punctuation">)</span>
        <span class="token keyword">for</span> _ <span class="token keyword">in</span> range<span class="token punctuation">(</span>self<span class="token punctuation">.</span>max_iter<span class="token punctuation">)</span><span class="token punctuation">:</span>
            <span class="token comment" spellcheck="true"># 计算梯度g(w)</span>
            grad <span class="token operator">=</span> self<span class="token punctuation">.</span>grad<span class="token punctuation">(</span>w<span class="token punctuation">)</span>
            <span class="token comment" spellcheck="true"># （3）当梯度g(w)的模长小于精度时，停止迭代</span>
            <span class="token keyword">if</span> <span class="token punctuation">(</span>np<span class="token punctuation">.</span>linalg<span class="token punctuation">.</span>norm<span class="token punctuation">(</span>grad<span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">,</span> keepdims<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span> <span class="token operator">&lt;</span> self<span class="token punctuation">.</span>epsilon<span class="token punctuation">)</span><span class="token punctuation">.</span>all<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
                self<span class="token punctuation">.</span>w <span class="token operator">=</span> w
                <span class="token keyword">break</span>

            <span class="token comment" spellcheck="true"># 梯度方向的一维函数</span>
            <span class="token keyword">def</span> <span class="token function">f</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">:</span>
                z <span class="token operator">=</span> w <span class="token operator">-</span> np<span class="token punctuation">.</span>dot<span class="token punctuation">(</span>x<span class="token punctuation">,</span> grad<span class="token punctuation">)</span>
                <span class="token keyword">return</span> <span class="token operator">-</span>self<span class="token punctuation">.</span>like_func<span class="token punctuation">(</span>z<span class="token punctuation">)</span>

            <span class="token comment" spellcheck="true"># （3）进行一维搜索，找到使得函数最大的lambda</span>
            _lambda <span class="token operator">=</span> fminbound<span class="token punctuation">(</span>f<span class="token punctuation">,</span> <span class="token operator">-</span>self<span class="token punctuation">.</span>distance<span class="token punctuation">,</span> self<span class="token punctuation">.</span>distance<span class="token punctuation">)</span>

            <span class="token comment" spellcheck="true"># （4）设置w(k+1)</span>
            w1 <span class="token operator">=</span> w <span class="token operator">-</span> np<span class="token punctuation">.</span>dot<span class="token punctuation">(</span>_lambda<span class="token punctuation">,</span> grad<span class="token punctuation">)</span>
            fw1 <span class="token operator">=</span> self<span class="token punctuation">.</span>like_func<span class="token punctuation">(</span>w1<span class="token punctuation">)</span>

            <span class="token comment" spellcheck="true"># （4）当f(w(k+1))-f(w(k))的二范数小于精度，或w(k+1)-w(k)的二范数小于精度</span>
            <span class="token keyword">if</span> np<span class="token punctuation">.</span>linalg<span class="token punctuation">.</span>norm<span class="token punctuation">(</span>fw1 <span class="token operator">-</span> fw<span class="token punctuation">)</span> <span class="token operator">&lt;</span> self<span class="token punctuation">.</span>epsilon <span class="token operator">or</span> \
                    <span class="token punctuation">(</span>np<span class="token punctuation">.</span>linalg<span class="token punctuation">.</span>norm<span class="token punctuation">(</span><span class="token punctuation">(</span>w1 <span class="token operator">-</span> w<span class="token punctuation">)</span><span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">,</span> keepdims<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span> <span class="token operator">&lt;</span> self<span class="token punctuation">.</span>epsilon<span class="token punctuation">)</span><span class="token punctuation">.</span>all<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
                self<span class="token punctuation">.</span>w <span class="token operator">=</span> w1
                <span class="token keyword">break</span>

            <span class="token comment" spellcheck="true"># （5） 设置k=k+1</span>
            k <span class="token operator">+=</span> <span class="token number">1</span>
            w<span class="token punctuation">,</span> fw <span class="token operator">=</span> w1<span class="token punctuation">,</span> fw1

        self<span class="token punctuation">.</span>grad_ <span class="token operator">=</span> grad
        self<span class="token punctuation">.</span>n_iter_ <span class="token operator">=</span> k
        self<span class="token punctuation">.</span>coef_ <span class="token operator">=</span> self<span class="token punctuation">.</span>w<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span>
        self<span class="token punctuation">.</span>intercept_ <span class="token operator">=</span> self<span class="token punctuation">.</span>w<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span>

    <span class="token keyword">def</span> <span class="token function">predict</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>
        p <span class="token operator">=</span> self<span class="token punctuation">.</span>sigmod<span class="token punctuation">(</span>np<span class="token punctuation">.</span>dot<span class="token punctuation">(</span>self<span class="token punctuation">.</span>preprocessing<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">,</span> self<span class="token punctuation">.</span>w<span class="token punctuation">.</span>T<span class="token punctuation">)</span><span class="token punctuation">)</span>
        p<span class="token punctuation">[</span>np<span class="token punctuation">.</span>where<span class="token punctuation">(</span>p <span class="token operator">></span> <span class="token number">0.5</span><span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token number">1</span>
        p<span class="token punctuation">[</span>np<span class="token punctuation">.</span>where<span class="token punctuation">(</span>p <span class="token operator">&lt;</span> <span class="token number">0.5</span><span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token number">0</span>
        <span class="token keyword">return</span> p

    <span class="token keyword">def</span> <span class="token function">score</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> X<span class="token punctuation">,</span> y<span class="token punctuation">)</span><span class="token punctuation">:</span>
        y_c <span class="token operator">=</span> self<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>X<span class="token punctuation">)</span>
        <span class="token comment" spellcheck="true"># 计算准确率</span>
        error_rate <span class="token operator">=</span> np<span class="token punctuation">.</span>sum<span class="token punctuation">(</span>np<span class="token punctuation">.</span>abs<span class="token punctuation">(</span>y_c <span class="token operator">-</span> y<span class="token punctuation">.</span>T<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token operator">/</span> y_c<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
        <span class="token keyword">return</span> <span class="token number">1</span> <span class="token operator">-</span> error_rate

    <span class="token keyword">def</span> <span class="token function">draw</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> X<span class="token punctuation">,</span> y<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment" spellcheck="true"># 分隔正负实例点</span>
        y <span class="token operator">=</span> y<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
        X_po <span class="token operator">=</span> X<span class="token punctuation">[</span>np<span class="token punctuation">.</span>where<span class="token punctuation">(</span>y <span class="token operator">==</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">]</span>
        X_ne <span class="token operator">=</span> X<span class="token punctuation">[</span>np<span class="token punctuation">.</span>where<span class="token punctuation">(</span>y <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">]</span>
        <span class="token comment" spellcheck="true"># 绘制数据集散点图</span>
        ax <span class="token operator">=</span> plt<span class="token punctuation">.</span>axes<span class="token punctuation">(</span>projection<span class="token operator">=</span><span class="token string">'3d'</span><span class="token punctuation">)</span>
        x_1 <span class="token operator">=</span> X_po<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">]</span>
        y_1 <span class="token operator">=</span> X_po<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">]</span>
        z_1 <span class="token operator">=</span> X_po<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">]</span>
        x_2 <span class="token operator">=</span> X_ne<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">]</span>
        y_2 <span class="token operator">=</span> X_ne<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">]</span>
        z_2 <span class="token operator">=</span> X_ne<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">]</span>
        ax<span class="token punctuation">.</span>scatter<span class="token punctuation">(</span>x_1<span class="token punctuation">,</span> y_1<span class="token punctuation">,</span> z_1<span class="token punctuation">,</span> c<span class="token operator">=</span><span class="token string">"r"</span><span class="token punctuation">,</span> label<span class="token operator">=</span><span class="token string">"正实例"</span><span class="token punctuation">)</span>
        ax<span class="token punctuation">.</span>scatter<span class="token punctuation">(</span>x_2<span class="token punctuation">,</span> y_2<span class="token punctuation">,</span> z_2<span class="token punctuation">,</span> c<span class="token operator">=</span><span class="token string">"b"</span><span class="token punctuation">,</span> label<span class="token operator">=</span><span class="token string">"负实例"</span><span class="token punctuation">)</span>
        ax<span class="token punctuation">.</span>legend<span class="token punctuation">(</span>loc<span class="token operator">=</span><span class="token string">'best'</span><span class="token punctuation">)</span>
        <span class="token comment" spellcheck="true"># 绘制透明度为0.5的分隔超平面</span>
        x <span class="token operator">=</span> np<span class="token punctuation">.</span>linspace<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span>
        y <span class="token operator">=</span> np<span class="token punctuation">.</span>linspace<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span>
        x_3<span class="token punctuation">,</span> y_3 <span class="token operator">=</span> np<span class="token punctuation">.</span>meshgrid<span class="token punctuation">(</span>x<span class="token punctuation">,</span> y<span class="token punctuation">)</span>
        a<span class="token punctuation">,</span> b<span class="token punctuation">,</span> c<span class="token punctuation">,</span> d <span class="token operator">=</span> self<span class="token punctuation">.</span>w<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
        z_3 <span class="token operator">=</span> <span class="token operator">-</span><span class="token punctuation">(</span>a <span class="token operator">*</span> x_3 <span class="token operator">+</span> b <span class="token operator">*</span> y_3 <span class="token operator">+</span> d<span class="token punctuation">)</span> <span class="token operator">/</span> c
        <span class="token comment" spellcheck="true"># 调节透明度</span>
        ax<span class="token punctuation">.</span>plot_surface<span class="token punctuation">(</span>x_3<span class="token punctuation">,</span> y_3<span class="token punctuation">,</span> z_3<span class="token punctuation">,</span> alpha<span class="token operator">=</span><span class="token number">0.5</span><span class="token punctuation">)</span>
        plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<pre class="line-numbers language-python"><code class="language-python"><span class="token comment" spellcheck="true"># 训练数据集</span>
X_train <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
y_train <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
<span class="token comment" spellcheck="true"># 构建实例，进行训练</span>
clf <span class="token operator">=</span> MyLogisticRegression<span class="token punctuation">(</span>epsilon<span class="token operator">=</span><span class="token number">1e</span><span class="token operator">-</span><span class="token number">6</span><span class="token punctuation">)</span>
clf<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>X_train<span class="token punctuation">,</span> y_train<span class="token punctuation">)</span>
clf<span class="token punctuation">.</span>draw<span class="token punctuation">(</span>X_train<span class="token punctuation">,</span> y_train<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"迭代次数：{}次"</span><span class="token punctuation">.</span>format<span class="token punctuation">(</span>clf<span class="token punctuation">.</span>n_iter_<span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"梯度：{}"</span><span class="token punctuation">.</span>format<span class="token punctuation">(</span>clf<span class="token punctuation">.</span>grad_<span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"权重：{}"</span><span class="token punctuation">.</span>format<span class="token punctuation">(</span>clf<span class="token punctuation">.</span>w<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"模型准确率：%0.2f%%"</span> <span class="token operator">%</span> <span class="token punctuation">(</span>clf<span class="token punctuation">.</span>score<span class="token punctuation">(</span>X_train<span class="token punctuation">,</span> y_train<span class="token punctuation">)</span> <span class="token operator">*</span> <span class="token number">100</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p><img src="/images/loading.gif" data-original="../images/ML/output_25_0.png" alt=""></p>
<pre><code>迭代次数：2095次
梯度：[ 7.33881397e-05  2.44073067e-05  2.52604176e-04 -5.13424350e-04]
权重：[  4.34496173   2.05340452   9.64074166 -22.85079478]
模型准确率：100.00%</code></pre><h3 id="习题6-3-⭐⭐⭐"><a href="#习题6-3-⭐⭐⭐" class="headerlink" title="习题6.3 ⭐⭐⭐"></a>习题6.3 ⭐⭐⭐</h3><p>  写出最大熵模型学习的DFP算法。（关于一般的DFP算法参见附录B）</p>
<p><strong>解答：</strong></p>
<p><strong>解答思路：</strong></p>
<ol>
<li>写出最大熵模型</li>
<li>根据附录B的DFP算法，写出最大熵模型学习的DFP算法</li>
<li>自编程实现最大熵模型学习的DFP算法</li>
</ol>
<p><strong>解答步骤：</strong></p>
<p><strong>第1步：最大熵模型</strong></p>
<p>  根据书中第98页的最大熵模型的定义：</p>
<blockquote>
<p>假设满足所有约束条件的模型集合为</p>
</blockquote>
<p>$$<br>\mathcal{C} = {P \in \mathcal{P} | E_P(f_i) = E_{\tilde{P} }(f_i), \quad i=1,2,\cdots,n }<br>$$</p>
<blockquote>
<p>定义在条件概率分布$P(Y|X)$上的条件熵为</p>
</blockquote>
<p>$$<br>H(P) = -\sum \limits_{x,y} \tilde{P}(x) P(y|x) \log P(y|x)<br>$$</p>
<blockquote>
<p>则模型集合$\mathcal{C}$中条件熵$H(P)$最大的模型称为最大熵模型。式中的对数为自然对数。</p>
</blockquote>
<p>  根据书中第97页最大熵模型的特征函数：</p>
<blockquote>
<p>用特征函数$f(x,y)$描述输入$x$与输出$y$之间的某一个事实。其定义是</p>
</blockquote>
<p>$$<br> f(x, y) = \left { \begin{array}{ll}<br>1, \quad x与y满足某一事实 \<br>0, \quad 否则<br>\end{array} \right.<br>$$</p>
<p>它是一个二值函数，当$x$和$y$满足这个事实时取值为1，否则取值为0。</p>
<p><strong>第2步：最大熵模型学习的DFP算法</strong></p>
<p>  根据书中第107页的最大熵模型学习：</p>
<blockquote>
<p>对于最大熵模型而言，</p>
</blockquote>
<p>$$<br>P_w(y | x)=\frac{\displaystyle \exp \left(\sum_{i=1}^n w_i f_i (x, y)\right)}{\displaystyle \sum_y \exp \left(\sum_{i=1}^n w_i f_i(x, y)\right)}<br>$$</p>
<blockquote>
<p>目标函数：</p>
</blockquote>
<p>$$<br>\min \limits_{w \in R^n} \quad f(w) = \sum_{x} \tilde{P}(x) \log \sum_{y} \exp \left(\sum_{i=1}^{n} w_{i} f_{i}(x, y)\right)-\sum_{x, y} \tilde{P}(x, y) \sum_{i=1}^{n} w_{i} f_{i}(x, y)<br>$$</p>
<blockquote>
<p>梯度：</p>
</blockquote>
<p>$$<br>g(w) = \left( \frac{\partial f(w)}{\partial w_1}, \frac{\partial f(w)}{\partial w_2}, \cdots, \frac{\partial f(w)}{\partial w_n}\right)^T<br>$$</p>
<blockquote>
<p>其中</p>
</blockquote>
<p>$$<br>\frac{\partial f(w)}{\partial w_1} = \sum \limits_{x,y} \tilde{P}(x) P_w(y|x) f_i(x,y) - E_{\tilde{P} }(f_i), \quad i=1,2,\cdots,n<br>$$</p>
<p>  根据书中第444页附录B的DFP算法：</p>
<blockquote>
<p>输入：目标函数$f(x)$，梯度$g(x) = \nabla f(x)$，精度要求$\varepsilon$；<br>输出：$f(x)$的极小值点$x^<em>$<br>（1）选定初始点$x^{(0)}$，取$G_0$为正定对称矩阵，置$k=0$<br>（2）计算$g_k=g(x^{(k)})$，若$|g_k| &lt; \varepsilon$，则停止计算，得近似解$x^</em>=x^{(k)}$，否则转（3）<br>（3）置$p_k=-G_k g_k$<br>（4）一维搜索：求$\lambda_k$使得</p>
</blockquote>
<p>$$<br>f (x^{(k)}+\lambda_k p_k )=\min \limits_{\lambda \geqslant 0} f(x^{(k)}+\lambda p_{k})<br>$$</p>
<blockquote>
<p>（5）置$x^{(k+1)}=x^{(k)}+\lambda_k p_k$<br>（6）计算$g_{k+1}=g(x^{(k+1)})$，若$|g_{k+1}| &lt; \varepsilon$，则停止计算，得近似解$x^*=x^{(k+1)}$；否则，按照式（B.24）算出$G_{k+1}$<br>（7）置$k=k+1$，转（3）  </p>
</blockquote>
<p>  根据公式（B.24），DFP算法的$G_{k+1}$的迭代公式为：<br>$$<br>G_{k+1}=G_k+\frac{\delta_k \delta_k^T}{\delta_k^T y_k}-\frac{G_k y_k y_k^T G_k}{y_k^T G_k y_k}<br>$$<br>  其中$y_k= g_{k+1} - g_k, \delta_k = w^{(k+1)} - w^{(k)}$。</p>
<p>最大熵模型的DFP算法：<br>输入：目标函数$f(w)$，梯度$g(w) = \nabla f(w)$，精度要求$\varepsilon$；<br>输出：$f(w)$的极小值点$w^<em>$<br>（1）选定初始点$w^{(0)}$，取$G_0$为正定对称矩阵，置$k=0$<br>（2）计算$g_k=g(w^{(k)})$，若$|g_k| &lt; \varepsilon$，则停止计算，得近似解$w^</em>=w^{(k)}$，否则转（3）<br>（3）置$p_k=-G_k g_k$<br>（4）一维搜索：求$\lambda_k$使得<br>$$<br>f(w^{(k)}+\lambda_k p_k) = \min \limits_{\lambda \geqslant 0} f(w^{(k)}+\lambda p_k)<br>$$<br>（5）置$w^{(k+1)}=w^{(k)}+\lambda_k p_k$<br>（6）计算$g_{k+1}=g(w^{(k+1)})$，若$|g_{k+1}| &lt; \varepsilon$，则停止计算，得近似解$w^*=w^{(k+1)}$；否则，按照DFP算法的迭代公式算出$G_{k+1}$<br>（7）置$k=k+1$，转（3）  </p>
<p><strong>第3步：自编程实现最大熵模型学习的DFP算法</strong></p>
<pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">import</span> copy
<span class="token keyword">from</span> collections <span class="token keyword">import</span> defaultdict

<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np
<span class="token keyword">from</span> scipy<span class="token punctuation">.</span>optimize <span class="token keyword">import</span> fminbound


<span class="token keyword">class</span> <span class="token class-name">MaxEntDFP</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> epsilon<span class="token punctuation">,</span> max_iter<span class="token operator">=</span><span class="token number">1000</span><span class="token punctuation">,</span> distance<span class="token operator">=</span><span class="token number">0.01</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token triple-quoted-string string">"""
        最大熵的DFP算法
        :param epsilon: 迭代停止阈值
        :param max_iter: 最大迭代次数
        :param distance: 一维搜索的长度范围
        """</span>
        self<span class="token punctuation">.</span>distance <span class="token operator">=</span> distance
        self<span class="token punctuation">.</span>epsilon <span class="token operator">=</span> epsilon
        self<span class="token punctuation">.</span>max_iter <span class="token operator">=</span> max_iter
        self<span class="token punctuation">.</span>w <span class="token operator">=</span> None
        self<span class="token punctuation">.</span>_dataset_X <span class="token operator">=</span> None
        self<span class="token punctuation">.</span>_dataset_y <span class="token operator">=</span> None
        <span class="token comment" spellcheck="true"># 标签集合，相当去去重后的y</span>
        self<span class="token punctuation">.</span>_y <span class="token operator">=</span> set<span class="token punctuation">(</span><span class="token punctuation">)</span>
        <span class="token comment" spellcheck="true"># key为(x,y), value为对应的索引号ID</span>
        self<span class="token punctuation">.</span>_xyID <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token punctuation">}</span>
        <span class="token comment" spellcheck="true"># key为对应的索引号ID, value为(x,y)</span>
        self<span class="token punctuation">.</span>_IDxy <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token punctuation">}</span>
        <span class="token comment" spellcheck="true"># 经验分布p(x,y)</span>
        self<span class="token punctuation">.</span>_pxy_dic <span class="token operator">=</span> defaultdict<span class="token punctuation">(</span>int<span class="token punctuation">)</span>
        <span class="token comment" spellcheck="true"># 样本数</span>
        self<span class="token punctuation">.</span>_N <span class="token operator">=</span> <span class="token number">0</span>
        <span class="token comment" spellcheck="true"># 特征键值(x,y)的个数</span>
        self<span class="token punctuation">.</span>_n <span class="token operator">=</span> <span class="token number">0</span>
        <span class="token comment" spellcheck="true"># 实际迭代次数</span>
        self<span class="token punctuation">.</span>n_iter_ <span class="token operator">=</span> <span class="token number">0</span>

    <span class="token comment" spellcheck="true"># 初始化参数</span>
    <span class="token keyword">def</span> <span class="token function">init_params</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> X<span class="token punctuation">,</span> y<span class="token punctuation">)</span><span class="token punctuation">:</span>
        self<span class="token punctuation">.</span>_dataset_X <span class="token operator">=</span> copy<span class="token punctuation">.</span>deepcopy<span class="token punctuation">(</span>X<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>_dataset_y <span class="token operator">=</span> copy<span class="token punctuation">.</span>deepcopy<span class="token punctuation">(</span>y<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>_N <span class="token operator">=</span> X<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>

        <span class="token keyword">for</span> i <span class="token keyword">in</span> range<span class="token punctuation">(</span>self<span class="token punctuation">.</span>_N<span class="token punctuation">)</span><span class="token punctuation">:</span>
            xi<span class="token punctuation">,</span> yi <span class="token operator">=</span> X<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">,</span> y<span class="token punctuation">[</span>i<span class="token punctuation">]</span>
            self<span class="token punctuation">.</span>_y<span class="token punctuation">.</span>add<span class="token punctuation">(</span>yi<span class="token punctuation">)</span>
            <span class="token keyword">for</span> _x <span class="token keyword">in</span> xi<span class="token punctuation">:</span>
                self<span class="token punctuation">.</span>_pxy_dic<span class="token punctuation">[</span><span class="token punctuation">(</span>_x<span class="token punctuation">,</span> yi<span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">+=</span> <span class="token number">1</span>

        self<span class="token punctuation">.</span>_n <span class="token operator">=</span> len<span class="token punctuation">(</span>self<span class="token punctuation">.</span>_pxy_dic<span class="token punctuation">)</span>
        <span class="token comment" spellcheck="true"># 初始化权重w</span>
        self<span class="token punctuation">.</span>w <span class="token operator">=</span> np<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span>self<span class="token punctuation">.</span>_n<span class="token punctuation">)</span>

        <span class="token keyword">for</span> i<span class="token punctuation">,</span> xy <span class="token keyword">in</span> enumerate<span class="token punctuation">(</span>self<span class="token punctuation">.</span>_pxy_dic<span class="token punctuation">)</span><span class="token punctuation">:</span>
            self<span class="token punctuation">.</span>_pxy_dic<span class="token punctuation">[</span>xy<span class="token punctuation">]</span> <span class="token operator">/=</span> self<span class="token punctuation">.</span>_N
            self<span class="token punctuation">.</span>_xyID<span class="token punctuation">[</span>xy<span class="token punctuation">]</span> <span class="token operator">=</span> i
            self<span class="token punctuation">.</span>_IDxy<span class="token punctuation">[</span>i<span class="token punctuation">]</span> <span class="token operator">=</span> xy

    <span class="token keyword">def</span> <span class="token function">calc_zw</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> X<span class="token punctuation">,</span> w<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token triple-quoted-string string">"""书中第100页公式6.23，计算Zw(x)"""</span>
        zw <span class="token operator">=</span> <span class="token number">0.0</span>
        <span class="token keyword">for</span> y <span class="token keyword">in</span> self<span class="token punctuation">.</span>_y<span class="token punctuation">:</span>
            zw <span class="token operator">+=</span> self<span class="token punctuation">.</span>calc_ewf<span class="token punctuation">(</span>X<span class="token punctuation">,</span> y<span class="token punctuation">,</span> w<span class="token punctuation">)</span>
        <span class="token keyword">return</span> zw

    <span class="token keyword">def</span> <span class="token function">calc_ewf</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> X<span class="token punctuation">,</span> y<span class="token punctuation">,</span> w<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token triple-quoted-string string">"""书中第100页公式6.22，计算分子"""</span>
        sum_wf <span class="token operator">=</span> self<span class="token punctuation">.</span>calc_wf<span class="token punctuation">(</span>X<span class="token punctuation">,</span> y<span class="token punctuation">,</span> w<span class="token punctuation">)</span>
        <span class="token keyword">return</span> np<span class="token punctuation">.</span>exp<span class="token punctuation">(</span>sum_wf<span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">calc_wf</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> X<span class="token punctuation">,</span> y<span class="token punctuation">,</span> w<span class="token punctuation">)</span><span class="token punctuation">:</span>
        sum_wf <span class="token operator">=</span> <span class="token number">0.0</span>
        <span class="token keyword">for</span> x <span class="token keyword">in</span> X<span class="token punctuation">:</span>
            <span class="token keyword">if</span> <span class="token punctuation">(</span>x<span class="token punctuation">,</span> y<span class="token punctuation">)</span> <span class="token keyword">in</span> self<span class="token punctuation">.</span>_pxy_dic<span class="token punctuation">:</span>
                sum_wf <span class="token operator">+=</span> w<span class="token punctuation">[</span>self<span class="token punctuation">.</span>_xyID<span class="token punctuation">[</span><span class="token punctuation">(</span>x<span class="token punctuation">,</span> y<span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">]</span>
        <span class="token keyword">return</span> sum_wf

    <span class="token keyword">def</span> <span class="token function">calc_pw_yx</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> X<span class="token punctuation">,</span> y<span class="token punctuation">,</span> w<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token triple-quoted-string string">"""计算Pw(y|x)"""</span>
        <span class="token keyword">return</span> self<span class="token punctuation">.</span>calc_ewf<span class="token punctuation">(</span>X<span class="token punctuation">,</span> y<span class="token punctuation">,</span> w<span class="token punctuation">)</span> <span class="token operator">/</span> self<span class="token punctuation">.</span>calc_zw<span class="token punctuation">(</span>X<span class="token punctuation">,</span> w<span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">calc_f</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> w<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token triple-quoted-string string">"""计算f(w)"""</span>
        fw <span class="token operator">=</span> <span class="token number">0.0</span>
        <span class="token keyword">for</span> i <span class="token keyword">in</span> range<span class="token punctuation">(</span>self<span class="token punctuation">.</span>_n<span class="token punctuation">)</span><span class="token punctuation">:</span>
            x<span class="token punctuation">,</span> y <span class="token operator">=</span> self<span class="token punctuation">.</span>_IDxy<span class="token punctuation">[</span>i<span class="token punctuation">]</span>
            <span class="token keyword">for</span> dataset_X <span class="token keyword">in</span> self<span class="token punctuation">.</span>_dataset_X<span class="token punctuation">:</span>
                <span class="token keyword">if</span> x <span class="token operator">not</span> <span class="token keyword">in</span> dataset_X<span class="token punctuation">:</span>
                    <span class="token keyword">continue</span>
                fw <span class="token operator">+=</span> np<span class="token punctuation">.</span>log<span class="token punctuation">(</span>self<span class="token punctuation">.</span>calc_zw<span class="token punctuation">(</span>x<span class="token punctuation">,</span> w<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token operator">-</span> \
                    self<span class="token punctuation">.</span>_pxy_dic<span class="token punctuation">[</span><span class="token punctuation">(</span>x<span class="token punctuation">,</span> y<span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">*</span> self<span class="token punctuation">.</span>calc_wf<span class="token punctuation">(</span>dataset_X<span class="token punctuation">,</span> y<span class="token punctuation">,</span> w<span class="token punctuation">)</span>

        <span class="token keyword">return</span> fw

    <span class="token comment" spellcheck="true"># DFP算法</span>
    <span class="token keyword">def</span> <span class="token function">fit</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> X<span class="token punctuation">,</span> y<span class="token punctuation">)</span><span class="token punctuation">:</span>
        self<span class="token punctuation">.</span>init_params<span class="token punctuation">(</span>X<span class="token punctuation">,</span> y<span class="token punctuation">)</span>

        <span class="token keyword">def</span> <span class="token function">calc_dfw</span><span class="token punctuation">(</span>i<span class="token punctuation">,</span> w<span class="token punctuation">)</span><span class="token punctuation">:</span>
            <span class="token triple-quoted-string string">"""计算书中第107页的拟牛顿法f(w)的偏导"""</span>

            <span class="token keyword">def</span> <span class="token function">calc_ewp</span><span class="token punctuation">(</span>i<span class="token punctuation">,</span> w<span class="token punctuation">)</span><span class="token punctuation">:</span>
                <span class="token triple-quoted-string string">"""计算偏导左边的公式"""</span>
                ep <span class="token operator">=</span> <span class="token number">0.0</span>
                x<span class="token punctuation">,</span> y <span class="token operator">=</span> self<span class="token punctuation">.</span>_IDxy<span class="token punctuation">[</span>i<span class="token punctuation">]</span>
                <span class="token keyword">for</span> dataset_X <span class="token keyword">in</span> self<span class="token punctuation">.</span>_dataset_X<span class="token punctuation">:</span>
                    <span class="token keyword">if</span> x <span class="token operator">not</span> <span class="token keyword">in</span> dataset_X<span class="token punctuation">:</span>
                        <span class="token keyword">continue</span>
                    ep <span class="token operator">+=</span> self<span class="token punctuation">.</span>calc_pw_yx<span class="token punctuation">(</span>dataset_X<span class="token punctuation">,</span> y<span class="token punctuation">,</span> w<span class="token punctuation">)</span> <span class="token operator">/</span> self<span class="token punctuation">.</span>_N
                <span class="token keyword">return</span> ep

            <span class="token keyword">def</span> <span class="token function">calc_ep</span><span class="token punctuation">(</span>i<span class="token punctuation">)</span><span class="token punctuation">:</span>
                <span class="token triple-quoted-string string">"""计算关于经验分布P(x,y)的期望值"""</span>
                <span class="token punctuation">(</span>x<span class="token punctuation">,</span> y<span class="token punctuation">)</span> <span class="token operator">=</span> self<span class="token punctuation">.</span>_IDxy<span class="token punctuation">[</span>i<span class="token punctuation">]</span>
                <span class="token keyword">return</span> self<span class="token punctuation">.</span>_pxy_dic<span class="token punctuation">[</span><span class="token punctuation">(</span>x<span class="token punctuation">,</span> y<span class="token punctuation">)</span><span class="token punctuation">]</span>

            <span class="token keyword">return</span> calc_ewp<span class="token punctuation">(</span>i<span class="token punctuation">,</span> w<span class="token punctuation">)</span> <span class="token operator">-</span> calc_ep<span class="token punctuation">(</span>i<span class="token punctuation">)</span>

        <span class="token comment" spellcheck="true"># 算出g(w)，是n*1维矩阵</span>
        <span class="token keyword">def</span> <span class="token function">calc_gw</span><span class="token punctuation">(</span>w<span class="token punctuation">)</span><span class="token punctuation">:</span>
            <span class="token keyword">return</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span>calc_dfw<span class="token punctuation">(</span>i<span class="token punctuation">,</span> w<span class="token punctuation">)</span> <span class="token keyword">for</span> i <span class="token keyword">in</span> range<span class="token punctuation">(</span>self<span class="token punctuation">.</span>_n<span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">.</span>T

        <span class="token comment" spellcheck="true"># （1）初始正定对称矩阵，单位矩阵</span>
        Gk <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span>np<span class="token punctuation">.</span>eye<span class="token punctuation">(</span>len<span class="token punctuation">(</span>self<span class="token punctuation">.</span>w<span class="token punctuation">)</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>float<span class="token punctuation">)</span><span class="token punctuation">)</span>

        <span class="token comment" spellcheck="true"># （2）计算g(w0)</span>
        w <span class="token operator">=</span> self<span class="token punctuation">.</span>w
        gk <span class="token operator">=</span> calc_gw<span class="token punctuation">(</span>w<span class="token punctuation">)</span>
        <span class="token comment" spellcheck="true"># 判断gk的范数是否小于阈值</span>
        <span class="token keyword">if</span> np<span class="token punctuation">.</span>linalg<span class="token punctuation">.</span>norm<span class="token punctuation">(</span>gk<span class="token punctuation">,</span> ord<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span> <span class="token operator">&lt;</span> self<span class="token punctuation">.</span>epsilon<span class="token punctuation">:</span>
            self<span class="token punctuation">.</span>w <span class="token operator">=</span> w
            <span class="token keyword">return</span>

        k <span class="token operator">=</span> <span class="token number">0</span>
        <span class="token keyword">for</span> _ <span class="token keyword">in</span> range<span class="token punctuation">(</span>self<span class="token punctuation">.</span>max_iter<span class="token punctuation">)</span><span class="token punctuation">:</span>
            <span class="token comment" spellcheck="true"># （3）计算pk</span>
            pk <span class="token operator">=</span> <span class="token operator">-</span>Gk<span class="token punctuation">.</span>dot<span class="token punctuation">(</span>gk<span class="token punctuation">)</span>

            <span class="token comment" spellcheck="true"># 梯度方向的一维函数</span>
            <span class="token keyword">def</span> <span class="token function">_f</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">:</span>
                z <span class="token operator">=</span> w <span class="token operator">+</span> np<span class="token punctuation">.</span>dot<span class="token punctuation">(</span>x<span class="token punctuation">,</span> pk<span class="token punctuation">)</span><span class="token punctuation">.</span>T<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
                <span class="token keyword">return</span> self<span class="token punctuation">.</span>calc_f<span class="token punctuation">(</span>z<span class="token punctuation">)</span>

            <span class="token comment" spellcheck="true"># （4）进行一维搜索，找到使得函数最小的lambda</span>
            _lambda <span class="token operator">=</span> fminbound<span class="token punctuation">(</span>_f<span class="token punctuation">,</span> <span class="token operator">-</span>self<span class="token punctuation">.</span>distance<span class="token punctuation">,</span> self<span class="token punctuation">.</span>distance<span class="token punctuation">)</span>

            delta_k <span class="token operator">=</span> _lambda <span class="token operator">*</span> pk
            <span class="token comment" spellcheck="true"># （5）更新权重</span>
            w <span class="token operator">+=</span> delta_k<span class="token punctuation">.</span>T<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>

            <span class="token comment" spellcheck="true"># （6）计算gk+1</span>
            gk1 <span class="token operator">=</span> calc_gw<span class="token punctuation">(</span>w<span class="token punctuation">)</span>
            <span class="token comment" spellcheck="true"># 判断gk1的范数是否小于阈值</span>
            <span class="token keyword">if</span> np<span class="token punctuation">.</span>linalg<span class="token punctuation">.</span>norm<span class="token punctuation">(</span>gk1<span class="token punctuation">,</span> ord<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span> <span class="token operator">&lt;</span> self<span class="token punctuation">.</span>epsilon<span class="token punctuation">:</span>
                self<span class="token punctuation">.</span>w <span class="token operator">=</span> w
                <span class="token keyword">break</span>
            <span class="token comment" spellcheck="true"># 根据DFP算法的迭代公式（附录B.24公式）计算Gk</span>
            yk <span class="token operator">=</span> gk1 <span class="token operator">-</span> gk
            Pk <span class="token operator">=</span> delta_k<span class="token punctuation">.</span>dot<span class="token punctuation">(</span>delta_k<span class="token punctuation">.</span>T<span class="token punctuation">)</span> <span class="token operator">/</span> <span class="token punctuation">(</span>delta_k<span class="token punctuation">.</span>T<span class="token punctuation">.</span>dot<span class="token punctuation">(</span>yk<span class="token punctuation">)</span><span class="token punctuation">)</span>
            Qk <span class="token operator">=</span> Gk<span class="token punctuation">.</span>dot<span class="token punctuation">(</span>yk<span class="token punctuation">)</span><span class="token punctuation">.</span>dot<span class="token punctuation">(</span>yk<span class="token punctuation">.</span>T<span class="token punctuation">)</span><span class="token punctuation">.</span>dot<span class="token punctuation">(</span>Gk<span class="token punctuation">)</span> <span class="token operator">/</span> <span class="token punctuation">(</span>yk<span class="token punctuation">.</span>T<span class="token punctuation">.</span>dot<span class="token punctuation">(</span>Gk<span class="token punctuation">)</span><span class="token punctuation">.</span>dot<span class="token punctuation">(</span>yk<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token operator">*</span> <span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>
            Gk <span class="token operator">=</span> Gk <span class="token operator">+</span> Pk <span class="token operator">+</span> Qk
            gk <span class="token operator">=</span> gk1

            <span class="token comment" spellcheck="true"># （7）置k=k+1</span>
            k <span class="token operator">+=</span> <span class="token number">1</span>

        self<span class="token punctuation">.</span>w <span class="token operator">=</span> w
        self<span class="token punctuation">.</span>n_iter_ <span class="token operator">=</span> k

    <span class="token keyword">def</span> <span class="token function">predict</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>
        result <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token punctuation">}</span>
        <span class="token keyword">for</span> y <span class="token keyword">in</span> self<span class="token punctuation">.</span>_y<span class="token punctuation">:</span>
            prob <span class="token operator">=</span> self<span class="token punctuation">.</span>calc_pw_yx<span class="token punctuation">(</span>x<span class="token punctuation">,</span> y<span class="token punctuation">,</span> self<span class="token punctuation">.</span>w<span class="token punctuation">)</span>
            result<span class="token punctuation">[</span>y<span class="token punctuation">]</span> <span class="token operator">=</span> prob

        <span class="token keyword">return</span> result<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<pre class="line-numbers language-python"><code class="language-python"><span class="token comment" spellcheck="true"># 训练数据集</span>
dataset <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token string">'no'</span><span class="token punctuation">,</span> <span class="token string">'sunny'</span><span class="token punctuation">,</span> <span class="token string">'hot'</span><span class="token punctuation">,</span> <span class="token string">'high'</span><span class="token punctuation">,</span> <span class="token string">'FALSE'</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
                    <span class="token punctuation">[</span><span class="token string">'no'</span><span class="token punctuation">,</span> <span class="token string">'sunny'</span><span class="token punctuation">,</span> <span class="token string">'hot'</span><span class="token punctuation">,</span> <span class="token string">'high'</span><span class="token punctuation">,</span> <span class="token string">'TRUE'</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
                    <span class="token punctuation">[</span><span class="token string">'yes'</span><span class="token punctuation">,</span> <span class="token string">'overcast'</span><span class="token punctuation">,</span> <span class="token string">'hot'</span><span class="token punctuation">,</span> <span class="token string">'high'</span><span class="token punctuation">,</span> <span class="token string">'FALSE'</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
                    <span class="token punctuation">[</span><span class="token string">'yes'</span><span class="token punctuation">,</span> <span class="token string">'rainy'</span><span class="token punctuation">,</span> <span class="token string">'mild'</span><span class="token punctuation">,</span> <span class="token string">'high'</span><span class="token punctuation">,</span> <span class="token string">'FALSE'</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
                    <span class="token punctuation">[</span><span class="token string">'yes'</span><span class="token punctuation">,</span> <span class="token string">'rainy'</span><span class="token punctuation">,</span> <span class="token string">'cool'</span><span class="token punctuation">,</span> <span class="token string">'normal'</span><span class="token punctuation">,</span> <span class="token string">'FALSE'</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
                    <span class="token punctuation">[</span><span class="token string">'no'</span><span class="token punctuation">,</span> <span class="token string">'rainy'</span><span class="token punctuation">,</span> <span class="token string">'cool'</span><span class="token punctuation">,</span> <span class="token string">'normal'</span><span class="token punctuation">,</span> <span class="token string">'TRUE'</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
                    <span class="token punctuation">[</span><span class="token string">'yes'</span><span class="token punctuation">,</span> <span class="token string">'overcast'</span><span class="token punctuation">,</span> <span class="token string">'cool'</span><span class="token punctuation">,</span> <span class="token string">'normal'</span><span class="token punctuation">,</span> <span class="token string">'TRUE'</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
                    <span class="token punctuation">[</span><span class="token string">'no'</span><span class="token punctuation">,</span> <span class="token string">'sunny'</span><span class="token punctuation">,</span> <span class="token string">'mild'</span><span class="token punctuation">,</span> <span class="token string">'high'</span><span class="token punctuation">,</span> <span class="token string">'FALSE'</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
                    <span class="token punctuation">[</span><span class="token string">'yes'</span><span class="token punctuation">,</span> <span class="token string">'sunny'</span><span class="token punctuation">,</span> <span class="token string">'cool'</span><span class="token punctuation">,</span> <span class="token string">'normal'</span><span class="token punctuation">,</span> <span class="token string">'FALSE'</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
                    <span class="token punctuation">[</span><span class="token string">'yes'</span><span class="token punctuation">,</span> <span class="token string">'rainy'</span><span class="token punctuation">,</span> <span class="token string">'mild'</span><span class="token punctuation">,</span> <span class="token string">'normal'</span><span class="token punctuation">,</span> <span class="token string">'FALSE'</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
                    <span class="token punctuation">[</span><span class="token string">'yes'</span><span class="token punctuation">,</span> <span class="token string">'sunny'</span><span class="token punctuation">,</span> <span class="token string">'mild'</span><span class="token punctuation">,</span> <span class="token string">'normal'</span><span class="token punctuation">,</span> <span class="token string">'TRUE'</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
                    <span class="token punctuation">[</span><span class="token string">'yes'</span><span class="token punctuation">,</span> <span class="token string">'overcast'</span><span class="token punctuation">,</span> <span class="token string">'mild'</span><span class="token punctuation">,</span> <span class="token string">'high'</span><span class="token punctuation">,</span> <span class="token string">'TRUE'</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
                    <span class="token punctuation">[</span><span class="token string">'yes'</span><span class="token punctuation">,</span> <span class="token string">'overcast'</span><span class="token punctuation">,</span> <span class="token string">'hot'</span><span class="token punctuation">,</span> <span class="token string">'normal'</span><span class="token punctuation">,</span> <span class="token string">'FALSE'</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
                    <span class="token punctuation">[</span><span class="token string">'no'</span><span class="token punctuation">,</span> <span class="token string">'rainy'</span><span class="token punctuation">,</span> <span class="token string">'mild'</span><span class="token punctuation">,</span> <span class="token string">'high'</span><span class="token punctuation">,</span> <span class="token string">'TRUE'</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>

X_train <span class="token operator">=</span> dataset<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">:</span><span class="token punctuation">]</span>
y_train <span class="token operator">=</span> dataset<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span>

mae <span class="token operator">=</span> MaxEntDFP<span class="token punctuation">(</span>epsilon<span class="token operator">=</span><span class="token number">1e</span><span class="token operator">-</span><span class="token number">4</span><span class="token punctuation">,</span> max_iter<span class="token operator">=</span><span class="token number">1000</span><span class="token punctuation">,</span> distance<span class="token operator">=</span><span class="token number">0.01</span><span class="token punctuation">)</span>
<span class="token comment" spellcheck="true"># 训练模型</span>
mae<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>X_train<span class="token punctuation">,</span> y_train<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"模型训练迭代次数：{}次"</span><span class="token punctuation">.</span>format<span class="token punctuation">(</span>mae<span class="token punctuation">.</span>n_iter_<span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"模型权重：{}"</span><span class="token punctuation">.</span>format<span class="token punctuation">(</span>mae<span class="token punctuation">.</span>w<span class="token punctuation">)</span><span class="token punctuation">)</span>

result <span class="token operator">=</span> mae<span class="token punctuation">.</span>predict<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token string">'overcast'</span><span class="token punctuation">,</span> <span class="token string">'mild'</span><span class="token punctuation">,</span> <span class="token string">'high'</span><span class="token punctuation">,</span> <span class="token string">'FALSE'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"预测结果："</span><span class="token punctuation">,</span> result<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<pre><code>模型训练迭代次数：878次
模型权重：[ 11.72083082  -0.7189626    9.69699232  -8.83693899   5.57382082
  19.50768089   0.7189626   -9.69699232   8.83693899  -4.5237319
   9.15646808  -6.6123125   12.96011049   4.5237319    6.6123125
 -12.96011049  -5.57382082  -9.15646808 -11.72083082]
预测结果： {'no': 2.097720173362797e-16, 'yes': 0.9999999999999998}</code></pre><h1 id="七、支持向量机"><a href="#七、支持向量机" class="headerlink" title="七、支持向量机"></a>七、支持向量机</h1><p>支持向量机（support vector machines,SVM）是一种二类分类模型。它的基本模型是定义在特征空间上的间隔最大的线性分类器，间隔最大使它有别于感知机；支持向量机还包括核技巧，这使它成为实质上的非线性分类器。支持向量机的学习策略就是间隔最大化，可形式化为一个求解凸二次规划（ convex quadratic programming）的问题，也等价于正则化的合页损失函数的最小化问题，支持向量机的学习算法是求解凸二次规划的最优化算法。</p>
<h2 id="7-1-线性可分支持向量机与硬间隔最大化"><a href="#7-1-线性可分支持向量机与硬间隔最大化" class="headerlink" title="7.1 线性可分支持向量机与硬间隔最大化"></a>7.1 线性可分支持向量机与硬间隔最大化</h2><h3 id="7-1-1-线性可分支持向量机"><a href="#7-1-1-线性可分支持向量机" class="headerlink" title="7.1.1 线性可分支持向量机"></a>7.1.1 线性可分支持向量机</h3><p>考虑一个二类分类问题。假设输入空间与特征空间为两个不同的空间。输入空间为欧氏空间或离散集合，特征空间为欧氏空间或希尔伯特空间。线性可分支持向量机、线性支持向量机假设这两个空间的元素一一对应，并将输入空间中的输入映射为特征空间中的特征向量。非线性支持向量机利用一个从输入空间到特征空间的非线性映射将输入映射为特征向量。所以，输入都由输入空间转换到特征空间，支持向量机的学习是在特征空间进行的.</p>
<p><strong>定义7.1（线性可分支持向量机）</strong>给定线性可分训练数据集，通过间隔最大化或等价地求解相应的凸二次规划问题学习得到的分离超平面为：<br>$$<br>\begin{gathered}<br>w^{<em>} \cdot x+b^{</em>}=0<br>\end{gathered}<br>$$<br>以及相应的分类决策函数：<br>$$<br>f(x)=\operatorname{sign}\left(w^{<em>} \cdot x+b^{</em>}\right)<br>$$<br>称为线性可分支持向量机</p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20220111124128946.png" alt="二类分类问题"></p>
<h3 id="7-1-2-函数间隔和几何间隔"><a href="#7-1-2-函数间隔和几何间隔" class="headerlink" title="7.1.2 函数间隔和几何间隔"></a>7.1.2 函数间隔和几何间隔</h3><p><strong>定义7.2（函数间隔）</strong></p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20220111124318491.png" alt=""></p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20220111124502583.png" alt="几何间隔"></p>
<p><strong>定义7.3（几何间隔）</strong></p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20220111124618043.png" alt=""></p>
<h3 id="7-1-3-间隔最大化"><a href="#7-1-3-间隔最大化" class="headerlink" title="7.1.3 间隔最大化"></a>7.1.3 间隔最大化</h3><p>支持向量机学习的基本想法是求解能够正确划分训练数据集并且几何间隔最大的分离超平面，对线性可分的训练数据集而言，线性可分分离超平面有无穷多个（等价于感知机），但是几何间隔最大的分离超平面是唯一的，这里的间隔最大化又称为硬间隔最大化（与将要讨论的训练数据集近似线性可分时的软间隔最大化相对应）</p>
<p>间隔最大化的直观解释是：对训练数据集找到几何间隔最大的超平面意味着以充分大的确信度对训练数据进行分类。也就是说，不仅将正负实例点分开，而且对最难分的实例点（离超平面最近的点）也有足够大的确信度将它们分开。这样的超平面应该对未知的新实例有很好的分类预测能力</p>
<ul>
<li>最大间隔分离超平面</li>
</ul>
<p><strong>算法7.1（线性可分支持向量机学习算法最大间隔法）</strong></p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20220111125038845.png" alt=""></p>
<ul>
<li>最大间隔分离超平面的存在唯一性</li>
</ul>
<p>线性可分训练数据集的最大间隔分离超平面是存在且唯一的.</p>
<p><strong>定理7.1（最大间隔分离超平面的存在唯一性）</strong>若训练数据集T线性可分，则可将训练数据集中的样本点完全正确分开的最大间隔分离超平面存在且唯一</p>
<ul>
<li>支持向量和间隔边界</li>
</ul>
<p>在线性可分情况下，训练数据集的样本点中与分离超平面距离最近的样本点<br>的实例称为支持向量（support vector）</p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20220111125315668.png" alt=""></p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20220111125324671.png" alt="支持向量"></p>
<h3 id="7-1-4-学习的对偶算法"><a href="#7-1-4-学习的对偶算法" class="headerlink" title="7.1.4 学习的对偶算法"></a>7.1.4 学习的对偶算法</h3><p><img src="/images/loading.gif" data-original="../images/ML/image-20220111125624646.png" alt=""></p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20220111125649752.png" alt=""></p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20220111125720417.png" alt=""></p>
<p><strong>定理7.2</strong></p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20220111125827174.png" alt=""></p>
<p><strong>算法7.2（线性可分支持向量机学习算法）</strong></p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20220111125957307.png" alt=""></p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20220111130016374.png" alt=""></p>
<p><strong>定义7.4（支持向量）</strong></p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20220111130118824.png" alt=""></p>
<h2 id="7-2-线性支持向量机与软间隔最大化"><a href="#7-2-线性支持向量机与软间隔最大化" class="headerlink" title="7.2 线性支持向量机与软间隔最大化"></a>7.2 线性支持向量机与软间隔最大化</h2><h3 id="7-2-1-线性支持向量机"><a href="#7-2-1-线性支持向量机" class="headerlink" title="7.2.1 线性支持向量机"></a>7.2.1 线性支持向量机</h3><p>线性可分问题的支持向量机学习方法，对线性不可分训练数据是不适用的，因为这时上述方法中的不等式约束并不能都成立。怎么オ能将它扩展到线性不可分问题呢？这就需要修改硬间隔最大化，使其成为软间隔最大化。</p>
<p>线性不可分的线性支持向量机的学习问题变成如下凸二次规划（convex quadratic programming）问题（原始问题）</p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20220111130502744.png" alt=""></p>
<p><strong>定义7.5（线性支持向量机）</strong></p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20220111130922451.png" alt=""></p>
<h3 id="7-2-2-学习的对偶算法"><a href="#7-2-2-学习的对偶算法" class="headerlink" title="7.2.2 学习的对偶算法"></a>7.2.2 学习的对偶算法</h3><p><strong>定理7.3</strong></p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20220111131103040.png" alt=""></p>
<p><strong>算法7.3（线性支持向量机学习算法）</strong></p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20220111131152729.png" alt=""></p>
<h3 id="7-2-3-支持向量"><a href="#7-2-3-支持向量" class="headerlink" title="7.2.3 支持向量"></a>7.2.3 支持向量</h3><p><img src="/images/loading.gif" data-original="../images/ML/image-20220111131256996.png" alt=""></p>
<h3 id="7-2-4-合页损失函数"><a href="#7-2-4-合页损失函数" class="headerlink" title="7.2.4 合页损失函数"></a>7.2.4 合页损失函数</h3><p><strong>定理7.4 线性支持向量机原始最优化问题</strong></p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20220111131414738.png" alt=""></p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20220111131450239.png" alt="合页损失函数"></p>
<h2 id="7-3-非线性支持向量机与核函数"><a href="#7-3-非线性支持向量机与核函数" class="headerlink" title="7.3 非线性支持向量机与核函数"></a>7.3 非线性支持向量机与核函数</h2><p>对解线性分类问题，线性分类支持向量机是一种非常有效的方法，但是，有时分类问题是非线性的，这时可以使用非线性支持向量机。</p>
<h3 id="7-3-1-核技巧"><a href="#7-3-1-核技巧" class="headerlink" title="7.3.1 核技巧"></a>7.3.1 核技巧</h3><ul>
<li>非线性分类问题</li>
</ul>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20220111131606079.png" alt="非线性分类问题与核技巧示例"></p>
<p>非线性问题往往不好求解，所以希望能用解线性分类问题的方法解决这个问题。所采取的方法是进行一个非线性变换，将非线性问题变换为线性问题，通过解变换后的线性问题的方法求解原来的非线性问题。</p>
<ul>
<li>核函数的定义</li>
</ul>
<p><strong>定义7.6（核函数）</strong></p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20220111131814283.png" alt=""></p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20220111131829429.png" alt=""></p>
<ul>
<li>核技巧在支持向量机中的应用</li>
</ul>
<p>在对偶问题的目标函数中的内积可以用核函数来代替。此时对偶问题的目标函数成为：<br>$$<br>W(\alpha)=\frac{1}{2} \sum_{i=1}^{N} \sum_{j=1}^{N} \alpha_{i} \alpha_{j} y_{i} y_{j} K\left(x_{i}, x_{j}\right)-\sum_{i=1}^{N} \alpha_{i}<br>$$<br>分类决策函数中的内积也可以用核函数代替，而分类决策函数式成为：<br>$$<br>f(x)=\operatorname{sign}\left(\sum_{i=1}^{N_{s}} a_{i}^{<em>} y_{i} \phi\left(x_{i}\right) \cdot \phi(x)+b^{</em>}\right)=\operatorname{sign}\left(\sum_{i=1}^{N_{s}} a_{i}^{<em>} y_{i} K\left(x_{i}, x\right)+b^{</em>}\right)<br>$$</p>
<h3 id="7-3-2-正定核"><a href="#7-3-2-正定核" class="headerlink" title="7.3.2 正定核"></a>7.3.2 正定核</h3><p><strong>定理7.5（正定核的充要条件）</strong></p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20220111132304571.png" alt=""></p>
<p><strong>定义7.7（正定核的等价定义）</strong></p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20220111132352326.png" alt=""></p>
<h3 id="7-3-3-常用核函数"><a href="#7-3-3-常用核函数" class="headerlink" title="7.3.3 常用核函数"></a>7.3.3 常用核函数</h3><ul>
<li>多项式核函数（polynomial kernel function）</li>
</ul>
<p>$$<br>K(x, z)=(x \cdot z+1)^{p}<br>$$<br>对应的支持向量机是一个 $p$ 次多项式分类器. 分类决策函数成为：<br>$$<br>f(x)=\operatorname{sign}\left(\sum_{i=1}^{N_{i}} a_{i}^{<em>} y_{i}\left(x_{i} \cdot x+1\right)^{p}+b^{</em>}\right)<br>$$</p>
<ul>
<li>高斯核函数（Gaussian kernel function）</li>
</ul>
<p>$$<br>K(x, z)=\exp \left(-\frac{|x-z|^{2}}{2 \sigma^{2}}\right)<br>$$<br>对应的支持向量机是高斯径向基函数 (radial basis function) 分类器. 分类决策函数成为<br>$$<br>f(x)=\operatorname{sign}\left(\sum_{i=1}^{N_{t}} a_{i}^{<em>} y_{i} \exp \left(-\frac{|x-z|^{2}}{2 \sigma^{2}}\right)+b^{</em>}\right)<br>$$</p>
<ul>
<li>字符串核函数( string kernel function)</li>
</ul>
<p>核函数不仅可以定义在欧氏空间上，还可以定义在离散数据的集合上。比如，字符串核是定义在字符串集合上的核函数。字符串核函数在文本分类、信息检索、生物信息学等方面都有应用。</p>
<p>两个字符串 $s$ 和 $t$ 上的字符串核函数是基于映射 $\phi_{n}$ 的特征空间中的内积:<br>$$<br>k_{n}(s, t)=\sum_{u \in \Sigma^{n}}\left[\phi_{n}(s)\right]<em>{u}\left[\phi</em>{n}(t)\right]<em>{u}=\sum</em>{u \in \sum^{n}(i, j)} \sum_{(i)=t(j)=u} \lambda^{(i)} \lambda^{l(j)}<br>$$<br>字符串核函数 $k_{n}(s, t)$ 给出了字符串 $s$ 和 $t$ 中长度等于 $n$ 的所有子串组成的特征向量的余弦相似度 （cosine similarity）. 直观上, 两个字符串相同的子串越多, 它们就越相似, 字符串核函数的值就越大. 字符串核函数可以由动态规划快速地计算.</p>
<h3 id="7-3-4-非线性支持向量分类机"><a href="#7-3-4-非线性支持向量分类机" class="headerlink" title="7.3.4 非线性支持向量分类机"></a>7.3.4 非线性支持向量分类机</h3><p><strong>定义7.8（非线性支持向量机）</strong></p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20220111133208112.png" alt=""></p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20220111133227079.png" alt=""></p>
<p><strong>算法7.4（非线性支持向量机学习算法）</strong></p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20220111133304246.png" alt=""></p>
<h2 id="7-4-序列最小最优化算法"><a href="#7-4-序列最小最优化算法" class="headerlink" title="7.4 序列最小最优化算法"></a>7.4 序列最小最优化算法</h2><p><img src="/images/loading.gif" data-original="../images/ML/image-20220111133350303.png" alt=""></p>
<p>SMO算法是一种启发式算法，其基本思路是：如果所有变量的解都满足此最优化问题的KKT条件（Karush-Kuhn- Tucker conditions）,那么这个最优化问题的解就得到了。因为KKT条件是该最优化问题的充分必要条件。否则，选择两个变量，固定其他变量，针对这两个变量构建一个二次规划问题，这个二次规划问题关于这两个变量的解应该更接近原始二次规划问题的解，因为这会使得原始二次规划问题的目标函数值变得更小，重要的是，这时子问题可以通过解析方法求解，这样就可以大大提高整个算法的计算速度子问题有两个变量，一个是违反KKT条件最严重的那一个，另一个由约束条件自动确定。如此，SMO算法将原问题不断分解为子问题并对子问题求解，进而达到求解原问题的目的。</p>
<h3 id="7-4-1-两个变量二次规划的求解方法"><a href="#7-4-1-两个变量二次规划的求解方法" class="headerlink" title="7.4.1 两个变量二次规划的求解方法"></a>7.4.1 两个变量二次规划的求解方法</h3><p><strong>定理7.5</strong></p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20220111133622770.png" alt=""></p>
<h3 id="7-4-2-变量的选择方法"><a href="#7-4-2-变量的选择方法" class="headerlink" title="7.4.2 变量的选择方法"></a>7.4.2 变量的选择方法</h3><h3 id="7-4-3-SMO算法"><a href="#7-4-3-SMO算法" class="headerlink" title="7.4.3 SMO算法"></a>7.4.3 SMO算法</h3><p><strong>算法7.5 (SMO算法)</strong></p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20220111133803108.png" alt=""></p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20220111133817444.png" alt=""></p>
<p>SMO算法是支持向量机学习的一种快速算法，其特点是不断地将原二次规划问题分解为只有两个变量的二次规划子问题，并对子问题进行解析求解，直到所有变量满足KKT条件为止。这样通过启发式的方法得到原二次规划问题的最优解。因为子间题有解析解，所以每次计算子问题都很快，虽然计算子问题次数很多，但在总体上还是高效的。</p>
<p>一些解释：</p>
<ul>
<li><a href="https://mp.weixin.qq.com/s/dYWYdnGN9YDzzvbNyKG9pA" target="_blank" rel="noopener">看了这篇文章你还不懂SVM你就来打我 </a></li>
</ul>
<h2 id="习题-6"><a href="#习题-6" class="headerlink" title="习题"></a>习题</h2><h3 id="习题7-1"><a href="#习题7-1" class="headerlink" title="习题7.1"></a>习题7.1</h3><p>  比较感知机的对偶形式与线性可分支持向量机的对偶形式。</p>
<p><strong>解答：</strong></p>
<p><strong>解答思路：</strong></p>
<ol>
<li>列出感知机的原始形式；</li>
<li>写出感知机的对偶形式；</li>
<li>列出线性可分支持向量机的原始形式；</li>
<li>写出线性可分支持向量机的对偶形式；</li>
<li>比较感知机和线性可分支持向量机的对偶形式。</li>
</ol>
<p><strong>解答步骤：</strong></p>
<p><strong>第1步：感知机的原始形式</strong></p>
<p>  根据书中第38页的感知机学习算法的原始形式：</p>
<blockquote>
<p>给定一个训练数据集</p>
</blockquote>
<p>$$<br>T={(x_1,y_1),(x_2,y_2),\cdots,(x_N,y_N)}<br>$$</p>
<blockquote>
<p>其中，$x_i \in \mathcal{X} = R^n, y_i \in \mathcal{Y}={-1,1}, i=1,2,\cdots,N$，求参数$w,b$，使其为以下损失函数极小化问题的解</p>
</blockquote>
<p>$$<br>\min \limits_{w,b} L(w,b)=-\sum_{x_i \in M} y_i(w \cdot x_i + b)<br>$$</p>
<blockquote>
<p>其中$M$为误分类点的集合。</p>
</blockquote>
<p>  根据书中第39页的算法2.1</p>
<blockquote>
<p>输入：训练数据集$T={(x_1,y_1),(x_2,y_2),\cdots,(x_N,y_N)}$，其中$x_i \in \mathcal{X} = R^n, y_i \in \mathcal{Y}={-1,+1}, i=1,2,\cdots,N$；学习率$\eta$（$0 &lt; \eta \leqslant 1$）；<br>输出：$w,b$；感知机模型$f(x)=\text{sign}(w \cdot x + b)$<br>（1）选取初值$w_0,b_0$；<br>（2）在训练集中选取数据$(x_i, y_i)$；<br>（3）如果$y_i(w \cdot x_i +b) \leqslant 0$，</p>
</blockquote>
<p>$$<br>w \leftarrow w + \eta y_i x_i \<br>b \leftarrow b + \eta y_i<br>$$</p>
<blockquote>
<p>（4）转至（2），直至训练集中没有误分类点。</p>
</blockquote>
<p><strong>第2步：感知机的对偶形式</strong></p>
<p>  根据书中第44页的算法2.2</p>
<blockquote>
<p>输入：线性可分的数据集$T={(x_1,y_1),(x_2,y_2),\cdots,(x_N,y_N)}$，其中$x_i \in R^n, y_i \in {-1, +1}, i=1,2,\cdots,N$；学习率$\eta$（$0 &lt; \eta \leqslant 1$）；<br>输出：$a,b$；感知机模型$\displaystyle f(x)=\text{sign} \left( \sum_{j=1}^N \alpha_j y_j x_j \cdot x + b \right)$，其中$\alpha = (\alpha_1, \alpha_2,\cdots, \alpha_N)^T$<br>（1）$\alpha \leftarrow 0,b \leftarrow 0$；<br>（2）在训练集中选取数据$(x_i, y_i)$；<br>（3）如果$\displaystyle y_i\left( \sum_{j=1}^N \alpha_j y_j x_j \cdot x + b \right) \leqslant 0$，</p>
</blockquote>
<p>$$<br>\alpha_i \leftarrow \alpha_i + \eta \<br>b \leftarrow b + \eta y_i<br>$$</p>
<blockquote>
<p>（4）转至（2），直至训练集中没有误分类数据。</p>
</blockquote>
<p>  根据书中第44页对偶形式的基本思想</p>
<blockquote>
<p>从学习过程不难看出，最后学习到的$w,b$可以分别表示为</p>
</blockquote>
<p>$$<br>w=\sum_{i=1}^N \alpha_i y_i x_i\<br>b=\sum_{i=1}^N \alpha_i y_i<br>$$</p>
<blockquote>
<p>这里，$\alpha_i \geqslant 0, i=1,2,\cdots,N$</p>
</blockquote>
<p>  综上所述：</p>
<ol>
<li>感知机的原始形式中的损失函数：</li>
</ol>
<p>$$<br>\min_{w,b} L(w,b)=-\sum_{x_i \in M} y_i(w \cdot x_i + b)<br>$$</p>
<ol start="2">
<li>感知机的对偶形式中的损失函数：可知$w,b$表示为$\langle x_i,y_i \rangle$的线性组合形式，则</li>
</ol>
<p>$$<br>\min_{w,b} L(w,b) = \min_{\alpha} L(\alpha) = - \sum \limits_{x_i \in M} ( y_i ( \sum_{j=1}^N \alpha_j y_j x_j \cdot x_i + \sum_{j=1}^N \alpha_j y_j ) )<br>$$</p>
<p>其中，$\alpha = (\alpha_1, \alpha_2,\cdots, \alpha_N)^T$</p>
<p><strong>第3步：线性可分支持向量机的原始形式</strong></p>
<p>  根据书中第116页的线性可分支持向量机学习的最优化问题，可作为原始最优化问题(7.13)~(7.14)：<br>$$<br>\begin{array}{cl}<br>\displaystyle \min_{w,b} &amp; \displaystyle \frac{1}{2} |w|^2 \<br>\text{s.t.} &amp; y_i(w \cdot x_i + b) -1 \geqslant 0, \quad i=1, 2,\cdots, N<br>\end{array}<br>$$</p>
<p><strong>第4步：线性可分支持向量机的对偶形式</strong></p>
<p>  根据书中第123页算法7.2：</p>
<blockquote>
<p>输入：线性可分训练集$T={(x_1,y_1),(x_2,y_2), \cdots, (x_N,y_N)}$，其中$x_i \in \mathcal{X} = R^n$，$y_i \in \mathcal{Y} = {-1, +1}$，$i=1,2,\cdots, N$；<br>输出：分离超平面和分类决策函数。<br>（1）构造并求解约束最优化问题</p>
</blockquote>
<p>$$<br>\begin{array}{cl}<br>\displaystyle \min_{\alpha} &amp; \displaystyle \frac{1}{2} \sum_{i=1}^N \sum_{j=1}^N \alpha_i \alpha_j y_i y_j (x_i \cdot x_j) - \sum_{i=1}^N<br>\alpha_i \<br>\text{s.t.} &amp; \displaystyle \sum_{i=1}^N \alpha_i y_i = 0 \<br>&amp; \alpha_i \geqslant 0, \quad i=1,2,\cdots,N<br>\end{array}<br>$$</p>
<blockquote>
<p>求得最优解$ \alpha^<em>=(\alpha_1^</em>, \alpha_2^<em>, \cdots, \alpha_N^</em>)^T$。<br>（2）计算</p>
</blockquote>
<p>$$<br>w^* = \sum_{i=1}^N \alpha_i^* y_j x_i<br>$$</p>
<blockquote>
<p>并选择$ \alpha^<em>$的一个正分量$ \alpha_j^</em> &gt; 0$，计算</p>
</blockquote>
<p>$$<br> b^<em>=y_i-\sum_{i=1}^N \alpha_i^</em> y_i (x_i \cdot x_j)<br>$$</p>
<blockquote>
<p>（3）求得分离超平面</p>
</blockquote>
<p>$$<br>w^* \cdot x + b^* = 0<br>$$</p>
<p>分类决策函数：<br>$$<br>f(x) = \text{sign}(w^* \cdot x + b^*)<br>$$<br>综上所述：</p>
<ol>
<li>线性可分支持向量机的原始形式中的损失函数：</li>
</ol>
<p>$$<br>\min_{w,b} L(w,b) = \frac{1}{2} |w|^2<br>$$</p>
<ol start="2">
<li>线性可分支持向量机的对偶形式中的损失函数：根据定理7.2，可知$w,b$表示为$\langle x_i,y_i \rangle$的线性组合形式，则</li>
</ol>
<p>$$<br>\min_{w,b} L(w,b) = \min_{\alpha} L(\alpha) = \frac{1}{2} \sum_{i=1}^N \sum_{j=1}^N \alpha_i \alpha_j y_i y_j (x_i \cdot x_j) - \sum_{i=1}^N<br>\alpha_i<br>$$</p>
<p>其中，$\alpha = (\alpha_1, \alpha_2,\cdots, \alpha_N)^T$</p>
<p><strong>第5步：感知机和线性可分支持向量机对偶形式的比较</strong></p>
<ol>
<li>在两者的对偶形式中，$w,b$都可以表示为$\langle x_i,y_i \rangle$的线性组合形式；</li>
<li>在两者的对偶形式中，都可以通过求解$\alpha=(\alpha_1, \alpha_2, \cdots, \alpha_N)^T$，最后代入由$x_i,y_i,\alpha_i$表示的$w$和$b$公式中，从而求解最优化问题的解$w^<em>$和$b^</em>$；</li>
<li>感知机学习得到一个分隔超平面，而线性可分支持向量机学习得到所有分隔超平面中的间隔最大分隔超平面。</li>
</ol>
<h3 id="习题7-2"><a href="#习题7-2" class="headerlink" title="习题7.2"></a>习题7.2</h3><p>  已知正例点$x_1=(1,2)^T,x_2=(2,3)^T,x_3=(3,3)^T$，负例点$x_4=(2,1)^T,x_5=(3,2)^T$，试求最大间隔分离平面和分类决策函数，并在图中画出分离超平面、间隔边界及支持向量。  </p>
<p><strong>解答：</strong></p>
<p><strong>解答思路：</strong></p>
<ol>
<li>通过调用sklearn.svm的SVC类构建模型，根据题目中的数据训练模型，得到$w$、$b$和支持向量；</li>
<li>调用matplotlib库，画出分离超平面、间隔边界和支持向量。</li>
</ol>
<p><strong>解答步骤：</strong></p>
<p><strong>第1步：训练模型，得到$w$、$b$和支持向量</strong></p>
<pre class="line-numbers language-python"><code class="language-python"><span class="token operator">%</span>matplotlib inline
<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>svm <span class="token keyword">import</span> SVC

<span class="token comment" spellcheck="true"># 加载数据</span>
X <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">]</span>
y <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span>

<span class="token comment" spellcheck="true"># 训练SVM模型</span>
clf <span class="token operator">=</span> SVC<span class="token punctuation">(</span>kernel<span class="token operator">=</span><span class="token string">'linear'</span><span class="token punctuation">,</span> C<span class="token operator">=</span><span class="token number">10000</span><span class="token punctuation">)</span>
clf<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>X<span class="token punctuation">,</span> y<span class="token punctuation">)</span>

<span class="token comment" spellcheck="true"># 得到w、b和支持向量</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"w ="</span><span class="token punctuation">,</span> clf<span class="token punctuation">.</span>coef_<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"b ="</span><span class="token punctuation">,</span> clf<span class="token punctuation">.</span>intercept_<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"support vectors ="</span><span class="token punctuation">,</span> clf<span class="token punctuation">.</span>support_vectors_<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<pre><code>w = [[-1.  2.]]
b = [-2.]
support vectors = [[3. 2.]
 [1. 2.]
 [3. 3.]]</code></pre><p>可得：</p>
<ol>
<li>最大间隔分离超平面：$-x^{(1)}+2x^{(2)}-2=0$  </li>
<li>分类决策函数：$f(x)=\text{sign}(-x^{(1)}+2x^{(2)}-2)$  </li>
<li>支持向量：$x_1=(3,2)^T,x_2=(1,2)^T, x_3=(3,3)^T$  </li>
</ol>
<p><strong>第2步：在图中画出分离超平面、间隔边界和支持向量</strong></p>
<pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> plt
<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np

<span class="token comment" spellcheck="true"># 绘制数据点</span>
color_seq <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">'red'</span> <span class="token keyword">if</span> v<span class="token operator">==</span><span class="token number">1</span> <span class="token keyword">else</span> <span class="token string">'blue'</span> <span class="token keyword">for</span> v <span class="token keyword">in</span> y<span class="token punctuation">]</span>
plt<span class="token punctuation">.</span>scatter<span class="token punctuation">(</span><span class="token punctuation">[</span>i<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token keyword">for</span> i <span class="token keyword">in</span> X<span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span>i<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token keyword">for</span> i <span class="token keyword">in</span> X<span class="token punctuation">]</span><span class="token punctuation">,</span> c<span class="token operator">=</span>color_seq<span class="token punctuation">)</span>

<span class="token comment" spellcheck="true"># 得到x轴的所有点</span>
xaxis <span class="token operator">=</span> np<span class="token punctuation">.</span>linspace<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">3.5</span><span class="token punctuation">)</span>
w <span class="token operator">=</span> clf<span class="token punctuation">.</span>coef_<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>

<span class="token comment" spellcheck="true"># 计算斜率</span>
a <span class="token operator">=</span> <span class="token operator">-</span>w<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">/</span> w<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span>

<span class="token comment" spellcheck="true"># 得到分离超平面</span>
y_sep <span class="token operator">=</span> a <span class="token operator">*</span> xaxis <span class="token operator">-</span> <span class="token punctuation">(</span>clf<span class="token punctuation">.</span>intercept_<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token operator">/</span> w<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span>

<span class="token comment" spellcheck="true"># 下边界超平面</span>
b <span class="token operator">=</span> clf<span class="token punctuation">.</span>support_vectors_<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
yy_down <span class="token operator">=</span> a <span class="token operator">*</span> xaxis <span class="token operator">+</span> <span class="token punctuation">(</span>b<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">-</span> a <span class="token operator">*</span> b<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span>

<span class="token comment" spellcheck="true"># 上边界超平面</span>
b <span class="token operator">=</span> clf<span class="token punctuation">.</span>support_vectors_<span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span>
yy_up <span class="token operator">=</span> a <span class="token operator">*</span> xaxis <span class="token operator">+</span> <span class="token punctuation">(</span>b<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">-</span> a <span class="token operator">*</span> b<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span>

<span class="token comment" spellcheck="true"># 绘制超平面</span>
plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>xaxis<span class="token punctuation">,</span> y_sep<span class="token punctuation">,</span> <span class="token string">'k-'</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>xaxis<span class="token punctuation">,</span> yy_down<span class="token punctuation">,</span> <span class="token string">'k--'</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>xaxis<span class="token punctuation">,</span> yy_up<span class="token punctuation">,</span> <span class="token string">'k--'</span><span class="token punctuation">)</span>

<span class="token comment" spellcheck="true"># 绘制支持向量</span>
plt<span class="token punctuation">.</span>xlabel<span class="token punctuation">(</span><span class="token string">'$x^{(1)}$'</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>ylabel<span class="token punctuation">(</span><span class="token string">'$x^{(2)}$'</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>scatter<span class="token punctuation">(</span>clf<span class="token punctuation">.</span>support_vectors_<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> clf<span class="token punctuation">.</span>support_vectors_<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> 
            s<span class="token operator">=</span><span class="token number">150</span><span class="token punctuation">,</span> facecolors<span class="token operator">=</span><span class="token string">'none'</span><span class="token punctuation">,</span> edgecolors<span class="token operator">=</span><span class="token string">'k'</span><span class="token punctuation">)</span>

plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p><img src="/images/loading.gif" data-original="../images/ML/output_22_0.png" alt=""></p>
<h3 id="习题7-3"><a href="#习题7-3" class="headerlink" title="习题7.3"></a>习题7.3</h3><p>  线性支持向量机还可以定义为以下形式：<br>$$<br>\begin{array}{cl}<br>\displaystyle \min \limits_{w,b,\xi} &amp; \displaystyle \frac{1}{2} |w|^2 + C \sum_{i=1}^N \xi_i^2 \<br>\text{s.t.} &amp; y_i(w \cdot x_i + b) \geqslant 1 - \xi_i, \quad i=1,2,\cdots, N \<br>&amp; \xi_i \geqslant 0, \quad i=1,2,\cdots, N<br>\end{array}<br>$$<br>试求其对偶形式。</p>
<p><strong>解答：</strong></p>
<p><strong>解答思路：</strong>  </p>
<p>参考书中第127页7.2.2节“学习的对偶算法”内容`</p>
<ol>
<li>根据附录C 拉格朗日对偶性，写出拉格朗日函数；</li>
<li>对 $L(w,b,\xi,\alpha,\mu)$ 求 $w,b,\xi$ 的极小；</li>
<li>对 $\displaystyle \min \limits_{w,b,\xi} L(w,b,\xi,\alpha,\mu)$ 求 $\alpha$ 的极大；</li>
<li>整理得到对偶形式。</li>
</ol>
<p><strong>解答步骤：</strong></p>
<p><strong>第1步：原始问题的拉格朗日函数</strong></p>
<p>  根据书中第447页附录C 拉格朗日对偶性：</p>
<blockquote>
<p>假设$f(x),c_i(x),h_j(x)$是定义在$R^n$上的连续可微函数。考虑约束最优化问题</p>
</blockquote>
<p>$$<br>\begin{array}{cl}<br>\displaystyle \min \limits_{x \in R^n} &amp; f(x) \<br>\text{s.t.} &amp; c_i(x) \leqslant 0, \quad i=1,2,\cdots, k \<br>&amp; h_j(x) = 0, \quad j=1,2,\cdots, l<br>\end{array}<br>$$</p>
<blockquote>
<p>称此约束最优化问题为原始最优化问题，或原始问题。</p>
<p>引入广义拉格朗日函数</p>
</blockquote>
<p>$$<br>L(x,\alpha, \beta) = f(x) + \sum_{i=1}^k \alpha_i c_i(x) + \sum_{j=1}^l \beta_j h_j(x)<br>$$</p>
<blockquote>
<p>这里，$x=(x^{(1)}, x^{(2)}, \cdots, x^{(n)})^T \in R^n$，$\alpha_i,\beta_j$是拉格朗日乘子，$\alpha_i \geqslant 0$。考虑$x$的函数：</p>
</blockquote>
<p>$$<br>\theta_P(x) = \max \limits_{\alpha,\beta:\alpha_i \geqslant 0} L(x, \alpha, \beta)<br>$$</p>
<blockquote>
<p>这里，下标$P$表示原始问题。</p>
</blockquote>
<p>  根据书中第448页原始问题极小化：</p>
<blockquote>
<p>如果考虑极小化问题</p>
</blockquote>
<p>$$<br>\min \limits_{x} \theta_P(x) = \min \limits_{x} \max \limits_{\alpha,\beta:\alpha_i \geqslant 0} L(x, \alpha, \beta)<br>$$</p>
<blockquote>
<p>上述问题称为广义拉格朗日函数的极小极大问题。</p>
</blockquote>
<p>  根据题意，原始问题为<br>$$<br>\begin{array}{cl}<br>\displaystyle \min \limits_{w,b,\xi} &amp; \displaystyle \frac{1}{2} |w|^2 + C \sum_{i=1}^N \xi_i^2 \<br>\text{s.t.} &amp; y_i(w \cdot x_i + b) \geqslant 1 - \xi_i, \quad i=1,2,\cdots, N \<br>&amp; \xi_i \geqslant 0, \quad i=1,2,\cdots, N<br>\end{array}<br>$$<br>  根据最优化函数的对应关系，可得<br>$$<br>\left { \begin{array}{ll}<br>\displaystyle f(x) = \frac{1}{2} |w|^2 + C \sum_{i=1}^N \xi_i^2 \<br>c_i^{(1)}(x) = 1 - \xi_i - y_i(w \cdot x_i + b), \quad i = 1,2,\cdots, N \<br>c_i^{(2)}(x) = - \xi_i, \quad i = 1,2,\cdots, N<br>\end{array} \right.<br>$$<br>  根据拉格朗日函数的定义，可得原始问题的拉格朗日函数为<br>$$<br> L(w,b,\xi, \alpha, \mu) = \frac{1}{2} |w|^2 + C \sum_{i=1}^N \xi_i^2 - \sum_{i=1}^N \alpha_i(y_i (w \cdot x_i + b)-1 + \xi_i) - \sum_{i=1}^N \mu_i \xi_i<br>$$<br>其中，$\alpha_i \geqslant 0, \mu_i \geqslant 0$</p>
<p><strong>第2步：对$L(w,b,\xi,\alpha,\mu)$求$w,b,\xi$的极小</strong></p>
<p>  根据拉格朗日对偶性，对偶问题是拉格朗日函数的极大极小问题，先对$L(w,b,\xi,\alpha,\mu)$求$w,b,\xi$的极小，分别对$w,b,\xi$求偏导，并令导数等于0，由<br>$$<br>\begin{array}{l}<br>\displaystyle \nabla_w L(w,b,\xi,\alpha,\mu)  = w - \sum_{i=1}^N \alpha_i y_i x_i = 0 \<br>\displaystyle \nabla_b L(w,b,\xi,\alpha,\mu)  =  -\sum_{i=1}^N \alpha_i y_i = 0 \<br>\displaystyle \nabla_{\xi_i} L(w,b,\xi,\alpha,\mu)  = 2C \xi_i - \alpha_i - \mu_i = 0<br>\end{array}<br>$$<br>  可得：<br>$$<br>\begin{array}{l}<br>\displaystyle w = \sum_{i=1}^N \alpha_i y_i x_i \<br>\displaystyle \sum_{i=1}^N \alpha_i y_i = 0 \<br>\displaystyle 2C \xi_i - \alpha_i - \mu_i = 0<br>\end{array}<br>$$<br>  将上式代入到原始问题的拉格朗日函数中，可得<br>$$<br>\begin{aligned}<br>L(w, b, \xi, \alpha, \mu)<br>&amp;= \frac{1}{2} \sum_{i=1}^N \sum_{j=1}^N \alpha_i \alpha_j y_i y_j (x_i \cdot x_j) +  C \sum_{i=1}^N \xi_i^2 - \sum_{i=1}^N \alpha_i y_i \left( \left( \sum_{j=1}^N \alpha_j y_j x_j \right) \cdot x_i + b \right) \<br>&amp; + \sum_{i=1}^N \alpha_i - \sum_{i=1}^N \alpha_i \xi_i - \sum_{i=1}^N \mu_i \xi_i \<br>&amp;= -\frac{1}{2} \sum_{i=1}^N \sum_{j=1}^N \alpha_i \alpha_j y_i y_j (x_i \cdot x_j) + \sum_{i=1}^N \alpha_i + C \sum_{i=1}^N \xi_i^2 - \sum_{i=1}^N \alpha_i \xi_i - \sum_{i=1}^N \mu_i \xi_i \<br>&amp;= -\frac{1}{2} \sum_{i=1}^N \sum_{j=1}^N \alpha_i \alpha_j y_i y_j (x_i \cdot x_j) + \sum_{i=1}^N \alpha_i + C \sum_{i=1}^N \xi_i^2 - \sum_{i=1}^N (\alpha_i + \mu_i) \xi_i \<br>&amp;= -\frac{1}{2} \sum_{i=1}^N \sum_{j=1}^N \alpha_i \alpha_j y_i y_j (x_i \cdot x_j) + \sum_{i=1}^N \alpha_i + C \sum_{i=1}^N \xi_i^2 - \sum_{i=1}^N \left( 2C \xi_i \right) \xi_i \<br>&amp;= -\frac{1}{2} \sum_{i=1}^N \sum_{j=1}^N \alpha_i \alpha_j y_i y_j (x_i \cdot x_j) + \sum_{i=1}^N \alpha_i + C \sum_{i=1}^N \xi_i^2 - 2C \sum_{i=1}^N \xi_i^2 \<br>&amp;= -\frac{1}{2} \sum_{i=1}^N \sum_{j=1}^N \alpha_i \alpha_j y_i y_j (x_i \cdot x_j) + \sum_{i=1}^N \alpha_i - C \sum_{i=1}^N \xi_i^2 \<br>&amp;= -\frac{1}{2} \sum_{i=1}^N \sum_{j=1}^N \alpha_i \alpha_j y_i y_j (x_i \cdot x_j) + \sum_{i=1}^N \alpha_i - C \sum_{i=1}^N \left(\frac{1}{4 C^2}(\alpha_i + \mu_i)^2 \right) \<br>&amp;= -\frac{1}{2} \sum_{i=1}^N \sum_{j=1}^N \alpha_i \alpha_j y_i y_j (x_i \cdot x_j) + \sum_{i=1}^N \alpha_i - \frac{1}{4 C}\sum_{i=1}^N (\alpha_i + \mu_i)^2<br>\end{aligned}<br>$$<br><strong>第3步：对$\displaystyle \min \limits_{w,b,\xi} L(w,b,\xi,\alpha,\mu)$求$\alpha$的极大</strong></p>
<p>  根据第2步，对$\displaystyle \min \limits_{w,b,\xi} L(w,b,\xi,\alpha,\mu)$求$\alpha$的极大，可得到对偶问题：<br>$$<br>\begin{array}{cl}<br>\displaystyle \max \limits_{\alpha} &amp; \displaystyle -\frac{1}{2} \sum_{i=1}^N \sum_{j=1}^N \alpha_i \alpha_j y_i y_j (x_i \cdot x_j) + \sum_{i=1}^N \alpha_i - \frac{1}{4 C}\sum_{i=1}^N (\alpha_i + \mu_i)^2 \<br>\text{s.t.} &amp; \displaystyle \sum_{i=1}^N \alpha_i y_i = 0 \<br>&amp; \displaystyle 2C \xi_i - \alpha_i - \mu_i = 0 \<br>&amp; \alpha_i \geqslant 0 ,\mu_i \geqslant 0, \xi_i \geqslant 0, \quad i=1,2,\cdots, N<br>\end{array}<br>$$<br><strong>第4步：进行公式变换，得到对偶形式</strong></p>
<p>  再将对目标函数求极大转换为求极小，于是得到原始问题的对偶形式<br>$$<br>\begin{array}{cl}<br>\displaystyle \min \limits_{\alpha} &amp; \displaystyle \frac{1}{2} \sum_{i=1}^N \sum_{j=1}^N \alpha_i \alpha_j y_i y_j (x_i \cdot x_j) - \sum_{i=1}^N \alpha_i + \frac{1}{4 C}\sum_{i=1}^N (\alpha_i + \mu_i)^2 \<br>\text{s.t.} &amp; \displaystyle \sum_{i=1}^N \alpha_i y_i = 0 \<br>&amp; \displaystyle 2C \xi_i - \alpha_i - \mu_i = 0 \<br>&amp; \alpha_i \geqslant 0 ,\mu_i \geqslant 0, \xi_i \geqslant 0, \quad i=1,2,\cdots, N<br>\end{array}<br>$$</p>
<h3 id="习题7-4"><a href="#习题7-4" class="headerlink" title="习题7.4"></a>习题7.4</h3><p>  证明内积的正整数幂函数：$$K(x,z)=(x \bullet z)^p$$是正定核函数，这里$p$是正整数，$x,z\in R^n$。</p>
<p><strong>解答：</strong></p>
<p><strong>解答思路：</strong>  </p>
<ol>
<li>写出正定核函数的判定依据</li>
<li>使用数学归纳法，证明<ol start="3">
<li>当$p=1$时，根据定理7.5，证明$K(x, z)=x \bullet z$是正定核函数</li>
<li>假设当$p=k$且$k&gt;1$时，$K(x, z)=(x \bullet z)^k$是正定核函数</li>
<li>证明当$p=k+1$时，$K(x, z)=(x \bullet z)^{k+1}$是正定核函数</li>
</ol>
</li>
</ol>
<p><strong>解答步骤：</strong></p>
<p><strong>第1步：列出正定核函数的判定依据</strong></p>
<p>根据书中第139页定理7.5（正定核的充要条件）：</p>
<blockquote>
<p>设$K: \mathcal{X} \times \mathcal{X} \rightarrow R$是对称函数，则$K(x,z)$为正定核函数的充要条件是对任意$x_i \in \mathcal{X}, i=1,2,\cdots, m$，$K(x, z)$对应的Gram矩阵：</p>
</blockquote>
<p>$$<br>K = [K(x_i, x_j)]_{m \times m}<br>$$</p>
<blockquote>
<p>是半正定矩阵。</p>
</blockquote>
<p><strong>第2步：使用数学归纳法，证明$K(x, z)=(x \bullet z)^p$是正定核函数</strong></p>
<ol>
<li>当$p=1$时，$K(x, z)=x \bullet z$，对任意$c_1,c_2,\cdots,c_n \in \mathbf{R}$，有</li>
</ol>
<p>$$<br>\begin{aligned}<br>\sum_{i,j=1}^n c_i c_j K(x_i,x_j)<br>&amp;= \sum_{i,j=1}^n c_i c_j (x_i \bullet x_j) \<br>&amp;= \left(\sum_{i=1}^m c_i x_i \right) \bullet \left(\sum_{j=1}^m c_j x_j \right) \<br>&amp;= \Bigg|\left( \sum_{i=1}^m c_i x_i \right)\Bigg|^2 \geqslant 0<br>\end{aligned}<br>$$</p>
<p>可得，当$p=1$时，$K(x, z)=x \bullet z$对应的Gram矩阵是半正定的，根据定理7.5，可知$K(x,z)=x \bullet z$是正定核函数。</p>
<ol start="2">
<li>假设$p=k$且$k$是大于1的正整数时，$K(x, z)=(x \bullet z)^k$是正定核函数</li>
</ol>
<p>根据书中第134页定义7.6的（核函数）：</p>
<blockquote>
<p>设$\mathcal{X}$是输入空间（欧式空间$R^n$的子集或离散集合），又设$\mathcal{H}$为特征空间（希尔伯特空间），如果存在一个从$\mathcal{X}$到$\mathcal{H}$的映射</p>
</blockquote>
<p>$$<br>\phi(x):\mathcal{X} \rightarrow \mathcal{H}<br>$$</p>
<blockquote>
<p>使得对所有$x,z \in \mathcal{X}$，函数$K(x,z)$满足条件</p>
</blockquote>
<p>$$<br>K(x,z) = \phi(x) \bullet \phi(z)<br>$$</p>
<blockquote>
<p>则称$K(x,z)$为核函数，$\phi(x)$为映射函数，式中$\phi(x) \bullet \phi(z)$为$\phi(x)$和$\phi(z)$的内积。</p>
</blockquote>
<p>故存在一个输入空间为$R^n$，$R^n$到$\mathcal{H}$的映射<br>$$<br>\phi(x):R^n \rightarrow \mathcal{H}<br>$$<br>使得对所有$x,z \in R^n$，函数$K(x,z)=(x \bullet z)^k$满足条件<br>$$<br>K(x,z) = \phi(x) \bullet \phi(z)<br>$$<br>可假设$\phi(x)=(f_1(x), f_2(x), \cdots, f_m(x))^T$，其中$x=(x^{(1)}, x^{(2)}, \cdots, x^{(n)})^T$</p>
<ol start="3">
<li>当$p=k+1$时  </li>
</ol>
<p>$$<br>\begin{aligned}<br>K(x,z)<br>&amp;= (x \bullet z)^{k+1} \<br>&amp;= (x \bullet z)^k (x \bullet z) \<br>&amp;= (\phi(x) \bullet \phi(z))(x \bullet z) \<br>&amp;= (f_1(x)f_1(z) + f_2(x)f_2(z) + \cdots + f_m(x)f_m(z))(x^{(1)}z^{(1)} + x^{(2)}z^{(2)} + \cdots + x^{(n)}z^{(n)}) \<br>&amp;= f_1(x)f_1(z)(x^{(1)}z^{(1)} + x^{(2)}z^{(2)} + \cdots + x^{(n)}z^{(n)}) \<br>&amp; \quad + f_2(x)f_2(z)(x^{(1)}z^{(1)} + x^{(2)}z^{(2)} + \cdots + x^{(n)}z^{(n)}) + \cdots \<br>&amp; \quad + f_m(x)f_m(z)(x^{(1)}z^{(1)} + x^{(2)}z^{(2)} + \cdots + x^{(n)}z^{(n)}) \<br>&amp;= (f_1(x)x^{(1)})(f_1(z)z^{(1)}) + (f_1(x)x^{(2)})(f_1(z)z^{(2)}) + \cdots \<br>&amp; \quad + (f_1(x)x^{(n)})(f_1(z)z^{(n)}) \<br>&amp; \quad + (f_2(x)x^{(1)})(f_2(z)z^{(1)}) + (f_2(x)x^{(2)})(f_2(z)z^{(2)}) + \cdots \<br>&amp; \quad + (f_2(x)x^{(n)})(f_2(z)z^{(n)}) + \cdots \<br>&amp; \quad + (f_m(x)x^{(1)})(f_m(z)z^{(1)}) + (f_m(x)x^{(2)})(f_m(z)z^{(2)}) + \cdots \<br>&amp; \quad + (f_m(x)x^{(n)})(f_m(z)z^{(n)})<br>\end{aligned}<br>$$</p>
<p>  可得<br>$$<br>\begin{aligned}<br>\phi’(x) &amp;= (f_1(x)x^{(1)}, f_1(x)x^{(2)}, \cdots, f_1(x)x^{(n)}, \<br>&amp; \quad f_2(x)x^{(1)}, f_2(x)x^{(2)}, \cdots, f_2(x)x^{(n)}, \<br>&amp; \quad f_m(x)x^{(1)}, \cdots, f_m(x)x^{(n)})^T<br>\end{aligned}<br>$$<br>  故存在从$R^n$到希尔伯特空间$\mathcal{H}$的映射$\phi’(x)$，使得<br>$$<br>K(x,z) = (x \bullet z)^{k+1} = \phi’(x) \bullet \phi’(z)<br>$$</p>
<p>  根据<a href="http://www.cse.zju.edu.cn/eclass/attachments/2015-10/01-1446086008-145421.pdf" target="_blank" rel="noopener">《矩阵分析》</a>书中定理7.5.3：</p>
<blockquote>
<p>如果$A,B \in M_n$是半正定矩阵，则$A \bullet B$也是半正定矩阵，此外如果$A$和$B$都是正定矩阵，则$A \bullet B$也是正定矩阵。<br>其中，$A \bullet B$称为$A$和$B$的Hadamard乘积。</p>
</blockquote>
<p>  由根据书中定理7.5，可得$K(x,z)=(x \bullet z)^{k+1}$是正定核函数。</p>
<p>  根据数学归纳法可得：<br>  当$p$是正整数，$x,z\in R^n$时，内积的正整数幂函数：$$K(x,z)=(x \bullet z)^p$$是正定核函数。</p>
<h1 id="八、提升方法"><a href="#八、提升方法" class="headerlink" title="八、提升方法"></a>八、提升方法</h1><p>提升( boosting)方法是一种常用的统计学习方法，应用广泛且有效。在分类问题中，它通过改变训练样本的权重，学习多个分类器，并将这些分类器进行线性组合，提高分类的性能。</p>
<h2 id="8-1-提升方法-Adaboost算法"><a href="#8-1-提升方法-Adaboost算法" class="headerlink" title="8.1 提升方法 Adaboost算法"></a>8.1 提升方法 Adaboost算法</h2><h3 id="8-1-1-提升方法的基本思路"><a href="#8-1-1-提升方法的基本思路" class="headerlink" title="8.1.1 提升方法的基本思路"></a>8.1.1 提升方法的基本思路</h3><p>提升方法基于这样一种思想：对于一个复杂任务来说，将多个专家的判断进行适当的综合所得出的判断，要比其中任何一个专家单独的判断好。</p>
<h3 id="8-1-2-Adaboost算法"><a href="#8-1-2-Adaboost算法" class="headerlink" title="8.1.2 Adaboost算法"></a>8.1.2 Adaboost算法</h3><p><strong>算法8.1 (Adaboost)</strong></p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20220111134455210.png" alt=""></p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20220111134519230.png" alt=""></p>
<h2 id="8-2-Adaboost算法的训练误差分析"><a href="#8-2-Adaboost算法的训练误差分析" class="headerlink" title="8.2 Adaboost算法的训练误差分析"></a>8.2 Adaboost算法的训练误差分析</h2><p>Adaboost最基本的性质是它能在学习过程中不断减少训练误差，即在训练数据集上的分类误差率。</p>
<p><strong>定理8.1( Adaboost的训练误差界)</strong></p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20220111135547509.png" alt=""></p>
<p><strong>定理8.2 (二类分类问题 Adaboost的训练误差界)</strong></p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20220111135621990.png" alt=""></p>
<p><strong>推论8.1</strong></p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20220111135704305.png" alt=""></p>
<h2 id="8-3-Adaboost算法的解释"><a href="#8-3-Adaboost算法的解释" class="headerlink" title="8.3 Adaboost算法的解释"></a>8.3 Adaboost算法的解释</h2><h3 id="8-3-1-前向分步算法"><a href="#8-3-1-前向分步算法" class="headerlink" title="8.3.1 前向分步算法"></a>8.3.1 前向分步算法</h3><p><strong>算法8.2（前向分步算法）</strong></p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20220111135800845.png" alt=""></p>
<h3 id="8-3-2-前向分步算法与-Adaboost"><a href="#8-3-2-前向分步算法与-Adaboost" class="headerlink" title="8.3.2 前向分步算法与 Adaboost"></a>8.3.2 前向分步算法与 Adaboost</h3><p><strong>定理8.3</strong> Adaboost算法是前向分步加法算法的特例。这时，模型是由基本分类器组成的加法模型，损失函数是指数函数.</p>
<h2 id="8-4-提升树"><a href="#8-4-提升树" class="headerlink" title="8.4 提升树"></a>8.4 提升树</h2><p>提升树是以分类树或回归树为基本分类器的提升方法。提升树被认为是统计学习中性能最好的方法之一。</p>
<h3 id="8-4-1-提升树模型"><a href="#8-4-1-提升树模型" class="headerlink" title="8.4.1 提升树模型"></a>8.4.1 提升树模型</h3><p>提升方法实际采用加法模型（即基函数的线性组合）与前向分步算法。以决策树为基函数的提升方法称为提升树（boosting tree）.对分类问题决策树是二叉分类树，对回归问题决策树是二叉回归树。提升树模型可以表示为决策树的加法模型：<br>$$<br>f_{M}(x)=\sum_{m=1}^{M} T\left(x ; \Theta_{m}\right)<br>$$</p>
<h3 id="8-4-2-提升树算法"><a href="#8-4-2-提升树算法" class="headerlink" title="8.4.2 提升树算法"></a>8.4.2 提升树算法</h3><p><strong>算法8.3（回归问题的提升树算法）</strong></p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20220111140445857.png" alt=""></p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20220111140457433.png" alt=""></p>
<h3 id="8-4-3-梯度提升"><a href="#8-4-3-梯度提升" class="headerlink" title="8.4.3 梯度提升"></a>8.4.3 梯度提升</h3><p><strong>算法8.4（梯度提升算法）</strong></p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20220111140607971.png" alt=""></p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20220111140629783.png" alt=""></p>
<p>一些解释</p>
<ul>
<li><p><a href="https://zhuanlan.zhihu.com/p/39972832" target="_blank" rel="noopener">AdaBoost算法</a></p>
</li>
<li><p><a href="https://zhuanlan.zhihu.com/p/59121403" target="_blank" rel="noopener">AdaBoost算法详解与python实现</a></p>
</li>
<li><p><a href="https://zhuanlan.zhihu.com/p/84139957" target="_blank" rel="noopener">深入理解提升树（Boosting tree）算法</a></p>
</li>
<li><p><a href="https://zhuanlan.zhihu.com/p/108622550" target="_blank" rel="noopener">集成学习(Ensemble Learning)——提升树（Boosting Tree）</a></p>
</li>
</ul>
<h2 id="习题-7"><a href="#习题-7" class="headerlink" title="习题"></a>习题</h2><h3 id="习题8-1-⭐⭐⭐"><a href="#习题8-1-⭐⭐⭐" class="headerlink" title="习题8.1 ⭐⭐⭐"></a>习题8.1 ⭐⭐⭐</h3><p>  某公司招聘职员考查身体、业务能力、发展潜力这3项。身体分为合格1、不合格0两级，业务能力和发展潜力分为上1、中2、下3三级。分类为合格1 、不合格-1两类。已知10个人的数据，如下表所示。假设弱分类器为决策树桩。试用AdaBoost算法学习一个强分类器。  </p>
<p>应聘人员情况数据表</p>
<table>
<thead>
<tr>
<th>  </th>
<th>1</th>
<th>2</th>
<th>3</th>
<th>4</th>
<th>5</th>
<th>6</th>
<th>7</th>
<th>8</th>
<th>9</th>
<th>10</th>
</tr>
</thead>
<tbody><tr>
<td>身体</td>
<td>0</td>
<td>0</td>
<td>1</td>
<td>1</td>
<td>1</td>
<td>0</td>
<td>1</td>
<td>1</td>
<td>1</td>
<td>0</td>
</tr>
<tr>
<td>业务</td>
<td>1</td>
<td>3</td>
<td>2</td>
<td>1</td>
<td>2</td>
<td>1</td>
<td>1</td>
<td>1</td>
<td>3</td>
<td>2</td>
</tr>
<tr>
<td>潜力</td>
<td>3</td>
<td>1</td>
<td>2</td>
<td>3</td>
<td>3</td>
<td>2</td>
<td>2</td>
<td>1</td>
<td>1</td>
<td>1</td>
</tr>
<tr>
<td>分类</td>
<td>-1</td>
<td>-1</td>
<td>-1</td>
<td>-1</td>
<td>-1</td>
<td>-1</td>
<td>1</td>
<td>1</td>
<td>-1</td>
<td>-1</td>
</tr>
</tbody></table>
<p><strong>解答：</strong></p>
<p><strong>解答思路：</strong></p>
<ol>
<li>列出AdaBoost算法；</li>
<li>采用sklearn的AdaBoostClassifier分类器，构建并训练得到强分类器；</li>
<li>自编程实现AdaBoost算法，并训练得到强分类器。</li>
</ol>
<p><strong>解答步骤：</strong></p>
<p><strong>第1步：提升方法AdaBoost算法</strong></p>
<p>  根据书中第156页算法8.1：</p>
<blockquote>
<p>输入：训练数据集$T={(x_1,y_1), (x_2,y_2), \cdots, (x_N,y_N)}$，其中$x_i \in \mathcal{X} \subseteq R^n$，$y_i \in \mathcal{Y} = {-1, +1}$；弱学习算法；<br>输出：最终分类器$G(x)$。<br>（1）初始化训练数据的权值分布</p>
</blockquote>
<p>$$<br>D_1 = (w_{11}, \cdots, w_{1i}, \cdots, w_{1N}), \quad w_{1i} = \frac{1}{N}, \quad i = 1, 2, \cdots, N<br>$$</p>
<blockquote>
<p>（2）对$m=1, 2, \cdots, M$<br>  （a）使用具有权值分布$D_m$的训练数据集学习，得到基本分类器</p>
</blockquote>
<p>$$<br>G_m(x):\mathcal{X} \rightarrow {-1, +1}<br>$$</p>
<blockquote>
<p>  （b）计算$G_m(x)$在训练数据集上的分类误差率</p>
</blockquote>
<p>$$<br>e_m = \sum_{i=1}^N P(G_m(x_i) \neq y_i) = \sum_{i=1}^N w_{mi}I(G_m(x_i) \neq y_i)<br>$$</p>
<blockquote>
<p>  （c）计算$G_m(x)$的系数</p>
</blockquote>
<p>$$<br>\alpha_m = \frac{1}{2} \log \frac{1 - e_m}{e_m}<br>$$</p>
<blockquote>
<p>  这里的对数是自然对数。<br>  （d）更新训练数据集的权值分布</p>
</blockquote>
<p>$$<br>D_{m+1} = (w_{m+1,1}, \cdots, w_{m+1, i}, \cdots, w_{m+1,N}) \<br>w_{m+1,i} = \frac{w_{mi} }{Z_m} \exp(-\alpha_m y_i G_m(x_i)), \quad i = 1, 2, \cdots, N<br>$$</p>
<blockquote>
<p>  这里，$Z_m$是规范化因子</p>
</blockquote>
<p>$$<br>Z_m = \sum_{i=1}^N w_{mi} \exp(-\alpha_m y_i G_m(x_i))<br>$$</p>
<blockquote>
<p>  它使$D_{m+1}$成为一个概率分布。<br>（3）构建基本分类器的线性组合</p>
</blockquote>
<p>$$<br>f(x) = \sum_{m=1}^M \alpha_m G_m(x)<br>$$</p>
<blockquote>
<p>得到最终分类器</p>
</blockquote>
<p>$$<br>\begin{aligned}<br>G(x) &amp;= \text{sign}(f(x)) \<br>&amp;= \text{sign}\left(\sum_{m=1}^M \alpha_m G_m(x) \right)<br>\end{aligned}<br>$$</p>
<p><strong>第2步：采用AdaBoostClassifier分类器实现</strong></p>
<p>  根据题目要求弱分类器采用决策树，通过sklearn的AdaBoostClassifier类，构建分类器，由于AdaBoostClassifier分类器默认采用CART决策树弱分类器，故不需要设置base_estimator参数。</p>
<pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>ensemble <span class="token keyword">import</span> AdaBoostClassifier
<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np

<span class="token comment" spellcheck="true"># 加载训练数据</span>
X <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
              <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
              <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
              <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
              <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
              <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
              <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
              <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
              <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
              <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span>
              <span class="token punctuation">]</span><span class="token punctuation">)</span>
y <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span>

<span class="token comment" spellcheck="true"># 使用sklearn的AdaBoostClassifier分类器</span>
clf <span class="token operator">=</span> AdaBoostClassifier<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token comment" spellcheck="true"># 进行分类器训练</span>
clf<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>X<span class="token punctuation">,</span> y<span class="token punctuation">)</span>
<span class="token comment" spellcheck="true"># 对数据进行预测</span>
y_predict <span class="token operator">=</span> clf<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>X<span class="token punctuation">)</span>
<span class="token comment" spellcheck="true"># 得到分类器的预测准确率</span>
score <span class="token operator">=</span> clf<span class="token punctuation">.</span>score<span class="token punctuation">(</span>X<span class="token punctuation">,</span> y<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"原始输出:"</span><span class="token punctuation">,</span> y<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"预测输出:"</span><span class="token punctuation">,</span> y_predict<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"预测准确率：{:.2% }"</span><span class="token punctuation">.</span>format<span class="token punctuation">(</span>score<span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<pre><code>原始输出: [-1 -1 -1 -1 -1 -1  1  1 -1 -1]
预测输出: [-1 -1 -1 -1 -1 -1  1  1 -1 -1]
预测准确率：100.00%</code></pre><p><strong>第3步：自编程实现AdaBoost算法</strong></p>
<p>代码思路：</p>
<ol>
<li>写出fit函数，即分类器训练函数；</li>
<li>根据书中第158页例8.1，编写build_stump函数，用于得到分类误差最低的基本分类器；</li>
<li>根据算法第2步(a)~(c)，编写代码；</li>
<li>根据算法第2步(d)，编写updata_w函数，用于更新训练数据集的权值分布；</li>
<li>编写predict函数，用于预测数据；</li>
<li>【附加】编写score函数，用于计算分类器的预测准确率；</li>
<li>【附加】编写print_G函数，用于打印最终分类器。</li>
</ol>
<pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">import</span> numpy <span class="token keyword">as</span> np


<span class="token keyword">class</span> <span class="token class-name">MyAdaBoost</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> tol<span class="token operator">=</span><span class="token number">0.05</span><span class="token punctuation">,</span> max_iter<span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment" spellcheck="true"># 特征</span>
        self<span class="token punctuation">.</span>X <span class="token operator">=</span> None
        <span class="token comment" spellcheck="true"># 标签</span>
        self<span class="token punctuation">.</span>y <span class="token operator">=</span> None
        <span class="token comment" spellcheck="true"># 分类误差小于精度时，分类器训练中止</span>
        self<span class="token punctuation">.</span>tol <span class="token operator">=</span> tol
        <span class="token comment" spellcheck="true"># 最大迭代次数</span>
        self<span class="token punctuation">.</span>max_iter <span class="token operator">=</span> max_iter
        <span class="token comment" spellcheck="true"># 权值分布</span>
        self<span class="token punctuation">.</span>w <span class="token operator">=</span> None
        <span class="token comment" spellcheck="true"># 弱分类器集合</span>
        self<span class="token punctuation">.</span>G <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>

    <span class="token keyword">def</span> <span class="token function">build_stump</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token triple-quoted-string string">"""
        以带权重的分类误差最小为目标，选择最佳分类阈值，得到最佳的决策树桩
        best_stump['dim'] 合适特征的所在维度
        best_stump['thresh']  合适特征的阈值
        best_stump['ineq']  树桩分类的标识lt,rt
        """</span>
        m<span class="token punctuation">,</span> n <span class="token operator">=</span> np<span class="token punctuation">.</span>shape<span class="token punctuation">(</span>self<span class="token punctuation">.</span>X<span class="token punctuation">)</span>
        <span class="token comment" spellcheck="true"># 分类误差</span>
        min_error <span class="token operator">=</span> np<span class="token punctuation">.</span>inf
        <span class="token comment" spellcheck="true"># 小于分类阈值的样本所属的标签类别</span>
        sign <span class="token operator">=</span> None
        <span class="token comment" spellcheck="true"># 最优决策树桩</span>
        best_stump <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token punctuation">}</span>
        <span class="token keyword">for</span> i <span class="token keyword">in</span> range<span class="token punctuation">(</span>n<span class="token punctuation">)</span><span class="token punctuation">:</span>
            <span class="token comment" spellcheck="true"># 求每一种特征的最小值和最大值</span>
            range_min <span class="token operator">=</span> self<span class="token punctuation">.</span>X<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> i<span class="token punctuation">]</span><span class="token punctuation">.</span>min<span class="token punctuation">(</span><span class="token punctuation">)</span>
            range_max <span class="token operator">=</span> self<span class="token punctuation">.</span>X<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> i<span class="token punctuation">]</span><span class="token punctuation">.</span>max<span class="token punctuation">(</span><span class="token punctuation">)</span>
            step_size <span class="token operator">=</span> <span class="token punctuation">(</span>range_max <span class="token operator">-</span> range_min<span class="token punctuation">)</span> <span class="token operator">/</span> n
            <span class="token keyword">for</span> j <span class="token keyword">in</span> range<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> int<span class="token punctuation">(</span>n<span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
                <span class="token comment" spellcheck="true"># 根据n的值，构造切分点</span>
                thresh_val <span class="token operator">=</span> range_min <span class="token operator">+</span> j <span class="token operator">*</span> step_size
                <span class="token comment" spellcheck="true"># 计算左子树和右子树的误差</span>
                <span class="token keyword">for</span> inequal <span class="token keyword">in</span> <span class="token punctuation">[</span><span class="token string">'lt'</span><span class="token punctuation">,</span> <span class="token string">'rt'</span><span class="token punctuation">]</span><span class="token punctuation">:</span>
                    <span class="token comment" spellcheck="true"># (a)得到基本分类器</span>
                    predict_values <span class="token operator">=</span> self<span class="token punctuation">.</span>base_estimator<span class="token punctuation">(</span>self<span class="token punctuation">.</span>X<span class="token punctuation">,</span> i<span class="token punctuation">,</span> thresh_val<span class="token punctuation">,</span> inequal<span class="token punctuation">)</span>
                    <span class="token comment" spellcheck="true"># (b)计算在训练集上的分类误差率</span>
                    err_arr <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span>np<span class="token punctuation">.</span>ones<span class="token punctuation">(</span>m<span class="token punctuation">)</span><span class="token punctuation">)</span>
                    err_arr<span class="token punctuation">[</span>predict_values<span class="token punctuation">.</span>T <span class="token operator">==</span> self<span class="token punctuation">.</span>y<span class="token punctuation">.</span>T<span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token number">0</span>
                    weighted_error <span class="token operator">=</span> np<span class="token punctuation">.</span>dot<span class="token punctuation">(</span>self<span class="token punctuation">.</span>w<span class="token punctuation">,</span> err_arr<span class="token punctuation">)</span>
                    <span class="token keyword">if</span> weighted_error <span class="token operator">&lt;</span> min_error<span class="token punctuation">:</span>
                        min_error <span class="token operator">=</span> weighted_error
                        sign <span class="token operator">=</span> predict_values
                        best_stump<span class="token punctuation">[</span><span class="token string">'dim'</span><span class="token punctuation">]</span> <span class="token operator">=</span> i
                        best_stump<span class="token punctuation">[</span><span class="token string">'thresh'</span><span class="token punctuation">]</span> <span class="token operator">=</span> thresh_val
                        best_stump<span class="token punctuation">[</span><span class="token string">'ineq'</span><span class="token punctuation">]</span> <span class="token operator">=</span> inequal
        <span class="token keyword">return</span> best_stump<span class="token punctuation">,</span> sign<span class="token punctuation">,</span> min_error

    <span class="token keyword">def</span> <span class="token function">updata_w</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> alpha<span class="token punctuation">,</span> predict<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token triple-quoted-string string">"""
        更新样本权重w
        :param alpha: alpha
        :param predict: yi
        :return:
        """</span>
        <span class="token comment" spellcheck="true"># (d)根据迭代公式，更新权值分布</span>
        P <span class="token operator">=</span> self<span class="token punctuation">.</span>w <span class="token operator">*</span> np<span class="token punctuation">.</span>exp<span class="token punctuation">(</span><span class="token operator">-</span>alpha <span class="token operator">*</span> self<span class="token punctuation">.</span>y <span class="token operator">*</span> predict<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>w <span class="token operator">=</span> P <span class="token operator">/</span> P<span class="token punctuation">.</span>sum<span class="token punctuation">(</span><span class="token punctuation">)</span>

    @staticmethod
    <span class="token keyword">def</span> <span class="token function">base_estimator</span><span class="token punctuation">(</span>X<span class="token punctuation">,</span> dimen<span class="token punctuation">,</span> thresh_val<span class="token punctuation">,</span> thresh_ineq<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token triple-quoted-string string">"""
        计算单个弱分类器（决策树桩）预测输出
        :param X: 特征
        :param dimen: 特征的位置（即第几个特征）
        :param thresh_val: 切分点
        :param thresh_ineq: 标记结点的位置，可取左子树(lt)，右子树(rt)
        :return: 返回预测结果矩阵
        """</span>
        <span class="token comment" spellcheck="true"># 预测结果矩阵</span>
        ret_array <span class="token operator">=</span> np<span class="token punctuation">.</span>ones<span class="token punctuation">(</span>np<span class="token punctuation">.</span>shape<span class="token punctuation">(</span>X<span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
        <span class="token comment" spellcheck="true"># 左叶子 ，整个矩阵的样本进行比较赋值</span>
        <span class="token keyword">if</span> thresh_ineq <span class="token operator">==</span> <span class="token string">'lt'</span><span class="token punctuation">:</span>
            ret_array<span class="token punctuation">[</span>X<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> dimen<span class="token punctuation">]</span> <span class="token operator">>=</span> thresh_val<span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token operator">-</span><span class="token number">1.0</span>
        <span class="token keyword">else</span><span class="token punctuation">:</span>
            ret_array<span class="token punctuation">[</span>X<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> dimen<span class="token punctuation">]</span> <span class="token operator">&lt;</span> thresh_val<span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token operator">-</span><span class="token number">1.0</span>
        <span class="token keyword">return</span> ret_array

    <span class="token keyword">def</span> <span class="token function">fit</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> X<span class="token punctuation">,</span> y<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token triple-quoted-string string">"""
        对分类器进行训练
        """</span>
        self<span class="token punctuation">.</span>X <span class="token operator">=</span> X
        self<span class="token punctuation">.</span>y <span class="token operator">=</span> y
        <span class="token comment" spellcheck="true"># （1）初始化训练数据的权值分布</span>
        self<span class="token punctuation">.</span>w <span class="token operator">=</span> np<span class="token punctuation">.</span>full<span class="token punctuation">(</span><span class="token punctuation">(</span>X<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token number">1</span> <span class="token operator">/</span> X<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
        G <span class="token operator">=</span> <span class="token number">0</span>
        <span class="token comment" spellcheck="true"># （2）对m=1,2,...,M进行遍历</span>
        <span class="token keyword">for</span> i <span class="token keyword">in</span> range<span class="token punctuation">(</span>self<span class="token punctuation">.</span>max_iter<span class="token punctuation">)</span><span class="token punctuation">:</span>
            <span class="token comment" spellcheck="true"># (b)得到Gm(x)的分类误差error，获取当前迭代最佳分类阈值sign</span>
            best_stump<span class="token punctuation">,</span> sign<span class="token punctuation">,</span> error <span class="token operator">=</span> self<span class="token punctuation">.</span>build_stump<span class="token punctuation">(</span><span class="token punctuation">)</span>
            <span class="token comment" spellcheck="true"># (c)计算弱分类器Gm(x)的系数</span>
            alpha <span class="token operator">=</span> <span class="token number">1</span> <span class="token operator">/</span> <span class="token number">2</span> <span class="token operator">*</span> np<span class="token punctuation">.</span>log<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">1</span> <span class="token operator">-</span> error<span class="token punctuation">)</span> <span class="token operator">/</span> error<span class="token punctuation">)</span>
            <span class="token comment" spellcheck="true"># 弱分类器Gm(x)权重</span>
            best_stump<span class="token punctuation">[</span><span class="token string">'alpha'</span><span class="token punctuation">]</span> <span class="token operator">=</span> alpha
            <span class="token comment" spellcheck="true"># 保存弱分类器Gm(x)，得到分类器集合G</span>
            self<span class="token punctuation">.</span>G<span class="token punctuation">.</span>append<span class="token punctuation">(</span>best_stump<span class="token punctuation">)</span>
            <span class="token comment" spellcheck="true"># 计算当前总分类器（之前所有弱分类器加权和）误差率</span>
            G <span class="token operator">+=</span> alpha <span class="token operator">*</span> sign
            y_predict <span class="token operator">=</span> np<span class="token punctuation">.</span>sign<span class="token punctuation">(</span>G<span class="token punctuation">)</span>
            error_rate <span class="token operator">=</span> np<span class="token punctuation">.</span>sum<span class="token punctuation">(</span>np<span class="token punctuation">.</span>abs<span class="token punctuation">(</span>y_predict <span class="token operator">-</span> self<span class="token punctuation">.</span>y<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token operator">/</span> <span class="token number">2</span> <span class="token operator">/</span> self<span class="token punctuation">.</span>y<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
            <span class="token keyword">if</span> error_rate <span class="token operator">&lt;</span> self<span class="token punctuation">.</span>tol<span class="token punctuation">:</span>
                <span class="token comment" spellcheck="true"># 满足中止条件，则跳出循环</span>
                <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"迭代次数：{}次"</span><span class="token punctuation">.</span>format<span class="token punctuation">(</span>i <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
                <span class="token keyword">break</span>
            <span class="token keyword">else</span><span class="token punctuation">:</span>
                <span class="token comment" spellcheck="true"># (d)更新训练数据集的权值分布</span>
                self<span class="token punctuation">.</span>updata_w<span class="token punctuation">(</span>alpha<span class="token punctuation">,</span> y_predict<span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">predict</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> X<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token triple-quoted-string string">"""对新数据进行预测"""</span>
        m <span class="token operator">=</span> np<span class="token punctuation">.</span>shape<span class="token punctuation">(</span>X<span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
        G <span class="token operator">=</span> np<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span>m<span class="token punctuation">)</span>
        <span class="token keyword">for</span> i <span class="token keyword">in</span> range<span class="token punctuation">(</span>len<span class="token punctuation">(</span>self<span class="token punctuation">.</span>G<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            stump <span class="token operator">=</span> self<span class="token punctuation">.</span>G<span class="token punctuation">[</span>i<span class="token punctuation">]</span>
            <span class="token comment" spellcheck="true"># 遍历每一个弱分类器，进行加权</span>
            _G <span class="token operator">=</span> self<span class="token punctuation">.</span>base_estimator<span class="token punctuation">(</span>X<span class="token punctuation">,</span> stump<span class="token punctuation">[</span><span class="token string">'dim'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> stump<span class="token punctuation">[</span><span class="token string">'thresh'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> stump<span class="token punctuation">[</span><span class="token string">'ineq'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
            alpha <span class="token operator">=</span> stump<span class="token punctuation">[</span><span class="token string">'alpha'</span><span class="token punctuation">]</span>
            <span class="token comment" spellcheck="true"># (3)构建基本分类器的线性组合</span>
            G <span class="token operator">+=</span> alpha <span class="token operator">*</span> _G
        <span class="token comment" spellcheck="true"># 计算最终分类器的预测结果</span>
        y_predict <span class="token operator">=</span> np<span class="token punctuation">.</span>sign<span class="token punctuation">(</span>G<span class="token punctuation">)</span>
        <span class="token keyword">return</span> y_predict<span class="token punctuation">.</span>astype<span class="token punctuation">(</span>int<span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">score</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> X<span class="token punctuation">,</span> y<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token triple-quoted-string string">"""计算分类器的预测准确率"""</span>
        y_predict <span class="token operator">=</span> self<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>X<span class="token punctuation">)</span>
        error_rate <span class="token operator">=</span> np<span class="token punctuation">.</span>sum<span class="token punctuation">(</span>np<span class="token punctuation">.</span>abs<span class="token punctuation">(</span>y_predict <span class="token operator">-</span> y<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token operator">/</span> <span class="token number">2</span> <span class="token operator">/</span> y<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
        <span class="token keyword">return</span> <span class="token number">1</span> <span class="token operator">-</span> error_rate

    <span class="token keyword">def</span> <span class="token function">print_G</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        i <span class="token operator">=</span> <span class="token number">1</span>
        s <span class="token operator">=</span> <span class="token string">"G(x) = sign[f(x)] = sign["</span>
        <span class="token keyword">for</span> stump <span class="token keyword">in</span> self<span class="token punctuation">.</span>G<span class="token punctuation">:</span>
            <span class="token keyword">if</span> i <span class="token operator">!=</span> <span class="token number">1</span><span class="token punctuation">:</span>
                s <span class="token operator">+=</span> <span class="token string">" + "</span>
            s <span class="token operator">+=</span> <span class="token string">"{}·G{}(x)"</span><span class="token punctuation">.</span>format<span class="token punctuation">(</span>round<span class="token punctuation">(</span>stump<span class="token punctuation">[</span><span class="token string">'alpha'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">,</span> i<span class="token punctuation">)</span>
            i <span class="token operator">+=</span> <span class="token number">1</span>
        s <span class="token operator">+=</span> <span class="token string">"]"</span>
        <span class="token keyword">return</span> s<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<pre class="line-numbers language-python"><code class="language-python"><span class="token comment" spellcheck="true"># 加载训练数据</span>
X <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
              <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
              <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
              <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
              <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
              <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
              <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
              <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
              <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
              <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span>
              <span class="token punctuation">]</span><span class="token punctuation">)</span>
y <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span>

clf <span class="token operator">=</span> MyAdaBoost<span class="token punctuation">(</span><span class="token punctuation">)</span>
clf<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>X<span class="token punctuation">,</span> y<span class="token punctuation">)</span>
y_predict <span class="token operator">=</span> clf<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>X<span class="token punctuation">)</span>
score <span class="token operator">=</span> clf<span class="token punctuation">.</span>score<span class="token punctuation">(</span>X<span class="token punctuation">,</span> y<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"原始输出:"</span><span class="token punctuation">,</span> y<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"预测输出:"</span><span class="token punctuation">,</span> y_predict<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"预测正确率：{:.2%}"</span><span class="token punctuation">.</span>format<span class="token punctuation">(</span>score<span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"最终分类器G(x)为:"</span><span class="token punctuation">,</span> clf<span class="token punctuation">.</span>print_G<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<pre><code>迭代次数：8次
原始输出: [-1 -1 -1 -1 -1 -1  1  1 -1 -1]
预测输出: [-1 -1 -1 -1 -1 -1  1  1 -1 -1]
预测正确率：100.00%
最终分类器G(x)为: G(x) = sign[f(x)] = sign[0.6931·G1(x) + 0.7332·G2(x) + 0.4993·G3(x) + 0.6236·G4(x) + 0.7214·G5(x) + 0.5575·G6(x) + 0.6021·G7(x) + 0.8397·G8(x)]</code></pre><h3 id="习题8-2"><a href="#习题8-2" class="headerlink" title="习题8.2"></a>习题8.2</h3><p>  比较支持向量机、 AdaBoost 、Logistic回归模型的学习策略与算法</p>
<p><strong>解答：</strong></p>
<p><strong>解答思路：</strong></p>
<ol>
<li>列出支持向量机的学习策略与学习算法</li>
<li>列出AdaBoost的学习策略与学习算法</li>
<li>列出Logistic回归模型的学习策略与学习算法</li>
<li>比较三者的学习策略与算法</li>
</ol>
<p><strong>解答步骤：</strong></p>
<p><strong>第1步：支持向量机的学习策略与算法</strong></p>
<p>  根据书中第131页7.2.4节（合页损失函数）</p>
<blockquote>
<p>  对于线性支持向量机学习来说，其模型为分离超平面$w^* \cdot x + b^* = 0$及决策函数$f(x)=\text{sign}(w^* \cdot x + b^*)$，其学习策略为软间隔最大化，学习算法为凸二次规划。<br>  线性支持向量机学习还有另外一种解释，就是最小化一下目标函数：</p>
</blockquote>
<p>$$<br>\sum_{i=1}^N [1 - y_i(w \cdot x_i + b)]_+ + \lambda |w|^2<br>$$</p>
<blockquote>
<p>目标函数的第1项是经验损失或经验风险，函数</p>
</blockquote>
<p>$$<br>L(y(w \cdot b + x)) = [1 - y_i(w \cdot x_i + b)]_+<br>$$</p>
<blockquote>
<p>被称为合页损失函数，第2项是系数为$\lambda$的$w$的$L_2$范数，是正则化项。</p>
</blockquote>
<p>  根据书中第142~143页7.4节（序列最小最优化算法）</p>
<blockquote>
<p>  SMO算法是一种启发式算法，其基本思路是：如果所有变量的解都满足此最优化问题的KKT条件，那么这个最优化问题的解就得到了。因为KKT条件是该最优化问题的充分必要条件。<br>  整个SMO算法包括两个部分：求解两个变量二次规划的解析方法和选择变量的启发式方法。</p>
</blockquote>
<p>综上所述：</p>
<ol>
<li>支持向量机的学习策略：软间隔最大化、最小化由合页损失函数和正则化项组成的目标函数</li>
<li>支持向量机的学习算法：凸二次规划、SMO算法（序列最小最优化算法）</li>
</ol>
<p><strong>第2步：AdaBoost的学习策略与算法</strong></p>
<p>  根据书中第162页8.3节（AdbBoost算法的解释）</p>
<blockquote>
<p>  AdaBoost算法还有另一个解释，即可认为AdaBoost算法是模型为加法模型、损失函数为指数函数、学习算法为前向分步算法时的二类分类学习方法。<br>  给定训练数据及损失函数$L(y,f(x))$的条件下，学习加法模型$f(x)$成为经验风险极小化即损失函数极小化问题：</p>
</blockquote>
<p>$$<br>\min \limits_{\beta_m ,\gamma_m} \sum_{i=1}^N L \left(y_i, \sum_{m=1}^M \beta_m b(x_i;\gamma_m) \right)<br>$$</p>
<blockquote>
<p>  定理8.3 AdaBoost算法是前向分步加法算法的特例。这时，模型是由基本分类器组成的加法模型，损失函数是指数函数。</p>
</blockquote>
<p>综上所述：</p>
<ol>
<li>AdaBoost的学习策略：极小化通过加法模型组成的指数损失函数</li>
<li>AdaBoost的学习算法：学习加法模型的前向分步算法</li>
</ol>
<p><strong>第3步：Logistic回归模型的学习策略与算法</strong></p>
<p>  根据书中第93页6.1.3节（模型参数估计）</p>
<blockquote>
<p>  Logistic回归模型学习时，对于给定的训练数据集$T={(x_1,y_1), (x_2,y_2), \cdots, (x_N,y_N)}$，其中$x_i \in R^n$，$y_i \in {0, 1}$，可以应用极大似然估计法估计模型参数，从而得到Logistic回归模型。</p>
</blockquote>
<p>  根据书中第103页6.3节（模型学习的最优化算法）</p>
<blockquote>
<p>  Logistic回归模型、最大熵模型学习归结为以似然函数为目标函数的最优化问题，通常通过迭代算法求解。常用的方法有改进的迭代尺度法、梯度下降法、牛顿法或拟牛顿法。</p>
</blockquote>
<p>综上所述：</p>
<ol>
<li>Logistic回归模型的学习策略：极大似然估计法</li>
<li>Logistic回归模型的学习算法：改进的迭代尺度法、梯度下降法、牛顿法或拟牛顿法</li>
</ol>
<p><strong>第4步：比较支持向量机、 AdaBoost 、Logistic回归模型的学习策略与算法</strong></p>
<table>
<thead>
<tr>
<th>  </th>
<th>学习策略</th>
<th>算法</th>
</tr>
</thead>
<tbody><tr>
<td>支持向量机</td>
<td>软间隔最大化、最小化由合页损失函数和正则化项组成的目标函数</td>
<td>凸二次规划、SMO算法（序列最小最优化算法）</td>
</tr>
<tr>
<td>AdaBoost</td>
<td>极小化通过加法模型组成的指数损失函数</td>
<td>学习加法模型的前向分步算法</td>
</tr>
<tr>
<td>Logistic回归</td>
<td>极大似然估计法</td>
<td>改进的迭代尺度法、梯度下降法、牛顿法或拟牛顿法</td>
</tr>
</tbody></table>
<h1 id="九、EM算法及其推广"><a href="#九、EM算法及其推广" class="headerlink" title="九、EM算法及其推广"></a>九、EM算法及其推广</h1><p>EM算法是一种迭代算法，1977年由 Dempster等人总结提出，用于含有隐变量（hidden variable）的概率模型参数的极大似然估计，或极大后验概率估计EM算法的每次迭代由两步组成：E步，求期望（expectation）;M步，求极大（maximization）.所以这一算法称为期望极大算法（expectation maximization algorithm）,简称EM算法。</p>
<h2 id="9-1-EM算法的引入"><a href="#9-1-EM算法的引入" class="headerlink" title="9.1 EM算法的引入"></a>9.1 EM算法的引入</h2><p>概率模型有时既含有观测变量( observable variable),又含有隐变量或潜在变量（latent variable）如果概率模型的变量都是观测变量，那么给定数据，可以直接用极大似然估计法，或贝叶斯估计法估计模型参数。但是，当模型含有隐变量时，就不能简单地使用这些估计方法。EM算法就是含有隐变量的概率模型参数的极大似然估计法，或极大后验概率估计法。</p>
<h3 id="9-1-1-EM算法"><a href="#9-1-1-EM算法" class="headerlink" title="9.1.1 EM算法"></a>9.1.1 EM算法</h3><p><strong>算法9.1(EM算法)</strong></p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20220112095322459.png" alt=""></p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20220112095350270.png" alt=""></p>
<p><strong>定义9.1(Q函数)</strong></p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20220112095438892.png" alt=""></p>
<h3 id="9-1-2-EM算法的导出"><a href="#9-1-2-EM算法的导出" class="headerlink" title="9.1.2 EM算法的导出"></a>9.1.2 EM算法的导出</h3><p>EM算法是通过不断求解下界的极大化逼近求解对数似然函数极大化的算法。</p>
<p>EM算法不能保证找到全局最优值。</p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20220112095712616.png" alt="EM算法解释"></p>
<h3 id="9-1-3-EM算法在非监督学习中的应用"><a href="#9-1-3-EM算法在非监督学习中的应用" class="headerlink" title="9.1.3 EM算法在非监督学习中的应用"></a>9.1.3 EM算法在非监督学习中的应用</h3><p>有时训练数据只有输入没有对应的输出${(x_1,·),(x_2,·)…,(x_N,·)}$,从这样的数据学习模型称为非监督学习问题。EM算法可以用于生成模型的非监督学习，生成模型由联合概率分布$P(X,Y)$表示，可以认为非监督学习训练数据是联合概率分布产生的数据。X为观测数据，Y为未观测数据。</p>
<h2 id="9-2-EM算法的收敛性"><a href="#9-2-EM算法的收敛性" class="headerlink" title="9.2 EM算法的收敛性"></a>9.2 EM算法的收敛性</h2><p>EM算法提供一种近似计算含有隐变量概率模型的极大似然估计的方法。EM算法的最大优点是简单性和普适性。我们很自然地要问：EM算法得到的估计序列是否收敛？如果收敛，是否收敛到全局最大值或局部极大值？</p>
<p><strong>定理 9,1</strong></p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20220112100223618.png" alt=""></p>
<p><strong>定理 9.2</strong></p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20220112100301580.png" alt=""></p>
<h2 id="9-3-EM算法在高斯混合模型学习中的应用"><a href="#9-3-EM算法在高斯混合模型学习中的应用" class="headerlink" title="9.3 EM算法在高斯混合模型学习中的应用"></a>9.3 EM算法在高斯混合模型学习中的应用</h2><p>EM算法的一个重要应用是高斯混合模型的参数估计。高斯混合模型应用广泛，在许多情况下，EM算法是学习高斯混合模型（Gaussian misture model）的有<br>效方法。</p>
<h3 id="9-3-1-高斯混合模型"><a href="#9-3-1-高斯混合模型" class="headerlink" title="9.3.1 高斯混合模型"></a>9.3.1 高斯混合模型</h3><p><strong>定义9.2（高斯混合模型）</strong></p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20220112100458163.png" alt=""></p>
<h3 id="9-3-2-高斯混合模型参数估计的EM算法"><a href="#9-3-2-高斯混合模型参数估计的EM算法" class="headerlink" title="9.3.2 高斯混合模型参数估计的EM算法"></a>9.3.2 高斯混合模型参数估计的EM算法</h3><p><strong>算法9.2 (高斯混合模型参数估计的EM算法)</strong></p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20220112100624518.png" alt=""></p>
<h2 id="9-4-EM算法的推广"><a href="#9-4-EM算法的推广" class="headerlink" title="9.4 EM算法的推广"></a>9.4 EM算法的推广</h2><p>EM算法还可以解释为F函数（Function）的极大-极大算法（maximization maximization algorithm）,基于这个解释有若干变形与推广，如广义期望极大（generalized expectation maximization,GEM）算法。</p>
<h3 id="9-4-1-F函数的极大ー极大算法"><a href="#9-4-1-F函数的极大ー极大算法" class="headerlink" title="9.4.1 F函数的极大ー极大算法"></a>9.4.1 F函数的极大ー极大算法</h3><p><strong>定义9.3 (F函数)</strong></p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20220112100825719.png" alt=""></p>
<p><strong>引理 9.1</strong></p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20220112100936561.png" alt=""></p>
<p><strong>引理 9.2</strong></p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20220112101017805.png" alt=""></p>
<p><strong>定理 9.3</strong></p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20220112101045899.png" alt=""></p>
<p><strong>定理9.4 EM算法的一次迭代可由F函数的极大-极大算法实现</strong></p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20220112101128799.png" alt=""></p>
<h3 id="9-4-2-GEM算法"><a href="#9-4-2-GEM算法" class="headerlink" title="9.4.2 GEM算法"></a>9.4.2 GEM算法</h3><p><strong>算法9.3 (GEM算法1)</strong></p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20220112101223923.png" alt=""></p>
<p><strong>算法9.4 (GEM算法2)</strong></p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20220112101322576.png" alt=""></p>
<p><strong>算法9.5 (GEM算法3)</strong></p>
<p>输入：观测数据，Q函数；</p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20220112101428667.png" alt=""></p>
<p>GEM算法的特点是每次迭代増加F函数值（并不一定是极大化F函数），从而增加似然函数值.</p>
<p>一些解释：</p>
<ul>
<li><a href="https://zhuanlan.zhihu.com/p/40991784" target="_blank" rel="noopener">EM算法详解</a></li>
<li><a href="https://zhuanlan.zhihu.com/p/78311644" target="_blank" rel="noopener">【机器学习】EM——期望最大（非常详细）</a></li>
</ul>
<h2 id="习题-8"><a href="#习题-8" class="headerlink" title="习题"></a>习题</h2><h3 id="习题9-1"><a href="#习题9-1" class="headerlink" title="习题9.1"></a>习题9.1</h3><p>  如例9.1的三硬币模型，假设观测数据不变，试选择不同的初值，例如，$\pi^{(0)}=0.46,p^{(0)}=0.55,q^{(0)}=0.67$，求模型参数为$\theta=(\pi,p,q)$的极大似然估计。  </p>
<p><strong>解答：</strong></p>
<p><strong>解答思路：</strong></p>
<ol>
<li>列出例9.1的三硬币模型；</li>
<li>写出三硬币模型的EM算法；</li>
<li>根据上述EM算法，编写代码，并求出模型参数的极大似然估计。</li>
</ol>
<p><strong>解答步骤：</strong></p>
<p><strong>第1步：例9.1的三硬币模型</strong></p>
<p>  根据书中第175页例9.1（三硬币模型）：</p>
<blockquote>
<p>  假设有3枚硬币，分别记作A，B，C。这些硬币正面出现的概率分别是$\pi$，$p$和$q$。进行如下掷硬币试验：先掷硬币A，根据其结果选出硬币B或硬币C，正面选硬币B，反面选硬币C；然后掷选出的硬币，掷硬币的结果，出现正面记作1，出现方面记作0；独立地重复$n$次试验（这里，$n=10$），观测结果如下：</p>
</blockquote>
<p>$$<br>1,1,0,1,0,0,1,0,1,1<br>$$</p>
<blockquote>
<p>假设只能观测到掷硬币的结果，不能观测掷硬币的过程。  </p>
<p>  三硬币模型可以写作</p>
</blockquote>
<p>$$<br>\begin{aligned}<br>P(y|\theta) &amp;= \sum_z P(y, z | \theta) = \sum_z P(z|\theta) P(y | z, \theta) \<br>&amp;= \pi p^y (1-p)^{1-y} + (1 - \pi) q^y (1- q)^{1-y}<br>\end{aligned}<br>$$</p>
<blockquote>
<p>这里：</p>
<ol>
<li>随机变量$y$是观测变量，表示一次试验观测的结果是1或0；</li>
<li>随机变量$z$是隐变量，表示未观测到的掷硬币A的结果；</li>
<li>$\theta=(\pi, p, q)$是模型参数。</li>
</ol>
</blockquote>
<p><strong>第2步：三硬币模型的EM算法</strong></p>
<p>  根据书中第176页三硬币模型的EM算法：</p>
<blockquote>
<p>  EM算法首先选取参数的初值，记作$\theta^{(0)}=(\pi^{(0)}, p^{(0)}, q^{(0)})$，然后通过下面的步骤迭代计算参数的估计值，直至收敛为止。第$i$次迭代参数的估计值为$\theta^{(i)}=(\pi^{(i)}, p^{(i)}, q^{(i)})$。EM算法的第$i+1$次迭代如下：</p>
<p>  E步：计算在模型参数$\pi^{(i)}, p^{(i)}, q^{(i)}$下观测数据$y_j$来自掷硬币B的概率</p>
</blockquote>
<p>$$<br>\mu_j^{(i+1)} = \frac{\pi^{(i)} (p^{(i)})^{y_j} (1-p^{(i)})^{1-y_j} }{\pi^{(i)} (p^{(i)})^{y_j} (1-p^{(i)})^{1-y_j} + (1-\pi^{(i)}) (q^{(i)})^{y_j} (1-q^{(i)})^{1-y_j} }<br>$$</p>
<blockquote>
<p>  M步：计算模型参数的新估计值</p>
</blockquote>
<p>$$<br>\pi^{(i+1)} = \frac{1}{n} \sum_{j=1}^N \mu_j^{(i+1)} \<br>p^{(i+1)} = \frac{ \displaystyle \sum_{j=1}^n \mu_j^{(i+1)} y_j }{ \displaystyle \sum_{j=1}^n \mu_j^{(i+1)} } \<br>q^{(i+1)} = \frac{ \displaystyle \sum_{j=1}^n ( 1 - \mu_j^{(i+1)} ) y_j }{ \displaystyle \sum_{j=1}^n ( 1 - \mu_j^{(i+1)} ) }<br>$$</p>
<p><strong>第3步：编写代码并求出模型参数的极大似然估计</strong></p>
<pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">import</span> math


<span class="token keyword">class</span> <span class="token class-name">ThreeCoinEM</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> prob<span class="token punctuation">,</span> tol<span class="token operator">=</span><span class="token number">1e</span><span class="token operator">-</span><span class="token number">6</span><span class="token punctuation">,</span> max_iter<span class="token operator">=</span><span class="token number">1000</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token triple-quoted-string string">"""
        初始化模型参数
        :param prob: 模型参数的初值
        :param tol: 收敛阈值
        :param max_iter: 最大迭代次数
        """</span>
        self<span class="token punctuation">.</span>prob_A<span class="token punctuation">,</span> self<span class="token punctuation">.</span>prob_B<span class="token punctuation">,</span> self<span class="token punctuation">.</span>prob_C <span class="token operator">=</span> prob
        self<span class="token punctuation">.</span>tol <span class="token operator">=</span> tol
        self<span class="token punctuation">.</span>max_iter <span class="token operator">=</span> max_iter

    <span class="token keyword">def</span> <span class="token function">calc_mu</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> j<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token triple-quoted-string string">"""
        （E步）计算mu
        :param j: 观测数据y的第j个
        :return: 在模型参数下观测数据yj来自掷硬币B的概率
        """</span>
        <span class="token comment" spellcheck="true"># 掷硬币A观测结果为正面</span>
        pro_1 <span class="token operator">=</span> self<span class="token punctuation">.</span>prob_A <span class="token operator">*</span> \
            math<span class="token punctuation">.</span>pow<span class="token punctuation">(</span>self<span class="token punctuation">.</span>prob_B<span class="token punctuation">,</span> data<span class="token punctuation">[</span>j<span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token operator">*</span> \
            math<span class="token punctuation">.</span>pow<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">1</span> <span class="token operator">-</span> self<span class="token punctuation">.</span>prob_B<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token number">1</span> <span class="token operator">-</span> data<span class="token punctuation">[</span>j<span class="token punctuation">]</span><span class="token punctuation">)</span>
        <span class="token comment" spellcheck="true"># 掷硬币A观测结果为反面</span>
        pro_2 <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token number">1</span> <span class="token operator">-</span> self<span class="token punctuation">.</span>prob_A<span class="token punctuation">)</span> <span class="token operator">*</span> math<span class="token punctuation">.</span>pow<span class="token punctuation">(</span>self<span class="token punctuation">.</span>prob_C<span class="token punctuation">,</span>
                                             data<span class="token punctuation">[</span>j<span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token operator">*</span> math<span class="token punctuation">.</span>pow<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">1</span> <span class="token operator">-</span> self<span class="token punctuation">.</span>prob_C<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token number">1</span> <span class="token operator">-</span> data<span class="token punctuation">[</span>j<span class="token punctuation">]</span><span class="token punctuation">)</span>
        <span class="token keyword">return</span> pro_1 <span class="token operator">/</span> <span class="token punctuation">(</span>pro_1 <span class="token operator">+</span> pro_2<span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">fit</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> data<span class="token punctuation">)</span><span class="token punctuation">:</span>
        count <span class="token operator">=</span> len<span class="token punctuation">(</span>data<span class="token punctuation">)</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"模型参数的初值："</span><span class="token punctuation">)</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"prob_A={}, prob_B={}, prob_C={}"</span><span class="token punctuation">.</span>format<span class="token punctuation">(</span>
            self<span class="token punctuation">.</span>prob_A<span class="token punctuation">,</span> self<span class="token punctuation">.</span>prob_B<span class="token punctuation">,</span> self<span class="token punctuation">.</span>prob_C<span class="token punctuation">)</span><span class="token punctuation">)</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"EM算法训练过程："</span><span class="token punctuation">)</span>
        <span class="token keyword">for</span> i <span class="token keyword">in</span> range<span class="token punctuation">(</span>self<span class="token punctuation">.</span>max_iter<span class="token punctuation">)</span><span class="token punctuation">:</span>
            <span class="token comment" spellcheck="true"># （E步）得到在模型参数下观测数据yj来自掷硬币B的概率</span>
            _mu <span class="token operator">=</span> <span class="token punctuation">[</span>self<span class="token punctuation">.</span>calc_mu<span class="token punctuation">(</span>j<span class="token punctuation">)</span> <span class="token keyword">for</span> j <span class="token keyword">in</span> range<span class="token punctuation">(</span>count<span class="token punctuation">)</span><span class="token punctuation">]</span>
            <span class="token comment" spellcheck="true"># （M步）计算模型参数的新估计值</span>
            prob_A <span class="token operator">=</span> <span class="token number">1</span> <span class="token operator">/</span> count <span class="token operator">*</span> sum<span class="token punctuation">(</span>_mu<span class="token punctuation">)</span>
            prob_B <span class="token operator">=</span> sum<span class="token punctuation">(</span><span class="token punctuation">[</span>_mu<span class="token punctuation">[</span>k<span class="token punctuation">]</span> <span class="token operator">*</span> data<span class="token punctuation">[</span>k<span class="token punctuation">]</span> <span class="token keyword">for</span> k <span class="token keyword">in</span> range<span class="token punctuation">(</span>count<span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">)</span> \
                <span class="token operator">/</span> sum<span class="token punctuation">(</span><span class="token punctuation">[</span>_mu<span class="token punctuation">[</span>k<span class="token punctuation">]</span> <span class="token keyword">for</span> k <span class="token keyword">in</span> range<span class="token punctuation">(</span>count<span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
            prob_C <span class="token operator">=</span> sum<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token number">1</span> <span class="token operator">-</span> _mu<span class="token punctuation">[</span>k<span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token operator">*</span> data<span class="token punctuation">[</span>k<span class="token punctuation">]</span> <span class="token keyword">for</span> k <span class="token keyword">in</span> range<span class="token punctuation">(</span>count<span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">)</span> \
                <span class="token operator">/</span> sum<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token number">1</span> <span class="token operator">-</span> _mu<span class="token punctuation">[</span>k<span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token keyword">for</span> k <span class="token keyword">in</span> range<span class="token punctuation">(</span>count<span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
            <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'第{}次：prob_A={:.4f}, prob_B={:.4f}, prob_C={:.4f}'</span><span class="token punctuation">.</span>format<span class="token punctuation">(</span>
                i <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">,</span> prob_A<span class="token punctuation">,</span> prob_B<span class="token punctuation">,</span> prob_C<span class="token punctuation">)</span><span class="token punctuation">)</span>
            <span class="token comment" spellcheck="true"># 计算误差值</span>
            error <span class="token operator">=</span> abs<span class="token punctuation">(</span>self<span class="token punctuation">.</span>prob_A <span class="token operator">-</span> prob_A<span class="token punctuation">)</span> <span class="token operator">+</span> \
                abs<span class="token punctuation">(</span>self<span class="token punctuation">.</span>prob_B <span class="token operator">-</span> prob_B<span class="token punctuation">)</span> <span class="token operator">+</span> abs<span class="token punctuation">(</span>self<span class="token punctuation">.</span>prob_C <span class="token operator">-</span> prob_C<span class="token punctuation">)</span>
            self<span class="token punctuation">.</span>prob_A <span class="token operator">=</span> prob_A
            self<span class="token punctuation">.</span>prob_B <span class="token operator">=</span> prob_B
            self<span class="token punctuation">.</span>prob_C <span class="token operator">=</span> prob_C
            <span class="token comment" spellcheck="true"># 判断是否收敛</span>
            <span class="token keyword">if</span> error <span class="token operator">&lt;</span> self<span class="token punctuation">.</span>tol<span class="token punctuation">:</span>
                <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"模型参数的极大似然估计："</span><span class="token punctuation">)</span>
                <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"prob_A={:.4f}, prob_B={:.4f}, prob_C={:.4f}"</span><span class="token punctuation">.</span>format<span class="token punctuation">(</span>self<span class="token punctuation">.</span>prob_A<span class="token punctuation">,</span> self<span class="token punctuation">.</span>prob_B<span class="token punctuation">,</span>
                                                                           self<span class="token punctuation">.</span>prob_C<span class="token punctuation">)</span><span class="token punctuation">)</span>
                <span class="token keyword">break</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<pre class="line-numbers language-python"><code class="language-python"><span class="token comment" spellcheck="true"># 加载数据</span>
data <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span>
<span class="token comment" spellcheck="true"># 模型参数的初值</span>
init_prob <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">0.46</span><span class="token punctuation">,</span> <span class="token number">0.55</span><span class="token punctuation">,</span> <span class="token number">0.67</span><span class="token punctuation">]</span>

<span class="token comment" spellcheck="true"># 三硬币模型的EM模型</span>
em <span class="token operator">=</span> ThreeCoinEM<span class="token punctuation">(</span>prob<span class="token operator">=</span>init_prob<span class="token punctuation">,</span> tol<span class="token operator">=</span><span class="token number">1e</span><span class="token operator">-</span><span class="token number">5</span><span class="token punctuation">,</span> max_iter<span class="token operator">=</span><span class="token number">100</span><span class="token punctuation">)</span>
<span class="token comment" spellcheck="true"># 模型训练</span>
em<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>data<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<pre><code>模型参数的初值：
prob_A=0.46, prob_B=0.55, prob_C=0.67
EM算法训练过程：
第1次：prob_A=0.4619, prob_B=0.5346, prob_C=0.6561
第2次：prob_A=0.4619, prob_B=0.5346, prob_C=0.6561
模型参数的极大似然估计：
prob_A=0.4619, prob_B=0.5346, prob_C=0.6561</code></pre><p>  可见通过两次迭代，模型参数已经收敛，三硬币正面出现的概率分别为0.4619，0.5346，0.6561</p>
<h3 id="习题9-2"><a href="#习题9-2" class="headerlink" title="习题9.2"></a>习题9.2</h3><p>证明引理9.2。</p>
<p><strong>解答：</strong></p>
<p><strong>解答思路：</strong></p>
<ol>
<li>写出需要证明的引理9.2；</li>
<li>列出$F$函数定义；</li>
<li>根据引理9.1，进行公式推导；</li>
<li>根据约束条件$\displaystyle \sum_z \tilde{P}_{\theta}(Z) = 1$，可证明引理9.2。</li>
</ol>
<p><strong>解答步骤：</strong></p>
<p><strong>第1步：需要证明的引理9.2</strong></p>
<p>  根据书中第188页引理9.2：</p>
<blockquote>
<p>若$\tilde{P}_{\theta}(Z)=P(Z | Y, \theta)$，则</p>
</blockquote>
<p>$$<br>F(\tilde{P}, \theta)=\log P(Y|\theta)<br>$$</p>
<p><strong>第2步：$F$函数定义</strong></p>
<p>  根据书中第187页$F$函数定义：</p>
<blockquote>
<p>  假设隐变量数据$Z$的概率分布为$\tilde{P}(Z)$，定义分布$\tilde{P}$与参数$\theta$的函数$F(\tilde{P}, \theta)$如下：</p>
</blockquote>
<p>$$<br>F(\tilde{P}, \theta) = E_{\tilde{P} }[\log P(Y, Z|\theta)] + H(\tilde{P})<br>$$</p>
<blockquote>
<p>称为$F$函数。式中$H(\tilde{P}) = - E_{\tilde{P} } \log \tilde{P}(Z)$是分布$\tilde{P}(Z)$的熵。</p>
</blockquote>
<p><strong>第3步：引理9.1</strong></p>
<p>  根据书中第187页引理9.1：</p>
<blockquote>
<p>对于固定的$\theta$，存在唯一的分布$\tilde{P}<em>{\theta}$极大化$F(\tilde{P}, \theta)$，这时$\tilde{P}</em>{\theta}$由下式给出：</p>
</blockquote>
<p>$$<br>\tilde{P}_{\theta}(Z) = P(Z | Y, \theta)<br>$$</p>
<blockquote>
<p>并且$\tilde{P}_{\theta}$随$\theta$连续变化。</p>
</blockquote>
<p>$\begin{aligned}<br>\therefore F(\tilde{P}, \theta)<br>&amp;= E_{\tilde{P} }[\log P(Y, Z|\theta)] + H(\tilde{P}) \<br>&amp;= E_{\tilde{P} }[\log P(Y,Z|\theta)] -E_{\tilde{P} } \log \tilde{P}(Z) \quad （F函数定义：H(\tilde{P}) = - E_{\tilde{P} } \log \tilde{P}(Z)）\<br>&amp;= \sum_Z \log P(Y,Z|\theta) \tilde{P}_{\theta}(Z) - \sum_Z \log \tilde{P}(Z) \cdot \tilde{P}(Z)<br>\end{aligned}$ </p>
<p>根据引理9.1：$\tilde{P}_{\theta}(Z) = P(Z | Y, \theta)$</p>
<p>$\begin{aligned}<br>F(\tilde{P}, \theta)<br>&amp;= \sum_Z \log P(Y,Z|\theta) \tilde{P}_{\theta}(Z) - \sum_Z \log \tilde{P}(Z) \cdot \tilde{P}(Z) \<br>&amp;= \sum_Z \log P(Y,Z|\theta) P(Z|Y,\theta) -  \sum_Z \log P(Z|Y,\theta) \cdot P(Z|Y,\theta) \<br>&amp;= \sum_Z P(Z|Y,\theta) \left[ \log P(Y,Z|\theta) - \log P(Z|Y,\theta) \right] \<br>&amp;= \sum_Z P(Z|Y,\theta) \log \frac{P(Y,Z|\theta)}{P(Z|Y,\theta)} \<br>&amp;= \sum_Z P(Z|Y,\theta) \log P(Y|\theta) \<br>&amp;= \log P(Y|\theta) \sum_Z P(Z|Y,\theta)<br>\end{aligned}$  </p>
<p><strong>第4步：根据引理9.1，得证</strong></p>
<p>根据引理9.1，可知：$\displaystyle \sum_Z P(Z|Y, \theta) = \sum_Z \tilde{P}_{\theta}(Z) = 1$  </p>
<p>$\therefore F(\tilde{P}, \theta) = \log P(Y|\theta)$，引理9.2得证。</p>
<h3 id="习题9-3-⭐⭐⭐"><a href="#习题9-3-⭐⭐⭐" class="headerlink" title="习题9.3 ⭐⭐⭐"></a>习题9.3 ⭐⭐⭐</h3><p>已知观测数据<br>-67，-48，6，8，14，16，23，24，28，29，41，49，56，60，75<br>试估计两个分量的高斯混合模型的5个参数。</p>
<p><strong>解答：</strong></p>
<p><strong>解答思路：</strong></p>
<p>  两个分量的高斯混合模型一共有6个参数$\mu_1, \mu_2, \sigma_1, \sigma_2, \alpha_1, \alpha_2$，其中$\alpha_2$可由$\alpha_2 = 1- \alpha_1$得到，故仅估计5个参数即可。</p>
<ol>
<li>写出高斯混合模型；</li>
<li>写出高斯混合模型参数估计的EM算法；</li>
<li>采用sklearn的GaussianMixture计算6个参数；</li>
<li>采用自编程实现高斯混合模型的EM算法。</li>
</ol>
<p><strong>解答步骤：</strong></p>
<p><strong>第1步：高斯混合模型</strong></p>
<p>  根据书中第183页高斯混合模型：</p>
<blockquote>
<p>高斯混合模型是指具有如下形式的概率分布模型：</p>
</blockquote>
<p>$$<br>P(y | \theta) = \sum_{k=1}^K \alpha_k \phi(y|\theta_k)<br>$$</p>
<blockquote>
<p>其中，$\alpha_k$是系数，$\alpha_k \geqslant 0$，$\displaystyle \sum_{k=1}^K \alpha_k = 1$；$\phi(y|\theta)$是高斯分布密度，$\theta_k=(u_k, \sigma_k^2)$，</p>
</blockquote>
<p>$$<br>\phi(y|\theta_k) = \frac{1}{\sqrt{2 \pi} \sigma_k} \exp \left( -\frac{(y - \mu_k)^2}{ 2 \sigma_k^2} \right)<br>$$</p>
<blockquote>
<p>称为第$k$个分模型。</p>
</blockquote>
<p>从上述描述中可知，如果是2个高斯混合分模型，一共需要估计的参数有6个$\mu_1, \mu_2, \sigma_1, \sigma_2, \alpha_1, \alpha_2$，其中$\alpha_1 + \alpha_2 = 1$</p>
<p><strong>第2步：高斯混合模型参数估计的EM算法</strong></p>
<p>  根据书中第186页算法9.2：</p>
<blockquote>
<p>输入：观测数据$y_1, y_2, \cdots, y_N$，高斯混合模型；<br>输出：高斯混合模型参数。<br>（1）取参数的初始值开始迭代；<br>（2）E步：依据当前模型参数，计算分模型$k$对观测数据$y_i$的响应度</p>
</blockquote>
<p>$$<br>\hat{\gamma}<em>{jk} = \frac{\alpha_k \phi(y_j | \theta_k)}{\displaystyle \sum</em>{k=1}^K \alpha_k \phi(y_j | \theta_k)}, \quad j=1,2,\cdots,N; \quad k=1,2,\cdots,K<br>$$</p>
<blockquote>
<p>（3）M步：计算新一轮迭代的模型参数</p>
</blockquote>
<p>$$<br>\hat{u}<em>k = \frac{\displaystyle \sum</em>{j=1}^N \hat{\gamma}<em>{jk} y_j }{\displaystyle \sum</em>{j=1}^N \hat{\gamma}<em>{jk} }, \quad k=1,2,\cdots,K \<br>\hat{\sigma}_k^2 = \frac{\displaystyle \sum</em>{j=1}^N \hat{\gamma}<em>{jk} (y_j - u_k)^2 }{\displaystyle \sum</em>{j=1}^N \hat{\gamma}<em>{jk} }, \quad k=1,2,\cdots,K \<br>\hat{\alpha}_k = \frac{\displaystyle \sum</em>{j=1}^N \hat{\gamma}_{jk} }{N}, \quad k=1,2,\cdots,K<br>$$</p>
<blockquote>
<p>（4）重复第（2）步和第（3）步，直到收敛。</p>
</blockquote>
<p><strong>第3步：采用sklearn的GaussianMixture计算6个参数</strong></p>
<pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>mixture <span class="token keyword">import</span> GaussianMixture
<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np
<span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> plt

<span class="token comment" spellcheck="true"># 初始化观测数据</span>
data <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">67</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">48</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">,</span> <span class="token number">8</span><span class="token punctuation">,</span> <span class="token number">14</span><span class="token punctuation">,</span> <span class="token number">16</span><span class="token punctuation">,</span> <span class="token number">23</span><span class="token punctuation">,</span> <span class="token number">24</span><span class="token punctuation">,</span> <span class="token number">28</span><span class="token punctuation">,</span>
                <span class="token number">29</span><span class="token punctuation">,</span> <span class="token number">41</span><span class="token punctuation">,</span> <span class="token number">49</span><span class="token punctuation">,</span> <span class="token number">56</span><span class="token punctuation">,</span> <span class="token number">60</span><span class="token punctuation">,</span> <span class="token number">75</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>

<span class="token comment" spellcheck="true"># 设置n_components=2，表示两个分量高斯混合模型</span>
gmm_model <span class="token operator">=</span> GaussianMixture<span class="token punctuation">(</span>n_components<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span>
<span class="token comment" spellcheck="true"># 对模型进行参数估计</span>
gmm_model<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>data<span class="token punctuation">)</span>
<span class="token comment" spellcheck="true"># 对数据进行聚类</span>
labels <span class="token operator">=</span> gmm_model<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>data<span class="token punctuation">)</span>

<span class="token comment" spellcheck="true"># 得到分类结果</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"分类结果：labels = {}\n"</span><span class="token punctuation">.</span>format<span class="token punctuation">(</span>labels<span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"两个分量高斯混合模型的6个参数如下："</span><span class="token punctuation">)</span>
<span class="token comment" spellcheck="true"># 得到参数u1,u2</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"means ="</span><span class="token punctuation">,</span> gmm_model<span class="token punctuation">.</span>means_<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token comment" spellcheck="true"># 得到参数sigma1, sigma1</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"covariances ="</span><span class="token punctuation">,</span> gmm_model<span class="token punctuation">.</span>covariances_<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token comment" spellcheck="true"># 得到参数a1, a2</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"weights = "</span><span class="token punctuation">,</span> gmm_model<span class="token punctuation">.</span>weights_<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<pre><code>分类结果：labels = [0 0 1 1 1 1 1 1 1 1 1 1 1 1 1]

两个分量高斯混合模型的6个参数如下：
means = [[-57.51107027  32.98489643]]
covariances = [[ 90.24987882 429.45764867]]
weights =  [[0.13317238 0.86682762]]</code></pre><pre class="line-numbers language-python"><code class="language-python"><span class="token comment" spellcheck="true"># 绘制观测数据的聚类情况</span>
<span class="token keyword">for</span> i <span class="token keyword">in</span> range<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> len<span class="token punctuation">(</span>labels<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">if</span> labels<span class="token punctuation">[</span>i<span class="token punctuation">]</span> <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">:</span>
        plt<span class="token punctuation">.</span>scatter<span class="token punctuation">(</span>i<span class="token punctuation">,</span> data<span class="token punctuation">.</span>take<span class="token punctuation">(</span>i<span class="token punctuation">)</span><span class="token punctuation">,</span> s<span class="token operator">=</span><span class="token number">15</span><span class="token punctuation">,</span> c<span class="token operator">=</span><span class="token string">'red'</span><span class="token punctuation">)</span>
    <span class="token keyword">elif</span> labels<span class="token punctuation">[</span>i<span class="token punctuation">]</span> <span class="token operator">==</span> <span class="token number">1</span><span class="token punctuation">:</span>
        plt<span class="token punctuation">.</span>scatter<span class="token punctuation">(</span>i<span class="token punctuation">,</span> data<span class="token punctuation">.</span>take<span class="token punctuation">(</span>i<span class="token punctuation">)</span><span class="token punctuation">,</span> s<span class="token operator">=</span><span class="token number">15</span><span class="token punctuation">,</span> c<span class="token operator">=</span><span class="token string">'blue'</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>title<span class="token punctuation">(</span><span class="token string">'Gaussian Mixture Model'</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>xlabel<span class="token punctuation">(</span><span class="token string">'x'</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>ylabel<span class="token punctuation">(</span><span class="token string">'y'</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p><img src="/images/loading.gif" data-original="../images/ML/output_29_0.png" alt=""></p>
<p><strong>第4步：自编程实现高斯混合模型的EM算法</strong></p>
<pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">import</span> numpy <span class="token keyword">as</span> np
<span class="token keyword">import</span> itertools


<span class="token keyword">class</span> <span class="token class-name">MyGMM</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> alphas_init<span class="token punctuation">,</span> means_init<span class="token punctuation">,</span> covariances_init<span class="token punctuation">,</span> tol<span class="token operator">=</span><span class="token number">1e</span><span class="token operator">-</span><span class="token number">6</span><span class="token punctuation">,</span> n_components<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span> max_iter<span class="token operator">=</span><span class="token number">50</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment" spellcheck="true"># (1)设置参数的初始值</span>
        <span class="token comment" spellcheck="true"># 分模型权重</span>
        self<span class="token punctuation">.</span>alpha_ <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span>
            alphas_init<span class="token punctuation">,</span> dtype<span class="token operator">=</span><span class="token string">"float16"</span><span class="token punctuation">)</span><span class="token punctuation">.</span>reshape<span class="token punctuation">(</span>n_components<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>
        <span class="token comment" spellcheck="true"># 分模型均值</span>
        self<span class="token punctuation">.</span>mean_ <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span>
            means_init<span class="token punctuation">,</span> dtype<span class="token operator">=</span><span class="token string">"float16"</span><span class="token punctuation">)</span><span class="token punctuation">.</span>reshape<span class="token punctuation">(</span>n_components<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>
        <span class="token comment" spellcheck="true"># 分模型标准差（方差的平方）</span>
        self<span class="token punctuation">.</span>covariances_ <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span>
            covariances_init<span class="token punctuation">,</span> dtype<span class="token operator">=</span><span class="token string">"float16"</span><span class="token punctuation">)</span><span class="token punctuation">.</span>reshape<span class="token punctuation">(</span>n_components<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>
        <span class="token comment" spellcheck="true"># 迭代停止的阈值</span>
        self<span class="token punctuation">.</span>tol <span class="token operator">=</span> tol
        <span class="token comment" spellcheck="true"># 高斯混合模型分量个数</span>
        self<span class="token punctuation">.</span>K <span class="token operator">=</span> n_components
        <span class="token comment" spellcheck="true"># 最大迭代次数</span>
        self<span class="token punctuation">.</span>max_iter <span class="token operator">=</span> max_iter
        <span class="token comment" spellcheck="true"># 观测数据</span>
        self<span class="token punctuation">.</span>_y <span class="token operator">=</span> None
        <span class="token comment" spellcheck="true"># 实际迭代次数</span>
        self<span class="token punctuation">.</span>n_iter_ <span class="token operator">=</span> <span class="token number">0</span>

    <span class="token keyword">def</span> <span class="token function">gaussian</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> mean<span class="token punctuation">,</span> convariances<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token triple-quoted-string string">"""计算高斯分布概率密度"""</span>
        <span class="token keyword">return</span> <span class="token number">1</span> <span class="token operator">/</span> np<span class="token punctuation">.</span>sqrt<span class="token punctuation">(</span><span class="token number">2</span> <span class="token operator">*</span> np<span class="token punctuation">.</span>pi <span class="token operator">*</span> convariances<span class="token punctuation">)</span> <span class="token operator">*</span> np<span class="token punctuation">.</span>exp<span class="token punctuation">(</span>
            <span class="token operator">-</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>_y <span class="token operator">-</span> mean<span class="token punctuation">)</span> <span class="token operator">**</span> <span class="token number">2</span> <span class="token operator">/</span> <span class="token punctuation">(</span><span class="token number">2</span> <span class="token operator">*</span> convariances<span class="token punctuation">)</span><span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">update_r</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> mean<span class="token punctuation">,</span> convariances<span class="token punctuation">,</span> alpha<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token triple-quoted-string string">"""更新r_jk 分模型k对观测数据yi的响应度"""</span>
        r_jk <span class="token operator">=</span> alpha <span class="token operator">*</span> self<span class="token punctuation">.</span>gaussian<span class="token punctuation">(</span>mean<span class="token punctuation">,</span> convariances<span class="token punctuation">)</span>
        <span class="token keyword">return</span> r_jk <span class="token operator">/</span> r_jk<span class="token punctuation">.</span>sum<span class="token punctuation">(</span>axis<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">update_params</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> r<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token triple-quoted-string string">"""更新u al si 每个分模型k的均值、权重、方差的平方"""</span>
        u <span class="token operator">=</span> self<span class="token punctuation">.</span>mean_<span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span>
        _mean <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token punctuation">(</span>r <span class="token operator">*</span> self<span class="token punctuation">.</span>_y<span class="token punctuation">)</span><span class="token punctuation">.</span>sum<span class="token punctuation">(</span>axis<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span> <span class="token operator">/</span> r<span class="token punctuation">.</span>sum<span class="token punctuation">(</span>axis<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>reshape<span class="token punctuation">(</span>self<span class="token punctuation">.</span>K<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>
        _covariances <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token punctuation">(</span>r <span class="token operator">*</span> <span class="token punctuation">(</span>self<span class="token punctuation">.</span>_y <span class="token operator">-</span> u<span class="token punctuation">)</span> <span class="token operator">**</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">.</span>sum<span class="token punctuation">(</span>axis<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span> <span class="token operator">/</span>
                        r<span class="token punctuation">.</span>sum<span class="token punctuation">(</span>axis<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>reshape<span class="token punctuation">(</span>self<span class="token punctuation">.</span>K<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>
        _alpha <span class="token operator">=</span> <span class="token punctuation">(</span>r<span class="token punctuation">.</span>sum<span class="token punctuation">(</span>axis<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span> <span class="token operator">/</span> self<span class="token punctuation">.</span>_y<span class="token punctuation">.</span>size<span class="token punctuation">)</span><span class="token punctuation">.</span>reshape<span class="token punctuation">(</span>self<span class="token punctuation">.</span>K<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>
        <span class="token keyword">return</span> _mean<span class="token punctuation">,</span> _covariances<span class="token punctuation">,</span> _alpha

    <span class="token keyword">def</span> <span class="token function">judge_stop</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> mean<span class="token punctuation">,</span> covariances<span class="token punctuation">,</span> alpha<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token triple-quoted-string string">"""中止条件判断"""</span>
        a <span class="token operator">=</span> np<span class="token punctuation">.</span>linalg<span class="token punctuation">.</span>norm<span class="token punctuation">(</span>self<span class="token punctuation">.</span>mean_ <span class="token operator">-</span> mean<span class="token punctuation">)</span>
        b <span class="token operator">=</span> np<span class="token punctuation">.</span>linalg<span class="token punctuation">.</span>norm<span class="token punctuation">(</span>self<span class="token punctuation">.</span>covariances_ <span class="token operator">-</span> covariances<span class="token punctuation">)</span>
        c <span class="token operator">=</span> np<span class="token punctuation">.</span>linalg<span class="token punctuation">.</span>norm<span class="token punctuation">(</span>self<span class="token punctuation">.</span>alpha_ <span class="token operator">-</span> alpha<span class="token punctuation">)</span>
        <span class="token keyword">return</span> <span class="token boolean">True</span> <span class="token keyword">if</span> np<span class="token punctuation">.</span>sqrt<span class="token punctuation">(</span>a <span class="token operator">**</span> <span class="token number">2</span> <span class="token operator">+</span> b <span class="token operator">**</span> <span class="token number">2</span> <span class="token operator">+</span> c <span class="token operator">**</span> <span class="token number">2</span><span class="token punctuation">)</span> <span class="token operator">&lt;</span> self<span class="token punctuation">.</span>tol <span class="token keyword">else</span> <span class="token boolean">False</span>

    <span class="token keyword">def</span> <span class="token function">fit</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> y<span class="token punctuation">)</span><span class="token punctuation">:</span>
        self<span class="token punctuation">.</span>_y <span class="token operator">=</span> np<span class="token punctuation">.</span>copy<span class="token punctuation">(</span>np<span class="token punctuation">.</span>array<span class="token punctuation">(</span>y<span class="token punctuation">)</span><span class="token punctuation">)</span>
        <span class="token triple-quoted-string string">"""迭代训练获得预估参数"""</span>
        <span class="token comment" spellcheck="true"># (2)E步：计算分模型k对观测数据yi的响应度</span>
        r <span class="token operator">=</span> self<span class="token punctuation">.</span>update_r<span class="token punctuation">(</span>self<span class="token punctuation">.</span>mean_<span class="token punctuation">,</span> self<span class="token punctuation">.</span>covariances_<span class="token punctuation">,</span> self<span class="token punctuation">.</span>alpha_<span class="token punctuation">)</span>
        <span class="token comment" spellcheck="true"># 更新r_jk 分模型k对观测数据yi的响应度</span>
        _mean<span class="token punctuation">,</span> _covariances<span class="token punctuation">,</span> _alpha <span class="token operator">=</span> self<span class="token punctuation">.</span>update_params<span class="token punctuation">(</span>r<span class="token punctuation">)</span>
        <span class="token comment" spellcheck="true"># 更新u al si 每个分模型k的均值、权重、方差的平方</span>
        <span class="token keyword">for</span> i <span class="token keyword">in</span> range<span class="token punctuation">(</span>self<span class="token punctuation">.</span>max_iter<span class="token punctuation">)</span><span class="token punctuation">:</span>
            <span class="token keyword">if</span> <span class="token operator">not</span> self<span class="token punctuation">.</span>judge_stop<span class="token punctuation">(</span>_mean<span class="token punctuation">,</span> _covariances<span class="token punctuation">,</span> _alpha<span class="token punctuation">)</span><span class="token punctuation">:</span>
                <span class="token comment" spellcheck="true"># (4)未达到阈值条件，重复迭代</span>
                r <span class="token operator">=</span> self<span class="token punctuation">.</span>update_r<span class="token punctuation">(</span>_mean<span class="token punctuation">,</span> _covariances<span class="token punctuation">,</span> _alpha<span class="token punctuation">)</span>
                <span class="token comment" spellcheck="true"># (3)M步：计算新一轮迭代的模型参数</span>
                _mean<span class="token punctuation">,</span> _covariances<span class="token punctuation">,</span> _alpha <span class="token operator">=</span> self<span class="token punctuation">.</span>update_params<span class="token punctuation">(</span>r<span class="token punctuation">)</span>
            <span class="token keyword">else</span><span class="token punctuation">:</span>
                <span class="token comment" spellcheck="true"># 达到阈值条件，停止迭代</span>
                self<span class="token punctuation">.</span>n_iter_ <span class="token operator">=</span> i
                <span class="token keyword">break</span>

            self<span class="token punctuation">.</span>mean_ <span class="token operator">=</span> _mean
            self<span class="token punctuation">.</span>covariances_ <span class="token operator">=</span> _covariances
            self<span class="token punctuation">.</span>alpha_ <span class="token operator">=</span> _alpha

    <span class="token keyword">def</span> <span class="token function">score</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token triple-quoted-string string">"""计算该局部最优解的score，即似然函数值"""</span>
        <span class="token keyword">return</span> <span class="token punctuation">(</span>self<span class="token punctuation">.</span>alpha_ <span class="token operator">*</span> self<span class="token punctuation">.</span>gaussian<span class="token punctuation">(</span>self<span class="token punctuation">.</span>mean_<span class="token punctuation">,</span> self<span class="token punctuation">.</span>covariances_<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>sum<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<pre class="line-numbers language-python"><code class="language-python"><span class="token comment" spellcheck="true"># 观测数据</span>
y <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">67</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">48</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">,</span> <span class="token number">8</span><span class="token punctuation">,</span> <span class="token number">14</span><span class="token punctuation">,</span> <span class="token number">16</span><span class="token punctuation">,</span> <span class="token number">23</span><span class="token punctuation">,</span> <span class="token number">24</span><span class="token punctuation">,</span> <span class="token number">28</span><span class="token punctuation">,</span>
             <span class="token number">29</span><span class="token punctuation">,</span> <span class="token number">41</span><span class="token punctuation">,</span> <span class="token number">49</span><span class="token punctuation">,</span> <span class="token number">56</span><span class="token punctuation">,</span> <span class="token number">60</span><span class="token punctuation">,</span> <span class="token number">75</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">15</span><span class="token punctuation">)</span>
<span class="token comment" spellcheck="true"># 预估均值和方差，以其邻域划分寻优范围</span>
y_mean <span class="token operator">=</span> y<span class="token punctuation">.</span>mean<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">//</span> <span class="token number">1</span>
y_std <span class="token operator">=</span> <span class="token punctuation">(</span>y<span class="token punctuation">.</span>std<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">**</span> <span class="token number">2</span><span class="token punctuation">)</span> <span class="token operator">//</span> <span class="token number">1</span>

<span class="token comment" spellcheck="true"># 网格搜索，对不同的初值进行参数估计</span>
alpha <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">[</span>i<span class="token punctuation">,</span> <span class="token number">1</span> <span class="token operator">-</span> i<span class="token punctuation">]</span> <span class="token keyword">for</span> i <span class="token keyword">in</span> np<span class="token punctuation">.</span>linspace<span class="token punctuation">(</span><span class="token number">0.1</span><span class="token punctuation">,</span> <span class="token number">0.9</span><span class="token punctuation">,</span> <span class="token number">9</span><span class="token punctuation">)</span><span class="token punctuation">]</span>
mean <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">[</span>y_mean <span class="token operator">+</span> i<span class="token punctuation">,</span> y_mean <span class="token operator">+</span> j<span class="token punctuation">]</span>
        <span class="token keyword">for</span> i <span class="token keyword">in</span> range<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">10</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">)</span> <span class="token keyword">for</span> j <span class="token keyword">in</span> range<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">10</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">]</span>
covariances <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">[</span>y_std <span class="token operator">+</span> i<span class="token punctuation">,</span> y_std <span class="token operator">+</span> j<span class="token punctuation">]</span>
               <span class="token keyword">for</span> i <span class="token keyword">in</span> range<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1000</span><span class="token punctuation">,</span> <span class="token number">1000</span><span class="token punctuation">,</span> <span class="token number">500</span><span class="token punctuation">)</span> <span class="token keyword">for</span> j <span class="token keyword">in</span> range<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1000</span><span class="token punctuation">,</span> <span class="token number">1000</span><span class="token punctuation">,</span> <span class="token number">500</span><span class="token punctuation">)</span><span class="token punctuation">]</span>
results <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
<span class="token keyword">for</span> i <span class="token keyword">in</span> itertools<span class="token punctuation">.</span>product<span class="token punctuation">(</span>alpha<span class="token punctuation">,</span> mean<span class="token punctuation">,</span> covariances<span class="token punctuation">)</span><span class="token punctuation">:</span>
    init_alpha <span class="token operator">=</span> i<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
    init_mean <span class="token operator">=</span> i<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span>
    init_covariances <span class="token operator">=</span> i<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span>
    clf <span class="token operator">=</span> MyGMM<span class="token punctuation">(</span>alphas_init<span class="token operator">=</span>init_alpha<span class="token punctuation">,</span> means_init<span class="token operator">=</span>init_mean<span class="token punctuation">,</span> covariances_init<span class="token operator">=</span>init_covariances<span class="token punctuation">,</span>
                n_components<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span> tol<span class="token operator">=</span><span class="token number">1e</span><span class="token operator">-</span><span class="token number">6</span><span class="token punctuation">)</span>
    clf<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>y<span class="token punctuation">)</span>
    <span class="token comment" spellcheck="true"># 得到不同初值收敛的局部最优解</span>
    results<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token punctuation">[</span>clf<span class="token punctuation">.</span>alpha_<span class="token punctuation">,</span> clf<span class="token punctuation">.</span>mean_<span class="token punctuation">,</span> clf<span class="token punctuation">.</span>covariances_<span class="token punctuation">,</span> clf<span class="token punctuation">.</span>score<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
<span class="token comment" spellcheck="true"># 根据score，从所有局部最优解找到相对最优解</span>
best_value <span class="token operator">=</span> max<span class="token punctuation">(</span>results<span class="token punctuation">,</span> key<span class="token operator">=</span><span class="token keyword">lambda</span> x<span class="token punctuation">:</span> x<span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">)</span>

<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"alpha : {}"</span><span class="token punctuation">.</span>format<span class="token punctuation">(</span>best_value<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>T<span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"mean : {}"</span><span class="token punctuation">.</span>format<span class="token punctuation">(</span>best_value<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">.</span>T<span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"std : {}"</span><span class="token punctuation">.</span>format<span class="token punctuation">(</span>best_value<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">.</span>T<span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<pre><code>alpha : [[0.56950675 0.43049325]]
mean : [[27.41762854 12.35515017]]
std : [[ 268.17311145 2772.33989897]]</code></pre><h3 id="习题9-4"><a href="#习题9-4" class="headerlink" title="习题9.4"></a>习题9.4</h3><p>  EM算法可以用到朴素贝叶斯法的非监督学习，试写出其算法。</p>
<p><strong>解答：</strong></p>
<p><strong>解答思路：</strong><br>参考： <a href="http://www.cs.columbia.edu/~mcollins/em.pdf" target="_blank" rel="noopener">http://www.cs.columbia.edu/~mcollins/em.pdf</a></p>
<ol>
<li>列出EM算法；</li>
<li>列出朴素贝叶斯算法；</li>
<li>推导朴素贝叶斯的EM算法。</li>
</ol>
<p><strong>解答步骤：</strong></p>
<p><strong>第1步：EM算法</strong></p>
<p>  根据书中第178页EM算法：</p>
<blockquote>
<p>输入：观测变量数据$Y$，隐变量数据$Z$，联合分布$P(Y,Z|\theta)$，条件分布$P(Z|Y,\theta)$；<br>输出：模型参数$\theta$。<br>（1）选择参数的初值$\theta^{(0)}$，开始迭代；<br>（2）E步：记$\theta^{(i)}$为第$i$次迭代参数$\theta$的估计值，在第$i+1$次迭代的E步，计算</p>
</blockquote>
<p>$$<br>\begin{aligned}<br>Q(\theta,\theta^{(i)}) &amp;= E_Z[\log P(Y,Z | \theta)| Y,\theta^{(i)}] \<br>&amp;= \sum_z \log P(Y,Z | \theta) P(Z|Y,\theta^{(i)})<br>\end{aligned}<br>$$</p>
<blockquote>
<p>这里，$P(Z|Y, \theta)$是在给定观测数据$Y$和当前的参数估计$\theta^{(i)}$下隐变量数据$Z$的条件概率分布；<br>（3）M步：求使$Q(\theta, \theta^{(i)})$极大化的$\theta$，确定第$i+1$次迭代的参数的估计值$\theta^{(i+1)}$</p>
</blockquote>
<p>$$<br>\theta^{(i+1)} = \arg \max \limits_{\theta} Q(\theta, \theta^{(i)})<br>$$</p>
<blockquote>
<p>（4）重复第（2）步和第（3）步，直至收敛。</p>
</blockquote>
<p><strong>第2步：朴素贝叶斯算法</strong></p>
<p>  根据书中第62页朴素贝叶斯算法：</p>
<blockquote>
<p>输入：训练数据$T={(x_1, y_1), (x_2, y_2), \cdots, (x_N, y_N)}$，其中$x_i=(x_i^{(1)}, x_i^{(2)}, \cdots, x_i^{(n)})^T$，$x_i^{(j)}$是第$i$个样本的第$j$个特征，$x_i^{(j)} \in {a_{j1}, a_{j2},\cdots, a_{j S_j}}$，$a_{jl}$是第$j$个特征可能取的第$l$个值，$j=1,2,\cdots, n$，$l=1,2,\cdots, S_j$，$y_i \in { c_1, c_2, \cdots, c_K}$；实例$x$；<br>输出：实例$x$的分类。<br>（1）计算先验概率及条件概率</p>
</blockquote>
<p>$$<br>P(Y=c_k) = \frac{\displaystyle \sum_{i=1}^N I(y_i=c_k)}{N}, \quad k=1,2,\cdots, K \<br>P(X^{(j)}=a_{jl}|Y=c_k)= \frac{\displaystyle \sum_{i=1}^N I(x_i^{(j)} = a_{jl}, y_i=c_k) }{\displaystyle \sum_{i=1}^N I(y_i=c_k)} \<br>j=1,2,\cdots,n; \quad l=1,2,\cdots, S_j; \quad k=1,2,\cdots, K<br>$$</p>
<blockquote>
<p>（2）对于给定的实例$x=(x^{(1)}, x^{(2)}, \cdots, x^{(n)})^T$，计算</p>
</blockquote>
<p>$$<br>P(Y=c_k) \prod_{j=1}^n P(X^{(j)}=x^{(j)} | Y=c_k), \quad k=1,2,\cdots,K<br>$$</p>
<blockquote>
<p>（3）确定实例$x$的类</p>
</blockquote>
<p>$$<br>y = \arg \max \limits_{c_k} P(Y=c_k) \prod_{j=1}^n P(X^{(j)}=x^{(j)} | Y=c_k)<br>$$</p>
<p><strong>第3步：推导朴素贝叶斯的EM算法</strong></p>
<p>推导思路：</p>
<ol>
<li>假设隐变量数据是$y \in \mathcal{Y} = {c_1, c_2, \cdots, c_K}$</li>
<li>设置初值，$P^{(0)}(Y=y) \geqslant 0$和$P_j^{(0)}(X=x|Y=y) \geqslant 0$，其中$j = 1,2,\cdots, n$，满足</li>
</ol>
<p>$$<br>\sum_{y \in \mathcal{Y} } P^{(0)}(Y=y) = 1 \<br>\sum_{x \in {-1, +1} } P_j^{(0)}(X=x|Y=y)=1<br>$$</p>
<ol start="3">
<li>根据概率公式，可知概率</li>
</ol>
<p>$$<br>\delta(y|i) = P(Y=y | X=x_i, \theta^{(t)}) = \frac<br>{\displaystyle P^{(t)}(Y=y) \prod_{j=1}^n P_j^{(t)}(X=x_i^{(j)} | Y=y) }<br>{\displaystyle \sum_{y \in \mathcal{Y} } P^{(t)}(Y=y) \prod_{j=1}^n P_j^{(t)}(X=x_i^{(j)} | Y=y)}<br>$$</p>
<p>其中$\theta$表示朴素贝叶斯模型中所有的参数向量</p>
<ol start="4">
<li>迭代更新参数</li>
</ol>
<p>$$<br>P^{(t+1)}(Y=y) = \frac{1}{N} \sum_{i=1}^N \delta(y | i) \<br>P_j^{(t+1)}(X=x_i^{(j)} | y) = \frac<br>{\displaystyle \sum_{i=1}^N P(X=x_i^{(j)})\delta(y|i) }<br>{\displaystyle \sum_{i=1}^N \delta(y|i)}<br>$$</p>
<ol start="5">
<li>计算似然函数，得到使得似然函数最大的$\theta$，重复第3步和第4步，直至收敛</li>
</ol>
<p>$$<br>\begin{aligned}<br>\theta^* &amp;= \arg \max \limits_{\theta \in \Omega} L(\theta) \<br>&amp;= \arg \max \limits_{\theta \in \Omega} \sum_{i=1}^N \sum_{y \in \mathcal{Y} } \delta(y|i) \log \left(P(Y=y) \prod_{j=1}^n P_j (X=x_i^{(j)} | Y=y)\right)<br>\end{aligned}<br>$$</p>
<p>所以，朴素贝叶斯的EM算法如下：</p>
<p>输入：隐变量数据是$y \in \mathcal{Y} = {c_1, c_2, \cdots, c_K}$，$x \in \mathcal{X} = (x_1, x_2, \cdots, x_N)$，输入空间$\mathcal{X} \subset R^n$为$n$维向量的集合，$x=(x^{(1)}, x^{(2)}, \cdots, x^{(n)})^T$，$x^{(i)}$取值范围是${-1, +1}$；<br>输出：参数$P^{(t+1)}(Y=y)$，$P_j^{(t+1)}(X=x_i^{(j)} | y)$；<br>（1）选择参数的初值$P^{(0)}(Y=y) \geqslant 0$和$P_j^{(0)}(X=x|Y=y) \geqslant 0$，开始迭代；<br>（2）E步：记$\theta^{(t)}$为第$t$次迭代参数$\theta$的估计值，在第$t+1$次迭代的E步，计算<br>$$<br>\delta(y|i) = P(Y=y | X=x_i, \theta^{(t)}) = \frac<br>{\displaystyle P^{(t)}(Y=y) \prod_{j=1}^n P_j^{(t)}(X=x_i^{(j)} | Y=y) }<br>{\displaystyle \sum_{y \in \mathcal{Y} } P^{(t)}(Y=y) \prod_{j=1}^n P_j^{(t)}(X=x_i^{(j)} | Y=y)}<br>$$<br>（3）M步：求使$Q(\theta, \theta^{(t)})$极大化的$\theta$，确定第$t+1$次迭代的参数的估计值<br>$$<br>P^{(t+1)}(Y=y) = \frac{1}{N} \sum_{i=1}^N \delta(y | i) \<br>P_j^{(t+1)}(X=x_i^{(j)} | y) = \frac<br>{\displaystyle \sum_{i=1}^N P(X=x_i^{(j)})\delta(y|i) }<br>{\displaystyle \sum_{i=1}^N \delta(y|i)}<br>$$<br>（4）重复第（2）步和第（3）步，直至收敛。</p>
<h1 id="十、隐马尔可夫模型"><a href="#十、隐马尔可夫模型" class="headerlink" title="十、隐马尔可夫模型"></a>十、隐马尔可夫模型</h1><p>隐马尔可夫模型( hidden Markov model,HMM)是可用于标注问题的统计学习模型，描述由隐藏的马尔可夫链随机生成观测序列的过程，属于生成模型。</p>
<h2 id="10-1-隐马尔可夫模型的基本概念"><a href="#10-1-隐马尔可夫模型的基本概念" class="headerlink" title="10.1 隐马尔可夫模型的基本概念"></a>10.1 隐马尔可夫模型的基本概念</h2><h3 id="10-1-1-隐马尔可夫模型的定义"><a href="#10-1-1-隐马尔可夫模型的定义" class="headerlink" title="10.1.1 隐马尔可夫模型的定义"></a>10.1.1 隐马尔可夫模型的定义</h3><p><strong>定义10.1（隐马尔可夫模型）</strong>隐马尔可夫模型是关于时序的概率模型，描述由一个隐藏的马尔可夫链随机生成不可观测的状态随机序列，再由各个状态生成一个观测而产生观测随机序列的过程。隐藏的马尔可夫链随机生成的状态的序列，称为状态序列（state sequence）;每个状态生成一个观测，而由此产生的观测的随机序列，称为观测序列（observation sequence）.序列的每一个位置又可以看作是一个时刻。</p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20220112102541706.png" alt=""></p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20220112102601639.png" alt=""></p>
<h3 id="10-1-2-观测序列的生成过程"><a href="#10-1-2-观测序列的生成过程" class="headerlink" title="10.1.2 观测序列的生成过程"></a>10.1.2 观测序列的生成过程</h3><p><strong>算法10.1（观测序列的生成）</strong></p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20220112103033527.png" alt=""></p>
<h3 id="10-1-3-隐马尔可夫模型的3个基本问题"><a href="#10-1-3-隐马尔可夫模型的3个基本问题" class="headerlink" title="10.1.3 隐马尔可夫模型的3个基本问题"></a>10.1.3 隐马尔可夫模型的3个基本问题</h3><p><img src="/images/loading.gif" data-original="../images/ML/image-20220112103214635.png" alt=""></p>
<h2 id="10-2-概率计算算法"><a href="#10-2-概率计算算法" class="headerlink" title="10.2 概率计算算法"></a>10.2 概率计算算法</h2><h3 id="10-2-1-直接计算法"><a href="#10-2-1-直接计算法" class="headerlink" title="10.2.1 直接计算法"></a>10.2.1 直接计算法</h3><p><img src="/images/loading.gif" data-original="../images/ML/image-20220112103706602.png" alt=""></p>
<h3 id="10-2-2-前向算法"><a href="#10-2-2-前向算法" class="headerlink" title="10.2.2 前向算法"></a>10.2.2 前向算法</h3><p><strong>定义10.2（前向概率）</strong></p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20220112103826384.png" alt=""></p>
<p><strong>算法10.2（观测序列概率的前向算法）</strong></p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20220112103900493.png" alt=""></p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20220112103917788.png" alt=""></p>
<h3 id="10-2-3-后向算法"><a href="#10-2-3-后向算法" class="headerlink" title="10.2.3 后向算法"></a>10.2.3 后向算法</h3><p><strong>定义10.3（后向概率）</strong></p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20220112104015979.png" alt=""></p>
<p><strong>算法10.3（观測序列概率的后向算法）</strong></p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20220112104049819.png" alt=""></p>
<h3 id="10-2-4-一些概率与期望值的计算"><a href="#10-2-4-一些概率与期望值的计算" class="headerlink" title="10.2.4 一些概率与期望值的计算"></a>10.2.4 一些概率与期望值的计算</h3><p><img src="/images/loading.gif" data-original="../images/ML/image-20220112104235762.png" alt=""></p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20220112104246865.png" alt="="></p>
<h2 id="10-3-学习算法"><a href="#10-3-学习算法" class="headerlink" title="10.3 学习算法"></a>10.3 学习算法</h2><h3 id="10-3-1-监督学习方法"><a href="#10-3-1-监督学习方法" class="headerlink" title="10.3.1 监督学习方法"></a>10.3.1 监督学习方法</h3><p><img src="/images/loading.gif" data-original="../images/ML/image-20220112104424092.png" alt=""></p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20220112104434457.png" alt=""></p>
<h3 id="10-3-2-Baum-Welch算法"><a href="#10-3-2-Baum-Welch算法" class="headerlink" title="10.3.2 Baum- Welch算法"></a>10.3.2 Baum- Welch算法</h3><h3 id="10-3-3-Baum-Welch模型参数估计公式"><a href="#10-3-3-Baum-Welch模型参数估计公式" class="headerlink" title="10.3.3 Baum- Welch模型参数估计公式"></a>10.3.3 Baum- Welch模型参数估计公式</h3><p><strong>算法10.4 (Baum- Welch算法)</strong></p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20220112104635256.png" alt=""></p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20220112104645760.png" alt=""></p>
<h2 id="10-4-预测算法"><a href="#10-4-预测算法" class="headerlink" title="10.4 预测算法"></a>10.4 预测算法</h2><h3 id="10-4-1-近似算法"><a href="#10-4-1-近似算法" class="headerlink" title="10.4.1 近似算法"></a>10.4.1 近似算法</h3><p><img src="/images/loading.gif" data-original="../images/ML/image-20220112104747133.png" alt=""></p>
<h3 id="10-4-2-维特比算法"><a href="#10-4-2-维特比算法" class="headerlink" title="10.4.2 维特比算法"></a>10.4.2 维特比算法</h3><p>维特比算法实际是用动态规划解隐马尔可夫模型预测问题，即用动态规划（dynamic programming）求概率最大路径（最优路径）。这时一条路径对应着一个状态序列</p>
<p><strong>算法10.5（维特比算法）</strong></p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20220112104921759.png" alt=""></p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20220112104931712.png" alt=""></p>
<p>一些解释</p>
<ul>
<li><p><a href="https://zhuanlan.zhihu.com/p/88362664" target="_blank" rel="noopener">隐马尔可夫模型（HMM）详解</a></p>
</li>
<li><p><a href="https://www.cnblogs.com/skyme/p/4651331.html" target="_blank" rel="noopener">一文搞懂HMM（隐马尔可夫模型）</a></p>
</li>
</ul>
<h2 id="习题-9"><a href="#习题-9" class="headerlink" title="习题"></a>习题</h2><h3 id="习题10-1-⭐⭐⭐"><a href="#习题10-1-⭐⭐⭐" class="headerlink" title="习题10.1 ⭐⭐⭐"></a>习题10.1 ⭐⭐⭐</h3><p>  给定盒子和球组成的隐马尔可夫模型$\lambda=(A,B,\pi)$，其中，</p>
<p>$$<br>A=\left[\begin{array}{ccc}<br>0.5&amp;0.2&amp;0.3 \<br>0.3&amp;0.5&amp;0.2 \<br>0.2&amp;0.3&amp;0.5<br>\end{array}\right],<br>\quad B=\left[\begin{array}{cc}<br>0.5&amp;0.5 \<br>0.4&amp;0.6 \<br>0.7&amp;0.3<br>\end{array}\right],<br>\quad \pi=(0.2,0.4,0.4)^T<br>$$</p>
<p>设$T=4$，$O=(红,白,红,白)$，试用后向算法计算$P(O|\lambda)$。</p>
<p><strong>解答：</strong></p>
<p><strong>解答思路：</strong></p>
<ol>
<li>列出隐马尔可夫模型的定义</li>
<li>列出后向算法</li>
<li>自编码实现隐马尔可夫的后向算法</li>
</ol>
<p><strong>解答步骤：</strong></p>
<p><strong>第1步：隐马尔可夫模型</strong></p>
<p>  根据书中第193页隐马尔可夫模型的定义：</p>
<blockquote>
<ol>
<li>条件假设：<br>  设$Q$是所有可能的状态的集合，$V$是所有可能的观测的集合：</li>
</ol>
</blockquote>
<p>$$<br>Q={q_1, q_2, \cdots, q_N}, \quad V={v_1, v_2, \cdots, v_M}<br>$$</p>
<blockquote>
<p>其中，$N$是可能的状态数，$M$是可能的观测数。<br>  $I$是长度为$T$的状态序列，$O$是对应的观测序列：</p>
</blockquote>
<p>$$<br>I = (i_1,i_2, \cdots, i_T), \quad O=(o_1, o_2, \cdots, o_T)<br>$$</p>
<blockquote>
<ol start="2">
<li>状态转移概率矩阵$A$：<br>  $A$是状态转移概率矩阵：</li>
</ol>
</blockquote>
<p>$$<br>A = [a_{ij}]_{N \times N}<br>$$</p>
<blockquote>
<p>其中，</p>
</blockquote>
<p>$$<br>a_{ij} = P(i_{t+1}=q_j | i_t = q_i), \quad i=1,2,\cdots, N; \quad j=1,2,\cdots N<br>$$</p>
<blockquote>
<p>是在时刻$t$处于状态$q_i$的条件下，在时刻$t+1$转移到状态$q_j$的概率。  </p>
<ol start="3">
<li>观测概率矩阵$B$：<br>  $B$是观测概率矩阵：</li>
</ol>
</blockquote>
<p>$$<br>B = [b_j(k)]_{N \times M}<br>$$</p>
<blockquote>
<p>其中，</p>
</blockquote>
<p>$$<br>b_j(k) = P(o_t=v_k | i_t = q_j), \quad k=1,2,\cdots, M; \quad j=1,2,\cdots N<br>$$</p>
<blockquote>
<p>是在时刻$t$处于状态$q_j$的条件下，生成观测$v_k$的概率。</p>
<ol start="4">
<li>初始状态概率向量$\pi$：<br>  $\pi$是初始状态概率向量：</li>
</ol>
</blockquote>
<p>$$<br>\pi = (\pi_i)<br>$$</p>
<blockquote>
<p>其中，</p>
</blockquote>
<p>$$<br>\pi = P(i_1 = q_i), \quad i=1,2,\cdots N<br>$$</p>
<blockquote>
<p>是时刻$t=1$处于状态$q_i$的概率。</p>
<ol start="5">
<li>隐马尔可夫模型的表示：<br>  隐马尔可夫模型由初始状态概率向量$\pi$、状态转移概率矩阵$A$和观测概率矩阵$B$决定。$\pi$和$A$决定状态序列，$B$决定观测序列。因此隐马尔可夫模型$\lambda$可以用三元符号表示，即</li>
</ol>
</blockquote>
<p>$$<br>\lambda = (A, B, \pi)<br>$$</p>
<blockquote>
<p>$A,B,\pi$称为隐马尔可夫模型的三要素。</p>
</blockquote>
<p><strong>第2步：后向算法</strong></p>
<p>  根据书中第201页的观测序列概率的后向算法：</p>
<blockquote>
<p>输入：隐马尔可夫模型$\lambda$，观测序列$O$<br>输出：观测序列概率$P(O|\lambda)$<br>（1）</p>
</blockquote>
<p>$$<br>\beta_T(i) = 1, \quad i = 1, 2, \cdots, N<br>$$</p>
<blockquote>
<p>（2）对$t= T-1, T-2, \cdots, 1$</p>
</blockquote>
<p>$$<br>\beta_t(i) = \sum_{j=1}^N a_{ij} b_j(o_{t+1}) \beta_{t+1}(j), \quad  i=1,2,\cdots, N<br>$$</p>
<blockquote>
<p>（3）</p>
</blockquote>
<p>$$<br>P(O|\lambda) = \sum_{i=1}^N \pi_i b_i(o_1) \beta_1(i)<br>$$</p>
<p><strong>第3步：自编码实现隐马尔可夫的后向算法</strong></p>
<pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">import</span> numpy <span class="token keyword">as</span> np


<span class="token keyword">class</span> <span class="token class-name">HiddenMarkovBackward</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        self<span class="token punctuation">.</span>betas <span class="token operator">=</span> None
        self<span class="token punctuation">.</span>backward_P <span class="token operator">=</span> None

    <span class="token keyword">def</span> <span class="token function">backward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> Q<span class="token punctuation">,</span> V<span class="token punctuation">,</span> A<span class="token punctuation">,</span> B<span class="token punctuation">,</span> O<span class="token punctuation">,</span> PI<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token triple-quoted-string string">"""
        后向算法
        :param Q: 所有可能的状态集合
        :param V: 所有可能的观测集合
        :param A: 状态转移概率矩阵
        :param B: 观测概率矩阵
        :param O: 观测序列
        :param PI: 初始状态概率向量
        """</span>
        <span class="token comment" spellcheck="true"># 状态序列的大小</span>
        N <span class="token operator">=</span> len<span class="token punctuation">(</span>Q<span class="token punctuation">)</span>
        <span class="token comment" spellcheck="true"># 观测序列的大小</span>
        M <span class="token operator">=</span> len<span class="token punctuation">(</span>O<span class="token punctuation">)</span>
        <span class="token comment" spellcheck="true"># (1)初始化后向概率beta值，书中第201页公式(10.19)</span>
        betas <span class="token operator">=</span> np<span class="token punctuation">.</span>ones<span class="token punctuation">(</span><span class="token punctuation">(</span>N<span class="token punctuation">,</span> M<span class="token punctuation">)</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>print_betas_T<span class="token punctuation">(</span>N<span class="token punctuation">,</span> M<span class="token punctuation">)</span>

        <span class="token comment" spellcheck="true"># (2)对观测序列逆向遍历，M-2即为T-1</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"\n从时刻T-1到1观测序列的后向概率："</span><span class="token punctuation">)</span>
        <span class="token keyword">for</span> t <span class="token keyword">in</span> range<span class="token punctuation">(</span>M <span class="token operator">-</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            <span class="token comment" spellcheck="true"># 得到序列对应的索引</span>
            index_of_o <span class="token operator">=</span> V<span class="token punctuation">.</span>index<span class="token punctuation">(</span>O<span class="token punctuation">[</span>t <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
            <span class="token comment" spellcheck="true"># 遍历状态序列</span>
            <span class="token keyword">for</span> i <span class="token keyword">in</span> range<span class="token punctuation">(</span>N<span class="token punctuation">)</span><span class="token punctuation">:</span>
                <span class="token comment" spellcheck="true"># 书中第201页公式(10.20)</span>
                betas<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">[</span>t<span class="token punctuation">]</span> <span class="token operator">=</span> np<span class="token punctuation">.</span>dot<span class="token punctuation">(</span>np<span class="token punctuation">.</span>multiply<span class="token punctuation">(</span>A<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span>b<span class="token punctuation">[</span>index_of_o<span class="token punctuation">]</span> <span class="token keyword">for</span> b <span class="token keyword">in</span> B<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                                     <span class="token punctuation">[</span>beta<span class="token punctuation">[</span>t <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">]</span> <span class="token keyword">for</span> beta <span class="token keyword">in</span> betas<span class="token punctuation">]</span><span class="token punctuation">)</span>
                real_t <span class="token operator">=</span> t <span class="token operator">+</span> <span class="token number">1</span>
                real_i <span class="token operator">=</span> i <span class="token operator">+</span> <span class="token number">1</span>
                self<span class="token punctuation">.</span>print_betas_t<span class="token punctuation">(</span>A<span class="token punctuation">,</span> B<span class="token punctuation">,</span> N<span class="token punctuation">,</span> betas<span class="token punctuation">,</span> i<span class="token punctuation">,</span> index_of_o<span class="token punctuation">,</span> real_i<span class="token punctuation">,</span> real_t<span class="token punctuation">,</span> t<span class="token punctuation">)</span>

        <span class="token comment" spellcheck="true"># 取出第一个值索引，用于得到o1</span>
        index_of_o <span class="token operator">=</span> V<span class="token punctuation">.</span>index<span class="token punctuation">(</span>O<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>betas <span class="token operator">=</span> betas
        <span class="token comment" spellcheck="true"># 书中第201页公式(10.21)</span>
        P <span class="token operator">=</span> np<span class="token punctuation">.</span>dot<span class="token punctuation">(</span>np<span class="token punctuation">.</span>multiply<span class="token punctuation">(</span>PI<span class="token punctuation">,</span> <span class="token punctuation">[</span>b<span class="token punctuation">[</span>index_of_o<span class="token punctuation">]</span> <span class="token keyword">for</span> b <span class="token keyword">in</span> B<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                   <span class="token punctuation">[</span>beta<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token keyword">for</span> beta <span class="token keyword">in</span> betas<span class="token punctuation">]</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>backward_P <span class="token operator">=</span> P
        self<span class="token punctuation">.</span>print_P<span class="token punctuation">(</span>B<span class="token punctuation">,</span> N<span class="token punctuation">,</span> P<span class="token punctuation">,</span> PI<span class="token punctuation">,</span> betas<span class="token punctuation">,</span> index_of_o<span class="token punctuation">)</span>

    @staticmethod
    <span class="token keyword">def</span> <span class="token function">print_P</span><span class="token punctuation">(</span>B<span class="token punctuation">,</span> N<span class="token punctuation">,</span> P<span class="token punctuation">,</span> PI<span class="token punctuation">,</span> betas<span class="token punctuation">,</span> index_of_o<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"\n观测序列概率："</span><span class="token punctuation">)</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"P(O|lambda) = "</span><span class="token punctuation">,</span> end<span class="token operator">=</span><span class="token string">""</span><span class="token punctuation">)</span>
        <span class="token keyword">for</span> i <span class="token keyword">in</span> range<span class="token punctuation">(</span>N<span class="token punctuation">)</span><span class="token punctuation">:</span>
            <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"%.1f * %.1f * %.5f + "</span>
                  <span class="token operator">%</span> <span class="token punctuation">(</span>PI<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">,</span> B<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">[</span>index_of_o<span class="token punctuation">]</span><span class="token punctuation">,</span> betas<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span> end<span class="token operator">=</span><span class="token string">""</span><span class="token punctuation">)</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"0 = %f"</span> <span class="token operator">%</span> P<span class="token punctuation">)</span>

    @staticmethod
    <span class="token keyword">def</span> <span class="token function">print_betas_t</span><span class="token punctuation">(</span>A<span class="token punctuation">,</span> B<span class="token punctuation">,</span> N<span class="token punctuation">,</span> betas<span class="token punctuation">,</span> i<span class="token punctuation">,</span> index_of_o<span class="token punctuation">,</span> real_i<span class="token punctuation">,</span> real_t<span class="token punctuation">,</span> t<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"beta%d(%d) = sum[a%dj * bj(o%d) * beta%d(j)] = ("</span>
              <span class="token operator">%</span> <span class="token punctuation">(</span>real_t<span class="token punctuation">,</span> real_i<span class="token punctuation">,</span> real_i<span class="token punctuation">,</span> real_t <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">,</span> real_t <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> end<span class="token operator">=</span><span class="token string">''</span><span class="token punctuation">)</span>
        <span class="token keyword">for</span> j <span class="token keyword">in</span> range<span class="token punctuation">(</span>N<span class="token punctuation">)</span><span class="token punctuation">:</span>
            <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"%.2f * %.2f * %.2f + "</span>
                  <span class="token operator">%</span> <span class="token punctuation">(</span>A<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">[</span>j<span class="token punctuation">]</span><span class="token punctuation">,</span> B<span class="token punctuation">[</span>j<span class="token punctuation">]</span><span class="token punctuation">[</span>index_of_o<span class="token punctuation">]</span><span class="token punctuation">,</span> betas<span class="token punctuation">[</span>j<span class="token punctuation">]</span><span class="token punctuation">[</span>t <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span> end<span class="token operator">=</span><span class="token string">''</span><span class="token punctuation">)</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"0) = %.3f"</span> <span class="token operator">%</span> betas<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">[</span>t<span class="token punctuation">]</span><span class="token punctuation">)</span>

    @staticmethod
    <span class="token keyword">def</span> <span class="token function">print_betas_T</span><span class="token punctuation">(</span>N<span class="token punctuation">,</span> M<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"初始化后向概率："</span><span class="token punctuation">)</span>
        <span class="token keyword">for</span> i <span class="token keyword">in</span> range<span class="token punctuation">(</span>N<span class="token punctuation">)</span><span class="token punctuation">:</span>
            <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'beta%d(%d) = 1'</span> <span class="token operator">%</span> <span class="token punctuation">(</span>M<span class="token punctuation">,</span> i <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<pre class="line-numbers language-python"><code class="language-python">Q <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">]</span>
V <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">'红'</span><span class="token punctuation">,</span> <span class="token string">'白'</span><span class="token punctuation">]</span>
A <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">0.5</span><span class="token punctuation">,</span> <span class="token number">0.2</span><span class="token punctuation">,</span> <span class="token number">0.3</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">0.3</span><span class="token punctuation">,</span> <span class="token number">0.5</span><span class="token punctuation">,</span> <span class="token number">0.2</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">0.2</span><span class="token punctuation">,</span> <span class="token number">0.3</span><span class="token punctuation">,</span> <span class="token number">0.5</span><span class="token punctuation">]</span><span class="token punctuation">]</span>
B <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">0.5</span><span class="token punctuation">,</span> <span class="token number">0.5</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">0.4</span><span class="token punctuation">,</span> <span class="token number">0.6</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">0.7</span><span class="token punctuation">,</span> <span class="token number">0.3</span><span class="token punctuation">]</span><span class="token punctuation">]</span>
O <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">'红'</span><span class="token punctuation">,</span> <span class="token string">'白'</span><span class="token punctuation">,</span> <span class="token string">'红'</span><span class="token punctuation">,</span> <span class="token string">'白'</span><span class="token punctuation">]</span>
PI <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">0.2</span><span class="token punctuation">,</span> <span class="token number">0.4</span><span class="token punctuation">,</span> <span class="token number">0.4</span><span class="token punctuation">]</span><span class="token punctuation">]</span>

hmm_backward <span class="token operator">=</span> HiddenMarkovBackward<span class="token punctuation">(</span><span class="token punctuation">)</span>
hmm_backward<span class="token punctuation">.</span>backward<span class="token punctuation">(</span>Q<span class="token punctuation">,</span> V<span class="token punctuation">,</span> A<span class="token punctuation">,</span> B<span class="token punctuation">,</span> O<span class="token punctuation">,</span> PI<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<pre><code>初始化后向概率：
beta4(1) = 1
beta4(2) = 1
beta4(3) = 1

从时刻T-1到1观测序列的后向概率：
beta3(1) = sum[a1j * bj(o4) * beta4(j)] = (0.50 * 0.50 * 1.00 + 0.20 * 0.60 * 1.00 + 0.30 * 0.30 * 1.00 + 0) = 0.460
beta3(2) = sum[a2j * bj(o4) * beta4(j)] = (0.30 * 0.50 * 1.00 + 0.50 * 0.60 * 1.00 + 0.20 * 0.30 * 1.00 + 0) = 0.510
beta3(3) = sum[a3j * bj(o4) * beta4(j)] = (0.20 * 0.50 * 1.00 + 0.30 * 0.60 * 1.00 + 0.50 * 0.30 * 1.00 + 0) = 0.430
beta2(1) = sum[a1j * bj(o3) * beta3(j)] = (0.50 * 0.50 * 0.46 + 0.20 * 0.40 * 0.51 + 0.30 * 0.70 * 0.43 + 0) = 0.246
beta2(2) = sum[a2j * bj(o3) * beta3(j)] = (0.30 * 0.50 * 0.46 + 0.50 * 0.40 * 0.51 + 0.20 * 0.70 * 0.43 + 0) = 0.231
beta2(3) = sum[a3j * bj(o3) * beta3(j)] = (0.20 * 0.50 * 0.46 + 0.30 * 0.40 * 0.51 + 0.50 * 0.70 * 0.43 + 0) = 0.258
beta1(1) = sum[a1j * bj(o2) * beta2(j)] = (0.50 * 0.50 * 0.25 + 0.20 * 0.60 * 0.23 + 0.30 * 0.30 * 0.26 + 0) = 0.112
beta1(2) = sum[a2j * bj(o2) * beta2(j)] = (0.30 * 0.50 * 0.25 + 0.50 * 0.60 * 0.23 + 0.20 * 0.30 * 0.26 + 0) = 0.122
beta1(3) = sum[a3j * bj(o2) * beta2(j)] = (0.20 * 0.50 * 0.25 + 0.30 * 0.60 * 0.23 + 0.50 * 0.30 * 0.26 + 0) = 0.105

观测序列概率：
P(O|lambda) = 0.2 * 0.5 * 0.11246 + 0.4 * 0.4 * 0.12174 + 0.4 * 0.7 * 0.10488 + 0 = 0.060091</code></pre><p>可得$P(O|\lambda) = 0.060091$</p>
<h3 id="习题10-2-⭐⭐⭐"><a href="#习题10-2-⭐⭐⭐" class="headerlink" title="习题10.2 ⭐⭐⭐"></a>习题10.2 ⭐⭐⭐</h3><p>  给定盒子和球组成的隐马尔可夫模型$\lambda=(A,B,\pi)$，其中，</p>
<p>$$<br>A=\left[<br>\begin{array}{ccc}<br>0.5&amp;0.1&amp;0.4 \<br>0.3&amp;0.5&amp;0.2 \<br>0.2&amp;0.2&amp;0.6<br>\end{array}\right],<br>\quad B=\left[<br>\begin{array}{cc}<br>0.5&amp;0.5 \<br>0.4&amp;0.6 \<br>0.7&amp;0.3<br>\end{array}\right],<br>\quad \pi=(0.2,0.3,0.5)^T<br>$$</p>
<p>设$T=8$，$O=(红,白,红,红,白,红,白,白)$，试用前向后向概率计算$P(i_4=q_3|O,\lambda)$</p>
<p><strong>解答：</strong></p>
<p><strong>解答思路：</strong></p>
<ol>
<li>列出前向算法</li>
<li>根据前向概率和后向概率，列出单个状态概率的计算公式</li>
<li>自编程实现用前向后向概率计算$P(i_4=q_3|O,\lambda)$</li>
</ol>
<p><strong>解答步骤：</strong></p>
<p><strong>第1步：前向算法</strong></p>
<p>  根据书中第198页观测序列概率的前向算法：</p>
<blockquote>
<p>输入：隐马尔可夫模型$\lambda$，观测序列$O$；<br>输出：观测序列概率$P(O|\lambda)$。<br>（1）初值</p>
</blockquote>
<p>$$<br>\alpha_1(i) = \pi_i b_i(o_1), \quad i=1,2,\cdots, N<br>$$</p>
<blockquote>
<p>（2）递推，对$t=1,2,\cdots,T-1，$</p>
</blockquote>
<p>$$<br>\alpha_{t+1}(i) = \left[ \sum_{j=1}^N \alpha_t(j) a_{ji} \right] b_i(o_{t+1})， \quad i=1,2,\cdots, N<br>$$</p>
<blockquote>
<p>（3）终止</p>
</blockquote>
<p>$$<br>P(O|\lambda) = \sum_{i=1}^N \alpha_T(i)<br>$$</p>
<p><strong>第2步：单个状态概率的计算公式</strong></p>
<p>  根据书中第202页单个状态概率的计算公式：</p>
<blockquote>
<p>  利用前向概率和后向概率，给定模型$\lambda$和观测$O$，在时刻$t$处于状态$q_i$的概率</p>
</blockquote>
<p>$$<br>\begin{aligned}<br>\gamma_t(i) &amp;= P(i_t = q_i |O, \lambda) \<br>&amp;= \frac{P(i_t=q_i,O|\lambda)}{P(O|\lambda)} \<br>&amp;= \frac{\alpha_t(i) \beta_t(i)}{P(O|\lambda)}<br>\end{aligned}<br>$$</p>
<p><strong>第3步：自编程实现前向后向算法</strong></p>
<pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">import</span> numpy <span class="token keyword">as</span> np


<span class="token keyword">class</span> <span class="token class-name">HiddenMarkovForwardBackward</span><span class="token punctuation">(</span>HiddenMarkovBackward<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> verbose<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        super<span class="token punctuation">(</span>HiddenMarkovBackward<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>alphas <span class="token operator">=</span> None
        self<span class="token punctuation">.</span>forward_P <span class="token operator">=</span> None
        self<span class="token punctuation">.</span>verbose <span class="token operator">=</span> verbose

    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> Q<span class="token punctuation">,</span> V<span class="token punctuation">,</span> A<span class="token punctuation">,</span> B<span class="token punctuation">,</span> O<span class="token punctuation">,</span> PI<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token triple-quoted-string string">"""
        前向算法
        :param Q: 所有可能的状态集合
        :param V: 所有可能的观测集合
        :param A: 状态转移概率矩阵
        :param B: 观测概率矩阵
        :param O: 观测序列
        :param PI: 初始状态概率向量
        """</span>
        <span class="token comment" spellcheck="true"># 状态序列的大小</span>
        N <span class="token operator">=</span> len<span class="token punctuation">(</span>Q<span class="token punctuation">)</span>
        <span class="token comment" spellcheck="true"># 观测序列的大小</span>
        M <span class="token operator">=</span> len<span class="token punctuation">(</span>O<span class="token punctuation">)</span>
        <span class="token comment" spellcheck="true"># 初始化前向概率alpha值</span>
        alphas <span class="token operator">=</span> np<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token punctuation">(</span>N<span class="token punctuation">,</span> M<span class="token punctuation">)</span><span class="token punctuation">)</span>
        <span class="token comment" spellcheck="true"># 时刻数=观测序列数</span>
        T <span class="token operator">=</span> M
        <span class="token comment" spellcheck="true"># (2)对观测序列遍历，遍历每一个时刻，计算前向概率alpha值</span>

        <span class="token keyword">for</span> t <span class="token keyword">in</span> range<span class="token punctuation">(</span>T<span class="token punctuation">)</span><span class="token punctuation">:</span>
            <span class="token keyword">if</span> self<span class="token punctuation">.</span>verbose<span class="token punctuation">:</span>
                <span class="token keyword">if</span> t <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">:</span>
                    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"前向概率初值："</span><span class="token punctuation">)</span>
                <span class="token keyword">elif</span> t <span class="token operator">==</span> <span class="token number">1</span><span class="token punctuation">:</span>
                    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"\n从时刻1到T-1观测序列的前向概率："</span><span class="token punctuation">)</span>
            <span class="token comment" spellcheck="true"># 得到序列对应的索引</span>
            index_of_o <span class="token operator">=</span> V<span class="token punctuation">.</span>index<span class="token punctuation">(</span>O<span class="token punctuation">[</span>t<span class="token punctuation">]</span><span class="token punctuation">)</span>
            <span class="token comment" spellcheck="true"># 遍历状态序列</span>
            <span class="token keyword">for</span> i <span class="token keyword">in</span> range<span class="token punctuation">(</span>N<span class="token punctuation">)</span><span class="token punctuation">:</span>
                <span class="token keyword">if</span> t <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">:</span>
                    <span class="token comment" spellcheck="true"># (1)初始化alpha初值，书中第198页公式(10.15)</span>
                    alphas<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">[</span>t<span class="token punctuation">]</span> <span class="token operator">=</span> PI<span class="token punctuation">[</span>t<span class="token punctuation">]</span><span class="token punctuation">[</span>i<span class="token punctuation">]</span> <span class="token operator">*</span> B<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">[</span>index_of_o<span class="token punctuation">]</span>
                    <span class="token keyword">if</span> self<span class="token punctuation">.</span>verbose<span class="token punctuation">:</span>
                        self<span class="token punctuation">.</span>print_alpha_t1<span class="token punctuation">(</span>alphas<span class="token punctuation">,</span> i<span class="token punctuation">,</span> t<span class="token punctuation">)</span>
                <span class="token keyword">else</span><span class="token punctuation">:</span>
                    <span class="token comment" spellcheck="true"># (2)递推，书中第198页公式(10.16)</span>
                    alphas<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">[</span>t<span class="token punctuation">]</span> <span class="token operator">=</span> np<span class="token punctuation">.</span>dot<span class="token punctuation">(</span><span class="token punctuation">[</span>alpha<span class="token punctuation">[</span>t <span class="token operator">-</span> <span class="token number">1</span><span class="token punctuation">]</span> <span class="token keyword">for</span> alpha <span class="token keyword">in</span> alphas<span class="token punctuation">]</span><span class="token punctuation">,</span>
                                          <span class="token punctuation">[</span>a<span class="token punctuation">[</span>i<span class="token punctuation">]</span> <span class="token keyword">for</span> a <span class="token keyword">in</span> A<span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token operator">*</span> B<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">[</span>index_of_o<span class="token punctuation">]</span>
                    <span class="token keyword">if</span> self<span class="token punctuation">.</span>verbose<span class="token punctuation">:</span>
                        self<span class="token punctuation">.</span>print_alpha_t<span class="token punctuation">(</span>alphas<span class="token punctuation">,</span> i<span class="token punctuation">,</span> t<span class="token punctuation">)</span>
        <span class="token comment" spellcheck="true"># (3)终止，书中第198页公式(10.17)</span>
        self<span class="token punctuation">.</span>forward_P <span class="token operator">=</span> np<span class="token punctuation">.</span>sum<span class="token punctuation">(</span><span class="token punctuation">[</span>alpha<span class="token punctuation">[</span>M <span class="token operator">-</span> <span class="token number">1</span><span class="token punctuation">]</span> <span class="token keyword">for</span> alpha <span class="token keyword">in</span> alphas<span class="token punctuation">]</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>alphas <span class="token operator">=</span> alphas

    @staticmethod
    <span class="token keyword">def</span> <span class="token function">print_alpha_t</span><span class="token punctuation">(</span>alphas<span class="token punctuation">,</span> i<span class="token punctuation">,</span> t<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"alpha%d(%d) = [sum alpha%d(i) * ai%d] * b%d(o%d) = %f"</span>
              <span class="token operator">%</span> <span class="token punctuation">(</span>t <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">,</span> i <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">,</span> t <span class="token operator">-</span> <span class="token number">1</span><span class="token punctuation">,</span> i<span class="token punctuation">,</span> i<span class="token punctuation">,</span> t<span class="token punctuation">,</span> alphas<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">[</span>t<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

    @staticmethod
    <span class="token keyword">def</span> <span class="token function">print_alpha_t1</span><span class="token punctuation">(</span>alphas<span class="token punctuation">,</span> i<span class="token punctuation">,</span> t<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'alpha1(%d) = pi%d * b%d * b(o1) = %f'</span>
              <span class="token operator">%</span> <span class="token punctuation">(</span>i <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">,</span> i<span class="token punctuation">,</span> i<span class="token punctuation">,</span> alphas<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">[</span>t<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">calc_t_qi_prob</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> t<span class="token punctuation">,</span> qi<span class="token punctuation">)</span><span class="token punctuation">:</span>
        result <span class="token operator">=</span> <span class="token punctuation">(</span>self<span class="token punctuation">.</span>alphas<span class="token punctuation">[</span>qi <span class="token operator">-</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">[</span>t <span class="token operator">-</span> <span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">*</span> self<span class="token punctuation">.</span>betas<span class="token punctuation">[</span>qi <span class="token operator">-</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">[</span>t <span class="token operator">-</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token operator">/</span> self<span class="token punctuation">.</span>backward_P<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
        <span class="token keyword">if</span> self<span class="token punctuation">.</span>verbose<span class="token punctuation">:</span>
            <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"计算P(i%d=q%d|O,lambda)："</span> <span class="token operator">%</span> <span class="token punctuation">(</span>t<span class="token punctuation">,</span> qi<span class="token punctuation">)</span><span class="token punctuation">)</span>
            <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"P(i%d=q%d|O,lambda) = alpha%d(%d) * beta%d(%d) / P(O|lambda) = %f"</span>
                  <span class="token operator">%</span> <span class="token punctuation">(</span>t<span class="token punctuation">,</span> qi<span class="token punctuation">,</span> t<span class="token punctuation">,</span> qi<span class="token punctuation">,</span> t<span class="token punctuation">,</span> qi<span class="token punctuation">,</span> result<span class="token punctuation">)</span><span class="token punctuation">)</span>

        <span class="token keyword">return</span> result<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<pre class="line-numbers language-python"><code class="language-python">Q <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">]</span>
V <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">'红'</span><span class="token punctuation">,</span> <span class="token string">'白'</span><span class="token punctuation">]</span>
A <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">0.5</span><span class="token punctuation">,</span> <span class="token number">0.1</span><span class="token punctuation">,</span> <span class="token number">0.4</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">0.3</span><span class="token punctuation">,</span> <span class="token number">0.5</span><span class="token punctuation">,</span> <span class="token number">0.2</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">0.2</span><span class="token punctuation">,</span> <span class="token number">0.2</span><span class="token punctuation">,</span> <span class="token number">0.6</span><span class="token punctuation">]</span><span class="token punctuation">]</span>
B <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">0.5</span><span class="token punctuation">,</span> <span class="token number">0.5</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">0.4</span><span class="token punctuation">,</span> <span class="token number">0.6</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">0.7</span><span class="token punctuation">,</span> <span class="token number">0.3</span><span class="token punctuation">]</span><span class="token punctuation">]</span>
O <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">'红'</span><span class="token punctuation">,</span> <span class="token string">'白'</span><span class="token punctuation">,</span> <span class="token string">'红'</span><span class="token punctuation">,</span> <span class="token string">'红'</span><span class="token punctuation">,</span> <span class="token string">'白'</span><span class="token punctuation">,</span> <span class="token string">'红'</span><span class="token punctuation">,</span> <span class="token string">'白'</span><span class="token punctuation">,</span> <span class="token string">'白'</span><span class="token punctuation">]</span>
PI <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">0.2</span><span class="token punctuation">,</span> <span class="token number">0.3</span><span class="token punctuation">,</span> <span class="token number">0.5</span><span class="token punctuation">]</span><span class="token punctuation">]</span>

hmm_forward_backward <span class="token operator">=</span> HiddenMarkovForwardBackward<span class="token punctuation">(</span>verbose<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
hmm_forward_backward<span class="token punctuation">.</span>forward<span class="token punctuation">(</span>Q<span class="token punctuation">,</span> V<span class="token punctuation">,</span> A<span class="token punctuation">,</span> B<span class="token punctuation">,</span> O<span class="token punctuation">,</span> PI<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
hmm_forward_backward<span class="token punctuation">.</span>backward<span class="token punctuation">(</span>Q<span class="token punctuation">,</span> V<span class="token punctuation">,</span> A<span class="token punctuation">,</span> B<span class="token punctuation">,</span> O<span class="token punctuation">,</span> PI<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
hmm_forward_backward<span class="token punctuation">.</span>calc_t_qi_prob<span class="token punctuation">(</span>t<span class="token operator">=</span><span class="token number">4</span><span class="token punctuation">,</span> qi<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<pre><code>前向概率初值：
alpha1(1) = pi0 * b0 * b(o1) = 0.100000
alpha1(2) = pi1 * b1 * b(o1) = 0.120000
alpha1(3) = pi2 * b2 * b(o1) = 0.350000

从时刻1到T-1观测序列的前向概率：
alpha2(1) = [sum alpha0(i) * ai0] * b0(o1) = 0.078000
alpha2(2) = [sum alpha0(i) * ai1] * b1(o1) = 0.084000
alpha2(3) = [sum alpha0(i) * ai2] * b2(o1) = 0.082200
alpha3(1) = [sum alpha1(i) * ai0] * b0(o2) = 0.040320
alpha3(2) = [sum alpha1(i) * ai1] * b1(o2) = 0.026496
alpha3(3) = [sum alpha1(i) * ai2] * b2(o2) = 0.068124
alpha4(1) = [sum alpha2(i) * ai0] * b0(o3) = 0.020867
alpha4(2) = [sum alpha2(i) * ai1] * b1(o3) = 0.012362
alpha4(3) = [sum alpha2(i) * ai2] * b2(o3) = 0.043611
alpha5(1) = [sum alpha3(i) * ai0] * b0(o4) = 0.011432
alpha5(2) = [sum alpha3(i) * ai1] * b1(o4) = 0.010194
alpha5(3) = [sum alpha3(i) * ai2] * b2(o4) = 0.011096
alpha6(1) = [sum alpha4(i) * ai0] * b0(o5) = 0.005497
alpha6(2) = [sum alpha4(i) * ai1] * b1(o5) = 0.003384
alpha6(3) = [sum alpha4(i) * ai2] * b2(o5) = 0.009288
alpha7(1) = [sum alpha5(i) * ai0] * b0(o6) = 0.002811
alpha7(2) = [sum alpha5(i) * ai1] * b1(o6) = 0.002460
alpha7(3) = [sum alpha5(i) * ai2] * b2(o6) = 0.002535
alpha8(1) = [sum alpha6(i) * ai0] * b0(o7) = 0.001325
alpha8(2) = [sum alpha6(i) * ai1] * b1(o7) = 0.001211
alpha8(3) = [sum alpha6(i) * ai2] * b2(o7) = 0.000941

初始化后向概率：
beta8(1) = 1
beta8(2) = 1
beta8(3) = 1

从时刻T-1到1观测序列的后向概率：
beta7(1) = sum[a1j * bj(o8) * beta8(j)] = (0.50 * 0.50 * 1.00 + 0.10 * 0.60 * 1.00 + 0.40 * 0.30 * 1.00 + 0) = 0.430
beta7(2) = sum[a2j * bj(o8) * beta8(j)] = (0.30 * 0.50 * 1.00 + 0.50 * 0.60 * 1.00 + 0.20 * 0.30 * 1.00 + 0) = 0.510
beta7(3) = sum[a3j * bj(o8) * beta8(j)] = (0.20 * 0.50 * 1.00 + 0.20 * 0.60 * 1.00 + 0.60 * 0.30 * 1.00 + 0) = 0.400
beta6(1) = sum[a1j * bj(o7) * beta7(j)] = (0.50 * 0.50 * 0.43 + 0.10 * 0.60 * 0.51 + 0.40 * 0.30 * 0.40 + 0) = 0.186
beta6(2) = sum[a2j * bj(o7) * beta7(j)] = (0.30 * 0.50 * 0.43 + 0.50 * 0.60 * 0.51 + 0.20 * 0.30 * 0.40 + 0) = 0.241
beta6(3) = sum[a3j * bj(o7) * beta7(j)] = (0.20 * 0.50 * 0.43 + 0.20 * 0.60 * 0.51 + 0.60 * 0.30 * 0.40 + 0) = 0.176
beta5(1) = sum[a1j * bj(o6) * beta6(j)] = (0.50 * 0.50 * 0.19 + 0.10 * 0.40 * 0.24 + 0.40 * 0.70 * 0.18 + 0) = 0.106
beta5(2) = sum[a2j * bj(o6) * beta6(j)] = (0.30 * 0.50 * 0.19 + 0.50 * 0.40 * 0.24 + 0.20 * 0.70 * 0.18 + 0) = 0.101
beta5(3) = sum[a3j * bj(o6) * beta6(j)] = (0.20 * 0.50 * 0.19 + 0.20 * 0.40 * 0.24 + 0.60 * 0.70 * 0.18 + 0) = 0.112
beta4(1) = sum[a1j * bj(o5) * beta5(j)] = (0.50 * 0.50 * 0.11 + 0.10 * 0.60 * 0.10 + 0.40 * 0.30 * 0.11 + 0) = 0.046
beta4(2) = sum[a2j * bj(o5) * beta5(j)] = (0.30 * 0.50 * 0.11 + 0.50 * 0.60 * 0.10 + 0.20 * 0.30 * 0.11 + 0) = 0.053
beta4(3) = sum[a3j * bj(o5) * beta5(j)] = (0.20 * 0.50 * 0.11 + 0.20 * 0.60 * 0.10 + 0.60 * 0.30 * 0.11 + 0) = 0.043
beta3(1) = sum[a1j * bj(o4) * beta4(j)] = (0.50 * 0.50 * 0.05 + 0.10 * 0.40 * 0.05 + 0.40 * 0.70 * 0.04 + 0) = 0.026
beta3(2) = sum[a2j * bj(o4) * beta4(j)] = (0.30 * 0.50 * 0.05 + 0.50 * 0.40 * 0.05 + 0.20 * 0.70 * 0.04 + 0) = 0.023
beta3(3) = sum[a3j * bj(o4) * beta4(j)] = (0.20 * 0.50 * 0.05 + 0.20 * 0.40 * 0.05 + 0.60 * 0.70 * 0.04 + 0) = 0.027
beta2(1) = sum[a1j * bj(o3) * beta3(j)] = (0.50 * 0.50 * 0.03 + 0.10 * 0.40 * 0.02 + 0.40 * 0.70 * 0.03 + 0) = 0.015
beta2(2) = sum[a2j * bj(o3) * beta3(j)] = (0.30 * 0.50 * 0.03 + 0.50 * 0.40 * 0.02 + 0.20 * 0.70 * 0.03 + 0) = 0.012
beta2(3) = sum[a3j * bj(o3) * beta3(j)] = (0.20 * 0.50 * 0.03 + 0.20 * 0.40 * 0.02 + 0.60 * 0.70 * 0.03 + 0) = 0.016
beta1(1) = sum[a1j * bj(o2) * beta2(j)] = (0.50 * 0.50 * 0.01 + 0.10 * 0.60 * 0.01 + 0.40 * 0.30 * 0.02 + 0) = 0.006
beta1(2) = sum[a2j * bj(o2) * beta2(j)] = (0.30 * 0.50 * 0.01 + 0.50 * 0.60 * 0.01 + 0.20 * 0.30 * 0.02 + 0) = 0.007
beta1(3) = sum[a3j * bj(o2) * beta2(j)] = (0.20 * 0.50 * 0.01 + 0.20 * 0.60 * 0.01 + 0.60 * 0.30 * 0.02 + 0) = 0.006

观测序列概率：
P(O|lambda) = 0.2 * 0.5 * 0.00633 + 0.3 * 0.4 * 0.00685 + 0.5 * 0.7 * 0.00578 + 0 = 0.003477

计算P(i4=q3|O,lambda)：
P(i4=q3|O,lambda) = alpha4(3) * beta4(3) / P(O|lambda) = 0.536952</code></pre><p>​    </p>
<p>可知，$\displaystyle P(i_4=q_3|O,\lambda)=\frac{P(i_4=q_3,O|\lambda)}{P(O|\lambda)}=\frac{\alpha_4(3)\beta_4(3)}{P(O|\lambda)} = 0.536952$</p>
<h3 id="习题10-3-⭐⭐⭐"><a href="#习题10-3-⭐⭐⭐" class="headerlink" title="习题10.3 ⭐⭐⭐"></a>习题10.3 ⭐⭐⭐</h3><p>  在习题10.1中，试用维特比算法求最优路径$I^<em>=(i_1^</em>,i_2^<em>,i_3^</em>,i_4^*)$。</p>
<p><strong>解答：</strong></p>
<p><strong>解答思路：</strong></p>
<ol>
<li>列出维特比算法</li>
<li>自编程实现维特比算法，并求最优路径</li>
</ol>
<p><strong>解答步骤：</strong></p>
<p><strong>第1步：维特比算法</strong></p>
<p>  根据书中第209页维特比算法：</p>
<blockquote>
<p>输入：模型$\lambda=(A,B, \pi)$和观测$O=(o_1, o_2, \cdots, o_T)$；<br>输出：最优路径$I^* = (i_1^<em>, i_2^</em>, \cdots, i_T^*)$。<br>（1）初始化</p>
</blockquote>
<p>$$<br>\delta_1(i) = \pi_i b_i(o_1), \quad i=1,2, \cdots, N \<br>\Psi_1(i) = 0, \quad i=1,2, \cdots, N<br>$$</p>
<blockquote>
<p>（2）递推。对$t=2,3, \cdots, T$</p>
</blockquote>
<p>$$<br>\delta_t(i) = \max \limits_{1 \leqslant j \leqslant N} [\delta_{t-1}(j) a_{ji}] b_i(o_t), \quad i=1,2, \cdots, N \<br>\Psi_t(i) = \arg \max \limits_{1 \leqslant j \leqslant N} [\delta_{t-1}(j) a_{ji}], \quad i=1,2, \cdots, N<br>$$</p>
<blockquote>
<p>（3）终止</p>
</blockquote>
<p>$$<br>P^* = \max \limits_{1 \leqslant i \leqslant N} \delta_T(i) \<br>i_T^* = \arg \max \limits_{1 \leqslant i \leqslant N} [\delta_T(i)]<br>$$</p>
<blockquote>
<p>（4）最优路径回溯。对$t=T-1, T-2, \cdots , 1$</p>
</blockquote>
<p>$$<br>i_t^* = \Psi_{t+1}(i_{t+1}^*)<br>$$</p>
<blockquote>
<p>求得最优路径$I^* = (i_1^<em>, i_2^</em>, \cdots, i_T^*)$。</p>
</blockquote>
<p><strong>第2步：自编程实现维特比算法</strong></p>
<pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">import</span> numpy <span class="token keyword">as</span> np


<span class="token keyword">class</span> <span class="token class-name">HiddenMarkovViterbi</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> verbose<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        self<span class="token punctuation">.</span>verbose <span class="token operator">=</span> verbose

    <span class="token keyword">def</span> <span class="token function">viterbi</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> Q<span class="token punctuation">,</span> V<span class="token punctuation">,</span> A<span class="token punctuation">,</span> B<span class="token punctuation">,</span> O<span class="token punctuation">,</span> PI<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token triple-quoted-string string">"""
        维特比算法
        :param Q: 所有可能的状态集合
        :param V: 所有可能的观测集合
        :param A: 状态转移概率矩阵
        :param B: 观测概率矩阵
        :param O: 观测序列
        :param PI: 初始状态概率向量
        """</span>
        <span class="token comment" spellcheck="true"># 状态序列的大小</span>
        N <span class="token operator">=</span> len<span class="token punctuation">(</span>Q<span class="token punctuation">)</span>
        <span class="token comment" spellcheck="true"># 观测序列的大小</span>
        M <span class="token operator">=</span> len<span class="token punctuation">(</span>O<span class="token punctuation">)</span>
        <span class="token comment" spellcheck="true"># 初始化deltas</span>
        deltas <span class="token operator">=</span> np<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token punctuation">(</span>N<span class="token punctuation">,</span> M<span class="token punctuation">)</span><span class="token punctuation">)</span>
        <span class="token comment" spellcheck="true"># 初始化psis</span>
        psis <span class="token operator">=</span> np<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token punctuation">(</span>N<span class="token punctuation">,</span> M<span class="token punctuation">)</span><span class="token punctuation">)</span>

        <span class="token comment" spellcheck="true"># 初始化最优路径矩阵，该矩阵维度与观测序列维度相同</span>
        I <span class="token operator">=</span> np<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> M<span class="token punctuation">)</span><span class="token punctuation">)</span>
        <span class="token comment" spellcheck="true"># (2)递推，遍历观测序列</span>
        <span class="token keyword">for</span> t <span class="token keyword">in</span> range<span class="token punctuation">(</span>M<span class="token punctuation">)</span><span class="token punctuation">:</span>
            <span class="token keyword">if</span> self<span class="token punctuation">.</span>verbose<span class="token punctuation">:</span>
                <span class="token keyword">if</span> t <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">:</span>
                    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"初始化Psi1和delta1："</span><span class="token punctuation">)</span>
                <span class="token keyword">elif</span> t <span class="token operator">==</span> <span class="token number">1</span><span class="token punctuation">:</span>
                    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"\n从时刻2到T的所有单个路径中概率"</span>
                          <span class="token string">"最大值delta和概率最大的路径的第t-1个结点Psi："</span><span class="token punctuation">)</span>

            <span class="token comment" spellcheck="true"># (2)递推从t=2开始</span>
            real_t <span class="token operator">=</span> t <span class="token operator">+</span> <span class="token number">1</span>
            <span class="token comment" spellcheck="true"># 得到序列对应的索引</span>
            index_of_o <span class="token operator">=</span> V<span class="token punctuation">.</span>index<span class="token punctuation">(</span>O<span class="token punctuation">[</span>t<span class="token punctuation">]</span><span class="token punctuation">)</span>
            <span class="token keyword">for</span> i <span class="token keyword">in</span> range<span class="token punctuation">(</span>N<span class="token punctuation">)</span><span class="token punctuation">:</span>
                real_i <span class="token operator">=</span> i <span class="token operator">+</span> <span class="token number">1</span>
                <span class="token keyword">if</span> t <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">:</span>
                    <span class="token comment" spellcheck="true"># (1)初始化</span>
                    deltas<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">[</span>t<span class="token punctuation">]</span> <span class="token operator">=</span> PI<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span>i<span class="token punctuation">]</span> <span class="token operator">*</span> B<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">[</span>index_of_o<span class="token punctuation">]</span>
                    psis<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">[</span>t<span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token number">0</span>

                    self<span class="token punctuation">.</span>print_delta_t1<span class="token punctuation">(</span>
                        B<span class="token punctuation">,</span> PI<span class="token punctuation">,</span> deltas<span class="token punctuation">,</span> i<span class="token punctuation">,</span> index_of_o<span class="token punctuation">,</span> real_i<span class="token punctuation">,</span> t<span class="token punctuation">)</span>
                    self<span class="token punctuation">.</span>print_psi_t1<span class="token punctuation">(</span>real_i<span class="token punctuation">)</span>
                <span class="token keyword">else</span><span class="token punctuation">:</span>
                    <span class="token comment" spellcheck="true"># (2)递推，对t=2,3,...,T</span>
                    deltas<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">[</span>t<span class="token punctuation">]</span> <span class="token operator">=</span> np<span class="token punctuation">.</span>max<span class="token punctuation">(</span>np<span class="token punctuation">.</span>multiply<span class="token punctuation">(</span><span class="token punctuation">[</span>delta<span class="token punctuation">[</span>t <span class="token operator">-</span> <span class="token number">1</span><span class="token punctuation">]</span> <span class="token keyword">for</span> delta <span class="token keyword">in</span> deltas<span class="token punctuation">]</span><span class="token punctuation">,</span>
                                                      <span class="token punctuation">[</span>a<span class="token punctuation">[</span>i<span class="token punctuation">]</span> <span class="token keyword">for</span> a <span class="token keyword">in</span> A<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token operator">*</span> B<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">[</span>index_of_o<span class="token punctuation">]</span>
                    self<span class="token punctuation">.</span>print_delta_t<span class="token punctuation">(</span>
                        A<span class="token punctuation">,</span> B<span class="token punctuation">,</span> deltas<span class="token punctuation">,</span> i<span class="token punctuation">,</span> index_of_o<span class="token punctuation">,</span> real_i<span class="token punctuation">,</span> real_t<span class="token punctuation">,</span> t<span class="token punctuation">)</span>

                    psis<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">[</span>t<span class="token punctuation">]</span> <span class="token operator">=</span> np<span class="token punctuation">.</span>argmax<span class="token punctuation">(</span>np<span class="token punctuation">.</span>multiply<span class="token punctuation">(</span><span class="token punctuation">[</span>delta<span class="token punctuation">[</span>t <span class="token operator">-</span> <span class="token number">1</span><span class="token punctuation">]</span> <span class="token keyword">for</span> delta <span class="token keyword">in</span> deltas<span class="token punctuation">]</span><span class="token punctuation">,</span>
                                                       <span class="token punctuation">[</span>a<span class="token punctuation">[</span>i<span class="token punctuation">]</span> <span class="token keyword">for</span> a <span class="token keyword">in</span> A<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
                    self<span class="token punctuation">.</span>print_psi_t<span class="token punctuation">(</span>i<span class="token punctuation">,</span> psis<span class="token punctuation">,</span> real_i<span class="token punctuation">,</span> real_t<span class="token punctuation">,</span> t<span class="token punctuation">)</span>

        last_deltas <span class="token operator">=</span> <span class="token punctuation">[</span>delta<span class="token punctuation">[</span>M <span class="token operator">-</span> <span class="token number">1</span><span class="token punctuation">]</span> <span class="token keyword">for</span> delta <span class="token keyword">in</span> deltas<span class="token punctuation">]</span>
        <span class="token comment" spellcheck="true"># (3)终止，得到所有路径的终结点最大的概率值</span>
        P <span class="token operator">=</span> np<span class="token punctuation">.</span>max<span class="token punctuation">(</span>last_deltas<span class="token punctuation">)</span>
        <span class="token comment" spellcheck="true"># (3)得到最优路径的终结点</span>
        I<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span>M <span class="token operator">-</span> <span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">=</span> np<span class="token punctuation">.</span>argmax<span class="token punctuation">(</span>last_deltas<span class="token punctuation">)</span>
        <span class="token keyword">if</span> self<span class="token punctuation">.</span>verbose<span class="token punctuation">:</span>
            <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"\n所有路径的终结点最大的概率值："</span><span class="token punctuation">)</span>
            <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"P = %f"</span> <span class="token operator">%</span> P<span class="token punctuation">)</span>
        <span class="token keyword">if</span> self<span class="token punctuation">.</span>verbose<span class="token punctuation">:</span>
            <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"\n最优路径的终结点："</span><span class="token punctuation">)</span>
            <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"i%d = argmax[deltaT(i)] = %d"</span> <span class="token operator">%</span> <span class="token punctuation">(</span>M<span class="token punctuation">,</span> I<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span>M <span class="token operator">-</span> <span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
            <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"\n最优路径的其他结点："</span><span class="token punctuation">)</span>

        <span class="token comment" spellcheck="true"># (4)递归由后向前得到其他结点</span>
        <span class="token keyword">for</span> t <span class="token keyword">in</span> range<span class="token punctuation">(</span>M <span class="token operator">-</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            I<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span>t<span class="token punctuation">]</span> <span class="token operator">=</span> psis<span class="token punctuation">[</span>int<span class="token punctuation">(</span>I<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span>t <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">[</span>t <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">]</span>
            <span class="token keyword">if</span> self<span class="token punctuation">.</span>verbose<span class="token punctuation">:</span>
                <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"i%d = Psi%d(i%d) = %d"</span> <span class="token operator">%</span>
                      <span class="token punctuation">(</span>t <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">,</span> t <span class="token operator">+</span> <span class="token number">2</span><span class="token punctuation">,</span> t <span class="token operator">+</span> <span class="token number">2</span><span class="token punctuation">,</span> I<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span>t<span class="token punctuation">]</span> <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

        <span class="token comment" spellcheck="true"># 输出最优路径</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"\n最优路径是："</span><span class="token punctuation">,</span> <span class="token string">"->"</span><span class="token punctuation">.</span>join<span class="token punctuation">(</span><span class="token punctuation">[</span>str<span class="token punctuation">(</span>int<span class="token punctuation">(</span>i <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token keyword">for</span> i <span class="token keyword">in</span> I<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">print_psi_t</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> i<span class="token punctuation">,</span> psis<span class="token punctuation">,</span> real_i<span class="token punctuation">,</span> real_t<span class="token punctuation">,</span> t<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">if</span> self<span class="token punctuation">.</span>verbose<span class="token punctuation">:</span>
            <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"Psi%d(%d) = argmax[delta%d(j) * aj%d] = %d"</span>
                  <span class="token operator">%</span> <span class="token punctuation">(</span>real_t<span class="token punctuation">,</span> real_i<span class="token punctuation">,</span> real_t <span class="token operator">-</span> <span class="token number">1</span><span class="token punctuation">,</span> real_i<span class="token punctuation">,</span> psis<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">[</span>t<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">print_delta_t</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> A<span class="token punctuation">,</span> B<span class="token punctuation">,</span> deltas<span class="token punctuation">,</span> i<span class="token punctuation">,</span> index_of_o<span class="token punctuation">,</span> real_i<span class="token punctuation">,</span> real_t<span class="token punctuation">,</span> t<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">if</span> self<span class="token punctuation">.</span>verbose<span class="token punctuation">:</span>
            <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"delta%d(%d) = max[delta%d(j) * aj%d] * b%d(o%d) = %.2f * %.2f = %.5f"</span>
                  <span class="token operator">%</span> <span class="token punctuation">(</span>real_t<span class="token punctuation">,</span> real_i<span class="token punctuation">,</span> real_t <span class="token operator">-</span> <span class="token number">1</span><span class="token punctuation">,</span> real_i<span class="token punctuation">,</span> real_i<span class="token punctuation">,</span> real_t<span class="token punctuation">,</span>
                     np<span class="token punctuation">.</span>max<span class="token punctuation">(</span>np<span class="token punctuation">.</span>multiply<span class="token punctuation">(</span><span class="token punctuation">[</span>delta<span class="token punctuation">[</span>t <span class="token operator">-</span> <span class="token number">1</span><span class="token punctuation">]</span> <span class="token keyword">for</span> delta <span class="token keyword">in</span> deltas<span class="token punctuation">]</span><span class="token punctuation">,</span>
                                        <span class="token punctuation">[</span>a<span class="token punctuation">[</span>i<span class="token punctuation">]</span> <span class="token keyword">for</span> a <span class="token keyword">in</span> A<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                     B<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">[</span>index_of_o<span class="token punctuation">]</span><span class="token punctuation">,</span> deltas<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">[</span>t<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">print_psi_t1</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> real_i<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">if</span> self<span class="token punctuation">.</span>verbose<span class="token punctuation">:</span>
            <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"Psi1(%d) = 0"</span> <span class="token operator">%</span> real_i<span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">print_delta_t1</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> B<span class="token punctuation">,</span> PI<span class="token punctuation">,</span> deltas<span class="token punctuation">,</span> i<span class="token punctuation">,</span> index_of_o<span class="token punctuation">,</span> real_i<span class="token punctuation">,</span> t<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">if</span> self<span class="token punctuation">.</span>verbose<span class="token punctuation">:</span>
            <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"delta1(%d) = pi%d * b%d(o1) = %.2f * %.2f = %.2f"</span>
                  <span class="token operator">%</span> <span class="token punctuation">(</span>real_i<span class="token punctuation">,</span> real_i<span class="token punctuation">,</span> real_i<span class="token punctuation">,</span> PI<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">,</span> B<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">[</span>index_of_o<span class="token punctuation">]</span><span class="token punctuation">,</span> deltas<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">[</span>t<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<pre class="line-numbers language-python"><code class="language-python">Q <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">]</span>
V <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">'红'</span><span class="token punctuation">,</span> <span class="token string">'白'</span><span class="token punctuation">]</span>
A <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">0.5</span><span class="token punctuation">,</span> <span class="token number">0.2</span><span class="token punctuation">,</span> <span class="token number">0.3</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">0.3</span><span class="token punctuation">,</span> <span class="token number">0.5</span><span class="token punctuation">,</span> <span class="token number">0.2</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">0.2</span><span class="token punctuation">,</span> <span class="token number">0.3</span><span class="token punctuation">,</span> <span class="token number">0.5</span><span class="token punctuation">]</span><span class="token punctuation">]</span>
B <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">0.5</span><span class="token punctuation">,</span> <span class="token number">0.5</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">0.4</span><span class="token punctuation">,</span> <span class="token number">0.6</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">0.7</span><span class="token punctuation">,</span> <span class="token number">0.3</span><span class="token punctuation">]</span><span class="token punctuation">]</span>
O <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">'红'</span><span class="token punctuation">,</span> <span class="token string">'白'</span><span class="token punctuation">,</span> <span class="token string">'红'</span><span class="token punctuation">,</span> <span class="token string">'白'</span><span class="token punctuation">]</span>
PI <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">0.2</span><span class="token punctuation">,</span> <span class="token number">0.4</span><span class="token punctuation">,</span> <span class="token number">0.4</span><span class="token punctuation">]</span><span class="token punctuation">]</span>

HMM <span class="token operator">=</span> HiddenMarkovViterbi<span class="token punctuation">(</span>verbose<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
HMM<span class="token punctuation">.</span>viterbi<span class="token punctuation">(</span>Q<span class="token punctuation">,</span> V<span class="token punctuation">,</span> A<span class="token punctuation">,</span> B<span class="token punctuation">,</span> O<span class="token punctuation">,</span> PI<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<pre><code>初始化Psi1和delta1：
delta1(1) = pi1 * b1(o1) = 0.20 * 0.50 = 0.10
Psi1(1) = 0
delta1(2) = pi2 * b2(o1) = 0.40 * 0.40 = 0.16
Psi1(2) = 0
delta1(3) = pi3 * b3(o1) = 0.40 * 0.70 = 0.28
Psi1(3) = 0

从时刻2到T的所有单个路径中概率最大值delta和概率最大的路径的第t-1个结点Psi：
delta2(1) = max[delta1(j) * aj1] * b1(o2) = 0.06 * 0.50 = 0.02800
Psi2(1) = argmax[delta1(j) * aj1] = 2
delta2(2) = max[delta1(j) * aj2] * b2(o2) = 0.08 * 0.60 = 0.05040
Psi2(2) = argmax[delta1(j) * aj2] = 2
delta2(3) = max[delta1(j) * aj3] * b3(o2) = 0.14 * 0.30 = 0.04200
Psi2(3) = argmax[delta1(j) * aj3] = 2
delta3(1) = max[delta2(j) * aj1] * b1(o3) = 0.02 * 0.50 = 0.00756
Psi3(1) = argmax[delta2(j) * aj1] = 1
delta3(2) = max[delta2(j) * aj2] * b2(o3) = 0.03 * 0.40 = 0.01008
Psi3(2) = argmax[delta2(j) * aj2] = 1
delta3(3) = max[delta2(j) * aj3] * b3(o3) = 0.02 * 0.70 = 0.01470
Psi3(3) = argmax[delta2(j) * aj3] = 2
delta4(1) = max[delta3(j) * aj1] * b1(o4) = 0.00 * 0.50 = 0.00189
Psi4(1) = argmax[delta3(j) * aj1] = 0
delta4(2) = max[delta3(j) * aj2] * b2(o4) = 0.01 * 0.60 = 0.00302
Psi4(2) = argmax[delta3(j) * aj2] = 1
delta4(3) = max[delta3(j) * aj3] * b3(o4) = 0.01 * 0.30 = 0.00220
Psi4(3) = argmax[delta3(j) * aj3] = 2

所有路径的终结点最大的概率值：
P = 0.003024

最优路径的终结点：
i4 = argmax[deltaT(i)] = 2

最优路径的其他结点：
i3 = Psi4(i4) = 2
i2 = Psi3(i3) = 2
i1 = Psi2(i2) = 3

最优路径是： 3-&gt;2-&gt;2-&gt;2</code></pre><p>所以，最优路径$I^<em>=(i_1^</em>,i_2^<em>,i_3^</em>,i_4^*)=(3,2,2,2)$。</p>
<h3 id="习题10-4"><a href="#习题10-4" class="headerlink" title="习题10.4"></a>习题10.4</h3><p>  试用前向概率和后向概率推导$$P(O|\lambda)=\sum_{i=1}^N\sum_{j=1}^N\alpha_t(i)a_{ij}b_j(o_{t+1})\beta_{t+1}(j),\quad t=1,2,\cdots,T-1$$</p>
<p><strong>解答：</strong></p>
<p><strong>解答思路：</strong></p>
<ol>
<li>将$P(O|\lambda)$按照定义展开，即$P(O|\lambda) = P(o_1,o_2,…,o_T|\lambda)$</li>
<li>假设在时刻$t$状态为$q_i$的条件下，将概率拆分为两个条件概率（前向概率、后向概率）</li>
<li>在后向概率中，假设在时刻$t+1$状态为$q_j$，继续拆分为两个条件概率（$t+1$时刻的概率和$t+2$至$T$的概率）</li>
<li>将$t+1$时刻的概率拆分为$t+1$时刻的观测概率和状态转移概率</li>
<li>按照前向概率和后向概率定义，使用$\alpha,\beta,a,b$来表示</li>
</ol>
<p><strong>解答步骤：</strong>  </p>
<p><strong>第1步：$P(O|\lambda)$展开推导</strong></p>
<p>$$\begin{aligned}<br>P(O|\lambda)<br>&amp;= P(o_1,o_2,…,o_T|\lambda) \<br>&amp;= \sum_{i=1}^N P(o_1,..,o_t,i_t=q_i|\lambda) P(o_{t+1},..,o_T|i_t=q_i,\lambda) \<br>&amp;= \sum_{i=1}^N \sum_{j=1}^N P(o_1,..,o_t,i_t=q_i|\lambda) P(o_{t+1},i_{t+1}=q_j|i_t=q_i,\lambda)P(o_{t+2},..,o_T|i_{t+1}=q_j,\lambda) \<br>&amp;= \sum_{i=1}^N \sum_{j=1}^N [P(o_1,..,o_t,i_t=q_i|\lambda) P(o_{t+1}|i_{t+1}=q_j,\lambda) P(i_{t+1}=q_j|i_t=q_i,\lambda) \<br>&amp; \quad \quad \quad \quad P(o_{t+2},..,o_T|i_{t+1}=q_j,\lambda)] \<br>\end{aligned}$$</p>
<p><strong>第2步：前向概率和后向概率</strong></p>
<p>根据书中第198页前向概率：</p>
<blockquote>
<p>  给定隐马尔可夫模型$\lambda$，定义到时刻$t$部分观测序列为$o_1, o_2, \cdots, o_t$且状态为$q_i$的概率为前向概率，记作  </p>
</blockquote>
<p>$$<br>\alpha_t(i) = P(o_1, o_2, \cdots, o_t, i_t=q_i | \lambda)<br>$$</p>
<blockquote>
<p>可以递推地求得前向概率$\alpha_t(i)$及观测序列概率$P(O|\lambda)$</p>
</blockquote>
<p>根据书中第201页后向概率：</p>
<blockquote>
<p>  给定隐马尔可夫模型$\lambda$，定义在时刻$t$状态为$q_i$的条件下，从$t+1$到$T$的部分观测序列为$o_{t+1}, o_{t+2}, \cdots, o_T$的后向概率，记作  </p>
</blockquote>
<p>$$<br>\beta_t(i) = P(o_{t+1}, o_{t+2}, \cdots, o_T| | i_t=q_i , \lambda)<br>$$</p>
<blockquote>
<p>可以用递推的方法求得后向概率$\beta_t(i)$及观测序列概率$P(O|\lambda)$</p>
</blockquote>
<p><strong>第3步：用$\alpha,\beta,a,b$表示</strong></p>
<p>根据书中第193~194页状态转移概率矩阵公式(10.2)和观测概率矩阵公式(10.4)的定义：<br>$$<br>a_{ij} = P(i_{t+1}=q_j | i_t = q_i), \quad i=1,2,\cdots,N; \quad j = 1,2,\cdots, N \<br>b_j(k) = P(o_t = v_k | i_t = q_j), \quad k=1,2, \cdots, M; \quad j=1,2,\cdots,N<br>$$</p>
<p>则<br>$$<br>\begin{aligned}<br>P(O|\lambda)<br>&amp;= \sum_{i=1}^N \sum_{j=1}^N [P(o_1,..,o_t,i_t=q_i|\lambda) P(o_{t+1}|i_{t+1}=q_j,\lambda) P(i_{t+1}=q_j|i_t=q_i,\lambda) \<br>&amp; \quad \quad \quad \quad P(o_{t+2},..,o_T|i_{t+1}=q_j,\lambda)] \<br>&amp;= \sum_{i=1}^N \sum_{j=1}^N \alpha_t(i) a_{ij} b_j(o_{t+1}) \beta_{t+1}(j), \quad t=1,2,…,T-1 \<br>\end{aligned}<br>$$<br>命题得证。</p>
<h3 id="习题10-5"><a href="#习题10-5" class="headerlink" title="习题10.5"></a>习题10.5</h3><p>  比较维特比算法中变量$\delta$的计算和前向算法中变量$\alpha$的计算的主要区别。</p>
<p><strong>解答：</strong> </p>
<p><strong>解答思路：</strong></p>
<ol>
<li>列出维特比算法中变量$\delta$的计算；</li>
<li>列出前向算法中变量$\alpha$的计算；</li>
<li>比较两个变量计算的主要区别。</li>
</ol>
<p><strong>解答步骤：</strong></p>
<p><strong>第1步：维特比算法中变量$\delta$的计算</strong></p>
<p>  根据书中第209页维特比算法：</p>
<blockquote>
<p>（1）初始化</p>
</blockquote>
<p>$$<br>\delta_1(i)=\pi_ib_i(o_1),i=1,2,\cdots,N<br>$$</p>
<blockquote>
<p>（2）递推，对$t=2,3,\cdots,T$</p>
</blockquote>
<p>$$<br>\delta_t(i)=\max_{1 \leqslant j \leqslant N} [\delta_{t-1}(j)a_{ji}]b_i(o_t), i=1,2,\cdots,N<br>$$</p>
<p><strong>第2步：前向算法中变量$\alpha$的计算</strong></p>
<p>  根据书中第198页观测序列概率的前向算法：</p>
<blockquote>
<p>（1）初值</p>
</blockquote>
<p>$$<br>\alpha_1(i)=\pi_ib_i(o_i),i=1,2,\cdots,N<br>$$</p>
<blockquote>
<p>（2）递推，对$t=1,2,\cdots,T-1$：</p>
</blockquote>
<p>$$<br>\alpha_{t+1}(i)=\left[\sum_{j=1}^N \alpha_t(j) a_{ji} \right]b_i(o_{t+1})，i=1,2,\cdots,N<br>$$</p>
<p><strong>第3步：比较两个变量计算的主要区别</strong></p>
<p>通过比较两个变量的计算，主要区别包括计算目标不同和关注对象不同两个方面：</p>
<ol>
<li><p>计算目标不同</p>
<ul>
<li>前向算法：计算长度为$t$的观测序列概率，以某一时刻某一状态为最终状态的概率；</li>
<li>维特比算法：计算长度为$t$的观测序列概率，选择当前观测序列的最大可能概率；</li>
</ul>
</li>
<li><p>关注对象不同</p>
<ul>
<li>前向算法：包含到$t-1$时刻所有可能的观测序列概率和，其中不变的是观测序列上的最终状态；</li>
<li>维特比算法：包含出现观测序列中所有$t$个时刻相应观测的最大概率，其中不变的是整条观测序列。</li>
</ul>
</li>
</ol>
<h1 id="十一、条件随机场"><a href="#十一、条件随机场" class="headerlink" title="十一、条件随机场"></a>十一、条件随机场</h1><p>条件随机场（conditional random field,CRF）是给定一组输入随机变量条件下另一组输出随机变量的条件概率分布模型，其特点是假设输出随机变量构成马尔可夫随机场，条件随机场可以用于不同的预测问题。因此主要讲述线性链( linear chain)条件随机场，这时，问题变成了由输入序列对输出序列预测的判别模型，形式为对数线性模型，其学习方法通常是极大似然估计或正则化的极大似然估计，线性链条件随机场应用于标注问题是由Lafferty等人于2001年提出的。</p>
<h2 id="11-1-概率无向图模型"><a href="#11-1-概率无向图模型" class="headerlink" title="11.1 概率无向图模型"></a>11.1 概率无向图模型</h2><h3 id="11-1-1-模型定义"><a href="#11-1-1-模型定义" class="headerlink" title="11.1.1 模型定义"></a>11.1.1 模型定义</h3><p><img src="/images/loading.gif" data-original="../images/ML/image-20220112105742016.png" alt="局部马尔可夫性"></p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20220112105757514.png" alt="全局马尔可夫性"></p>
<p><strong>定义11.1（概率无向图模型）</strong>设有联合概率分布$P(Y)$,由无向图$G=(V,E)$表示，在图G中，结点表示随机变量，边表示随机变量之间的依赖关系。如果联合概率分布$P(Y)$满足成对、局部或全局马尔可夫性，就称此联合概率分布为概率无向图模型（probability undirected graphical model）,或马尔可夫随机场（Markovr random field）</p>
<h3 id="11-1-2-概率无向图模型的因子分解"><a href="#11-1-2-概率无向图模型的因子分解" class="headerlink" title="11.1.2 概率无向图模型的因子分解"></a>11.1.2 概率无向图模型的因子分解</h3><p><strong>定义11.2（团与最大团）</strong>无向图G中任何两个结点均有边连接的结点子集称为团（clique）.若C是无向图G的一个团，并且不能再加进任何一个G的结点使其成为一个更大的团，则称此C为最大团（maximal clique）.</p>
<p><strong>定理11.1（Hammersley- Clifford定理）</strong></p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20220112110333066.png" alt=""></p>
<h2 id="11-2-条件随机场的定义与形式"><a href="#11-2-条件随机场的定义与形式" class="headerlink" title="11.2 条件随机场的定义与形式"></a>11.2 条件随机场的定义与形式</h2><h3 id="11-2-1-条件随机场的定义"><a href="#11-2-1-条件随机场的定义" class="headerlink" title="11.2.1 条件随机场的定义"></a>11.2.1 条件随机场的定义</h3><p><strong>定义11.3（条件随机场）</strong></p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20220112110437433.png" alt=""></p>
<p><strong>定义11.4（线性链条件随机场）</strong></p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20220112110509634.png" alt=""></p>
<h3 id="11-2-2-条件随机场的参数化形式"><a href="#11-2-2-条件随机场的参数化形式" class="headerlink" title="11.2.2 条件随机场的参数化形式"></a>11.2.2 条件随机场的参数化形式</h3><p><strong>定理11.2（线性链条件随机场的参数化形式）</strong></p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20220112110600831.png" alt=""></p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20220112110611374.png" alt=""></p>
<h3 id="11-2-3-条件随机场的简化形式"><a href="#11-2-3-条件随机场的简化形式" class="headerlink" title="11.2.3 条件随机场的简化形式"></a>11.2.3 条件随机场的简化形式</h3><p>条件随机场可以写成向量w与$F(y,x)$的内积的形式：<br>$$<br>\begin{aligned}<br>P_{w}(y \mid x)=\frac{\exp (w \cdot F(y, x))}{Z_{w}(x)}<br>\end{aligned}<br>$$<br>其中，<br>$$<br>Z_{w}(x)=\sum_{y} \exp (w \cdot F(y, x))<br>$$</p>
<h3 id="11-2-4-条件随机场的矩阵形式"><a href="#11-2-4-条件随机场的矩阵形式" class="headerlink" title="11.2.4 条件随机场的矩阵形式"></a>11.2.4 条件随机场的矩阵形式</h3><h2 id="11-3-条件随机场的概率计算问题"><a href="#11-3-条件随机场的概率计算问题" class="headerlink" title="11.3 条件随机场的概率计算问题"></a>11.3 条件随机场的概率计算问题</h2><h3 id="11-3-1-前向-一后向算法"><a href="#11-3-1-前向-一后向算法" class="headerlink" title="11.3.1 前向-一后向算法"></a>11.3.1 前向-一后向算法</h3><p><img src="/images/loading.gif" data-original="../images/ML/image-20220112111111329.png" alt=""></p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20220112111234791.png" alt=""></p>
<h3 id="11-3-2-概率计算"><a href="#11-3-2-概率计算" class="headerlink" title="11.3.2 概率计算"></a>11.3.2 概率计算</h3><p><img src="/images/loading.gif" data-original="../images/ML/image-20220112111303480.png" alt=""></p>
<h3 id="11-3-3-期望值的计算"><a href="#11-3-3-期望值的计算" class="headerlink" title="11.3.3 期望值的计算"></a>11.3.3 期望值的计算</h3><p><img src="/images/loading.gif" data-original="../images/ML/image-20220112111339905.png" alt=""></p>
<h2 id="11-4-条件随机场的学习算法"><a href="#11-4-条件随机场的学习算法" class="headerlink" title="11.4 条件随机场的学习算法"></a>11.4 条件随机场的学习算法</h2><h3 id="11-4-1-改进的迭代尺度法"><a href="#11-4-1-改进的迭代尺度法" class="headerlink" title="11.4.1 改进的迭代尺度法"></a>11.4.1 改进的迭代尺度法</h3><p><strong>算法11.1（条件随机场模型学习的改进的迭代尺度法）</strong></p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20220112111444521.png" alt=""></p>
<h3 id="11-4-2-拟牛顿法"><a href="#11-4-2-拟牛顿法" class="headerlink" title="11.4.2 拟牛顿法"></a>11.4.2 拟牛顿法</h3><p><strong>算法11.2 (条件随机场模型学习的BFGS算法)</strong></p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20220112111547275.png" alt=""></p>
<h2 id="11-5-条件随机场的预测算法"><a href="#11-5-条件随机场的预测算法" class="headerlink" title="11.5 条件随机场的预测算法"></a>11.5 条件随机场的预测算法</h2><p><strong>算法11.3（条件随机场预测的维特比算法）</strong></p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20220112111700167.png" alt=""></p>
<p>一些解释：</p>
<ul>
<li><p><a href="https://zhuanlan.zhihu.com/p/148813079" target="_blank" rel="noopener">CRF条件随机场的原理、例子、公式推导和应用</a></p>
</li>
<li><p><a href="https://www.cnblogs.com/Determined22/p/6915730.html" target="_blank" rel="noopener">NLP —— 图模型（二）条件随机场（Conditional random field，CRF）</a></p>
</li>
</ul>
<h2 id="习题-10"><a href="#习题-10" class="headerlink" title="习题"></a>习题</h2><h3 id="习题11-1"><a href="#习题11-1" class="headerlink" title="习题11.1"></a>习题11.1</h3><p>  写出图11.3中无向图描述的概率图模型的因子分解式。</p>
<p><img src="/images/loading.gif" data-original="../images/ML/11-1-Maximal-Clique-16417076137924.png" alt=""></p>
<p><strong>解答：</strong></p>
<p><strong>解答思路：</strong></p>
<ol>
<li>给出无向图中团与最大团的定义；</li>
<li>给出概率无向图模型的因子分解的定义；</li>
<li>计算概率无向图模型的因子分解式。</li>
</ol>
<p><strong>解答步骤：</strong></p>
<p><strong>第1步：无向图中团与最大团的定义</strong></p>
<p>  根据书中第217页团与最大团的定义：</p>
<blockquote>
<p>  无向图$G$中任意两个结点均有边连接的结点子集称为团（clique），若$C$是无向图$G$的一个团，并且不能再加进任何一个$G$的结点使其成为一个更大的团，则称此$C$为最大团（maximal clique）。</p>
</blockquote>
<p><strong>第2步：概率无向图模型的因子分解的定义</strong></p>
<p>  根据书中第218页概率无向图模型的因子分解定义：</p>
<blockquote>
<p>  将概率无向图模型的联合概率分布表示为其最大团上的随机变量的函数的乘积形式的操作，称为概率无向图模型的因子分解（factorization）。 </p>
</blockquote>
<p>  根据书中第218页概率无向图模型的联合概率分布：</p>
<blockquote>
<p>  给定概率无向图模型，设其无向图为$G$，$C$为$G$上的最大团，$Y_C$表示$C$对应的随机变量。那么概率无向图模型的联合概率分布$P(Y)$可写作图中所有最大团$C$上的函数$\Psi_C(Y_C)$的乘积形式，即</p>
</blockquote>
<p>$$<br>P(Y) = \frac{1}{Z} \prod_C \Psi_C(Y_C)<br>$$</p>
<blockquote>
<p>其中，$Z$是规范化因子（normaliztion factor），由式</p>
</blockquote>
<p>$$<br>Z = \sum_Y \prod_C \Psi_C(Y_C)<br>$$</p>
<blockquote>
<p>给出。</p>
</blockquote>
<p><strong>第3步：计算概率无向图模型的因子分解式</strong></p>
<p>由图11.3可知，该图是由4个结点组成的无向图，结点分别为$Y_1, Y_2, Y_3, Y_4$，根据第1步的团和最大团定义，可得：  </p>
<ol>
<li>图中由2个结点组成的团有5个：${Y_1,Y_2},{Y_2,Y_3},{Y_3,Y_4},{Y_4,Y_2}$和${Y_1,Y_3}$    </li>
<li>图中包括2个最大团：${Y_1,Y_2,Y_3}$和${Y_2,Y_3,Y_4}$  </li>
<li>由于$Y_1$和$Y_4$没有边连接，所以${Y_1,Y_2,Y_3,Y_4}$不是一个团。  </li>
</ol>
<p>根据第2步中概率图模型的因子分解定义和联合概率分布的计算公式，可得因子分解：<br>$$<br>P(Y)=\frac{\Psi_{(1,2,3)}(Y_{(1,2,3)})\cdot\Psi_{(2,3,4)}(Y_{(2,3,4)})}<br>{\displaystyle \sum_Y \left[ \Psi_{(1,2,3)}(Y_{(1,2,3)})\cdot\Psi_{(2,3,4)}(Y_{(2,3,4)})\right]}<br>$$</p>
<h3 id="习题11-2"><a href="#习题11-2" class="headerlink" title="习题11.2"></a>习题11.2</h3><p>  证明$Z(x)=a_n^T(x) \cdot \boldsymbol{1} = \boldsymbol{1}^T \cdot \beta_0(x)$，其中$\boldsymbol{1}$是元素均为1的$m$维列向量。</p>
<p><strong>解答：</strong></p>
<p><strong>解答思路：</strong></p>
<ol>
<li>给出$Z(x)$的定义公式；</li>
<li>根据书中第225页前向-后向算法，推导$\alpha_n^T(x)$和$\beta_0(x)$；</li>
<li>证明$Z(x) = \alpha_n^T(x) \cdot \boldsymbol{1}$</li>
<li>证明$Z(x) = \boldsymbol{1}^T\cdot\beta_0(x)$</li>
</ol>
<p><strong>解答步骤：</strong></p>
<p><strong>第1步：给出$Z(x)$的定义式</strong></p>
<p>  根据书中第223页条件随机场的矩阵形式：</p>
<blockquote>
<p>  假设$P_w(y|x)$是由式(11.15)~式(11.16)给出的线性链条件随机场，表示对给定观测序列$x$，相应的标记序列$y$的条件概率。对每个标记序列引进特殊的起点和终点状态标记$y_0 = \text{start}$和$y_{n+1} = \text{stop}$，这时标注序列的概率$P_w(y|x)$可以通过矩阵形式表示并有效计算。<br>  对观测序列$x$的每一个位置$i=1,2,\cdots, n+1$，由于$y_{i-1}$和$y_i$在$m$个标记中取值，可以定义一个$m$阶矩阵随机变量</p>
</blockquote>
<p>$$<br>M_i(x) = [M_i(y_{i-1}, y_i | x)]<br>$$</p>
<blockquote>
<p>条件概率$P_w(y|x)$是</p>
</blockquote>
<p>$$<br>P_w(y|x) = \frac{1}{Z_w(x)} \prod_{i=1}^{n+1} M_i(y_{i-1}, y_i | x)<br>$$</p>
<blockquote>
<p>其中，$Z_w(x)$为规范化因子，是$n+1$个矩阵的乘积的(start, stop)元素，即</p>
</blockquote>
<p>$$<br>Z_w(x) = \left[M_1(x)M_2(x)\cdots M_{n+1}(x)\right]_{\text{start}, \text{stop} }<br>$$</p>
<blockquote>
<p>注意，$y_0 = \text{start}$与$y_{n+1} = \text{stop}$表示开始状态与终止状态，规范化因子$Z_w(x)$是以start为起点stop为终点，通过状态的所有路径$y_1 y_2 \cdots y_n$的非规范化概率$\displaystyle \prod_{i=1}^{n+1} M_i(y_{i-1}, y_i | x)$之和。</p>
</blockquote>
<p><strong>第2步：给出$\alpha_n^T(x)$和$\beta_1(x)$的定义式</strong></p>
<p>  根据书中第225页前向-后向算法：</p>
<blockquote>
<p>  对每个指标$i=0,1,\cdots, n+1$，定义前向向量$\alpha_i(x)$：</p>
</blockquote>
<p>$$<br> \alpha_0(y|x)=\left { \begin{array}{ll}<br>1, &amp; y=\text{start} \<br>0, &amp; 否则<br>\end{array} \right.<br>$$</p>
<blockquote>
<p>递推公式为：</p>
</blockquote>
<p>$$<br>\alpha_i^T (y_i|x) = \alpha_{i-1}^T (y_{i-1}|x) M_i(y_{i-1},y_i|x), \quad i=1, 2, \cdots, n+1<br>$$</p>
<blockquote>
<p>又可表示为</p>
</blockquote>
<p>$$<br>\alpha_i^T (x) = \alpha_{i-1}^T(x) M_i(x)<br>$$</p>
<blockquote>
<p>$\alpha_i(y_i|x)$表示在位置$i$的标记是$y_i$，并且从1到$i$的前部分标记序列的非规范化概率，$y_i$可取的值有$m$个，所以$\alpha_i(x)$是$m$维列向量。</p>
</blockquote>
<p>  根据书中第225页前向-后向算法：</p>
<blockquote>
<p>  对每个指标$i=0,1,\cdots, n+1$，定义后向向量$\beta_i(x)$：</p>
</blockquote>
<p>$$<br> \beta_{n+1}(y_{n+1}|x) = \left {<br>\begin{array}{ll}<br>1, &amp; y_{n+1}=\text{stop} \<br>0, &amp; 否则<br>\end{array} \right.<br>$$</p>
<blockquote>
</blockquote>
<p>$$<br>\beta_i(y_i|x) = [M_{i+1}(y_i, y_{i+1} | x)] \beta_{i+1}(y_{i+1} | x)<br>$$</p>
<blockquote>
<p>又可表示为</p>
</blockquote>
<p>$$<br>\beta_i(x) = M_{i+1}(x) \beta_{i+1}(x)<br>$$</p>
<blockquote>
<p>$\beta_i(y_i | x)$表示在位置$i$的标记为$y_i$，并且从$i+1$到$n$的后部分标记序列的非规范化概率。</p>
</blockquote>
<p>  根据参考文献 <a href="http://portal.acm.org/ft_gateway.cfm?id=1073473&amp;type=pdf&amp;CFID=4684435&amp;CFTOKEN=39459323" target="_blank" rel="noopener">Shallow Parsing with Conditional Random Fields</a> 中的第2章Conditional Random Fields：<br>$$<br> \alpha_i = \left {<br>\begin{array}{ll}<br>\alpha_{i-1} M_i, &amp; 0 &lt; i \leqslant n \<br>\boldsymbol{1}, &amp; i = 0<br>\end{array}<br>\right.<br>$$</p>
<blockquote>
</blockquote>
<p>$$<br> \beta_i^T = \left {<br>\begin{array}{ll}<br>M_{i+1} \beta_{i+1}^T, &amp; 1 \leqslant i  &lt;  n \<br>\boldsymbol{1}, &amp; i = n<br>\end{array}<br>\right.<br>$$</p>
<p>  由上述可得：</p>
<ol>
<li>当观测序列$x$有n个结点时，有</li>
</ol>
<p>$$<br>\alpha_{n}^T(x) = \alpha_0^T(x) M_1(x)\cdots M_{n}(x)<br>$$</p>
<p>其中$y_0=\text{start}$和$y_{n}=\text{stop}$分别表示开始状态和终止状态，且$Z(x)=[M_1(x) M_2(x) \cdots M_n(x)]_{\text{start, stop} }$</p>
<ol start="2">
<li>当观测序列$x$有n-1个结点时，有</li>
</ol>
<p>$$<br>\beta_1(x) = M_2(x)\cdots M_{n}(x)\beta_{n}(x)<br>$$</p>
<p>其中$y_1=\text{start}$和$y_{n}=\text{stop}$分别表示开始状态和终止状态，且$Z(x)=[M_2(x) \cdots M_n(x)]_{\text{start, stop} }$</p>
<p><strong>第3步：证明$Z(x) = \alpha_{n}^T(x) \cdot \boldsymbol{1}$</strong></p>
<p>$ \because \alpha_0(y|x)=\left { \begin{array}{ll}<br>1, &amp; y_0 = \text{start} \<br>0, &amp; 否则<br>\end{array} \right.$  </p>
<p>$ \begin{aligned}<br>\therefore \alpha_n^T(x) \cdot \boldsymbol{1}<br>&amp;= \alpha_0^T(x) M_1(x)\cdots M_{n}(x) \cdot \boldsymbol{1} \<br>&amp;= \boldsymbol{1}^T \cdot M_1(x)\cdots M_{n}(x) \cdot \boldsymbol{1} \<br>&amp;= Z(x)<br>\end{aligned}$</p>
<p><strong>第4步：证明$Z(x)=\boldsymbol{1}^T \cdot \beta_1(x)$</strong></p>
<p>$\because \beta_{n}(y_{n}|x) = \left {<br>\begin{array}{ll}<br>1, &amp; y_{n}=\text{stop} \<br>0, &amp; 否则<br>\end{array} \right.$</p>
<p>$\begin{aligned}<br>\therefore \boldsymbol{1}^T \cdot \beta_1(x)<br>&amp;= \boldsymbol{1}^T \cdot M_2(x) \cdots M_{n}(x) \beta_{n}(x) \<br>&amp;= \boldsymbol{1}^T \cdot M_2(x) \cdots M_{n}(x) \cdot \boldsymbol{1} \<br>&amp;= Z(x)<br>\end{aligned}$</p>
<p>综上所述：$Z(x)=a_{n}^T(x) \cdot \boldsymbol{1} = \boldsymbol{1}^T \cdot \beta_1(x)$，命题得证。  </p>
<h3 id="习题11-3"><a href="#习题11-3" class="headerlink" title="习题11.3"></a>习题11.3</h3><p>  写出条件随机场模型学习的梯度下降法。</p>
<p><strong>解答：</strong></p>
<p><strong>解答思路：</strong></p>
<ol>
<li>给出条件随机场模型的对数似然函数；</li>
<li>写出条件随机场模型学习的梯度下降法。</li>
</ol>
<p><strong>解答步骤：</strong></p>
<p><strong>第1步：条件随机场模型的对数似然函数</strong></p>
<p>  根据书中第220页线性链条件随机场的参数化形式：</p>
<blockquote>
<p>设$P(Y|X)$为线性链条件随机场，则在随机变量$X$取值为$x$的条件下，随机变量$Y$取值为$y$的条件概率具有如下形式：</p>
</blockquote>
<p>$$<br>P(y|x) = \frac{1}{Z(x)} \exp \left( \sum_{i,k} \lambda_k t_k (y_{i-1}, y_i, x, i) + \sum_{i,l} \mu_l s_l (y_i, x, i) \right)<br>$$</p>
<blockquote>
<p>其中，</p>
</blockquote>
<p>$$<br>Z(x) = \sum_y \exp \left( \sum_{i,k} \lambda_k t_k (y_{i-1}, y_i, x, i) + \sum_{i,l} \mu_l s_l (y_i, x, i)  \right)<br>$$</p>
<blockquote>
<p>式中，$t_k$和$s_l$是特征函数，$\lambda_k$和$\mu_l$是对应的权值。$Z(x)$是规范化因子，求和是在所有可能的输出序列上进行的。</p>
</blockquote>
<p>  根据书中第221页~第222页条件随机场的简化形式：</p>
<blockquote>
<p>设有$K_1$个转移特征，$K_2$个状态特征，$K=K_1 + K_2$，记</p>
</blockquote>
<p>$$<br> f_k(y_{i-1}, y_i, x, i) = \left { \begin{array}{ll}<br>t_k(y_{i-1}, y_i, x, i), &amp; k=1,2,\cdots,K_1 \<br>s_l(y_i, x, i), &amp; k=K_1 + l; \quad l = 1,2,\cdots,K_2<br>\end{array} \right.<br>$$</p>
<blockquote>
<p>然后，对转移特征与状态特征在各个位置$i$求和，记作</p>
</blockquote>
<p>$$<br>f_k(y,x) = \sum_{i=1}^n f_k(y_{i-1}, y_i, x, i), \quad k=1,2, \cdots, K<br>$$</p>
<blockquote>
<p>用$w_k$表示特征$f_k(y,x)$的权值，即</p>
</blockquote>
<p>$$<br> w_k = \left { \begin{array}{ll}<br>\lambda_k, &amp;  k=1,2,\cdots, K_1 \<br>\mu_l, &amp;  k=K_1 + l; \quad l = 1,2,\cdots,K_2<br>\end{array}\right.<br>$$</p>
<blockquote>
<p>于是，条件随机场可表示为</p>
</blockquote>
<p>$$<br>P(y|x) = \frac{1}{Z(x)} \exp \sum_{k=1}^K w_k f_k(y,x) \<br>Z(x) = \sum_y \exp \sum_{k=1}^K w_k f_k(y,x)<br>$$</p>
<p>  根据书中第227页条件随机场模型的对数似然函数：</p>
<blockquote>
<p>当$P_w$是一个由式(11.15)和(11.16)给出的条件随机场模型时，对数似然函数为</p>
</blockquote>
<p>$$<br>L(w)=\sum^N_{j=1} \sum^K_{k=1} w_k f_k(y_j,x_j)-\sum^N_{j=1} \log{Z_w(x_j)}<br>$$</p>
<p>  将对数似然函数求偏导，可得<br>$$<br>\begin{aligned}<br>g(w^{(n)}) = \frac{\partial L(w)}{\partial w^{(n)} }<br>&amp;= \sum^N_{j=1} f_n(y_j,x_j) - \sum^N_{j=1} \frac{1}{Z_w(x_j)} \cdot \frac{\partial{Z_w(x_j)} }{\partial{w_n} }\<br>&amp;= \sum^N_{j=1} f_n(y_j,x_j) - \sum^N_{i=1} \frac{1}{Z_w(x_i)} \cdot \sum^N_{j=1} \left[ \left( \exp{\sum^K_{k=1} w_k f_k (y_j,x_i)} \right) \cdot f_n(y_j, x_i) \right]<br>\end{aligned}<br>$$<br>  梯度函数为<br>$$<br>\nabla L(w)=\left[\frac{\partial L(w)}{\partial w^{(0)} }, \cdots, \frac{\partial L(w)}{\partial w^{(N)} }\right]<br>$$<br><strong>第2步：写出条件随机场模型学习的梯度下降法</strong></p>
<p>  根据书中第439页附录A 梯度下降法的算法：</p>
<blockquote>
<p>输入：目标函数$f(x)$，梯度函数$g(x)= \nabla f(x)$，计算精度$\varepsilon$；<br>输出：$f(x)$的极小值$x^<em>$。<br>(1) 取初始值$x^{(0)} \in R^n$，置$k=0$<br>(2) 计算$f(x^{(k)})$<br>(3) 计算梯度$g_k=g(x^{(k)})$，当$|g_k| &lt; \varepsilon$时，停止迭代，令$x^</em> = x^{(k)}$；否则，令$p_k=-g(x^{(k)})$，求$\lambda_k$，使</p>
</blockquote>
<p>$$<br>\displaystyle f(x^{(k)}+\lambda_k p_k) = \min \limits_{\lambda \geqslant 0}f(x^{(k)}+\lambda p_k)<br>$$</p>
<blockquote>
<p>(4) 置$x^{(k+1)}=x^{(k)}+\lambda_k p_k$，计算$f(x^{(k+1)})$<br>当$|f(x^{(k+1)}) - f(x^{(k)})| &lt; \varepsilon$或 $|x^{(k+1)} - x^{(k)}| &lt; \varepsilon$时，停止迭代，令$x^* = x^{(k+1)}$<br>(5) 否则，置$k=k+1$，转(3)</p>
</blockquote>
<p>条件随机场模型学习的梯度下降法：  </p>
<p>输入：目标函数$f(w)$，梯度函数$g(w) = \nabla f(w)$，计算精度$\varepsilon$<br>输出：$f(w)$的极大值$w^<em>$<br>(1) 取初始值$w^{(0)} \in R^n$，置$k=0$<br>(2) 计算$f(w^{(n)})$<br>(3) 计算梯度$g_n=g(w^{(n)})$，当$|g_n| &lt; \varepsilon$时，停止迭代，令$w^</em> = w^{(n)}$；否则，令$p_n=-g(w^{(n)})$，求$\lambda_n$，使<br>$$<br>\displaystyle f(w^{(n)}+\lambda_n p_n) = \max_{\lambda \geqslant 0}f(w^{(n)}+\lambda p_n)<br>$$<br>(4) 置$w^{(n+1)}=w^{(n)}+\lambda_n p_n$，计算$f(w^{(n+1)})$<br>当$|f(w^{(n+1)}) - f(w^{(n)})| &lt; \varepsilon$或 $|w^{(n+1)} - w^{(n)}| &lt; \varepsilon$时，停止迭代，令$w^* = w^{(n+1)}$<br>(5) 否则，置$n=n+1$，转(3)</p>
<h3 id="习题11-4"><a href="#习题11-4" class="headerlink" title="习题11.4"></a>习题11.4</h3><p>参考图11.6的状态路径图，假设随机矩阵$M_1(x),M_2(x),M_3(x),M_4(x)$分别是<br>$$<br>M_1(x)=\begin{bmatrix}0&amp;0 \ 0.5&amp;0.5 \end{bmatrix} ,<br>M_2(x)=\begin{bmatrix}0.3&amp;0.7 \ 0.7&amp;0.3\end{bmatrix} \<br>M_3(x)=\begin{bmatrix}0.5&amp;0.5 \ 0.6&amp;0.4\end{bmatrix},<br>M_4(x)=\begin{bmatrix}0&amp;1 \ 0&amp;1\end{bmatrix}<br>$$<br>求以$\text{start}=2$为起点$\text{stop}=2$为终点的所有路径的状态序列$y$的概率及概率最大的状态序列。</p>
<p><strong>解答：</strong></p>
<p><strong>解答思路：</strong>  </p>
<p>  根据书中第223页条件随机场的矩阵形式，以及例题11.2，通过自编程实现计算所有路径状态序列的概率及概率最大的状态序列。</p>
<p><strong>解答步骤：</strong></p>
<pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">import</span> numpy <span class="token keyword">as</span> np


<span class="token keyword">class</span> <span class="token class-name">CRFMatrix</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> M<span class="token punctuation">,</span> start<span class="token punctuation">,</span> stop<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment" spellcheck="true"># 随机矩阵</span>
        self<span class="token punctuation">.</span>M <span class="token operator">=</span> M
        <span class="token comment" spellcheck="true">#</span>
        self<span class="token punctuation">.</span>start <span class="token operator">=</span> start
        self<span class="token punctuation">.</span>stop <span class="token operator">=</span> stop
        self<span class="token punctuation">.</span>path_prob <span class="token operator">=</span> None

    <span class="token keyword">def</span> <span class="token function">_create_path</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token triple-quoted-string string">"""按照图11.6的状态路径图，生成路径"""</span>
        <span class="token comment" spellcheck="true"># 初始化start结点</span>
        path <span class="token operator">=</span> <span class="token punctuation">[</span>self<span class="token punctuation">.</span>start<span class="token punctuation">]</span>
        <span class="token keyword">for</span> i <span class="token keyword">in</span> range<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> len<span class="token punctuation">(</span>self<span class="token punctuation">.</span>M<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            paths <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
            <span class="token keyword">for</span> _<span class="token punctuation">,</span> r <span class="token keyword">in</span> enumerate<span class="token punctuation">(</span>path<span class="token punctuation">)</span><span class="token punctuation">:</span>
                temp <span class="token operator">=</span> np<span class="token punctuation">.</span>transpose<span class="token punctuation">(</span>r<span class="token punctuation">)</span>
                <span class="token comment" spellcheck="true"># 添加状态结点1</span>
                paths<span class="token punctuation">.</span>append<span class="token punctuation">(</span>np<span class="token punctuation">.</span>append<span class="token punctuation">(</span>temp<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
                <span class="token comment" spellcheck="true"># 添加状态结点2</span>
                paths<span class="token punctuation">.</span>append<span class="token punctuation">(</span>np<span class="token punctuation">.</span>append<span class="token punctuation">(</span>temp<span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
            path <span class="token operator">=</span> paths<span class="token punctuation">.</span>copy<span class="token punctuation">(</span><span class="token punctuation">)</span>

        <span class="token comment" spellcheck="true"># 添加stop结点</span>
        path <span class="token operator">=</span> <span class="token punctuation">[</span>np<span class="token punctuation">.</span>append<span class="token punctuation">(</span>r<span class="token punctuation">,</span> self<span class="token punctuation">.</span>stop<span class="token punctuation">)</span> <span class="token keyword">for</span> _<span class="token punctuation">,</span> r <span class="token keyword">in</span> enumerate<span class="token punctuation">(</span>path<span class="token punctuation">)</span><span class="token punctuation">]</span>
        <span class="token keyword">return</span> path

    <span class="token keyword">def</span> <span class="token function">fit</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        path <span class="token operator">=</span> self<span class="token punctuation">.</span>_create_path<span class="token punctuation">(</span><span class="token punctuation">)</span>
        pr <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
        <span class="token keyword">for</span> _<span class="token punctuation">,</span> row <span class="token keyword">in</span> enumerate<span class="token punctuation">(</span>path<span class="token punctuation">)</span><span class="token punctuation">:</span>
            p <span class="token operator">=</span> <span class="token number">1</span>
            <span class="token keyword">for</span> i <span class="token keyword">in</span> range<span class="token punctuation">(</span>len<span class="token punctuation">(</span>row<span class="token punctuation">)</span> <span class="token operator">-</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
                a <span class="token operator">=</span> row<span class="token punctuation">[</span>i<span class="token punctuation">]</span>
                b <span class="token operator">=</span> row<span class="token punctuation">[</span>i <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">]</span>
                <span class="token comment" spellcheck="true"># 根据公式11.24，计算条件概率</span>
                p <span class="token operator">*=</span> M<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">[</span>a <span class="token operator">-</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">[</span>b <span class="token operator">-</span> <span class="token number">1</span><span class="token punctuation">]</span>
            pr<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token punctuation">(</span>row<span class="token punctuation">.</span>tolist<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> p<span class="token punctuation">)</span><span class="token punctuation">)</span>
        <span class="token comment" spellcheck="true"># 按照概率从大到小排列</span>
        pr <span class="token operator">=</span> sorted<span class="token punctuation">(</span>pr<span class="token punctuation">,</span> key<span class="token operator">=</span><span class="token keyword">lambda</span> x<span class="token punctuation">:</span> x<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> reverse<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>path_prob <span class="token operator">=</span> pr

    <span class="token keyword">def</span> <span class="token function">print</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment" spellcheck="true"># 打印结果</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"以start=%s为起点stop=%s为终点的所有路径的状态序列y的概率为："</span> <span class="token operator">%</span> <span class="token punctuation">(</span>self<span class="token punctuation">.</span>start<span class="token punctuation">,</span> self<span class="token punctuation">.</span>stop<span class="token punctuation">)</span><span class="token punctuation">)</span>
        <span class="token keyword">for</span> path<span class="token punctuation">,</span> p <span class="token keyword">in</span> self<span class="token punctuation">.</span>path_prob<span class="token punctuation">:</span>
            <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"    路径为："</span> <span class="token operator">+</span> <span class="token string">"->"</span><span class="token punctuation">.</span>join<span class="token punctuation">(</span><span class="token punctuation">[</span>str<span class="token punctuation">(</span>x<span class="token punctuation">)</span> <span class="token keyword">for</span> x <span class="token keyword">in</span> path<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span> end<span class="token operator">=</span><span class="token string">" "</span><span class="token punctuation">)</span>
            <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"概率为："</span> <span class="token operator">+</span> str<span class="token punctuation">(</span>p<span class="token punctuation">)</span><span class="token punctuation">)</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"概率最大["</span> <span class="token operator">+</span> str<span class="token punctuation">(</span>self<span class="token punctuation">.</span>path_prob<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token string">"]的状态序列为:"</span><span class="token punctuation">,</span>
              <span class="token string">"->"</span><span class="token punctuation">.</span>join<span class="token punctuation">(</span><span class="token punctuation">[</span>str<span class="token punctuation">(</span>x<span class="token punctuation">)</span> <span class="token keyword">for</span> x <span class="token keyword">in</span> self<span class="token punctuation">.</span>path_prob<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<pre class="line-numbers language-python"><code class="language-python"><span class="token comment" spellcheck="true"># 创建随机矩阵</span>
M1 <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">0.5</span><span class="token punctuation">,</span> <span class="token number">0.5</span><span class="token punctuation">]</span><span class="token punctuation">]</span>
M2 <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">0.3</span><span class="token punctuation">,</span> <span class="token number">0.7</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">0.7</span><span class="token punctuation">,</span> <span class="token number">0.3</span><span class="token punctuation">]</span><span class="token punctuation">]</span>
M3 <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">0.5</span><span class="token punctuation">,</span> <span class="token number">0.5</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">0.6</span><span class="token punctuation">,</span> <span class="token number">0.4</span><span class="token punctuation">]</span><span class="token punctuation">]</span>
M4 <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">]</span>
M <span class="token operator">=</span> <span class="token punctuation">[</span>M1<span class="token punctuation">,</span> M2<span class="token punctuation">,</span> M3<span class="token punctuation">,</span> M4<span class="token punctuation">]</span>
<span class="token comment" spellcheck="true"># 构建条件随机场的矩阵模型</span>
crf <span class="token operator">=</span> CRFMatrix<span class="token punctuation">(</span>M<span class="token operator">=</span>M<span class="token punctuation">,</span> start<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span> stop<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span>
<span class="token comment" spellcheck="true"># 得到所有路径的状态序列的概率</span>
crf<span class="token punctuation">.</span>fit<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token comment" spellcheck="true"># 打印结果</span>
crf<span class="token punctuation">.</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<pre><code>以start=2为起点stop=2为终点的所有路径的状态序列y的概率为：
    路径为：2-&gt;1-&gt;2-&gt;1-&gt;2 概率为：0.21
    路径为：2-&gt;2-&gt;1-&gt;1-&gt;2 概率为：0.175
    路径为：2-&gt;2-&gt;1-&gt;2-&gt;2 概率为：0.175
    路径为：2-&gt;1-&gt;2-&gt;2-&gt;2 概率为：0.13999999999999999
    路径为：2-&gt;2-&gt;2-&gt;1-&gt;2 概率为：0.09
    路径为：2-&gt;1-&gt;1-&gt;1-&gt;2 概率为：0.075
    路径为：2-&gt;1-&gt;1-&gt;2-&gt;2 概率为：0.075
    路径为：2-&gt;2-&gt;2-&gt;2-&gt;2 概率为：0.06
概率最大[0.21]的状态序列为: 2-&gt;1-&gt;2-&gt;1-&gt;2</code></pre><h1 id="十二、统计学习方法总结"><a href="#十二、统计学习方法总结" class="headerlink" title="十二、统计学习方法总结"></a>十二、统计学习方法总结</h1><p>本书共介绍了10种主要的统计学习方法：感知机、k近邻法、朴素贝叶斯法、决策树、逻辑斯谛回归与最大熵模型、支持向量机、提升方法、EM算法、隐马尔可夫模型和条件随机场。</p>
<p><img src="/images/loading.gif" data-original="../images/ML/image-20220112112219494.png" alt=""></p>
<h1 id="附录"><a href="#附录" class="headerlink" title="附录"></a>附录</h1><h2 id="A-梯度下降法"><a href="#A-梯度下降法" class="headerlink" title="A 梯度下降法"></a>A 梯度下降法</h2><h2 id="B-牛顿法与拟牛顿法"><a href="#B-牛顿法与拟牛顿法" class="headerlink" title="B 牛顿法与拟牛顿法"></a>B 牛顿法与拟牛顿法</h2><h2 id="C-拉格朗日对偶性"><a href="#C-拉格朗日对偶性" class="headerlink" title="C 拉格朗日对偶性"></a>C 拉格朗日对偶性</h2><h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><ul>
<li>《统计学习方法》-李航</li>
<li><a href="https://github.com/datawhalechina/statistical-learning-method-solutions-manual" target="_blank" rel="noopener">《统计学习方法习题解答》</a></li>
</ul>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        文章作者:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://jackhcc.github.io" rel="external nofollow noreferrer">杰克成</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        文章链接:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://jackhcc.github.io/posts/Lesson-Statistical-Learning-Method.html">https://jackhcc.github.io/posts/Lesson-Statistical-Learning-Method.html</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        版权声明:
                    </i>
                </span>
                <span class="reprint-info">
                    本博客所有文章除特別声明外，均采用
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    许可协议。转载请注明来源
                    <a href="https://jackhcc.github.io" target="_blank">杰克成</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>复制成功，请遵循本文的转载规则</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">查看</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/tags/Lesson/">
                                    <span class="chip bg-color">Lesson</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/libs/share/css/share.min.css">

<div id="article-share">
    
    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>微信扫一扫即可分享！</p>"></div>
    <script src="https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
                <style>
    #reward {
        margin: 40px 0;
        text-align: center;
    }

    #reward .reward-link {
        font-size: 1.4rem;
        line-height: 38px;
    }

    #reward .btn-floating:hover {
        box-shadow: 0 6px 12px rgba(0, 0, 0, 0.2), 0 5px 15px rgba(0, 0, 0, 0.2);
    }

    #rewardModal {
        width: 320px;
        height: 350px;
    }

    #rewardModal .reward-title {
        margin: 15px auto;
        padding-bottom: 5px;
    }

    #rewardModal .modal-content {
        padding: 10px;
    }

    #rewardModal .close {
        position: absolute;
        right: 15px;
        top: 15px;
        color: rgba(0, 0, 0, 0.5);
        font-size: 1.3rem;
        line-height: 20px;
        cursor: pointer;
    }

    #rewardModal .close:hover {
        color: #ef5350;
        transform: scale(1.3);
        -moz-transform:scale(1.3);
        -webkit-transform:scale(1.3);
        -o-transform:scale(1.3);
    }

    #rewardModal .reward-tabs {
        margin: 0 auto;
        width: 210px;
    }

    .reward-tabs .tabs {
        height: 38px;
        margin: 10px auto;
        padding-left: 0;
    }

    .reward-content ul {
        padding-left: 0 !important;
    }

    .reward-tabs .tabs .tab {
        height: 38px;
        line-height: 38px;
    }

    .reward-tabs .tab a {
        color: #fff;
        background-color: #ccc;
    }

    .reward-tabs .tab a:hover {
        background-color: #ccc;
        color: #fff;
    }

    .reward-tabs .wechat-tab .active {
        color: #fff !important;
        background-color: #22AB38 !important;
    }

    .reward-tabs .alipay-tab .active {
        color: #fff !important;
        background-color: #019FE8 !important;
    }

    .reward-tabs .reward-img {
        width: 210px;
        height: 210px;
    }
</style>

<div id="reward">
    <a href="#rewardModal" class="reward-link modal-trigger btn-floating btn-medium waves-effect waves-light red">赏</a>

    <!-- Modal Structure -->
    <div id="rewardModal" class="modal">
        <div class="modal-content">
            <a class="close modal-close"><i class="fas fa-times"></i></a>
            <h4 class="reward-title">你的赏识是我前进的动力</h4>
            <div class="reward-content">
                <div class="reward-tabs">
                    <ul class="tabs row">
                        <li class="tab col s6 alipay-tab waves-effect waves-light"><a href="#alipay">支付宝</a></li>
                        <li class="tab col s6 wechat-tab waves-effect waves-light"><a href="#wechat">微 信</a></li>
                    </ul>
                    <div id="alipay">
                        <img src="/images/loading.gif" data-original="https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/medias/reward/aliqr.png" class="reward-img" alt="支付宝打赏二维码">
                    </div>
                    <div id="wechat">
                        <img src="/images/loading.gif" data-original="https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/medias/reward/wxqr.png" class="reward-img" alt="微信打赏二维码">
                    </div>
                </div>
            </div>
        </div>
    </div>
</div>

<script>
    $(function () {
        $('.tabs').tabs();
    });
</script>
            
        </div>
    </div>

    
        <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/libs/gitalk/gitalk.css">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/css/my-gitalk.css">

<div class="card gitalk-card" data-aos="fade-up">
    <div class="comment_headling" style="font-size: 20px; font-weight: 700; position: relative; left: 20px; top: 15px; padding-bottom: 5px;">
        <i class="fas fa-comments fa-fw" aria-hidden="true"></i>
        <span>评论</span>
    </div>
    <div id="gitalk-container" class="card-content"></div>
</div>

<script src="https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/libs/gitalk/gitalk.min.js"></script>
<script>
    let gitalk = new Gitalk({
        clientID: '3821a0bbb773038a51fc',
        clientSecret: '4b30b507d67ec5497ec0e77f43f80cb3e0d7dd3a',
        repo: 'JackHCC.github.io',
        owner: 'JackHCC',
        admin: "JackHCC",
        id: '2022-01-09T09-49-33',
        distractionFreeMode: false  // Facebook-like distraction free mode
    });

    gitalk.render('gitalk-container');
</script>
    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;上一篇</div>
            <div class="card">
                <a href="/posts/Code-Safe-Rules.html">
                    <div class="card-image">
                        
                        
                        <img src="/images/loading.gif" data-original="https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/medias/featureimages/3.jpg" class="responsive-img" alt="C/C++安全规则集合">
                        
                        <span class="card-title">C/C++安全规则集合</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            代码安全规范大全
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2022-01-21
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/categories/Basic/" class="post-category">
                                    Basic
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/tags/Basic/">
                        <span class="chip bg-color">Basic</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                下一篇&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/posts/Awesome-Sundary.html">
                    <div class="card-image">
                        
                        
                        <img src="/images/loading.gif" data-original="https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/medias/featureimages/6.jpg" class="responsive-img" alt="Awesome Sundary Share">
                        
                        <span class="card-title">Awesome Sundary Share</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            杂项优质文章汇总
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2022-01-01
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/categories/Awesome/" class="post-category">
                                    Awesome
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/tags/Sundary/">
                        <span class="chip bg-color">Sundary</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- 代码块功能依赖 -->
<script type="text/javascript" src="https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/libs/codeBlock/codeBlockFuction.js"></script>

<!-- 代码语言 -->

<script type="text/javascript" src="https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/libs/codeBlock/codeLang.js"></script>


<!-- 代码块复制 -->

<script type="text/javascript" src="https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/libs/codeBlock/codeCopy.js"></script>


<!-- 代码块收缩 -->

<script type="text/javascript" src="https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/libs/codeBlock/codeShrink.js"></script>


<!-- 代码块折行 -->

<style type="text/css">
code[class*="language-"], pre[class*="language-"] { white-space: pre !important; }
</style>


    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;目录</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC 悬浮按钮. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('4'),
            headingSelector: 'h1, h2, h3, h4'
        });

        // modify the toc link href to support Chinese.
        let i = 0;
        let tocHeading = 'toc-heading-';
        $('#toc-content a').each(function () {
            $(this).attr('href', '#' + tocHeading + (++i));
        });

        // modify the heading title id to support Chinese.
        i = 0;
        $('#articleContent').children('h1, h2, h3, h4').each(function () {
            $(this).attr('id', tocHeading + (++i));
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* 修复文章卡片 div 的宽度. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // 切换TOC目录展开收缩的相关操作.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>

    

</main>


<script src="https://cdn.bootcss.com/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
<script>
    MathJax.Hub.Config({
        tex2jax: {inlineMath: [['$', '$'], ['\(', '\)']]}
    });
</script>


    <footer class="page-footer bg-color">
    <div class="container row center-align" style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            <span id="year">2020</span>
            <a href="https://jackhcc.github.io" target="_blank">杰克成</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            <br>
            
            &nbsp;<i class="fas fa-chart-area"></i>&nbsp;站点总字数:&nbsp;<span
                class="white-color">3591.2k</span>&nbsp;字
            
            
            
            
            
            
            <span id="busuanzi_container_site_pv">
                |&nbsp;<i class="far fa-eye"></i>&nbsp;总访问量:&nbsp;<span id="busuanzi_value_site_pv"
                    class="white-color"></span>&nbsp;次
            </span>
            
            
            <span id="busuanzi_container_site_uv">
                |&nbsp;<i class="fas fa-users"></i>&nbsp;总访问人数:&nbsp;<span id="busuanzi_value_site_uv"
                    class="white-color"></span>&nbsp;人
            </span>
            
            <br>
            
            <span id="sitetime">载入运行时间...</span>
            <script>
                function siteTime() {
                    var seconds = 1000;
                    var minutes = seconds * 60;
                    var hours = minutes * 60;
                    var days = hours * 24;
                    var years = days * 365;
                    var today = new Date();
                    var startYear = "2020";
                    var startMonth = "2";
                    var startDate = "27";
                    var startHour = "6";
                    var startMinute = "30";
                    var startSecond = "0";
                    var todayYear = today.getFullYear();
                    var todayMonth = today.getMonth() + 1;
                    var todayDate = today.getDate();
                    var todayHour = today.getHours();
                    var todayMinute = today.getMinutes();
                    var todaySecond = today.getSeconds();
                    var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                    var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                    var diff = t2 - t1;
                    var diffYears = Math.floor(diff / years);
                    var diffDays = Math.floor((diff / days) - diffYears * 365);
                    var diffHours = Math.floor((diff - (diffYears * 365 + diffDays) * days) / hours);
                    var diffMinutes = Math.floor((diff - (diffYears * 365 + diffDays) * days - diffHours * hours) /
                        minutes);
                    var diffSeconds = Math.floor((diff - (diffYears * 365 + diffDays) * days - diffHours * hours -
                        diffMinutes * minutes) / seconds);
                    if (startYear == todayYear) {
                        document.getElementById("year").innerHTML = todayYear;
                        document.getElementById("sitetime").innerHTML = "本站已安全运行 " + diffDays + " 天 " + diffHours +
                            " 小时 " + diffMinutes + " 分钟 " + diffSeconds + " 秒";
                    } else {
                        document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                        document.getElementById("sitetime").innerHTML = "本站已安全运行 " + diffYears + " 年 " + diffDays +
                            " 天 " + diffHours + " 小时 " + diffMinutes + " 分钟 " + diffSeconds + " 秒";
                    }
                }
                setInterval(siteTime, 1000);
            </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/JackHCC" class="tooltipped" target="_blank" data-tooltip="访问我的GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:jackcc0701@163.com" class="tooltipped" target="_blank" data-tooltip="邮件联系我" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>



    <a href="https://www.facebook.com/profile.php?id=100046343443643" class="tooltipped" target="_blank" data-tooltip="关注我的Facebook: https://www.facebook.com/profile.php?id=100046343443643" data-position="top" data-delay="50">
        <i class="fab fa-facebook-f"></i>
    </a>



    <a href="https://twitter.com/JackChe66021834" class="tooltipped" target="_blank" data-tooltip="关注我的Twitter: https://twitter.com/JackChe66021834" data-position="top" data-delay="50">
        <i class="fab fa-twitter"></i>
    </a>



    <a href="tencent://AddContact/?fromId=50&fromSubId=1&subcmd=all&uin=2508074836" class="tooltipped" target="_blank" data-tooltip="QQ联系我: 2508074836" data-position="top" data-delay="50">
        <i class="fab fa-qq"></i>
    </a>



    <a href="https://weibo.com/u/6885584679" class="tooltipped" target="_blank" data-tooltip="关注我的微博: https://weibo.com/u/6885584679" data-position="top" data-delay="50">
        <i class="fab fa-weibo"></i>
    </a>



    <a href="https://www.zhihu.com/people/8f8482f01f0d6a04e844efe32e0f0710" class="tooltipped" target="_blank" data-tooltip="关注我的知乎: https://www.zhihu.com/people/8f8482f01f0d6a04e844efe32e0f0710" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">知</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- 搜索遮罩框 -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;搜索</span>
            <input type="search" id="searchInput" name="s" placeholder="请输入搜索的关键字"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script src="https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/js/search.js"></script>
<script type="text/javascript">
$(function () {
    searchFunc("https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/" + "search.xml", 'searchInput', 'searchResult');
});
</script>
    <!-- 回到顶部按钮 -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/libs/materialize/materialize.min.js"></script>
    <script src="https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/libs/aos/aos.js"></script>
    <script src="https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/js/matery.js"></script>

    <canvas class="fireworks" style="position: fixed;left: 0;top: 0;z-index: 1; pointer-events: none;" ></canvas>
    <script type="text/javascript" src="//cdn.bootcss.com/animejs/2.2.0/anime.min.js"></script>
    <script type="text/javascript" src="/js/fireworks.js"></script>

    <script type="text/javascript">
        //只在桌面版网页启用特效
        var windowWidth = $(window).width();
        if (windowWidth > 768) {
            document.write('<script type="text/javascript" src="/js/sakura.js"><\/script>'); }
    </script>

    <!-- weather -->
	<script type="text/javascript">
	WIDGET = {FID: 'TToslpmkVO'}
	</script>
	<script type="text/javascript" src="https://apip.weatherdt.com/float/static/js/r.js?v=1111"></script>


    <!-- Global site tag (gtag.js) - Google Analytics -->


    <!-- Baidu Analytics -->

<script>
    var _hmt = _hmt || [];
    (function () {
        var hm = document.createElement("script");
        hm.src = "https://hm.baidu.com/hm.js?";
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(hm, s);
    })();
</script>

    <!-- Baidu Push -->

    
    
    <script async src="https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/libs/others/busuanzi.pure.mini.js"></script>
    

    
        <script src="//code.tidio.co/kqhlkxviiccyoa0czpfpu4ijuey9hfre.js"></script>
        <script> 
            $(document).ready(function () {
                setInterval(change_Tidio, 50);  
                function change_Tidio() { 
                    var tidio=$("#tidio-chat iframe");
                    if(tidio.css("display")=="block"&& $(window).width()>977 ){
                        document.getElementById("tidio-chat-iframe").style.bottom= ($("div#backTop.top-scroll").css("display")=="none" &&$(window).width()>977)>0? "-40px" : ($("div.toc-title").length&&$(window).width()>977)>0?"85px":"20px";   
                        document.getElementById("tidio-chat-iframe").style.right="-15px";   
                        document.getElementById("tidio-chat-iframe").style.height=parseInt(tidio.css("height"))>=520?"520px":tidio.css("height");
                        document.getElementById("tidio-chat-iframe").style.zIndex="997";
                    } 
                    else if(tidio.css("display")=="block"&&$(window).width()>601 &&$(window).width()<992 ){
                        document.getElementById("tidio-chat-iframe").style.bottom= ($("div#backTop.top-scroll").css("display")=="none" && 601< $(window).width()<992)>0? "-40px":"20px" ;   
                        document.getElementById("tidio-chat-iframe").style.right="-15px"; 
                        document.getElementById("tidio-chat-iframe").style.zIndex="997";
                    }
                    else if(tidio.css("display")=="block"&&$(window).width()<601 && parseInt(tidio.css("height"))<230){
                        document.getElementById("tidio-chat-iframe").style.bottom= ($("div#backTop.top-scroll").css("display")=="none" && $(window).width()<601)>0? "-10px":"45px" ;   
                        document.getElementById("tidio-chat-iframe").style.zIndex="997";
                    }
                    if( tidio.css("display")=="block"&&$(window).width()<601 && parseInt(tidio.css("height"))>=230){
                        document.getElementById("tidio-chat-iframe").style.zIndex="998";
                    }
                } 
            }); 
        </script>
    

    

    
    <script type="text/javascript" color="0,0,255"
        pointColor="0,0,255" opacity='0.7'
        zIndex="-1" count="99"
        src="https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/libs/background/canvas-nest.js"></script>
    

    

    
    <script type="text/javascript" src="https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/libs/background/ribbon-dynamic.js" async="async"></script>
    
    
    
    <script src="https://cdn.jsdelivr.net/gh/JackHCC/JackHCC.github.io/libs/instantpage/instantpage.js" type="module"></script>
    

        <script src="//cdn.jsdelivr.net/npm/js-base64/base64.min.js"></script>
        <script>
        $('a').each(function() {
          const $this = $(this);
          const href = $this.attr('href');
          if (href && href.match('^((http|https|thunder|qqdl|ed2k|Flashget|qbrowser|ftp|rtsp|mms)://)')) {
            const strs = href.split('/');
            if (strs.length >= 3) {
                const host = strs[2];
                if (host !== 'your_domain' || window.location.host) {
                    $this.attr('href', '/go.html?u='+Base64.encode(href)+'').attr('rel', 'external nofollow noopener noreferrer');
                    if (true) {
                        $this.attr('target', '_blank');
                    }
                }
            }
          }
        });
        </script><script>!function(e){var c=Array.prototype.slice.call(document.querySelectorAll("img[data-original]"));function i(){for(var r=0;r<c.length;r++)t=c[r],0<=(n=t.getBoundingClientRect()).bottom&&0<=n.left&&n.top<=(e.innerHeight||document.documentElement.clientHeight)&&function(){var t,n,e,i,o=c[r];t=o,n=function(){c=c.filter(function(t){return o!==t})},e=new Image,i=t.getAttribute("data-original"),e.onload=function(){t.src=i,n&&n()},e.src=i}();var t,n}i(),e.addEventListener("scroll",function(){var t,n;t=i,n=e,clearTimeout(t.tId),t.tId=setTimeout(function(){t.call(n)},500)})}(this);</script><script>window.addEventListener("load",function(){var t=/\.(gif|jpg|jpeg|tiff|png)$/i,r=/^data:image\/[a-z]+;base64,/;Array.prototype.slice.call(document.querySelectorAll("img[data-original]")).forEach(function(a){var e=a.parentNode;"A"===e.tagName&&(e.href.match(t)||e.href.match(r))&&(e.href=a.dataset.original)})});</script></body>

</html>

